# Comparing `tmp/modelscope-1.7.1.tar.gz` & `tmp/modelscope-1.8.0rc0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/modelscope-1.7.1.tar", last modified: Tue Jul  4 16:22:43 2023, max compression
+gzip compressed data, was "dist/modelscope-1.8.0rc0.tar", last modified: Mon Jul 31 12:41:38 2023, max compression
```

## Comparing `modelscope-1.7.1.tar` & `modelscope-1.8.0rc0.tar`

### file list

```diff
@@ -1,2822 +1,2906 @@
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/
--rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-04 16:22:42.000000 modelscope-1.7.1/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (122)    19397 2023-07-04 16:22:43.000000 modelscope-1.7.1/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)    15977 2023-07-04 16:22:42.000000 modelscope-1.7.1/README.md
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/
--rw-r--r--   0 runner    (1001) docker     (122)     3655 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/cli/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      829 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/cli.py
--rw-r--r--   0 runner    (1001) docker     (122)     1230 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/download.py
--rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/modelcard.py
--rw-r--r--   0 runner    (1001) docker     (122)     4371 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/plugins.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/cli/template/
--rw-r--r--   0 runner    (1001) docker     (122)      523 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/template/readme.tpl
--rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/cli/template/template.tpl
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/configs/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/configs/examples/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/configs/examples/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/exporters/
--rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/exporters/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2272 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/audio/ans_dfsmn_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2667 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      732 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/exporters/cv/
--rw-r--r--   0 runner    (1001) docker     (122)      869 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2593 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/cv/cartoon_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3619 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/cv/face_detection_scrfd_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/cv/object_detection_damoyolo_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/exporters/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)      531 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/multi_modal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11238 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/multi_modal/stable_diffusion_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/exporters/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7341 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/nlp/csanmt_for_translation_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/nlp/model_for_token_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     3409 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     2316 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4809 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/tf_model_exporter.py
--rw-r--r--   0 runner    (1001) docker     (122)    15145 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/exporters/torch_model_exporter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/fileio/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/file.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/fileio/format/
--rw-r--r--   0 runner    (1001) docker     (122)      143 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/format/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      454 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/format/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1050 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/format/json.py
--rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/format/jsonplus.py
--rw-r--r--   0 runner    (1001) docker     (122)      669 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/format/yaml.py
--rw-r--r--   0 runner    (1001) docker     (122)     4254 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/fileio/io.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/hub/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    42783 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/api.py
--rw-r--r--   0 runner    (1001) docker     (122)     3649 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/check_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1628 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/constants.py
--rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/errors.py
--rw-r--r--   0 runner    (1001) docker     (122)    12706 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/file_download.py
--rw-r--r--   0 runner    (1001) docker     (122)     8958 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/git.py
--rw-r--r--   0 runner    (1001) docker     (122)     7272 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/push_to_hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    12489 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/repository.py
--rw-r--r--   0 runner    (1001) docker     (122)     7178 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/snapshot_download.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/hub/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9916 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/utils/caching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2978 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/hub/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    54722 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metainfo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)     3978 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/accuracy_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7530 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/action_detection_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     1925 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/audio_noise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1454 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1726 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/bleu_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/metrics/ciderD/
--rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ciderD/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ciderD/ciderD.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ciderD/ciderD_scorer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8664 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_color_enhance_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13387 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_colorization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    10011 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_denoise_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_inpainting_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)    13318 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_instance_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1739 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_portrait_enhancement_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2536 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_quality_assessment_degradation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1632 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/image_quality_assessment_mos_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2231 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/inbatch_recall_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/loss_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3002 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/map_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2032 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/movie_scene_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ned_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2310 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ocr_recognition_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     2082 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/ppl_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/prediction_saving_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/referring_video_object_segmentation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3112 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/sequence_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3694 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/text_generation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/text_ranking_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5765 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/token_classification_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5703 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/translation_evaluation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_frame_interpolation_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     8655 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_stabilization_metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     3092 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_summarization_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/matlab_functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/metric_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8932 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/niqe.py
--rw-r--r--   0 runner    (1001) docker     (122)     1710 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/
--rw-r--r--   0 runner    (1001) docker     (122)      519 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/aec/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1434 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2700 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)     5630 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1322 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)    14384 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/layers/uni_deep_fsmn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/aec/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14438 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/network/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     9382 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/network/modulation_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    15396 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/aec/network/se_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/ans/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/complex_nn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3688 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/conv_stft.py
--rw-r--r--   0 runner    (1001) docker     (122)     2513 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/denoise_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/frcrn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1468 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/activations.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/layer_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5284 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/layers/uni_deep_fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1038 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/se_module_complex.py
--rw-r--r--   0 runner    (1001) docker     (122)     9833 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/ans/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/asr/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/asr/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/asr/generic_automatic_speech_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/itn/
--rw-r--r--   0 runner    (1001) docker     (122)      557 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/itn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1462 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/itn/generic_inverse_text_processing.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/kws/
--rw-r--r--   0 runner    (1001) docker     (122)      735 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14349 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     7861 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py
--rw-r--r--   0 runner    (1001) docker     (122)     3521 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2608 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/farfield/model_def.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/generic_key_word_spotting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/kws/nearfield/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/nearfield/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/nearfield/cmvn.py
--rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/nearfield/fsmn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6079 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/kws/nearfield/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/punc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/punc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/punc/generic_punctuation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/separation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/separation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/separation/layer_norm.py
--rw-r--r--   0 runner    (1001) docker     (122)    13963 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/separation/mossformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9142 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/separation/mossformer_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     9004 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/separation/mossformer_conv_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/sv/
--rw-r--r--   0 runner    (1001) docker     (122)     7326 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/DTDNN.py
--rw-r--r--   0 runner    (1001) docker     (122)     8425 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/DTDNN_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11515 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/ERes2Net.py
--rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/ERes2Net_aug.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5612 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/cluster_backend.py
--rw-r--r--   0 runner    (1001) docker     (122)    14980 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/ecapa_tdnn.py
--rw-r--r--   0 runner    (1001) docker     (122)      904 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/generic_speaker_verification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3630 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/pooling_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    16895 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/rdino.py
--rw-r--r--   0 runner    (1001) docker     (122)    12338 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/sv/speaker_change_locator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/audio/tts/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/tts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11845 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/tts/sambert_hifi.py
--rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/audio/tts/voice.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/base/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/base/base_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6994 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/base/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/base/base_torch_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5679 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/base/base_torch_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1812 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3806 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      113 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
--rw-r--r--   0 runner    (1001) docker     (122)      145 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      493 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/action_detection_onnx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9364 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py
--rw-r--r--   0 runner    (1001) docker     (122)    12132 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_detection/modules/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      709 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/models.py
--rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/s3dg.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/tada_convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    45442 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/animal_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/animal_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/animal_recognition/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/animal_recognition/splat.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      496 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2589 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     8773 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/w48.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/
--rw-r--r--   0 runner    (1001) docker     (122)      601 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       51 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8957 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/
--rw-r--r--   0 runner    (1001) docker     (122)       98 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11552 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/block.py
--rw-r--r--   0 runner    (1001) docker     (122)     8080 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py
--rw-r--r--   0 runner    (1001) docker     (122)     2516 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7719 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/
--rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      713 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/facer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/model_tf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5265 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cartoon/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/c3d.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py
--rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      414 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/annotator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      504 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
--rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
--rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py
--rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/controlnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/crowd_counting/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/crowd_counting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1100 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/crowd_counting/cc_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22875 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/fair_face/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/fair_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      930 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/mogface.py
--rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/mogprednet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5415 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py
--rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py
--rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/facer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4832 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/
--rw-r--r--   0 runner    (1001) docker     (122)      174 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/damofd_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/
--rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)      325 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
--rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3423 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
--rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
--rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
--rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4202 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
--rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
--rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
--rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py
--rw-r--r--   0 runner    (1001) docker     (122)      960 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/
--rw-r--r--   0 runner    (1001) docker     (122)       90 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      571 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
--rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
--rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/
--rw-r--r--   0 runner    (1001) docker     (122)      327 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/emotion_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/emotion_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/face.py
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/face_align.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/op/
--rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/op/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/op/conv2d_gradfix.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/op/fused_act.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/op/upfirdn2d.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_generation/stylegan2.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4109 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/det_infer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/ghost_pan.py
--rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/align_face.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/
--rwxr-xr-x   0 runner    (1001) docker     (122)      473 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/
--rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7186 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)     1428 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2583 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6561 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5124 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    30403 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py
--rw-r--r--   0 runner    (1001) docker     (122)      277 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/opt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
--rw-r--r--   0 runner    (1001) docker     (122)      779 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/renderer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    31247 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/face_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      484 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/
--rw-r--r--   0 runner    (1001) docker     (122)      121 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/
--rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     4932 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/hand_static/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/hand_static/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2480 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/hand_static/hand_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/hand_static/networks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/
--rw-r--r--   0 runner    (1001) docker     (122)     5936 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/Reconstruction.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4542 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/PixToMesh.py
--rw-r--r--   0 runner    (1001) docker     (122)    11301 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Res_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2418 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Surface_head.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/detectors.py
--rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/geometry.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/human_segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/networks.py
--rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/human_reconstruction/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2859 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/bnext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/
--rw-r--r--   0 runner    (1001) docker     (122)      500 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3920 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py
--rw-r--r--   0 runner    (1001) docker     (122)     6541 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    13616 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/person_info.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py
--rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py
--rw-r--r--   0 runner    (1001) docker     (122)    15760 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/slim_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      598 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      107 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/beit_v2.py
--rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/nextvit.py
--rw-r--r--   0 runner    (1001) docker     (122)     2185 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/mmcls_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1554 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/resnet50_cc.py
--rw-r--r--   0 runner    (1001) docker     (122)     5255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_classification/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/adaint/
--rw-r--r--   0 runner    (1001) docker     (122)       44 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/adaint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14338 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/adaint/adaint.py
--rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/csrnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/
--rw-r--r--   0 runner    (1001) docker     (122)       66 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2575 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
--rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     2821 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_color_enhance/image_color_enhance.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/
--rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9385 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6437 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
--rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/
--rw-r--r--   0 runner    (1001) docker     (122)      129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_debanding/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_debanding/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_debanding/rrdb/
--rw-r--r--   0 runner    (1001) docker     (122)       53 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_debanding/rrdb/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3005 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_deblur/
--rw-r--r--   0 runner    (1001) docker     (122)      510 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_deblur/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4241 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4329 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
--rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/
--rw-r--r--   0 runner    (1001) docker     (122)      448 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6827 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py
--rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
--rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py
--rw-r--r--   0 runner    (1001) docker     (122)     1732 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py
--rw-r--r--   0 runner    (1001) docker     (122)     4803 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2617 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py
--rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/
--rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6757 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py
--rw-r--r--   0 runner    (1001) docker     (122)    18233 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    10106 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    13560 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1600 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/newcrfs_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2606 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_driving_perception/
--rw-r--r--   0 runner    (1001) docker     (122)      999 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_driving_perception/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2022 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_driving_perception/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_driving_perception/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3124 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py
--rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/
--rw-r--r--   0 runner    (1001) docker     (122)      242 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
--rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py
--rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/align_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
--rw-r--r--   0 runner    (1001) docker     (122)     9077 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/image_face_fusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3045 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/aad_layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8555 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/bfm.py
--rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/dense_motion.py
--rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/facerecon_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/model_irse.py
--rw-r--r--   0 runner    (1001) docker     (122)     7790 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/ops.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/
--rw-r--r--   0 runner    (1001) docker     (122)      575 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11736 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8257 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8361 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15097 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5634 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_human_parsing/parsing_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2690 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7605 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/default.py
--rw-r--r--   0 runner    (1001) docker     (122)     1253 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/
--rw-r--r--   0 runner    (1001) docker     (122)       81 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/adversarial.py
--rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/feature_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ffc.py
--rw-r--r--   0 runner    (1001) docker     (122)    11842 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/inception.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/perceptual.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py
--rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_inpainting/refinement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      664 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3826 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9305 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      101 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3992 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14867 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6266 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     8692 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/
--rw-r--r--   0 runner    (1001) docker     (122)      600 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     7274 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1429 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11454 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7886 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/config/default.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/
--rw-r--r--   0 runner    (1001) docker     (122)      171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      588 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
--rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)     2735 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/quadtree_attention_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      344 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_matching/utils/misc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      521 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/module.py
--rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_paintbyexample/
--rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_paintbyexample/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_paintbyexample/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      513 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_panoptic_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1694 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8563 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/align_faces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1836 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py
--rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    22869 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/gpen.py
--rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/
--rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_probing_model/
--rw-r--r--   0 runner    (1001) docker     (122)      533 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_probing_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_probing_model/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3319 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_probing_model/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_probing_model/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      584 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4654 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2600 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/maniqa.py
--rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/swin.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      272 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/heads/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2651 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_reid_person/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_reid_person/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5444 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_reid_person/pass_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_reid_person/transreid_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/
--rw-r--r--   0 runner    (1001) docker     (122)      527 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/demoire_models/
--rw-r--r--   0 runner    (1001) docker     (122)       69 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/demoire_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/demoire_models/nets.py
--rw-r--r--   0 runner    (1001) docker     (122)     2640 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_restoration/image_restoration_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      712 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
--rw-r--r--   0 runner    (1001) docker     (122)     5155 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
--rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3208 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2122 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/
--rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/
--rw-r--r--   0 runner    (1001) docker     (122)      290 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      249 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
--rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      251 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
--rw-r--r--   0 runner    (1001) docker     (122)      253 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      368 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      398 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
--rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/
--rw-r--r--   0 runner    (1001) docker     (122)      650 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9312 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/
--rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
--rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/unet.py
--rw-r--r--   0 runner    (1001) docker     (122)    11210 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/skychange.py
--rw-r--r--   0 runner    (1001) docker     (122)     7874 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_skychange/skychange_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      120 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      603 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/losses.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/data/
--rw-r--r--   0 runner    (1001) docker     (122)      127 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/data/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/model_translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/
--rw-r--r--   0 runner    (1001) docker     (122)      384 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/apps.py
--rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/degradation.py
--rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/losses.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/metrics.py
--rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/random_color.py
--rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/random_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/svd.py
--rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      486 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)      136 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4099 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
--rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py
--rw-r--r--   0 runner    (1001) docker     (122)     3251 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
--rw-r--r--   0 runner    (1001) docker     (122)    14887 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5518 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py
--rw-r--r--   0 runner    (1001) docker     (122)     3406 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py
--rw-r--r--   0 runner    (1001) docker     (122)     4808 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1834 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/panovit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/
--rwxr-xr-x   0 runner    (1001) docker     (122)      542 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6441 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/
--rwxr-xr-x   0 runner    (1001) docker     (122)      508 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/models.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/cfg_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/mdm.py
--rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     3914 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/rotation2xyz.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/smpl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/get_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      181 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      798 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py
--rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/trn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/
--rw-r--r--   0 runner    (1001) docker     (122)      602 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18782 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     7876 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/nerf.py
--rw-r--r--   0 runner    (1001) docker     (122)     1509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/segmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      606 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3432 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/
--rw-r--r--   0 runner    (1001) docker     (122)      321 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      278 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      426 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      375 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/
--rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/depe_detect.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/
--rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
--rw-r--r--   0 runner    (1001) docker     (122)      299 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6670 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4476 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
--rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
--rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      294 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      522 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
--rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
--rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    59197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      562 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
--rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/result_vis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      473 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26142 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/dbnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    31084 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/mix_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     5974 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/proxyless.py
--rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7972 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6378 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/CRNN/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/CRNN/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3724 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)      753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/
--rw-r--r--   0 runner    (1001) docker     (122)       43 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    25097 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)    10662 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     5031 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3710 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/ocr_recognition/preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/open_vocabulary_detection_vild/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/open_vocabulary_detection_vild/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14225 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/open_vocabulary_detection_vild/vild.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      511 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5077 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/equi.py
--rw-r--r--   0 runner    (1001) docker     (122)     7500 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     7839 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py
--rw-r--r--   0 runner    (1001) docker     (122)    14421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9175 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py
--rw-r--r--   0 runner    (1001) docker     (122)     3962 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/pedestrian_attribute_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pedestrian_attribute_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3468 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pedestrian_attribute_recognition/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      495 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16147 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1797 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     4340 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/product_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      528 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_segmentation/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     2194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/product_segmentation/seg_infer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      318 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py
--rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py
--rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py
--rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
--rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py
--rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/robust_image_classification/
--rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/robust_image_classification/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/robust_image_classification/easyrobust_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/
--rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
--rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6525 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/senet.py
--rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/u2net.py
--rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/models/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/salient_detection/salient_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/head_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/models.py
--rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/neck_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/shop_seg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4095 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/shop_seg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/shop_segmentation/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/detection_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     2532 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5759 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py
--rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/box_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/network.py
--rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/predict_single.py
--rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/prior_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3890 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/unet_deploy.py
--rw-r--r--   0 runner    (1001) docker     (122)     9917 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1169 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/skin_retouching/weights_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/
--rw-r--r--   0 runner    (1001) docker     (122)      526 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/data/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/data/data_augment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/
--rw-r--r--   0 runner    (1001) docker     (122)      165 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      274 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/base_exp.py
--rw-r--r--   0 runner    (1001) docker     (122)      392 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/build.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/default/
--rw-r--r--   0 runner    (1001) docker     (122)      137 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/default/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/yolox_base.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/
--rw-r--r--   0 runner    (1001) docker     (122)      238 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/network_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/streamyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/tal_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/realtime_video_detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      270 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)      209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/stream_yolo/utils/format.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      555 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/arch_util.py
--rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/ecb.py
--rw-r--r--   0 runner    (1001) docker     (122)     3525 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/ecbsr_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/super_resolution/rrdbnet_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/
--rw-r--r--   0 runner    (1001) docker     (122)      462 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16198 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/lineless_table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3360 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/model_lore.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/lore_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/lore_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)      777 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4143 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_net.py
--rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/
--rw-r--r--   0 runner    (1001) docker     (122)      594 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    43681 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/basic_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/global_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/master_net.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/model_zoo.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/plain_net_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7405 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    14983 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py
--rw-r--r--   0 runner    (1001) docker     (122)     8709 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py
--rw-r--r--   0 runner    (1001) docker     (122)     6923 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2067 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
--rw-r--r--   0 runner    (1001) docker     (122)     4000 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
--rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
--rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/
--rw-r--r--   0 runner    (1001) docker     (122)      148 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/
--rw-r--r--   0 runner    (1001) docker     (122)      621 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3701 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
--rw-r--r--   0 runner    (1001) docker     (122)     9356 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
--rw-r--r--   0 runner    (1001) docker     (122)     7465 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14261 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    10559 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    13101 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    18626 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     7526 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12602 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
--rw-r--r--   0 runner    (1001) docker     (122)    19162 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5588 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
--rw-r--r--   0 runner    (1001) docker     (122)    12284 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7347 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
--rw-r--r--   0 runner    (1001) docker     (122)    24842 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
--rw-r--r--   0 runner    (1001) docker     (122)     3499 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/detectors/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/detectors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2809 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py
--rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/
--rw-r--r--   0 runner    (1001) docker     (122)      189 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11594 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py
--rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1164 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6400 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/detector.py
--rw-r--r--   0 runner    (1001) docker     (122)      627 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py
--rw-r--r--   0 runner    (1001) docker     (122)      643 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/tinynas_detector.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/tinynas_detection/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/
--rw-r--r--   0 runner    (1001) docker     (122)     2896 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
--rw-r--r--   0 runner    (1001) docker     (122)      494 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      773 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/deinterlace_arch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3159 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/archs.py
--rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
--rw-r--r--   0 runner    (1001) docker     (122)     2972 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/enh.py
--rw-r--r--   0 runner    (1001) docker     (122)     3572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/fre.py
--rw-r--r--   0 runner    (1001) docker     (122)     3716 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/configs/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/configs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/configs/default_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     6731 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/dro_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5494 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/camera.py
--rw-r--r--   0 runner    (1001) docker     (122)     2285 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/pose.py
--rw-r--r--   0 runner    (1001) docker     (122)     3685 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2356 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    10098 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7204 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py
--rw-r--r--   0 runner    (1001) docker     (122)     4387 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10532 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
--rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6815 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/augmentations.py
--rw-r--r--   0 runner    (1001) docker     (122)    10248 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)    15068 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/depth.py
--rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/horovod.py
--rw-r--r--   0 runner    (1001) docker     (122)    10965 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9407 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/image_gt.py
--rw-r--r--   0 runner    (1001) docker     (122)     6499 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/load.py
--rw-r--r--   0 runner    (1001) docker     (122)     2726 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/misc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/types.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)     1894 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3334 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
--rw-r--r--   0 runner    (1001) docker     (122)      458 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5346 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/update.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/
--rw-r--r--   0 runner    (1001) docker     (122)    13745 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
--rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
--rw-r--r--   0 runner    (1001) docker     (122)    16050 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
--rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3314 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py
--rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/
--rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/
--rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/effv2.py
--rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/lraspp.py
--rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/matting.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      524 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_inpainting/inpainting.py
--rw-r--r--   0 runner    (1001) docker     (122)    13727 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_inpainting/inpainting_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      582 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
--rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    18059 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/video_knet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     2420 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/decode.py
--rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     4921 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/yolo.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py
--rw-r--r--   0 runner    (1001) docker     (122)    14995 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py
--rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/aggregate.py
--rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/cbam.py
--rw-r--r--   0 runner    (1001) docker     (122)     1979 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/eval_network.py
--rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/inference_core.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py
--rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/mod_resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)      974 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    15309 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/modules.py
--rw-r--r--   0 runner    (1001) docker     (122)     5593 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/network.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/
--rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
--rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py
--rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/neck/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/neck/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/track/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/track/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
--rw-r--r--   0 runner    (1001) docker     (122)    17155 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/visualizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/config/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/config/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/config/ostrack.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py
--rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3380 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)      653 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12278 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3497 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py
--rw-r--r--   0 runner    (1001) docker     (122)      943 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/
--rw-r--r--   0 runner    (1001) docker     (122)      114 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py
--rw-r--r--   0 runner    (1001) docker     (122)     7123 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/utils/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/
--rw-r--r--   0 runner    (1001) docker     (122)    14702 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/MotionPro.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3290 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py
--rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5275 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py
--rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py
--rw-r--r--   0 runner    (1001) docker     (122)     3922 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/Smoother.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     7292 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py
--rw-r--r--   0 runner    (1001) docker     (122)     3452 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/
--rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py
--rw-r--r--   0 runner    (1001) docker     (122)    14212 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/MedianFilter.py
--rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/WarpUtils.py
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14474 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/image_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/math_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/
--rw-r--r--   0 runner    (1001) docker     (122)      487 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7097 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5774 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
--rw-r--r--   0 runner    (1001) docker     (122)     4848 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
--rw-r--r--   0 runner    (1001) docker     (122)     9990 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py
--rw-r--r--   0 runner    (1001) docker     (122)     3905 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/
--rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/base_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/cpd_auto.py
--rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py
--rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/pgl_sum.py
--rw-r--r--   0 runner    (1001) docker     (122)     8812 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_summarization/summarizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      689 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14118 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/basicvsr_net.py
--rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3636 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)     3637 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/vidt/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/deformable_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/fpn_fusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     3651 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vidt/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/virual_tryon/
--rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/virual_tryon/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17690 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/virual_tryon/sdafnet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16152 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)      797 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     1786 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/petl.py
--rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py
--rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py
--rw-r--r--   0 runner    (1001) docker     (122)     5614 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6494 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vision_middleware/vim.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/
--rw-r--r--   0 runner    (1001) docker     (122)      919 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12238 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/basic_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    13520 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/model_se.py
--rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/cv/vop_retrieval/tokenization_clip.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     2182 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/bert_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/configuration_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)    22351 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip/modeling_bert.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip_interrogator/
--rw-r--r--   0 runner    (1001) docker     (122)       37 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip_interrogator/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24293 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/clip_interrogator/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    26652 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    14447 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/structbert.py
--rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py
--rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py
--rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/dpm_solver_pytorch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10300 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/gemm/
--rw-r--r--   0 runner    (1001) docker     (122)      139 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/gemm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21694 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/gemm/gemm_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3718 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/gemm/gemm_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/gemm/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/respace.py
--rw-r--r--   0 runner    (1001) docker     (122)     1365 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/script.py
--rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/unet.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/
--rw-r--r--   0 runner    (1001) docker     (122)     1444 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)   101942 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8651 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     3268 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)    10331 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mgeo/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/
--rw-r--r--   0 runner    (1001) docker     (122)      141 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/dataloaders/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/dataloaders/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/
--rw-r--r--   0 runner    (1001) docker     (122)      162 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9790 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
--rw-r--r--   0 runner    (1001) docker     (122)    21257 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/module_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/module_cross.py
--rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/tokenization_clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/until_module.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)      739 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/clip/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6030 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/configuration_mplug.py
--rwxr-xr-x   0 runner    (1001) docker     (122)   120753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/modeling_mplug.py
--rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/mvit.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug/predictor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5536 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug_for_all_tasks.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/
--rw-r--r--   0 runner    (1001) docker     (122)      835 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10293 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py
--rw-r--r--   0 runner    (1001) docker     (122)    64194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py
--rw-r--r--   0 runner    (1001) docker     (122)    28436 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    13487 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/prior.py
--rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/adaptor/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/adaptor/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/configuration_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/configuration_ofa.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py
--rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/search.py
--rw-r--r--   0 runner    (1001) docker     (122)    41976 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/sequence_generator.py
--rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py
--rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/modeling_mmspeech.py
--rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/modeling_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/resnet.py
--rw-r--r--   0 runner    (1001) docker     (122)    15028 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/tokenization_ofa.py
--rw-r--r--   0 runner    (1001) docker     (122)     8004 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      676 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     1877 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa/vit.py
--rw-r--r--   0 runner    (1001) docker     (122)    24779 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa_for_all_tasks.py
--rw-r--r--   0 runner    (1001) docker     (122)    12983 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/rleg/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/rleg/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4865 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/rleg/model.py
--rw-r--r--   0 runner    (1001) docker     (122)     3410 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/rleg/rleg.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/
--rw-r--r--   0 runner    (1001) docker     (122)      678 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/blocks.py
--rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/clip.py
--rw-r--r--   0 runner    (1001) docker     (122)     6165 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/swin_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/soonet/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/stable_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/stable_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6267 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5181 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/team/team_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/team/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/autoencoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)     9504 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
--rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/unet_sd.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/
--rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11339 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    16687 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/model.py
--rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py
--rw-r--r--   0 runner    (1001) docker     (122)    20956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/processing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4680 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/multi_modal/vldoc/transformer_local.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/T5/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    67374 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/T5/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7541 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/T5/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    21517 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/T5/text2text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     6810 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/bart/
--rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bart/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3058 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bart/text_error_correction.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/bert/
--rw-r--r--   0 runner    (1001) docker     (122)     1519 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40458 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4113 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)      512 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6074 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/sentence_embedding.py
--rw-r--r--   0 runner    (1001) docker     (122)     7153 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/siamese_uie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1478 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     1138 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     2140 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/token_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     6904 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bert/word_alignment.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/bloom/
--rw-r--r--   0 runner    (1001) docker     (122)      472 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bloom/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      505 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/bloom/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/canmt/
--rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/canmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/canmt/canmt_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     2940 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/canmt/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/canmt/sequence_generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/
--rw-r--r--   0 runner    (1001) docker     (122)     1578 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4402 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    15788 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/quantization.py
--rw-r--r--   0 runner    (1001) docker     (122)    60839 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    17391 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm/tokenization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/
--rw-r--r--   0 runner    (1001) docker     (122)     1584 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2397 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    15263 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/quantization.py
--rw-r--r--   0 runner    (1001) docker     (122)    51543 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     9669 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/chatglm2/tokenization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/
--rwxr-xr-x   0 runner    (1001) docker     (122)      730 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     3995 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4008 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/inference.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/codegeex/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/csanmt/
--rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/csanmt/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    61868 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/csanmt/translation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    47998 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10364 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    10698 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/deberta_v2/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/
--rw-r--r--   0 runner    (1001) docker     (122)      939 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7092 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1656 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/fid_T5/
--rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_T5/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8108 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_T5/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/fid_plug/
--rw-r--r--   0 runner    (1001) docker     (122)     1181 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    45082 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6709 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/fid_plug/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/
--rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/generation/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/generation/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/generation/strategies.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/initialize.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/kernels/
--rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/kernels/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/
--rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/functional.py
--rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/layers.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    13504 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/glm_130b/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/gpt2/
--rw-r--r--   0 runner    (1001) docker     (122)      470 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt2/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/
--rw-r--r--   0 runner    (1001) docker     (122)      852 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16094 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    52130 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/distributed_gpt3.py
--rw-r--r--   0 runner    (1001) docker     (122)     3198 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt3/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/
--rw-r--r--   0 runner    (1001) docker     (122)      874 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/checkpointing.py
--rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    49316 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/experts.py
--rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/layer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/mappings.py
--rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py
--rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2717 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_moe/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_neo/
--rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_neo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      518 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/gpt_neo/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/heads/
--rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    25248 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/crf_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     6947 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/fill_mask_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     5145 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/infromation_extraction_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2056 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/text_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      964 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/text_generation_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2029 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/text_ranking_head.py
--rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/token_classification_head.py
--rw-r--r--   0 runner    (1001) docker     (122)      948 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/heads/torch_pretrain_head.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/hf_transformers/
--rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/hf_transformers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4897 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/hf_transformers/backbone.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/llama/
--rw-r--r--   0 runner    (1001) docker     (122)      866 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    29197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     4695 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    11349 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py
--rw-r--r--   0 runner    (1001) docker     (122)     7212 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    10333 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/llama/tokenization_fast.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/lstm/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/lstm/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1312 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/lstm/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     2187 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/lstm/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/megatron_bert/
--rw-r--r--   0 runner    (1001) docker     (122)      688 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/megatron_bert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    39864 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/megatron_bert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6599 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/megatron_bert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    12452 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/megatron_bert/fill_mask.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/
--rw-r--r--   0 runner    (1001) docker     (122)      572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/arguments.py
--rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/blocklm_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/configure_data.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/
--rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    20350 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/corpora.py
--rw-r--r--   0 runner    (1001) docker     (122)    45765 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/datasets.py
--rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/extraction.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/lazy_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/samplers.py
--rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/tokenization.py
--rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/wordpiece.py
--rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/generation_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    16247 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/mglm_for_text_summarization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/
--rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/downstream.py
--rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/modeling_bert.py
--rw-r--r--   0 runner    (1001) docker     (122)     8743 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/modeling_glm.py
--rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/prompt.py
--rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/model/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/process_grid.py
--rw-r--r--   0 runner    (1001) docker     (122)      203 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/run_test.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/test/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      950 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/test/test_block.py
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/test/test_rel_shift.py
--rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/train_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/mglm/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/palm_v2/
--rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/palm_v2/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5532 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/palm_v2/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/palm_v2/dureader_eval.py
--rw-r--r--   0 runner    (1001) docker     (122)    55450 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/palm_v2/text_generation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/peer/
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/peer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    55780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/peer/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11716 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/peer/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/peer/sas_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/peer/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/plug/
--rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/AnnealingLR.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    41209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)    11797 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10983 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/distributed_plug.py
--rw-r--r--   0 runner    (1001) docker     (122)     8427 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug/generator.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/
--rw-r--r--   0 runner    (1001) docker     (122)     1359 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7671 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    47486 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    10881 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/plug_mental/text_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/
--rw-r--r--   0 runner    (1001) docker     (122)     1490 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    37918 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     6366 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4176 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/document_segmentation.py
--rw-r--r--   0 runner    (1001) docker     (122)    11011 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     7147 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/ponet/tokenization.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)      987 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1208 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     3832 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/dialog_intent_prediction.py
--rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/dialog_modeling.py
--rw-r--r--   0 runner    (1001) docker     (122)    16648 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/dialog_state_tracking.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/
--rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10281 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/gen_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10757 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/generator.py
--rw-r--r--   0 runner    (1001) docker     (122)     7505 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/intent_unified_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/model_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/tokenization_space.py
--rw-r--r--   0 runner    (1001) docker     (122)    11941 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/model/unified_transformer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2398 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/embedder.py
--rw-r--r--   0 runner    (1001) docker     (122)      956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/feedforward.py
--rw-r--r--   0 runner    (1001) docker     (122)     1721 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/functions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/multihead_attention.py
--rw-r--r--   0 runner    (1001) docker     (122)     1922 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space/modules/transformer_block.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_cn/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    44438 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_cn/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_cn/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    30117 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_cn/table_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/space_T_en/text_to_sql.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/
--rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7673 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/adv_utils.py
--rwxr-xr-x   0 runner    (1001) docker     (122)    40848 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7686 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    27203 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/faq_question_answering.py
--rw-r--r--   0 runner    (1001) docker     (122)    12581 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)    11862 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)    11074 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/structbert/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/
--rw-r--r--   0 runner    (1001) docker     (122)     1453 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5323 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/feature_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)     2698 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/information_extraction.py
--rw-r--r--   0 runner    (1001) docker     (122)    28991 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/task_model.py
--rw-r--r--   0 runner    (1001) docker     (122)     1912 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     8678 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/text_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2092 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/text_ranking.py
--rw-r--r--   0 runner    (1001) docker     (122)     5116 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/task_models/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/unite/
--rw-r--r--   0 runner    (1001) docker     (122)      626 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/unite/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/unite/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)    18320 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/unite/translation_evaluation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/use/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/use/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5133 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/use/transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/use/user_satisfaction_estimation.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/veco/
--rw-r--r--   0 runner    (1001) docker     (122)     1479 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4031 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     1192 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/configuration.py
--rw-r--r--   0 runner    (1001) docker     (122)     4278 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/fill_mask.py
--rw-r--r--   0 runner    (1001) docker     (122)     6643 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     4129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/veco/token_classification.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/
--rw-r--r--   0 runner    (1001) docker     (122)     1156 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    42932 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/backbone.py
--rw-r--r--   0 runner    (1001) docker     (122)     7697 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/configuration.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/
--rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/unifold/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/
--rw-r--r--   0 runner    (1001) docker     (122)      634 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    49139 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/data_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/msa_pairing.py
--rw-r--r--   0 runner    (1001) docker     (122)     8941 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/process.py
--rw-r--r--   0 runner    (1001) docker     (122)    14792 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/process_multimer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11422 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/protein.py
--rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/residue_constants.py
--rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/data/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/model.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/
--rw-r--r--   0 runner    (1001) docker     (122)      187 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/alphafold.py
--rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/attentions.py
--rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/auxillary_heads.py
--rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/common.py
--rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/confidence.py
--rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/embedders.py
--rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/evoformer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6820 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/featurization.py
--rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/frame.py
--rw-r--r--   0 runner    (1001) docker     (122)    18476 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/structure_module.py
--rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/template.py
--rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/modules/triangle_multiplication.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/
--rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/mmcif.py
--rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/msa_identifiers.py
--rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/parsers.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    45468 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/templates.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/
--rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hhblits.py
--rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hhsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hmmbuild.py
--rw-r--r--   0 runner    (1001) docker     (122)     5013 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hmmsearch.py
--rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/jackhmmer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/kalign.py
--rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/models/science/unifold/msa/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/
--rw-r--r--   0 runner    (1001) docker     (122)       84 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      346 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/audio/asr_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/auth/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/auth/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/auth/auth_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/context/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/context/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/context/dataset_context_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/data_files/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/data_files/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5270 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/data_files/data_files_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/data_loader/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/data_loader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    12636 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/data_loader/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5764 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/data_loader/data_loader_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/
--rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     4111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      730 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1737 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8512 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     7723 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    11689 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/
--rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      791 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/
--rw-r--r--   0 runner    (1001) docker     (122)      134 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4708 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py
--rw-r--r--   0 runner    (1001) docker     (122)      945 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/
--rw-r--r--   0 runner    (1001) docker     (122)      177 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3815 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py
--rw-r--r--   0 runner    (1001) docker     (122)    16180 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/
--rw-r--r--   0 runner    (1001) docker     (122)      934 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/
--rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/
--rw-r--r--   0 runner    (1001) docker     (122)      312 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2622 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py
--rw-r--r--   0 runner    (1001) docker     (122)     4858 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     1469 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/
--rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1086 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py
--rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2141 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/
--rw-r--r--   0 runner    (1001) docker     (122)      539 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/
--rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py
--rw-r--r--   0 runner    (1001) docker     (122)    12152 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    12574 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/
--rw-r--r--   0 runner    (1001) docker     (122)      577 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1629 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/
--rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/
--rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4849 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6225 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      559 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/
--rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py
--rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/
--rw-r--r--   0 runner    (1001) docker     (122)       40 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py
--rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/
--rw-r--r--   0 runner    (1001) docker     (122)      309 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      971 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py
--rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
--rw-r--r--   0 runner    (1001) docker     (122)      707 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py
--rw-r--r--   0 runner    (1001) docker     (122)     2402 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2017 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    16767 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     8725 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/
--rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1984 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     5114 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1635 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2664 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/
--rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/
--rw-r--r--   0 runner    (1001) docker     (122)      543 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      809 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2624 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/
--rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2370 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    11485 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/dataset_cls/dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/download/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/download/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    20627 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/download/dataset_builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/download/download_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     2487 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/download/download_manager.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/meta/
--rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/meta/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1772 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/meta/data_meta_config.py
--rw-r--r--   0 runner    (1001) docker     (122)     8679 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/meta/data_meta_manager.py
--rw-r--r--   0 runner    (1001) docker     (122)    36737 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/ms_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/
--rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      408 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/gopro_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      401 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/reds_image_deblurring_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/sidd_image_denoising.py
--rw-r--r--   0 runner    (1001) docker     (122)      410 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/torch_base_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/task_datasets/video_summarization_dataset.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/msdatasets/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8124 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/dataset_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/delete_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/maxcompute_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6200 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/oss_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2496 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/msdatasets/utils/upload_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/ailut/
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/ailut/Ailut/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/ailut/Ailut/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/ailut/Ailut/csrc/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/ailut/Ailut/csrc/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/ailut/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/ailut/pyinterfaces.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/
--rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/functions/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/functions/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2925 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/functions/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/modules/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    13956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/modules/quadtree_attention.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/src/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/ops/quadtree_attention/src/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/outputs/
--rw-r--r--   0 runner    (1001) docker     (122)      132 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/outputs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/outputs/cv_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    19855 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/outputs/nlp_outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    51098 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/outputs/outputs.py
--rw-r--r--   0 runner    (1001) docker     (122)    11135 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipeline_inputs.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/
--rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/audio/
--rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7519 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/ans_dfsmn_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5016 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/ans_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    23889 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/asr_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4357 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/inverse_text_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3830 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/kws_farfield_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/kws_kwsbp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5642 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/linear_aec_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8068 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/lm_infer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6481 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/punctuation_processing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    13047 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/segmentation_clustering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2560 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/separation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4763 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_change_locating_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11117 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_diarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4078 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6271 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_light_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/text_to_speech_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11937 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/timestamp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9696 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/audio/voice_activity_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    23113 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     7702 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/cv/
--rw-r--r--   0 runner    (1001) docker     (122)    16450 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/action_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4852 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/action_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4024 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/animal_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/arc_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2614 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/bad_image_detecting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14219 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/card_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2528 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/content_check_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5055 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/controllable_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5942 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/crowd_counting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5136 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3993 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1531 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_emotion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2894 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_image_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_liveness_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3573 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_liveness_xc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7748 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_processing_base_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3872 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_quality_assessment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3528 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3493 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2878 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_ood_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    19634 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/face_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2400 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2681 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4442 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/general_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/hand_static_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2982 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/human_reconstruction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1399 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_body_reshaping_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2919 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5251 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_cartoon_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5857 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3296 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_color_enhance_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4441 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_debanding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4624 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_deblur_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3517 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4160 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_denoise_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1943 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1854 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4134 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_driving_perception_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2317 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_face_fusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4866 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_human_parsing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5854 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4673 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3903 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5929 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_matching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2796 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2770 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6113 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_paintbyexample_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3549 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2835 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2801 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_reid_person_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1702 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_restoration_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1644 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_salient_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2237 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_skychange_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2839 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4615 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_style_transfer_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3138 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9718 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_to_image_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12737 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/image_to_image_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1883 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     9872 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4570 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/license_plate_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4182 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/live_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2757 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/mask_face_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2787 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3670 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1857 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/mog_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4844 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/motion_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2628 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1953 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3328 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6018 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/object_detection_3d_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11033 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_recognition_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/
--rw-r--r--   0 runner    (1001) docker     (122)      966 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      720 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py
--rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_dla34.py
--rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py
--rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
--rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_vlpt.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/
--rw-r--r--   0 runner    (1001) docker     (122)      550 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py
--rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
--rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
--rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ops.py
--rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py
--rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/resnet_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/table_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     7971 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3029 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9781 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4199 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1457 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1451 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/product_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2020 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9239 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/retina_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1760 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/shop_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/skin_retouching_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4446 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/table_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4899 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_utils/
--rw-r--r--   0 runner    (1001) docker     (122)       10 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15542 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_utils/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1841 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3246 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/tinynas_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/tinynas_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1888 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    13776 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_category_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6097 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_colorization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7757 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_deinterlace_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1565 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_depth_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    24271 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3635 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_human_matting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1719 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_inpainting_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9652 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4724 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_object_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4683 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3436 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_stabilization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4289 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7078 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/video_super_resolution_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7564 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/vidt_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5240 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/virtual_try_on_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3986 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/vision_middleware_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4762 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/vop_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5787 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)     3057 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/asr_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/
--rw-r--r--   0 runner    (1001) docker     (122)      622 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2013 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11691 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2537 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/
--rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15631 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
--rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2311 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2931 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1093 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9352 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/gridvlp_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/image_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7869 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3325 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     8561 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1848 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/sudoku_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/text2sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3556 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2150 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/video_captioning_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     6798 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3696 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/canmt_translation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2202 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     2885 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2251 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2577 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2308 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/dialog_modeling_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     7663 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1851 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4425 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/distributed_plug_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2754 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    25997 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5480 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9623 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/document_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6259 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/extractive_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3348 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/faq_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2437 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3258 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/feature_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    10171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/fid_dialogue_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4655 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/fill_mask_pipeline.py
--rwxr-xr-x   0 runner    (1001) docker     (122)      999 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2383 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/information_extraction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/interactive_translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     9928 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/language_identification_pipline.py
--rw-r--r--   0 runner    (1001) docker     (122)     1776 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3184 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/sentence_embedding_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    14334 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/siamese_uie_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/summarization_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    16315 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/table_question_answering_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6787 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/text_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3490 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/text_error_correction_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)    11117 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/text_generation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2877 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/text_ranking_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/token_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/translation_evaluation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5586 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/translation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2339 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4613 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2713 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/word_alignment_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     4523 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/word_segmentation_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     5875 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     2816 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/pipeline_template.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/pipelines/science/
--rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/science/protein_structure_pipeline.py
--rw-r--r--   0 runner    (1001) docker     (122)     3492 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/pipelines/util.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/
--rw-r--r--   0 runner    (1001) docker     (122)     5792 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10063 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)     8680 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/audio.py
--rw-r--r--   0 runner    (1001) docker     (122)    15312 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/base.py
--rw-r--r--   0 runner    (1001) docker     (122)      812 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/common.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1896 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7446 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/action_detection_mapper.py
--rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/controllable_image_generation.py
--rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/cv2_transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    12826 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/image_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1250 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/image_quality_assessment_man.py
--rw-r--r--   0 runner    (1001) docker     (122)     2113 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/image_quality_assessment_mos.py
--rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/image_restoration_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/mmcls_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/util.py
--rw-r--r--   0 runner    (1001) docker     (122)     1501 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/video_stabilization.py
--rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/cv/video_super_resolution.py
--rw-r--r--   0 runner    (1001) docker     (122)    13406 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/image.py
--rw-r--r--   0 runner    (1001) docker     (122)     4884 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/kws.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/movie_scene_segmentation/
--rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/movie_scene_segmentation/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/movie_scene_segmentation/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)    30172 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/multi_modal.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     5966 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3929 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/canmt_translation.py
--rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4102 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4391 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4086 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    11004 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     6844 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    12086 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/fill_mask_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     8199 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1168 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4023 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1424 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)     1219 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1908 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)     1553 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/batch.py
--rw-r--r--   0 runner    (1001) docker     (122)     3629 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/data_loader.py
--rw-r--r--   0 runner    (1001) docker     (122)     2701 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5457 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/dst_processors.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      592 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    33884 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/gen_field.py
--rw-r--r--   0 runner    (1001) docker     (122)    42467 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/intent_field.py
--rw-r--r--   0 runner    (1001) docker     (122)     1147 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/lazy_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1935 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/preprocess.py
--rw-r--r--   0 runner    (1001) docker     (122)     1610 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/sampler.py
--rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/tensorlistdataset.py
--rw-r--r--   0 runner    (1001) docker     (122)    24803 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space/tokenizer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/
--rw-r--r--   0 runner    (1001) docker     (122)      654 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/database.py
--rw-r--r--   0 runner    (1001) docker     (122)    15867 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py
--rw-r--r--   0 runner    (1001) docker     (122)     4888 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py
--rw-r--r--   0 runner    (1001) docker     (122)     4175 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)      846 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4902 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/
--rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21521 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12500 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/parse.py
--rw-r--r--   0 runner    (1001) docker     (122)     1380 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/text_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/text_clean.py
--rw-r--r--   0 runner    (1001) docker     (122)     2298 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/text_error_correction.py
--rw-r--r--   0 runner    (1001) docker     (122)    14124 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/text_generation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3834 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/text_ranking_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)    19629 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1640 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     1238 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     4482 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/transformers_tokenizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7304 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4962 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/word_alignment_preprocessor.py
--rw-r--r--   0 runner    (1001) docker     (122)     2584 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4839 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/asr.py
--rw-r--r--   0 runner    (1001) docker     (122)    11909 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4172 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/image_captioning.py
--rw-r--r--   0 runner    (1001) docker     (122)     6461 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/image_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     5740 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/ocr_recognition.py
--rw-r--r--   0 runner    (1001) docker     (122)     4603 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/sudoku.py
--rw-r--r--   0 runner    (1001) docker     (122)     5210 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/summarization.py
--rw-r--r--   0 runner    (1001) docker     (122)    16449 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/text2sql.py
--rw-r--r--   0 runner    (1001) docker     (122)     5368 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/text_classification.py
--rw-r--r--   0 runner    (1001) docker     (122)     2164 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/text_to_image_synthesis.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3221 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/audio_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py
--rw-r--r--   0 runner    (1001) docker     (122)     6809 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/collate.py
--rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/constant.py
--rw-r--r--   0 runner    (1001) docker     (122)     3421 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/get_tables.py
--rw-r--r--   0 runner    (1001) docker     (122)     1302 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/random_help.py
--rw-r--r--   0 runner    (1001) docker     (122)     5459 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/text2phone.py
--rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/transforms.py
--rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/utils/vision_helper.py
--rw-r--r--   0 runner    (1001) docker     (122)     7664 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/visual_entailment.py
--rw-r--r--   0 runner    (1001) docker     (122)     8484 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/visual_grounding.py
--rw-r--r--   0 runner    (1001) docker     (122)     6796 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/ofa/visual_question_answering.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/preprocessors/science/
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/science/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    21698 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/science/uni_fold.py
--rw-r--r--   0 runner    (1001) docker     (122)     2101 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/tts.py
--rw-r--r--   0 runner    (1001) docker     (122)    13168 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/preprocessors/video.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/swift/
--rw-r--r--   0 runner    (1001) docker     (122)     1394 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7288 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/adapter.py
--rw-r--r--   0 runner    (1001) docker     (122)      841 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/base.py
--rw-r--r--   0 runner    (1001) docker     (122)    38973 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/control_sd_lora.py
--rw-r--r--   0 runner    (1001) docker     (122)    27160 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/lora.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/swift/optimizers/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/optimizers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8586 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/prompt.py
--rw-r--r--   0 runner    (1001) docker     (122)     8811 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/swift/sd_lora.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/tools/
--rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/tools/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      772 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/tools/eval.py
--rw-r--r--   0 runner    (1001) docker     (122)     5359 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/tools/speech_tts_autolabel.py
--rw-r--r--   0 runner    (1001) docker     (122)      607 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/tools/train.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/
--rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/audio/
--rw-r--r--   0 runner    (1001) docker     (122)      826 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/ans_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6969 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/asr_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12816 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_farfield_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22065 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_nearfield_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/
--rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    22114 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/batch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    11499 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/det_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     7022 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/model_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/kws_utils/runtime_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    21962 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/separation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10858 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/audio/tts_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     1808 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cli_argument_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/cv/
--rw-r--r--   0 runner    (1001) docker     (122)     1974 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     7494 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/action_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      668 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/card_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10044 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/cartoon_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     6737 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/face_detection_scrfd_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20323 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_classifition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    11655 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    22965 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_detection_damoyolo_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4405 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_inpainting_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      816 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_instance_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     5520 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/image_portrait_enhancement_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      680 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/movie_scene_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20149 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/nerf_recon_acc_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    16911 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/ocr_detection_db_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/ocr_recognition_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4602 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/cv/vision_efficient_tuning_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/default_config.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/
--rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/
--rw-r--r--   0 runner    (1001) docker     (122)      116 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    19086 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)    10690 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py
--rw-r--r--   0 runner    (1001) docker     (122)     5541 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      764 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/compression/
--rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/compression/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4812 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/compression/sparsity_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6915 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/compression/utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/distributed/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/distributed/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/distributed/ddp_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)    17072 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/distributed/deepspeed_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6925 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/distributed/megatron_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     4398 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/early_stop_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/evaluation_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/hook.py
--rw-r--r--   0 runner    (1001) docker     (122)      731 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/iter_timer_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/logger/
--rw-r--r--   0 runner    (1001) docker     (122)      718 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/logger/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     4498 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/logger/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     4507 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/logger/tensorboard_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     7443 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/logger/text_logger_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     6567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/lr_scheduler_hook.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/hooks/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      743 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3139 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/optimizer/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     3729 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py
--rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/hooks/priority.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/
--rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/
--rw-r--r--   0 runner    (1001) docker     (122)      614 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2547 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/base.py
--rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/warmup.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/
--rw-r--r--   0 runner    (1001) docker     (122)      682 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/clip/
--rw-r--r--   0 runner    (1001) docker     (122)       89 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/clip/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     9702 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/clip/clip_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4388 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/dreambooth_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      118 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    15330 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2874 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/lora_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/lora_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     3224 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8086 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/mplug/
--rw-r--r--   0 runner    (1001) docker     (122)       91 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/mplug/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1642 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/mplug/mplug_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/
--rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    10186 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/ofa_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/stable_diffusion/
--rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/stable_diffusion/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1144 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/team/
--rw-r--r--   0 runner    (1001) docker     (122)       95 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/team/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5429 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/team/team_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2443 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/multi_modal/team/team_trainer_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)     1332 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    14266 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/csanmt_translation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     9999 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    24284 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    12769 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/faq_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3064 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/gpt3_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     2097 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/gpt_moe_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8171 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/plug_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/sentence_embedding_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     8378 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/sequence_classification_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17110 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/siamese_uie_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     5324 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/dialog_intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     4229 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/dialog_modeling_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    36354 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/eval.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/metrics/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/metrics/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2447 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/metrics/metrics_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    30567 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/gen_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    29570 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/intent_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    20453 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/table_question_answering_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)      991 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/text_generation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7514 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/text_ranking_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    15326 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp/translation_evaluation_trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)     7129 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/nlp_trainer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/optimizer/
--rw-r--r--   0 runner    (1001) docker     (122)      210 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/optimizer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1753 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/optimizer/builder.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/parallel/
--rw-r--r--   0 runner    (1001) docker     (122)       80 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/parallel/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      681 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/parallel/builder.py
--rw-r--r--   0 runner    (1001) docker     (122)      754 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/parallel/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    59000 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/trainer.py
--rw-r--r--   0 runner    (1001) docker     (122)    17846 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/training_args.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/trainers/utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11090 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/utils/inference.py
--rw-r--r--   0 runner    (1001) docker     (122)     1294 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/trainers/utils/log_buffer.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/
--rw-r--r--   0 runner    (1001) docker     (122)       56 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)   527290 2023-07-04 16:22:42.000000 modelscope-1.7.1/modelscope/utils/ast_index_file.py
--rw-r--r--   0 runner    (1001) docker     (122)    28920 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/ast_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/audio/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/audio/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    11795 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/audio/audio_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2428 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/audio/tts_exceptions.py
--rw-r--r--   0 runner    (1001) docker     (122)    26430 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/checkpoint.py
--rw-r--r--   0 runner    (1001) docker     (122)     2573 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/chinese_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    27433 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/config.py
--rw-r--r--   0 runner    (1001) docker     (122)     1027 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/config_ds.py
--rw-r--r--   0 runner    (1001) docker     (122)    18793 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/constant.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/cv/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)    23195 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/image_utils.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/cv/motion_utils/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/motion_utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/motion_utils/motion_process.py
--rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/motion_utils/plot_script.py
--rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/cv/motion_utils/rotation_conversions.py
--rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/data_collators.py
--rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/data_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     3744 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/device.py
--rw-r--r--   0 runner    (1001) docker     (122)     6339 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/error.py
--rw-r--r--   0 runner    (1001) docker     (122)     1128 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/file_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     5939 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/hub.py
--rw-r--r--   0 runner    (1001) docker     (122)    15823 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/import_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    25538 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/input_output.py
--rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/input_output_typing.py
--rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/json_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/logger.py
--rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/megatron_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/metric.py
--rw-r--r--   0 runner    (1001) docker     (122)     5099 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/model_tag.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/nlp/
--rw-r--r--   0 runner    (1001) docker     (122)      499 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/__init__.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/distributed.py
--rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/load_checkpoint.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/nlp/space/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)     1909 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/args.py
--rw-r--r--   0 runner    (1001) docker     (122)    11818 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/clean_dataset.py
--rw-r--r--   0 runner    (1001) docker     (122)     1439 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/criterions.py
--rw-r--r--   0 runner    (1001) docker     (122)    11252 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/db_ops.py
--rw-r--r--   0 runner    (1001) docker     (122)     6174 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/ontology.py
--rw-r--r--   0 runner    (1001) docker     (122)      197 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/scores.py
--rw-r--r--   0 runner    (1001) docker     (122)     6356 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1054 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space/utils_dst.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope/utils/nlp/space_T_en/
--rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space_T_en/__init__.py
--rw-r--r--   0 runner    (1001) docker     (122)      859 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/space_T_en/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     2554 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/nlp/utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    40106 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/plugins.py
--rw-r--r--   0 runner    (1001) docker     (122)      572 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/pre_compile.py
--rw-r--r--   0 runner    (1001) docker     (122)     7833 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/registry.py
--rw-r--r--   0 runner    (1001) docker     (122)    30195 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/regress_test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6127 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/service_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     6243 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/streaming_output.py
--rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/task_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1593 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/tensor_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)    12532 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/test_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/timer.py
--rw-r--r--   0 runner    (1001) docker     (122)    10966 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/torch_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      597 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/trie.py
--rw-r--r--   0 runner    (1001) docker     (122)     1696 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/type_assert.py
--rw-r--r--   0 runner    (1001) docker     (122)      783 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/utils/url_utils.py
--rw-r--r--   0 runner    (1001) docker     (122)      272 2023-07-04 16:21:45.000000 modelscope-1.7.1/modelscope/version.py
-drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/
--rw-r--r--   0 runner    (1001) docker     (122)    19397 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (122)   133944 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (122)       59 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/entry_points.txt
--rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (122)     4850 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (122)       11 2023-07-04 16:22:43.000000 modelscope-1.7.1/modelscope.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (122)       38 2023-07-04 16:22:43.000000 modelscope-1.7.1/setup.cfg
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/
+-rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (122)    19508 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)    16077 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/README.md
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/
+-rw-r--r--   0 runner    (1001) docker     (122)     4020 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/cli/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      829 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/cli.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1230 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/download.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/modelcard.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4371 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/plugins.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/cli/template/
+-rw-r--r--   0 runner    (1001) docker     (122)      523 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/template/readme.tpl
+-rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/cli/template/template.tpl
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/configs/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/configs/examples/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-31 12:40:31.000000 modelscope-1.8.0rc0/modelscope/configs/examples/configuration.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/exporters/
+-rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/exporters/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2272 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/audio/ans_dfsmn_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2659 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      732 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/exporters/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)      869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2585 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/cv/cartoon_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3619 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/cv/face_detection_scrfd_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/cv/object_detection_damoyolo_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/exporters/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)      531 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/multi_modal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11238 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/multi_modal/stable_diffusion_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/csanmt_for_translation_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4579 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/model_for_token_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3409 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2316 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4809 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/tf_model_exporter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15145 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/exporters/torch_model_exporter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/fileio/
+-rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/file.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/fileio/format/
+-rw-r--r--   0 runner    (1001) docker     (122)      143 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/format/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      454 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/format/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1050 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/format/json.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13853 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/format/jsonplus.py
+-rw-r--r--   0 runner    (1001) docker     (122)      669 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/format/yaml.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4254 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/fileio/io.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/hub/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42689 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/api.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3927 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/check_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1628 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4066 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/errors.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12706 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/file_download.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8958 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/git.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7272 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/push_to_hub.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12489 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/repository.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7178 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/snapshot_download.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/hub/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9916 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/utils/caching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2978 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/hub/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56449 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metainfo.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)     3978 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/accuracy_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7530 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/action_detection_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1925 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/audio_noise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1454 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1726 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/bleu_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/metrics/ciderD/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       21 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ciderD/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1926 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ciderD/ciderD.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8931 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ciderD/ciderD_scorer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8664 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_color_enhance_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13387 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_colorization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10011 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_denoise_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_inpainting_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13318 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_instance_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1739 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_portrait_enhancement_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2536 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_quality_assessment_degradation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1632 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/image_quality_assessment_mos_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2231 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/inbatch_recall_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1358 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/loss_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3002 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/map_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2032 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/movie_scene_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ned_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2310 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ocr_recognition_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2082 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/ppl_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1163 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/prediction_saving_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4453 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/referring_video_object_segmentation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3112 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/sequence_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3694 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/text_generation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/text_ranking_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5765 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/token_classification_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5703 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/translation_evaluation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5435 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_frame_interpolation_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8655 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_stabilization_metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3092 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_summarization_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/matlab_functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/metric_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8932 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/niqe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1710 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      519 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1434 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2700 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5630 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1322 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14384 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/uni_deep_fsmn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14438 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/network/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9382 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/network/modulation_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15396 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/aec/network/se_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/
+-rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/complex_nn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3688 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/conv_stft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2513 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/denoise_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10241 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/frcrn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1468 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/activations.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/layer_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5284 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/uni_deep_fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1038 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/se_module_complex.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9833 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/ans/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/asr/
+-rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/asr/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/asr/generic_automatic_speech_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/itn/
+-rw-r--r--   0 runner    (1001) docker     (122)      557 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/itn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1462 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/itn/generic_inverse_text_processing.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/
+-rw-r--r--   0 runner    (1001) docker     (122)      735 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14349 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7861 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3521 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2608 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/model_def.py
+-rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/generic_key_word_spotting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3300 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/cmvn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17496 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/fsmn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6079 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/punc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/punc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1466 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/punc/generic_punctuation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2240 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/layer_norm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13963 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9142 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9004 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer_conv_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/
+-rw-r--r--   0 runner    (1001) docker     (122)     7326 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/DTDNN.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8425 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/DTDNN_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11692 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/ERes2Net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11358 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/ERes2Net_aug.py
+-rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6397 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/cluster_backend.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14980 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/ecapa_tdnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)      904 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/generic_speaker_verification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3743 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/lanuage_recognition_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3630 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/pooling_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16895 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/rdino.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12338 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/speaker_change_locator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3519 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/speaker_diarization_dialogue_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5170 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/audio/tts/
+-rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/tts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11845 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/tts/sambert_hifi.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/audio/tts/voice.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/base/base_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/base/base_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/base/base_torch_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5679 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/base/base_torch_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1812 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3806 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)      113 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/
+-rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6414 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/
+-rw-r--r--   0 runner    (1001) docker     (122)      145 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6729 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      493 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/action_detection_onnx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9364 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12132 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      709 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4304 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/s3dg.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/tada_convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45442 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14141 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/splat.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      496 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2589 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12660 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8773 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/w48.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/
+-rw-r--r--   0 runner    (1001) docker     (122)      601 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)       51 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8957 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8196 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/
+-rw-r--r--   0 runner    (1001) docker     (122)       98 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11552 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12870 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8080 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2516 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7719 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3401 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/
+-rw-r--r--   0 runner    (1001) docker     (122)     1216 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      713 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5158 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4563 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/facer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9075 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/model_tf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6072 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8519 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4404 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5265 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cartoon/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3876 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/c3d.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8949 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      414 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13516 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/annotator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4960 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      504 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10152 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2746 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5829 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8045 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15438 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9896 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25158 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12595 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3894 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9024 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8031 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/controlnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1100 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/cc_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22875 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      490 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/fair_face/
+-rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/fair_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2559 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      930 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4675 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/mogface.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5578 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/mogprednet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6264 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7072 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/
+-rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7061 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5415 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5232 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/LK/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/LK/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3578 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4210 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/facer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4832 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4766 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4590 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/
+-rw-r--r--   0 runner    (1001) docker     (122)      174 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/damofd_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      192 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)      325 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2945 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      292 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3423 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      471 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11707 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4169 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    30670 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5543 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      289 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      361 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4202 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3590 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16146 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      270 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    46999 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      295 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11062 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6092 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6395 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5970 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3451 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py
+-rw-r--r--   0 runner    (1001) docker     (122)      960 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/
+-rw-r--r--   0 runner    (1001) docker     (122)       90 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1477 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4126 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2058 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      571 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3719 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2845 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4621 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/
+-rw-r--r--   0 runner    (1001) docker     (122)      327 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15911 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20077 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2007 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/emotion_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/emotion_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2844 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/face.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/face_align.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/
+-rwxr-xr-x   0 runner    (1001) docker     (122)       89 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/conv2d_gradfix.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3104 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/fused_act.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5922 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/upfirdn2d.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    19998 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_generation/stylegan2.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4109 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/det_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12584 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/ghost_pan.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16846 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1833 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5791 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8874 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/align_face.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      473 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1080 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1977 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8551 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4744 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7186 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31337 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1428 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2583 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6561 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5124 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30403 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21235 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8821 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py
+-rw-r--r--   0 runner    (1001) docker     (122)      277 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/opt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31957 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5908 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)      779 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13410 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/renderer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31247 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      484 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/
+-rw-r--r--   0 runner    (1001) docker     (122)      121 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2414 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3277 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/
+-rw-r--r--   0 runner    (1001) docker     (122)      115 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4932 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/hand_static/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/hand_static/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2480 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/hand_static/hand_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10891 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/hand_static/networks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/
+-rw-r--r--   0 runner    (1001) docker     (122)     5936 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/Reconstruction.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4542 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/PixToMesh.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11301 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Res_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2418 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Surface_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2716 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/detectors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1982 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/geometry.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/human_segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11865 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/networks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6105 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2859 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/bnext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/
+-rw-r--r--   0 runner    (1001) docker     (122)      500 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3920 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6541 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13616 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/person_info.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12027 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5673 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1311 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15760 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/slim_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      598 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      107 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20295 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/beit_v2.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17261 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/nextvit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2185 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/mmcls_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1554 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/resnet50_cc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_classification/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/adaint/
+-rw-r--r--   0 runner    (1001) docker     (122)       44 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/adaint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14338 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/adaint/adaint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/csrnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/
+-rw-r--r--   0 runner    (1001) docker     (122)       66 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2575 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31764 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2821 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/image_color_enhance.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/
+-rw-r--r--   0 runner    (1001) docker     (122)      122 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9385 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6437 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9576 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6857 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7796 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6465 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6510 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/
+-rw-r--r--   0 runner    (1001) docker     (122)      129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10574 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/rrdb/
+-rw-r--r--   0 runner    (1001) docker     (122)       53 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/rrdb/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3005 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_deblur/
+-rw-r--r--   0 runner    (1001) docker     (122)      510 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_deblur/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4241 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4329 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12474 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3141 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      448 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6827 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10779 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1220 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1732 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4770 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23599 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4803 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3595 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2617 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11013 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/
+-rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/
+-rw-r--r--   0 runner    (1001) docker     (122)     6664 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1627 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6757 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18233 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10106 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26006 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13560 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1600 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/newcrfs_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2606 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1485 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2819 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2506 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8545 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)      999 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2022 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3124 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21432 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/
+-rw-r--r--   0 runner    (1001) docker     (122)      242 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3094 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5912 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10514 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/align_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9077 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/image_face_fusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3045 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/aad_layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8555 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9366 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/bfm.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12449 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/dense_motion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20604 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/facerecon_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7433 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/model_irse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7790 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/ops.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/
+-rw-r--r--   0 runner    (1001) docker     (122)      575 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11736 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8257 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8361 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5634 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/parsing_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2690 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7605 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/default.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1253 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/
+-rw-r--r--   0 runner    (1001) docker     (122)       81 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12202 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5348 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/adversarial.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1564 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/feature_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19052 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ffc.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11842 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/inception.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/perceptual.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13350 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/refinement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1065 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      664 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3826 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27174 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9305 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      101 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3992 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14867 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6266 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8692 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/
+-rw-r--r--   0 runner    (1001) docker     (122)      600 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10072 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15407 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18188 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7274 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6712 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1429 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11454 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1549 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7886 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6991 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/config/default.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/
+-rw-r--r--   0 runner    (1001) docker     (122)      171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      588 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7244 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3784 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3012 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2994 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9677 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10531 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3048 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2132 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2735 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/quadtree_attention_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      344 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_matching/utils/misc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      521 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8546 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18175 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9861 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9404 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21735 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3367 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_paintbyexample/
+-rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_paintbyexample/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_paintbyexample/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      513 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_panoptic_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1694 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8563 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/align_faces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1836 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4710 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    22869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/gpen.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7114 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4336 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3286 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3155 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7313 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/
+-rwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4845 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4676 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4120 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/
+-rw-r--r--   0 runner    (1001) docker     (122)      533 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10076 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3319 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5206 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      584 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4654 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2600 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5163 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/maniqa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23230 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/swin.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      272 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16222 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1060 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2651 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/
+-rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5444 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/pass_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14108 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/transreid_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/
+-rw-r--r--   0 runner    (1001) docker     (122)      527 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/demoire_models/
+-rw-r--r--   0 runner    (1001) docker     (122)       69 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/demoire_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10243 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/demoire_models/nets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2640 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/image_restoration_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      712 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7896 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5155 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2273 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3208 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/
+-rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1516 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2122 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/
+-rw-r--r--   0 runner    (1001) docker     (122)      303 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      290 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      249 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17484 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18241 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6379 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      251 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10785 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26514 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/
+-rw-r--r--   0 runner    (1001) docker     (122)      253 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12370 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      368 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      398 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1938 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1788 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/
+-rw-r--r--   0 runner    (1001) docker     (122)      650 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9312 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/
+-rw-r--r--   0 runner    (1001) docker     (122)     3740 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21275 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18023 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/unet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11210 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/skychange.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7874 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/skychange_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      120 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10476 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      603 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24469 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/losses.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      127 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3309 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/data/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10527 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/model_translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12670 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12594 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/
+-rw-r--r--   0 runner    (1001) docker     (122)      384 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21828 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/apps.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36549 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/degradation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24615 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1320 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/losses.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/metrics.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6736 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/random_color.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2745 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/random_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3777 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/svd.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6728 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/
+-rw-r--r--   0 runner    (1001) docker     (122)      518 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15834 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16386 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/landmark.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9109 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/try_on_infer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    46223 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/image_try_on/warping.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      486 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)      136 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4099 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2510 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3251 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14887 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/modality/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/modality/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5518 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3406 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4808 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1834 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/panovit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      542 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6441 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      508 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     1900 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     7275 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/models.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      826 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2690 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/
+-rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2151 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/cfg_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26783 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13594 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/mdm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5412 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3914 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/rotation2xyz.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/smpl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/get_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8465 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      181 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      798 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4291 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5057 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/trn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/
+-rw-r--r--   0 runner    (1001) docker     (122)      598 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2934 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/load_blender.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4301 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/load_data.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    17159 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/load_llff.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/load_tankstemple.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/read_write_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/nerf_preprocess.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    10526 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/nerf_recon_4k.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/network/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    77434 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/network/dvgo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/network/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/
+-rw-r--r--   0 runner    (1001) docker     (122)      602 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/dataloader/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18782 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7297 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7876 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13317 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/nerf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/segmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/
+-rw-r--r--   0 runner    (1001) docker     (122)      662 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/
+-rw-r--r--   0 runner    (1001) docker     (122)      315 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6055 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/blender.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10222 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/llff.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7105 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/nsvf.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10361 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/ray_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/dataloader/tankstemple.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3890 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/nerf_recon_vq_compression.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/
+-rw-r--r--   0 runner    (1001) docker     (122)       61 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23489 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11430 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF_VQ.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19228 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/tensorBase.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16555 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/network/weighted_vq.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7142 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/renderer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7854 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_vq_compression/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      606 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3432 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/
+-rw-r--r--   0 runner    (1001) docker     (122)      321 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      211 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21306 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      278 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2220 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11529 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9021 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      426 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      375 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8542 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      239 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17739 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21926 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1204 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/
+-rw-r--r--   0 runner    (1001) docker     (122)      467 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2657 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/depe_detect.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/
+-rw-r--r--   0 runner    (1001) docker     (122)      605 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/
+-rw-r--r--   0 runner    (1001) docker     (122)      299 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6670 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4476 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/
+-rw-r--r--   0 runner    (1001) docker     (122)      276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2041 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      294 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3095 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)      522 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7936 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8689 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12874 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      282 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7442 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    59197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)      255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9533 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9032 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      562 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18126 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5175 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11047 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/result_vis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      473 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26142 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/dbnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    31084 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/mix_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5974 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/proxyless.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8217 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7972 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6378 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/CRNN/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/CRNN/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3724 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/
+-rw-r--r--   0 runner    (1001) docker     (122)       43 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10662 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5031 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3710 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/open_vocabulary_detection_vild/
+-rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/open_vocabulary_detection_vild/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14225 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/open_vocabulary_detection_vild/vild.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      511 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5077 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/equi.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7500 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7839 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9175 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3962 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/pedestrian_attribute_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pedestrian_attribute_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3468 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pedestrian_attribute_recognition/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      495 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16147 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11898 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1797 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18618 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/
+-rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20974 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4340 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      528 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7978 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2194 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/seg_infer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      514 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      318 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8504 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9206 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7299 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7935 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6242 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16610 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2091 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5629 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5180 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27941 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/robust_image_classification/
+-rw-r--r--   0 runner    (1001) docker     (122)      501 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/robust_image_classification/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/robust_image_classification/easyrobust_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)      219 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5374 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15565 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5737 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15735 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26071 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17279 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/networks/util_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/s2net_panorama_depth_estimation/s2net_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      213 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)     6558 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py
+-rw-r--r--   0 runner    (1001) docker     (122)      256 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6525 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/senet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12007 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/u2net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3524 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2704 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/salient_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2203 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4385 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/head_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)    32989 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/models.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9319 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/neck_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5632 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/shop_seg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4095 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/shop_seg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6699 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/detection_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2532 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5759 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3233 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10898 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/box_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3911 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4799 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5003 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/predict_single.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1035 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/prior_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3890 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/unet_deploy.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9917 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1169 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/weights_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/
+-rw-r--r--   0 runner    (1001) docker     (122)      526 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/data/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2094 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/data/data_augment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)      165 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      274 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/base_exp.py
+-rw-r--r--   0 runner    (1001) docker     (122)      392 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/build.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/default/
+-rw-r--r--   0 runner    (1001) docker     (122)      137 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/default/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1845 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/yolox_base.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      238 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6274 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10911 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6156 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/network_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1314 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/streamyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5669 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/tal_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4352 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/realtime_video_detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      270 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3681 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)      209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/utils/format.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      555 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7652 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/arch_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10508 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/ecb.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3525 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/ecbsr_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/rrdbnet_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/
+-rw-r--r--   0 runner    (1001) docker     (122)      462 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16198 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/lineless_table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3360 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/model_lore.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12614 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/lore_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15090 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/lore_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)      777 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7587 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4143 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6145 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18951 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16418 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5165 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_to_360panorama_image/
+-rw-r--r--   0 runner    (1001) docker     (122)      680 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_to_360panorama_image/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39007 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_to_360panorama_image/pipeline_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56816 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/text_to_360panorama_image/pipeline_sr.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/
+-rw-r--r--   0 runner    (1001) docker     (122)      594 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43681 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/basic_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2174 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/global_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2902 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/master_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/model_zoo.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/plain_net_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7405 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14983 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8709 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6923 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2067 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4000 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3460 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8123 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2345 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5911 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2842 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/
+-rw-r--r--   0 runner    (1001) docker     (122)      148 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/
+-rw-r--r--   0 runner    (1001) docker     (122)      621 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3701 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9356 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7465 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14261 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10559 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13101 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    18626 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7526 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      561 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12602 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19162 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5588 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12284 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7347 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24842 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3499 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/detectors/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/detectors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2809 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2627 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2774 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11594 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5838 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1164 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6400 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)      627 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py
+-rw-r--r--   0 runner    (1001) docker     (122)      643 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/tinynas_detector.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/
+-rw-r--r--   0 runner    (1001) docker     (122)     2896 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py
+-rw-r--r--   0 runner    (1001) docker     (122)      494 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      773 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/deinterlace_arch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3159 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/archs.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1441 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2972 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/enh.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/fre.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3716 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/configs/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/configs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/configs/default_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6731 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/dro_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5494 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/camera.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2285 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3737 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/pose.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3685 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5277 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2356 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10098 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7204 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4387 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10532 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8902 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1607 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1915 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15781 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8039 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6815 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/augmentations.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10248 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15068 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/depth.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1153 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/horovod.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10965 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9407 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/image_gt.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6499 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/load.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2726 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/misc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1348 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/types.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)     1894 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3334 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      458 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3212 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9228 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5346 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/update.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/
+-rw-r--r--   0 runner    (1001) docker     (122)    13745 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4049 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3823 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16050 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36415 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3314 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2907 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/
+-rw-r--r--   0 runner    (1001) docker     (122)      558 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1324 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/
+-rw-r--r--   0 runner    (1001) docker     (122)       36 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2662 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5506 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/effv2.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2904 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/lraspp.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2234 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/matting.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      524 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11056 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/inpainting.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13727 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/inpainting_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      582 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18236 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21551 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20983 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4136 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)      525 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11733 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26843 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4163 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18059 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/video_knet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2970 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2420 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/decode.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1890 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4921 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/yolo.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1084 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3117 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14995 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2230 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9570 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7296 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2888 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/aggregate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3582 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/cbam.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1979 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/eval_network.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3980 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/inference_core.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7037 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/mod_resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)      974 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15309 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/modules.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5593 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/network.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      477 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10040 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26628 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/
+-rw-r--r--   0 runner    (1001) docker     (122)      515 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8349 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20677 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28653 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4081 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6696 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8627 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5885 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/neck/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/neck/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/track/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/track/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8508 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17155 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5440 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/visualizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/config/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/config/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1024 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/config/ostrack.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5004 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4805 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1234 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3380 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3393 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)      653 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12278 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3497 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py
+-rw-r--r--   0 runner    (1001) docker     (122)      943 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4473 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/
+-rw-r--r--   0 runner    (1001) docker     (122)      114 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7123 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/utils/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/
+-rw-r--r--   0 runner    (1001) docker     (122)    14702 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/MotionPro.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3290 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9214 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5275 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5526 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3922 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/Smoother.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1447 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7292 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7981 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3452 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     4684 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14212 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/MedianFilter.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22544 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2893 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/WarpUtils.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14474 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/image_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4977 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/math_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/
+-rw-r--r--   0 runner    (1001) docker     (122)      487 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5774 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4848 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9990 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3905 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/
+-rw-r--r--   0 runner    (1001) docker     (122)      536 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4959 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/base_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1221 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/cpd_auto.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3238 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13098 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/pgl_sum.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8812 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/summarizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      689 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14118 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/basicvsr_net.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4727 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3636 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3637 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    40074 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25588 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/deformable_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7436 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/fpn_fusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16697 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3651 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vidt/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/virual_tryon/
+-rw-r--r--   0 runner    (1001) docker     (122)      464 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/virual_tryon/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17690 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/virual_tryon/sdafnet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      502 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16152 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)      797 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1786 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9340 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/petl.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5021 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5040 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5614 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5749 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28089 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6494 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6192 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/vim.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/
+-rw-r--r--   0 runner    (1001) docker     (122)      919 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12238 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5188 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/basic_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13520 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5299 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/model_se.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5177 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/tokenization_clip.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     2182 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       97 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14496 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/bert_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3898 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/configuration_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22351 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20998 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/modeling_bert.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip_interrogator/
+-rw-r--r--   0 runner    (1001) docker     (122)       37 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip_interrogator/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24293 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/clip_interrogator/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26652 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14447 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39910 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/structbert.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11834 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8566 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12361 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44602 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/dpm_solver_pytorch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12939 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/
+-rw-r--r--   0 runner    (1001) docker     (122)      139 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21694 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/gemm_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3718 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/gemm_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      548 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36265 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2969 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/respace.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1365 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/script.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36898 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/unet.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/
+-rw-r--r--   0 runner    (1001) docker     (122)     1444 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)   101942 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8651 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3268 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10331 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/
+-rw-r--r--   0 runner    (1001) docker     (122)      141 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/dataloaders/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/dataloaders/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/
+-rw-r--r--   0 runner    (1001) docker     (122)      162 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9790 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1442 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21257 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18790 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/module_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3577 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/module_cross.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5581 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/tokenization_clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4116 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/until_module.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)      739 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       86 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16605 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/clip/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6030 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/configuration_mplug.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)   120753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/modeling_mplug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    34049 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/mvit.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    21332 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/predictor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5536 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_for_all_tasks.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/
+-rw-r--r--   0 runner    (1001) docker     (122)      835 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10465 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py
+-rw-r--r--   0 runner    (1001) docker     (122)    70240 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10208 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11503 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28436 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13487 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/prior.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6898 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16675 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6565 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      306 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/adaptor/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/adaptor/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/configuration_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16552 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/configuration_ofa.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1785 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21049 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5658 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)    43439 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/search.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41976 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/sequence_generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16690 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4883 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44296 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/modeling_mmspeech.py
+-rw-r--r--   0 runner    (1001) docker     (122)   100933 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/modeling_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13226 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/resnet.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15028 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/tokenization_ofa.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8004 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      676 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1877 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8435 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/vit.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24779 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa_for_all_tasks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12983 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4865 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3410 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/rleg.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/
+-rw-r--r--   0 runner    (1001) docker     (122)      678 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9838 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/blocks.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11896 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/clip.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6165 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22584 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/swin_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4885 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1597 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6903 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)      140 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5181 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/team/team_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11502 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/team/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18477 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/autoencoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9264 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9564 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/unet_sd.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/
+-rw-r--r--   0 runner    (1001) docker     (122)       93 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11339 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16687 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/model.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47348 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/processing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4680 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7333 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/transformer_local.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/T5/
+-rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    67374 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/T5/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7541 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/T5/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21517 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/T5/text2text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7172 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bart/
+-rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bart/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3058 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bart/text_error_correction.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1519 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40458 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7308 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4113 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)      512 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6074 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/sentence_embedding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7153 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/siamese_uie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1478 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1138 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2140 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/token_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6904 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bert/word_alignment.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bloom/
+-rw-r--r--   0 runner    (1001) docker     (122)      472 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bloom/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      505 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/bloom/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/canmt/
+-rw-r--r--   0 runner    (1001) docker     (122)      102 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/canmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52235 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/canmt/canmt_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2940 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/canmt/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    35688 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/canmt/sequence_generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/
+-rw-r--r--   0 runner    (1001) docker     (122)     1578 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4403 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/quantization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    60869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17422 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1584 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15206 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/quantization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55471 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10173 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      730 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    35473 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3995 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4008 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9997 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/inference.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     6111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/csanmt/
+-rw-r--r--   0 runner    (1001) docker     (122)       96 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/csanmt/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    61868 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/csanmt/translation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    47998 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10364 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10698 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/
+-rw-r--r--   0 runner    (1001) docker     (122)      939 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7092 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1656 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_T5/
+-rw-r--r--   0 runner    (1001) docker     (122)     1082 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_T5/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8108 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_T5/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/
+-rw-r--r--   0 runner    (1001) docker     (122)     1181 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45112 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5045 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6709 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/
+-rw-r--r--   0 runner    (1001) docker     (122)      540 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/generation/
+-rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/generation/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    10112 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/generation/strategies.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5152 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/initialize.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/kernels/
+-rw-r--r--   0 runner    (1001) docker     (122)     3263 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/kernels/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/
+-rw-r--r--   0 runner    (1001) docker     (122)     2635 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/functional.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4510 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/layers.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    13504 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt2/
+-rw-r--r--   0 runner    (1001) docker     (122)      470 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt2/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/
+-rw-r--r--   0 runner    (1001) docker     (122)      852 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16094 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8971 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52139 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/distributed_gpt3.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2586 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/
+-rw-r--r--   0 runner    (1001) docker     (122)      874 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5198 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/checkpointing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4930 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49316 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/experts.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3504 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/layer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2553 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/mappings.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23756 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2717 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2277 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_neo/
+-rw-r--r--   0 runner    (1001) docker     (122)      474 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_neo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      518 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/gpt_neo/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/
+-rw-r--r--   0 runner    (1001) docker     (122)      661 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25248 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/crf_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6947 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/fill_mask_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5145 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/infromation_extraction_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2056 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)      964 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_generation_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2029 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_ranking_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2596 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/token_classification_head.py
+-rw-r--r--   0 runner    (1001) docker     (122)      948 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/heads/torch_pretrain_head.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/hf_transformers/
+-rw-r--r--   0 runner    (1001) docker     (122)      488 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/hf_transformers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4897 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/hf_transformers/backbone.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/
+-rw-r--r--   0 runner    (1001) docker     (122)      866 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    29189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4695 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11349 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7557 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10325 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4712 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/
+-rw-r--r--   0 runner    (1001) docker     (122)      876 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    32097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8226 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10447 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16964 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/llama2/tokenization_fast.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/lstm/
+-rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/lstm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1312 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/lstm/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2187 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/lstm/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/
+-rw-r--r--   0 runner    (1001) docker     (122)      688 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    39864 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6599 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12452 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/fill_mask.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/
+-rw-r--r--   0 runner    (1001) docker     (122)      572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    28115 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/arguments.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28162 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/blocklm_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17995 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/configure_data.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)    13656 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    20350 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/corpora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45765 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/datasets.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3342 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/extraction.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     8459 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/lazy_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7221 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/samplers.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4661 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    53304 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/tokenization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14551 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    15773 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/wordpiece.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21669 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/generation_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16247 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/mglm_for_text_summarization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/
+-rwxr-xr-x   0 runner    (1001) docker     (122)      984 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     5443 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9967 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/downstream.py
+-rw-r--r--   0 runner    (1001) docker     (122)    70249 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/modeling_bert.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8743 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/modeling_glm.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2531 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/prompt.py
+-rw-r--r--   0 runner    (1001) docker     (122)    48886 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/process_grid.py
+-rw-r--r--   0 runner    (1001) docker     (122)      203 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/run_test.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      950 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/test_block.py
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/test_rel_shift.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17815 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/train_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19029 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/mglm/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/
+-rw-r--r--   0 runner    (1001) docker     (122)     1268 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5532 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29453 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/dureader_eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55450 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    55772 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11708 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6166 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/sas_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4933 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/peer/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/
+-rwxr-xr-x   0 runner    (1001) docker     (122)     3321 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/AnnealingLR.py
+-rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    41209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11797 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10983 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/distributed_plug.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8427 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug/generator.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/
+-rw-r--r--   0 runner    (1001) docker     (122)     1359 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7671 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    47486 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10881 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/text_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/polylm/
+-rw-r--r--   0 runner    (1001) docker     (122)      499 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/polylm/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1947 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/polylm/text_generation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/
+-rw-r--r--   0 runner    (1001) docker     (122)     1490 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    37918 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6366 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4176 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/document_segmentation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11011 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7147 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/ponet/tokenization.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)      987 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1208 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3832 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_intent_prediction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4354 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_modeling.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16648 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_state_tracking.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/
+-rw-r--r--   0 runner    (1001) docker     (122)      421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10281 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/gen_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10757 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/generator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7505 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/intent_unified_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3032 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/model_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/tokenization_space.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11941 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/model/unified_transformer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2398 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/embedder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/feedforward.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1721 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/functions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3397 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/multihead_attention.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1922 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/transformer_block.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    44438 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5194 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30117 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/table_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      492 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3715 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/space_T_en/text_to_sql.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/
+-rw-r--r--   0 runner    (1001) docker     (122)     1674 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7673 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/adv_utils.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)    40848 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7686 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27203 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/faq_question_answering.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12581 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11862 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11074 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/structbert/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/
+-rw-r--r--   0 runner    (1001) docker     (122)     1453 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5323 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/feature_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2698 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)      766 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/information_extraction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28991 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/task_model.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1912 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8678 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2092 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_ranking.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5116 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/task_models/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/unite/
+-rw-r--r--   0 runner    (1001) docker     (122)      626 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/unite/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      409 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/unite/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18320 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/unite/translation_evaluation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/use/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/use/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5133 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/use/transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5832 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/use/user_satisfaction_estimation.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/
+-rw-r--r--   0 runner    (1001) docker     (122)     1479 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4031 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1192 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/configuration.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4278 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/fill_mask.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6643 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/veco/token_classification.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/
+-rw-r--r--   0 runner    (1001) docker     (122)     1156 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42932 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/backbone.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7697 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/configuration.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      491 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24057 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/
+-rw-r--r--   0 runner    (1001) docker     (122)      634 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    49139 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/data_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19691 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/msa_pairing.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8941 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/process.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14792 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/process_multimer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11422 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/protein.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42023 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/residue_constants.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4628 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/data/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19250 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/model.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      187 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17066 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/alphafold.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12323 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/attentions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5403 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/auxillary_heads.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10676 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/common.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5814 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/confidence.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/embedders.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11078 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/evoformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6820 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/featurization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18025 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/frame.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18476 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/structure_module.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9771 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/template.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5623 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/triangle_multiplication.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/
+-rw-r--r--   0 runner    (1001) docker     (122)       46 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17940 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/mmcif.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3128 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/msa_identifiers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23503 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/parsers.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    45468 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/templates.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)      639 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6218 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hhblits.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3991 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hhsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5098 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hmmbuild.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5013 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hmmsearch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8662 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/jackhmmer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3752 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/kalign.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2892 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/
+-rw-r--r--   0 runner    (1001) docker     (122)       84 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      346 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/audio/asr_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/auth/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/auth/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1326 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/auth/auth_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/context/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/context/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3444 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/context/dataset_context_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_files/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_files/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5270 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_files/data_files_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12636 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5764 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/data_loader_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/
+-rw-r--r--   0 runner    (1001) docker     (122)      111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)     4111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      730 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1919 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8512 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7723 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11689 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/
+-rw-r--r--   0 runner    (1001) docker     (122)      541 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1264 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      791 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/
+-rw-r--r--   0 runner    (1001) docker     (122)      134 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4708 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)      945 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)      177 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3815 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16180 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/
+-rw-r--r--   0 runner    (1001) docker     (122)      934 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/
+-rw-r--r--   0 runner    (1001) docker     (122)      544 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/
+-rw-r--r--   0 runner    (1001) docker     (122)      312 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2622 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4858 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1469 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/
+-rw-r--r--   0 runner    (1001) docker     (122)      196 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1086 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1511 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2141 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/
+-rw-r--r--   0 runner    (1001) docker     (122)      539 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2196 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/
+-rw-r--r--   0 runner    (1001) docker     (122)      529 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2968 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12152 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12574 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/
+-rw-r--r--   0 runner    (1001) docker     (122)      577 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1091 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1629 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/
+-rw-r--r--   0 runner    (1001) docker     (122)      615 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1487 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/
+-rw-r--r--   0 runner    (1001) docker     (122)      583 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1194 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4849 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6225 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      559 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4013 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/
+-rw-r--r--   0 runner    (1001) docker     (122)      161 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1589 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4945 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5437 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/
+-rw-r--r--   0 runner    (1001) docker     (122)       40 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7547 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3416 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/
+-rw-r--r--   0 runner    (1001) docker     (122)      309 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3172 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      971 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5818 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2000 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3512 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)      707 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4912 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2402 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2017 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      599 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16767 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8725 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/
+-rw-r--r--   0 runner    (1001) docker     (122)      545 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1475 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1984 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2684 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5114 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1635 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2664 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/
+-rw-r--r--   0 runner    (1001) docker     (122)      573 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1390 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/
+-rw-r--r--   0 runner    (1001) docker     (122)      543 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      809 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2624 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/
+-rw-r--r--   0 runner    (1001) docker     (122)      553 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2370 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11485 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/download/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/download/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21287 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/download/dataset_builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      640 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/download/download_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2487 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/download/download_manager.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/meta/
+-rw-r--r--   0 runner    (1001) docker     (122)       50 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/meta/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1772 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/meta/data_meta_config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8679 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/meta/data_meta_manager.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36737 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/ms_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/
+-rw-r--r--   0 runner    (1001) docker     (122)     1072 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      408 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/gopro_image_deblurring_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      401 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/reds_image_deblurring_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/sidd_image_denoising.py
+-rw-r--r--   0 runner    (1001) docker     (122)      410 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/torch_base_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)      404 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/video_summarization_dataset.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8124 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/dataset_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1026 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/delete_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5540 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/maxcompute_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6200 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/oss_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2496 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/msdatasets/utils/upload_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/4knerf/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/4knerf/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/Ailut/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/Ailut/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/Ailut/csrc/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/Ailut/csrc/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      105 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4314 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/ailut/pyinterfaces.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/
+-rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/functions/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/functions/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2925 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/functions/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/modules/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/modules/quadtree_attention.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/src/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/src/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/outputs/
+-rw-r--r--   0 runner    (1001) docker     (122)      132 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/outputs/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      908 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/outputs/cv_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19855 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/outputs/nlp_outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    52143 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/outputs/outputs.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11586 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipeline_inputs.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/
+-rw-r--r--   0 runner    (1001) docker     (122)      150 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)     1567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7519 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/ans_dfsmn_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5016 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/ans_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/asr_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3189 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4357 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/inverse_text_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3830 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/kws_farfield_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/kws_kwsbp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5698 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/language_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5642 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/linear_aec_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8068 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/lm_infer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6481 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/punctuation_processing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12545 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/segmentation_clustering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2560 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/separation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4829 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_change_locating_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6038 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_diarization_dialogue_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_diarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4246 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_diarization_semantic_speaker_turn_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4078 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6089 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_light_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10817 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4072 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/text_to_speech_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11930 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/timestamp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9696 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/audio/voice_activity_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23185 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7702 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)    16754 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2545 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/action_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4852 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/action_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4024 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/animal_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2576 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/arc_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2614 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/bad_image_detecting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14219 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/card_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2528 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/content_check_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5055 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/controllable_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5942 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/crowd_counting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5136 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1965 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3993 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1531 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_emotion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2894 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_image_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3312 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_liveness_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3573 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_liveness_xc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7748 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_processing_base_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3872 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_quality_assessment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3528 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3493 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2878 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_ood_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19634 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/face_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2400 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2681 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4442 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4030 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/general_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1360 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/hand_static_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2982 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/human_reconstruction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1399 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_body_reshaping_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2919 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5251 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_cartoon_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5857 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3296 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_color_enhance_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4441 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2648 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_debanding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4624 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_deblur_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3517 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4160 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_denoise_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1943 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1854 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4134 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_driving_perception_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2317 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_face_fusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4866 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_human_parsing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5854 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4673 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3903 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5929 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_matching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2796 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2770 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6113 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_paintbyexample_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3549 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2835 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2801 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_reid_person_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1702 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_restoration_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1644 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_salient_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3207 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2237 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_skychange_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2839 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4615 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_style_transfer_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3138 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9718 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_to_image_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12737 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_to_image_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2319 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/image_try_on_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1883 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     9872 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4570 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/license_plate_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4182 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5276 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/live_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2757 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/mask_face_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2787 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3670 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1857 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/mog_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4844 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/motion_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2628 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1953 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3245 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/nerf_recon_4k_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3328 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3592 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/nerf_recon_vq_compression_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6018 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/object_detection_3d_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11033 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_recognition_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)      966 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      720 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19821 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_dla34.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8768 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5286 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_vlpt.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/
+-rw-r--r--   0 runner    (1001) docker     (122)      550 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11644 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1560 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38278 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19004 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11371 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/resnet_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11168 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/table_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7971 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3029 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2791 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/panorama_depth_estimation_s2net_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9781 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4199 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1457 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1451 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/product_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2020 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9239 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/retina_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1760 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/shop_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/skin_retouching_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4446 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/table_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4899 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       10 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15542 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_utils/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1841 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8865 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/text_to_360panorama_image_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3246 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tinynas_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3244 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/tinynas_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1888 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13776 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_category_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_colorization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7757 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_deinterlace_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1565 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_depth_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24271 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3635 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_human_matting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1719 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_inpainting_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9652 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3294 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4724 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_object_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4683 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3436 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_stabilization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4289 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7078 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/video_super_resolution_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7564 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/vidt_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5240 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/virtual_try_on_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3986 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2180 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/vision_middleware_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4762 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/vop_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5787 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)     3057 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2366 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/asr_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/
+-rw-r--r--   0 runner    (1001) docker     (122)      622 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2026 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      704 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8750 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/
+-rw-r--r--   0 runner    (1001) docker     (122)      585 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15631 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py
+-rw-r--r--   0 runner    (1001) docker     (122)    18987 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2311 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3086 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1093 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9352 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/gridvlp_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3219 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/image_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1612 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1648 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3254 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8561 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1848 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/sudoku_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1059 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text2sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3796 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2150 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_captioning_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1329 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1956 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1780 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1781 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2396 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     6953 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6939 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3696 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/canmt_translation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2202 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     2885 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2251 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2577 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2308 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_modeling_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7663 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3882 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1851 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4425 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_plug_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2754 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25997 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5480 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9797 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6259 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/extractive_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3348 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/faq_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2437 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3258 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/feature_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/fid_dialogue_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4655 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/fill_mask_pipeline.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)      999 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2383 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/information_extraction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6363 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/interactive_translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9928 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/language_identification_pipline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4079 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/llama2_text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1776 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2955 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2671 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/polylm_text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3184 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/sentence_embedding_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14334 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/siamese_uie_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2566 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/summarization_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16315 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/table_question_answering_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6787 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3490 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_error_correction_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11117 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_generation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2877 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_ranking_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6399 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/token_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4372 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_evaluation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5586 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2339 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4613 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2713 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/word_alignment_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4523 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/word_segmentation_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5875 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2816 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/pipeline_template.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/pipelines/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      538 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8255 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/science/protein_structure_pipeline.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3492 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/pipelines/util.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/
+-rw-r--r--   0 runner    (1001) docker     (122)     5792 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10063 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8680 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/audio.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15531 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)      812 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6982 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/common.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1896 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7446 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/action_detection_mapper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1126 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/controllable_image_generation.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20909 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/cv2_transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12826 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1250 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_quality_assessment_man.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2113 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_quality_assessment_mos.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2790 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_restoration_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2625 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/mmcls_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3050 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/timer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3606 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1501 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/video_stabilization.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8579 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/cv/video_super_resolution.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13406 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/image.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4884 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/kws.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/movie_scene_segmentation/
+-rw-r--r--   0 runner    (1001) docker     (122)      483 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/movie_scene_segmentation/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10809 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/movie_scene_segmentation/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30257 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/multi_modal.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     5966 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3929 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/canmt_translation.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2572 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4102 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4391 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4086 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11004 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6844 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3304 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12086 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/fill_mask_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8199 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1168 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4023 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1424 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)     1219 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1908 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1553 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/batch.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3629 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/data_loader.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2701 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2789 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5457 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    56779 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dst_processors.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      592 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    33884 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/gen_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42467 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/intent_field.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1147 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/lazy_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1935 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/preprocess.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1610 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/sampler.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2084 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/tensorlistdataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24803 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/tokenizer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/
+-rw-r--r--   0 runner    (1001) docker     (122)      654 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4936 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/database.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15867 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4888 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4175 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)      846 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4902 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/
+-rw-r--r--   0 runner    (1001) docker     (122)      818 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21521 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12500 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/parse.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1380 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2111 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6422 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1641 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_clean.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2298 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_error_correction.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14124 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_generation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3834 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_ranking_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19629 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1640 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1238 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4482 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/transformers_tokenizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7304 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3622 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4962 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/word_alignment_preprocessor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2584 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)      762 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4839 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/asr.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11909 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4172 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/image_captioning.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6461 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/image_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5740 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/ocr_recognition.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4603 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/sudoku.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5210 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/summarization.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16449 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text2sql.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5368 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text_classification.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2164 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text_to_image_synthesis.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3221 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/audio_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8936 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6809 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/collate.py
+-rw-r--r--   0 runner    (1001) docker     (122)      660 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/constant.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3421 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/get_tables.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1302 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/random_help.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5459 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/text2phone.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19116 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/transforms.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9581 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/vision_helper.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7664 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_entailment.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8484 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_grounding.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6796 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_question_answering.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/preprocessors/science/
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/science/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21698 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/science/uni_fold.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13735 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/speaker.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2101 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/tts.py
+-rw-r--r--   0 runner    (1001) docker     (122)    13168 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/preprocessors/video.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/swift/
+-rw-r--r--   0 runner    (1001) docker     (122)     1394 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7462 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/adapter.py
+-rw-r--r--   0 runner    (1001) docker     (122)      841 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)    38973 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/control_sd_lora.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27160 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/lora.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/swift/optimizers/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/optimizers/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6931 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9560 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/prompt.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8811 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/swift/sd_lora.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/tools/
+-rw-r--r--   0 runner    (1001) docker     (122)       49 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/tools/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      772 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/tools/eval.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5359 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/tools/speech_tts_autolabel.py
+-rw-r--r--   0 runner    (1001) docker     (122)      607 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/tools/train.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/
+-rw-r--r--   0 runner    (1001) docker     (122)     1799 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)      826 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1873 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/ans_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6969 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/asr_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12816 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_farfield_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22065 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_nearfield_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)     1768 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22114 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/batch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11499 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/det_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7022 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4509 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/model_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2854 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/runtime_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    21962 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/separation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10858 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/audio/tts_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4389 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1808 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5553 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cli_argument_parser.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)     1974 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7494 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/action_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      668 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/card_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10044 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/cartoon_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6737 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/face_detection_scrfd_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20323 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_classifition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11655 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    22965 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_detection_damoyolo_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4405 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_inpainting_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      816 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_instance_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5520 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/image_portrait_enhancement_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)      680 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/movie_scene_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20149 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/nerf_recon_acc_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    16911 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/ocr_detection_db_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3153 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/ocr_recognition_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2248 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4602 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/cv/vision_efficient_tuning_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2607 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/default_config.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/
+-rw-r--r--   0 runner    (1001) docker     (122)     2064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/
+-rw-r--r--   0 runner    (1001) docker     (122)      116 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19610 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11015 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5541 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      764 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/
+-rw-r--r--   0 runner    (1001) docker     (122)      610 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4812 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/sparsity_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6915 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1458 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/ddp_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17119 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/deepspeed_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7030 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/megatron_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4398 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/early_stop_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3825 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/evaluation_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)      731 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/iter_timer_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/
+-rw-r--r--   0 runner    (1001) docker     (122)      718 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4498 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4507 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/tensorboard_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7443 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/text_logger_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/lr_scheduler_hook.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)      743 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3139 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3786 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3729 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1707 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/hooks/priority.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/
+-rw-r--r--   0 runner    (1001) docker     (122)      699 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2040 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/
+-rw-r--r--   0 runner    (1001) docker     (122)      614 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2547 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/base.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2934 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/warmup.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/
+-rw-r--r--   0 runner    (1001) docker     (122)      682 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/__init__.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/
+-rw-r--r--   0 runner    (1001) docker     (122)       89 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9702 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/clip_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4388 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/custom_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/custom_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    32625 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/custom_diffusion/custom_diffusion_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/dreambooth_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      118 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15264 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3047 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/lora_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      106 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/lora_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3503 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8086 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mplug/
+-rw-r--r--   0 runner    (1001) docker     (122)       91 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mplug/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1642 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mplug/mplug_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/
+-rw-r--r--   0 runner    (1001) docker     (122)       87 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    10186 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/ofa_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17647 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/stable_diffusion/
+-rw-r--r--   0 runner    (1001) docker     (122)      112 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/stable_diffusion/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1144 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/
+-rw-r--r--   0 runner    (1001) docker     (122)       95 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5429 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/team_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2443 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/team_trainer_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)     1332 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    14266 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/csanmt_translation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     9999 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    24284 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8159 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12769 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/faq_question_answering_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3064 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/gpt3_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2097 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/gpt_moe_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8171 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/plug_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3869 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/sentence_embedding_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     8378 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/sequence_classification_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17110 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/siamese_uie_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5324 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/dialog_intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4229 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/dialog_modeling_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    36354 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/eval.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/metrics/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/metrics/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2447 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/metrics/metrics_tracker.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30567 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/gen_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    29570 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/intent_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    20453 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/table_question_answering_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1367 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/text_generation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7514 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/text_ranking_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15326 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp/translation_evaluation_trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/nlp_trainer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/optimizer/
+-rw-r--r--   0 runner    (1001) docker     (122)      210 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/optimizer/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1753 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/optimizer/builder.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/parallel/
+-rw-r--r--   0 runner    (1001) docker     (122)       80 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/parallel/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      681 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/parallel/builder.py
+-rw-r--r--   0 runner    (1001) docker     (122)      754 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/parallel/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    59372 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/trainer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    17846 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/training_args.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/trainers/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11090 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/utils/inference.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1294 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/trainers/utils/log_buffer.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/
+-rw-r--r--   0 runner    (1001) docker     (122)       56 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)   545816 2023-07-31 12:41:36.000000 modelscope-1.8.0rc0/modelscope/utils/ast_index_file.py
+-rw-r--r--   0 runner    (1001) docker     (122)    28920 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/ast_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/audio/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/audio/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11795 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/audio/audio_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2428 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/audio/tts_exceptions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    26390 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/checkpoint.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2573 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/chinese_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    27433 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/config.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1027 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/config_ds.py
+-rw-r--r--   0 runner    (1001) docker     (122)    19245 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/constant.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/cv/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)    23195 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/image_utils.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2307 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/motion_process.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3847 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/plot_script.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4290 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/rotation_conversions.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3145 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/data_collators.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1279 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/data_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     3744 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/device.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6522 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/error.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1128 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/file_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     4501 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/hf_util.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5939 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/hub.py
+-rw-r--r--   0 runner    (1001) docker     (122)    15900 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/import_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25766 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/input_output.py
+-rw-r--r--   0 runner    (1001) docker     (122)      296 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/input_output_typing.py
+-rw-r--r--   0 runner    (1001) docker     (122)      478 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/json_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2817 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/logger.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7612 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/megatron_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2335 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/metric.py
+-rw-r--r--   0 runner    (1001) docker     (122)     5099 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/model_tag.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/
+-rw-r--r--   0 runner    (1001) docker     (122)      499 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/__init__.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4424 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/distributed.py
+-rwxr-xr-x   0 runner    (1001) docker     (122)     4526 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/load_checkpoint.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1909 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/args.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11818 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/clean_dataset.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1439 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/criterions.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11252 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/db_ops.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6174 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/ontology.py
+-rw-r--r--   0 runner    (1001) docker     (122)      197 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/scores.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6356 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1054 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space/utils_dst.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space_T_en/
+-rw-r--r--   0 runner    (1001) docker     (122)        0 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space_T_en/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (122)      859 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/space_T_en/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2554 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/nlp/utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    42024 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/plugins.py
+-rw-r--r--   0 runner    (1001) docker     (122)      697 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/pre_compile.py
+-rw-r--r--   0 runner    (1001) docker     (122)     7833 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/registry.py
+-rw-r--r--   0 runner    (1001) docker     (122)    30195 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/regress_test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     6127 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/service_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    25333 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/streaming_output.py
+-rw-r--r--   0 runner    (1001) docker     (122)     2500 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/task_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1593 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/tensor_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)    12532 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/test_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1209 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/timer.py
+-rw-r--r--   0 runner    (1001) docker     (122)    11129 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/torch_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      597 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/trie.py
+-rw-r--r--   0 runner    (1001) docker     (122)     1696 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/type_assert.py
+-rw-r--r--   0 runner    (1001) docker     (122)      783 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/utils/url_utils.py
+-rw-r--r--   0 runner    (1001) docker     (122)      275 2023-07-31 12:40:32.000000 modelscope-1.8.0rc0/modelscope/version.py
+drwxr-xr-x   0 runner    (1001) docker     (122)        0 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (122)    19508 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (122)   138147 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       59 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/entry_points.txt
+-rw-r--r--   0 runner    (1001) docker     (122)        1 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (122)     5022 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       11 2023-07-31 12:41:37.000000 modelscope-1.8.0rc0/modelscope.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (122)       38 2023-07-31 12:41:38.000000 modelscope-1.8.0rc0/setup.cfg
```

### Comparing `modelscope-1.7.1/PKG-INFO` & `modelscope-1.8.0rc0/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: modelscope
-Version: 1.7.1
+Version: 1.8.0rc0
 Summary: ModelScope: bring the notion of Model-as-a-Service to life.
 Home-page: https://github.com/modelscope/modelscope
 Author: ModelScope team
 Author-email: contact@modelscope.cn
 License: Apache License 2.0
 Description: 
         <p align="center">
@@ -25,15 +25,16 @@
         
         <!-- [![GitHub contributors](https://img.shields.io/github/contributors/modelscope/modelscope.svg)](https://GitHub.com/modelscope/modelscope/graphs/contributors/) -->
         <!-- [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) -->
         
         <h4 align="center">
             <p>
                 <b>English</b> |
-                <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a>
+                <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a> |
+                <a href="https://github.com/modelscope/modelscope/blob/master/README_ja.md"></a>
             <p>
         </h4>
         
         
         </div>
         
         # Introduction
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: modelscope Version: 1.7.1 Summary: ModelScope:
+Metadata-Version: 2.1 Name: modelscope Version: 1.8.0rc0 Summary: ModelScope:
 bring the notion of Model-as-a-Service to life. Home-page: https://github.com/
 modelscope/modelscope Author: ModelScope team Author-email:
 contact@modelscope.cn License: Apache License 2.0 Description:
 
        [https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif]
  [![PyPI](https://img.shields.io/pypi/v/modelscope)](https://pypi.org/project/
   modelscope/)  [![license](https://img.shields.io/github/license/modelscope/
@@ -12,15 +12,15 @@
       pull-requests](https://img.shields.io/github/issues-pr/modelscope/
   modelscope.svg)](https://GitHub.com/modelscope/modelscope/pull/) [![GitHub
  latest commit](https://badgen.net/github/last-commit/modelscope/modelscope)]
   (https://GitHub.com/modelscope/modelscope/commit/) [![Leaderboard](https://
  img.shields.io/badge/ModelScope-Check%20Your%20Contribution-orange)](https://
                opensource.alibaba.com/contribution_leaderboard/
                       details?projectValue=modelscope)
-                           *** English |  ***
+                     *** English |  |  ***
 # Introduction [ModelScope]( https://www.modelscope.cn) is built upon the
 notion of Model-as-a-Service (MaaS). It seeks to bring together most
 advanced machine learning models from the AI community, and streamlines the
 process of leveraging AI models in real-world applications. The core ModelScope
 library open-sourced in this repository provides the interfaces and
 implementations that allow developers to perform model inference, training and
 evaluation. In particular, with rich layers of API-abstraction, the ModelScope
```

### Comparing `modelscope-1.7.1/README.md` & `modelscope-1.8.0rc0/README.md`

 * *Files 1% similar despite different names*

```diff
@@ -17,15 +17,16 @@
 
 <!-- [![GitHub contributors](https://img.shields.io/github/contributors/modelscope/modelscope.svg)](https://GitHub.com/modelscope/modelscope/graphs/contributors/) -->
 <!-- [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) -->
 
 <h4 align="center">
     <p>
         <b>English</b> |
-        <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a>
+        <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a> |
+        <a href="https://github.com/modelscope/modelscope/blob/master/README_ja.md"></a>
     <p>
 </h4>
 
 
 </div>
 
 # Introduction
```

#### html2text {}

```diff
@@ -8,15 +8,15 @@
       pull-requests](https://img.shields.io/github/issues-pr/modelscope/
   modelscope.svg)](https://GitHub.com/modelscope/modelscope/pull/) [![GitHub
  latest commit](https://badgen.net/github/last-commit/modelscope/modelscope)]
   (https://GitHub.com/modelscope/modelscope/commit/) [![Leaderboard](https://
  img.shields.io/badge/ModelScope-Check%20Your%20Contribution-orange)](https://
                opensource.alibaba.com/contribution_leaderboard/
                       details?projectValue=modelscope)
-                           *** English |  ***
+                     *** English |  |  ***
 # Introduction [ModelScope]( https://www.modelscope.cn) is built upon the
 notion of Model-as-a-Service (MaaS). It seeks to bring together most
 advanced machine learning models from the AI community, and streamlines the
 process of leveraging AI models in real-world applications. The core ModelScope
 library open-sourced in this repository provides the interfaces and
 implementations that allow developers to perform model inference, training and
 evaluation. In particular, with rich layers of API-abstraction, the ModelScope
```

### Comparing `modelscope-1.7.1/modelscope/__init__.py` & `modelscope-1.8.0rc0/modelscope/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -22,14 +22,17 @@
         ImageQualityAssessmentDegradationMetric, ImageQualityAssessmentMosMetric, TextRankingMetric, \
         LossMetric, ImageColorizationMetric, OCRRecognitionMetric
     from .models import Model, TorchModel
     from .preprocessors import Preprocessor
     from .pipelines import Pipeline, pipeline
     from .utils.hub import read_config, create_model_if_not_exist
     from .utils.logger import get_logger
+    from .utils.hf_util import AutoConfig, GenerationConfig
+    from .utils.hf_util import AutoModel, AutoModelForCausalLM, AutoModelForSeq2SeqLM
+    from .utils.hf_util import AutoTokenizer
     from .msdatasets import MsDataset
 
 else:
     _import_structure = {
         'version': ['__release_datetime__', '__version__'],
         'trainers': [
             'EpochBasedTrainer', 'TrainingArgs', 'Hook', 'Priority',
@@ -61,14 +64,18 @@
             'LossMetric', 'ImageColorizationMetric', 'OCRRecognitionMetric'
         ],
         'models': ['Model', 'TorchModel'],
         'preprocessors': ['Preprocessor'],
         'pipelines': ['Pipeline', 'pipeline'],
         'utils.hub': ['read_config', 'create_model_if_not_exist'],
         'utils.logger': ['get_logger'],
+        'utils.hf_util': [
+            'AutoConfig', 'GenerationConfig', 'AutoModel',
+            'AutoModelForCausalLM', 'AutoModelForSeq2SeqLM', 'AutoTokenizer'
+        ],
         'msdatasets': ['MsDataset']
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
```

### Comparing `modelscope-1.7.1/modelscope/cli/cli.py` & `modelscope-1.8.0rc0/modelscope/cli/cli.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/download.py` & `modelscope-1.8.0rc0/modelscope/cli/download.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/modelcard.py` & `modelscope-1.8.0rc0/modelscope/cli/modelcard.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/pipeline.py` & `modelscope-1.8.0rc0/modelscope/cli/pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/plugins.py` & `modelscope-1.8.0rc0/modelscope/cli/plugins.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/template/readme.tpl` & `modelscope-1.8.0rc0/modelscope/cli/template/readme.tpl`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/cli/template/template.tpl` & `modelscope-1.8.0rc0/modelscope/cli/template/template.tpl`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/__init__.py` & `modelscope-1.8.0rc0/modelscope/exporters/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/audio/ans_dfsmn_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/audio/ans_dfsmn_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/base.py` & `modelscope-1.8.0rc0/modelscope/exporters/base.py`

 * *Files 4% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 
 from modelscope.models import Model
 from modelscope.utils.config import Config, ConfigDict
 from modelscope.utils.constant import ModelFile
 from modelscope.utils.logger import get_logger
 from .builder import build_exporter
 
-logger = get_logger(__name__)
+logger = get_logger()
 
 
 class Exporter(ABC):
     """Exporter base class to output model to onnx, torch_script, graphdef, etc.
     """
 
     def __init__(self, model=None):
```

### Comparing `modelscope-1.7.1/modelscope/exporters/builder.py` & `modelscope-1.8.0rc0/modelscope/exporters/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/cv/__init__.py` & `modelscope-1.8.0rc0/modelscope/exporters/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/cv/cartoon_translation_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/cv/cartoon_translation_exporter.py`

 * *Files 1% similar despite different names*

```diff
@@ -5,15 +5,15 @@
 from packaging import version
 
 from modelscope.exporters.builder import EXPORTERS
 from modelscope.exporters.tf_model_exporter import TfModelExporter
 from modelscope.models.cv.cartoon import CartoonModel
 from modelscope.utils.logger import get_logger
 
-logger = get_logger(__name__)
+logger = get_logger()
 
 if version.parse(tf.__version__) < version.parse('2'):
     pass
 else:
     logger.info(
         f'TensorFlow version {_tf_version} found, TF2.x is not supported by CartoonTranslationExporter.'
     )
```

### Comparing `modelscope-1.7.1/modelscope/exporters/cv/face_detection_scrfd_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/cv/face_detection_scrfd_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/cv/object_detection_damoyolo_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/cv/object_detection_damoyolo_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/multi_modal/__init__.py` & `modelscope-1.8.0rc0/modelscope/exporters/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/multi_modal/stable_diffusion_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/multi_modal/stable_diffusion_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/nlp/__init__.py` & `modelscope-1.8.0rc0/modelscope/exporters/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/nlp/csanmt_for_translation_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/nlp/csanmt_for_translation_exporter.py`

 * *Files 1% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 from modelscope.exporters.builder import EXPORTERS
 from modelscope.exporters.tf_model_exporter import TfModelExporter
 from modelscope.metainfo import Models
 from modelscope.utils.constant import Tasks
 from modelscope.utils.logger import get_logger
 from modelscope.utils.test_utils import compare_arguments_nested
 
-logger = get_logger(__name__)
+logger = get_logger()
 
 if tf.__version__ >= '2.0':
     tf = tf.compat.v1
 
 tf.logging.set_verbosity(tf.logging.INFO)
```

### Comparing `modelscope-1.7.1/modelscope/exporters/nlp/model_for_token_classification_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/nlp/model_for_token_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/nlp/sbert_for_sequence_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/nlp/sbert_for_zero_shot_classification_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/tf_model_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/tf_model_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/exporters/torch_model_exporter.py` & `modelscope-1.8.0rc0/modelscope/exporters/torch_model_exporter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/fileio/file.py` & `modelscope-1.8.0rc0/modelscope/fileio/file.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/fileio/format/json.py` & `modelscope-1.8.0rc0/modelscope/fileio/format/json.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/fileio/format/jsonplus.py` & `modelscope-1.8.0rc0/modelscope/fileio/format/jsonplus.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/fileio/format/yaml.py` & `modelscope-1.8.0rc0/modelscope/fileio/format/yaml.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/fileio/io.py` & `modelscope-1.8.0rc0/modelscope/fileio/io.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/api.py` & `modelscope-1.8.0rc0/modelscope/hub/api.py`

 * *Files 1% similar despite different names*

```diff
@@ -581,16 +581,14 @@
         return dataset_id, dataset_type
 
     def get_dataset_meta_file_list(self, dataset_name: str, namespace: str, dataset_id: str, revision: str):
         """ Get the meta file-list of the dataset. """
         datahub_url = f'{self.endpoint}/api/v1/datasets/{dataset_id}/repo/tree?Revision={revision}'
         cookies = ModelScopeConfig.get_cookies()
         r = self.session.get(datahub_url, cookies=cookies, headers=self.headers)
-        r = self.session.get(
-            datahub_url, cookies=cookies, headers=self.headers)
         resp = r.json()
         datahub_raise_on_error(datahub_url, resp)
         file_list = resp['Data']
         if file_list is None:
             raise NotExistError(
                 f'The modelscope dataset [dataset_name = {dataset_name}, namespace = {namespace}, '
                 f'version = {revision}] dose not exist')
```

### Comparing `modelscope-1.7.1/modelscope/hub/check_model.py` & `modelscope-1.8.0rc0/modelscope/hub/check_model.py`

 * *Files 8% similar despite different names*

```diff
@@ -17,28 +17,28 @@
 def check_local_model_is_latest(
     model_root_path: str,
     user_agent: Optional[Union[Dict, str]] = None,
 ):
     """Check local model repo is latest.
     Check local model repo is same as hub latest version.
     """
-    model_cache = None
-    # download with git
-    if os.path.exists(os.path.join(model_root_path, '.git')):
-        git_cmd_wrapper = GitCommandWrapper()
-        git_url = git_cmd_wrapper.get_repo_remote_url(model_root_path)
-        if git_url.endswith('.git'):
-            git_url = git_url[:-4]
-        u_parse = urlparse(git_url)
-        model_id = u_parse.path[1:]
-    else:  # snapshot_download
-        model_cache = ModelFileSystemCache(model_root_path)
-        model_id = model_cache.get_model_id()
-
     try:
+        model_cache = None
+        # download with git
+        if os.path.exists(os.path.join(model_root_path, '.git')):
+            git_cmd_wrapper = GitCommandWrapper()
+            git_url = git_cmd_wrapper.get_repo_remote_url(model_root_path)
+            if git_url.endswith('.git'):
+                git_url = git_url[:-4]
+            u_parse = urlparse(git_url)
+            model_id = u_parse.path[1:]
+        else:  # snapshot_download
+            model_cache = ModelFileSystemCache(model_root_path)
+            model_id = model_cache.get_model_id()
+
         # make headers
         headers = {
             'user-agent':
             ModelScopeConfig.get_user_agent(user_agent=user_agent, )
         }
         cookies = ModelScopeConfig.get_cookies()
 
@@ -71,26 +71,28 @@
                 continue
             # check model_file updated
             if model_cache is not None:
                 if model_cache.exists(model_file):
                     continue
                 else:
                     logger.info(
-                        'Model is updated from modelscope hub, you can verify from https://www.modelscope.cn.'
+                        f'Model file {model_file["Name"]} is different from the latest version `{latest_revision}`,'
+                        f'This is because you are using an older version or the file is updated manually.'
                     )
                     break
             else:
                 if FILE_HASH in model_file:
                     local_file_hash = compute_hash(
                         os.path.join(model_root_path, model_file['Path']))
                     if local_file_hash == model_file[FILE_HASH]:
                         continue
                     else:
                         logger.info(
-                            'Model is updated from modelscope hub, you can verify from https://www.modelscope.cn.'
+                            f'Model file {model_file["Name"]} is different from the latest version `{latest_revision}`,'
+                            f'This is because you are using an older version or the file is updated manually.'
                         )
                         break
     except:  # noqa: E722
         pass  # ignore
 
 
 def check_model_is_id(model_id: str, token=None):
```

### Comparing `modelscope-1.7.1/modelscope/hub/constants.py` & `modelscope-1.8.0rc0/modelscope/hub/constants.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/deploy.py` & `modelscope-1.8.0rc0/modelscope/hub/deploy.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/errors.py` & `modelscope-1.8.0rc0/modelscope/hub/errors.py`

 * *Files 3% similar despite different names*

```diff
@@ -66,32 +66,30 @@
     return message
 
 
 def handle_http_post_error(response, url, request_body):
     try:
         response.raise_for_status()
     except HTTPError as error:
-        logger.error('Request %s with body: %s exception' %
-                     (url, request_body))
         message = _decode_response_error(response)
-        logger.error('Response details: %s' % message)
-        raise error
+        raise HTTPError('Request %s with body: %s exception, '
+                        'Response details: %s' %
+                        (url, request_body, message)) from error
 
 
 def handle_http_response(response, logger, cookies, model_id):
     try:
         response.raise_for_status()
     except HTTPError as error:
         if cookies is None:  # code in [403] and
             logger.error(
                 f'Authentication token does not exist, failed to access model {model_id} which may not exist or may be \
                 private. Please login first.')
         message = _decode_response_error(response)
-        logger.error('Response details: %s' % message)
-        raise error
+        raise HTTPError('Response details: %s' % message) from error
 
 
 def raise_on_error(rsp):
     """If response error, raise exception
 
     Args:
         rsp (_type_): The server response
```

### Comparing `modelscope-1.7.1/modelscope/hub/file_download.py` & `modelscope-1.8.0rc0/modelscope/hub/file_download.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/git.py` & `modelscope-1.8.0rc0/modelscope/hub/git.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/push_to_hub.py` & `modelscope-1.8.0rc0/modelscope/hub/push_to_hub.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/repository.py` & `modelscope-1.8.0rc0/modelscope/hub/repository.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/snapshot_download.py` & `modelscope-1.8.0rc0/modelscope/hub/snapshot_download.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/utils/caching.py` & `modelscope-1.8.0rc0/modelscope/hub/utils/caching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/hub/utils/utils.py` & `modelscope-1.8.0rc0/modelscope/hub/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metainfo.py` & `modelscope-1.8.0rc0/modelscope/metainfo.py`

 * *Files 2% similar despite different names*

```diff
@@ -50,14 +50,15 @@
     language_guided_video_summarization = 'clip-it-language-guided-video-summarization'
     swinL_semantic_segmentation = 'swinL-semantic-segmentation'
     vitadapter_semantic_segmentation = 'vitadapter-semantic-segmentation'
     text_driven_segmentation = 'text-driven-segmentation'
     newcrfs_depth_estimation = 'newcrfs-depth-estimation'
     panovit_layout_estimation = 'panovit-layout-estimation'
     unifuse_depth_estimation = 'unifuse-depth-estimation'
+    s2net_depth_estimation = 's2net-depth-estimation'
     dro_resnet18_depth_estimation = 'dro-resnet18-depth-estimation'
     resnet50_bert = 'resnet50-bert'
     referring_video_object_segmentation = 'swinT-referring-video-object-segmentation'
     fer = 'fer'
     fairface = 'fairface'
     retinaface = 'retinaface'
     damofd = 'damofd'
@@ -107,21 +108,24 @@
     ocr_detection = 'OCRDetection'
     lineless_table_recognition = 'LoreModel'
     image_quality_assessment_mos = 'image-quality-assessment-mos'
     image_quality_assessment_man = 'image-quality-assessment-man'
     image_quality_assessment_degradation = 'image-quality-assessment-degradation'
     m2fp = 'm2fp'
     nerf_recon_acc = 'nerf-recon-acc'
+    nerf_recon_4k = 'nerf-recon-4k'
+    nerf_recon_vq_compression = 'nerf-recon-vq-compression'
     bts_depth_estimation = 'bts-depth-estimation'
     vision_efficient_tuning = 'vision-efficient-tuning'
     bad_image_detecting = 'bad-image-detecting'
     controllable_image_generation = 'controllable-image-generation'
     longshortnet = 'longshortnet'
     fastinst = 'fastinst'
     pedestrian_attribute_recognition = 'pedestrian-attribute-recognition'
+    image_try_on = 'image-try-on'
 
     # nlp models
     bert = 'bert'
     palm = 'palm-v2'
     structbert = 'structbert'
     deberta_v2 = 'deberta_v2'
     veco = 'veco'
@@ -144,14 +148,15 @@
     gpt3 = 'gpt3'
     gpt_moe = 'gpt-moe'
     gpt_neo = 'gpt-neo'
     plug = 'plug'
     bert_for_ds = 'bert-for-document-segmentation'
     ponet_for_ds = 'ponet-for-document-segmentation'
     ponet = 'ponet'
+    polylm = 'polylm'
     T5 = 'T5'
     mglm = 'mglm'
     codegeex = 'codegeex'
     glm130b = 'glm130b'
     bloom = 'bloom'
     unite = 'unite'
     megatron_bert = 'megatron-bert'
@@ -161,14 +166,15 @@
     lstm = 'lstm'
     xlm_roberta = 'xlm-roberta'
     transformers = 'transformers'
     plug_mental = 'plug-mental'
     doc2bot = 'doc2bot'
     peer = 'peer'
     llama = 'llama'
+    llama2 = 'llama2'
     chatglm_6b = 'chatglm6b'
     chatglm2_6b = 'chatglm2-6b'
 
     # audio models
     sambert_hifigan = 'sambert-hifigan'
     speech_frcrn_ans_cirm_16k = 'speech_frcrn_ans_cirm_16k'
     speech_dfsmn_ans = 'speech_dfsmn_ans'
@@ -183,14 +189,15 @@
     generic_punc = 'generic-punc'
     generic_sv = 'generic-sv'
     ecapa_tdnn_sv = 'ecapa-tdnn-sv'
     campplus_sv = 'cam++-sv'
     eres2net_sv = 'eres2net-sv'
     eres2net_aug_sv = 'eres2net-aug-sv'
     scl_sd = 'scl-sd'
+    campplus_lre = 'cam++-lre'
     cluster_backend = 'cluster-backend'
     rdino_tdnn_sv = 'rdino_ecapa-tdnn-sv'
     generic_lm = 'generic-lm'
 
     # multi-modal models
     ofa = 'ofa'
     clip = 'clip-multi-modal-embedding'
@@ -206,14 +213,15 @@
     vldoc = 'vldoc'
     hitea = 'hitea'
     soonet = 'soonet'
     efficient_diffusion_tuning = 'efficient-diffusion-tuning'
     mplug_owl = 'mplug-owl'
     clip_interrogator = 'clip-interrogator'
     stable_diffusion = 'stable-diffusion'
+    text_to_360panorama_image = 'text-to-360panorama-image'
 
     # science models
     unifold = 'unifold'
     unifold_symmetry = 'unifold-symmetry'
 
 
 class TaskModels(object):
@@ -354,14 +362,15 @@
     video_summarization = 'googlenet_pgl_video_summarization'
     language_guided_video_summarization = 'clip-it-video-summarization'
     image_semantic_segmentation = 'image-semantic-segmentation'
     image_depth_estimation = 'image-depth-estimation'
     indoor_layout_estimation = 'indoor-layout-estimation'
     video_depth_estimation = 'video-depth-estimation'
     panorama_depth_estimation = 'panorama-depth-estimation'
+    panorama_depth_estimation_s2net = 'panorama-depth-estimation-s2net'
     image_reid_person = 'passvitb-image-reid-person'
     image_inpainting = 'fft-inpainting'
     image_paintbyexample = 'stablediffusion-paintbyexample'
     image_inpainting_sdv2 = 'image-inpainting-sdv2'
     text_driven_segmentation = 'text-driven-segmentation'
     movie_scene_segmentation = 'resnet50-bert-movie-scene-segmentation'
     shop_segmentation = 'shop-segmentation'
@@ -399,23 +408,27 @@
     ddpm_image_semantic_segmentation = 'ddpm-image-semantic-segmentation'
     video_colorization = 'video-colorization'
     motion_generattion = 'mdm-motion-generation'
     mobile_image_super_resolution = 'mobile-image-super-resolution'
     image_human_parsing = 'm2fp-image-human-parsing'
     object_detection_3d_depe = 'object-detection-3d-depe'
     nerf_recon_acc = 'nerf-recon-acc'
+    nerf_recon_4k = 'nerf-recon-4k'
+    nerf_recon_vq_compression = 'nerf-recon-vq-compression'
     bad_image_detecting = 'bad-image-detecting'
     controllable_image_generation = 'controllable-image-generation'
     fast_instance_segmentation = 'fast-instance-segmentation'
     image_quality_assessment_mos = 'image-quality-assessment-mos'
     image_quality_assessment_man = 'image-quality-assessment-man'
     image_quality_assessment_degradation = 'image-quality-assessment-degradation'
     vision_efficient_tuning = 'vision-efficient-tuning'
     image_bts_depth_estimation = 'image-bts-depth-estimation'
     pedestrian_attribute_recognition = 'resnet50_pedestrian-attribute-recognition_image'
+    text_to_360panorama_image = 'text-to-360panorama-image'
+    image_try_on = 'image-try-on'
 
     # nlp tasks
     automatic_post_editing = 'automatic-post-editing'
     translation_quality_estimation = 'translation-quality-estimation'
     domain_classification = 'domain-classification'
     sentence_similarity = 'sentence-similarity'
     word_segmentation = 'word-segmentation'
@@ -441,14 +454,15 @@
     dialog_modeling = 'dialog-modeling'
     dialog_state_tracking = 'dialog-state-tracking'
     zero_shot_classification = 'zero-shot-classification'
     text_error_correction = 'text-error-correction'
     word_alignment = 'word-alignment'
     plug_generation = 'plug-generation'
     gpt3_generation = 'gpt3-generation'
+    polylm_text_generation = 'polylm-text-generation'
     gpt_moe_generation = 'gpt-moe-generation'
     faq_question_answering = 'faq-question-answering'
     conversational_text_to_sql = 'conversational-text-to-sql'
     table_question_answering_pipeline = 'table-question-answering-pipeline'
     sentence_embedding = 'sentence-embedding'
     text_ranking = 'text-ranking'
     mgeo_ranking = 'mgeo-ranking'
@@ -486,15 +500,18 @@
     punc_inference = 'punc-inference'
     sv_inference = 'sv-inference'
     speaker_diarization_inference = 'speaker-diarization-inference'
     vad_inference = 'vad-inference'
     speaker_verification = 'speaker-verification'
     speaker_verification_rdino = 'speaker-verification-rdino'
     speaker_verification_eres2net = 'speaker-verification-eres2net'
+    speech_language_recognition = 'speech-language-recognition'
     speaker_change_locating = 'speaker-change-locating'
+    speaker_diarization_dialogue_detection = 'speaker-diarization-dialogue-detection'
+    speaker_diarization_semantic_speaker_turn_detection = 'speaker-diarization-semantic-speaker-turn-detection'
     segmentation_clustering = 'segmentation-clustering'
     lm_inference = 'language-score-prediction'
     speech_timestamp_inference = 'speech-timestamp-inference'
 
     # multi-modal tasks
     image_captioning = 'image-captioning'
     multi_modal_embedding = 'multi-modal-embedding'
@@ -518,14 +535,15 @@
     chinese_stable_diffusion = 'chinese-stable-diffusion'
     text_to_video_synthesis = 'latent-text-to-video-synthesis'  # latent-text-to-video-synthesis
     gridvlp_multi_modal_classification = 'gridvlp-multi-modal-classification'
     gridvlp_multi_modal_embedding = 'gridvlp-multi-modal-embedding'
     soonet_video_temporal_grounding = 'soonet-video-temporal-grounding'
     efficient_diffusion_tuning = 'efficient-diffusion-tuning'
     multimodal_dialogue = 'multimodal-dialogue'
+    llama2_text_generation_pipeline = 'llama2-text-generation-pipeline'
 
     # science tasks
     protein_structure = 'unifold-protein-structure'
 
 
 DEFAULT_MODEL_FOR_PIPELINE = {
     # TaskName: (pipeline_module_name, model_repo)
@@ -838,19 +856,29 @@
         'damo/cv_vitb16_classification_vision-efficient-tuning-adapter'),
     Tasks.object_detection_3d: (Pipelines.object_detection_3d_depe,
                                 'damo/cv_object-detection-3d_depe'),
     Tasks.bad_image_detecting: (Pipelines.bad_image_detecting,
                                 'damo/cv_mobilenet-v2_bad-image-detecting'),
     Tasks.nerf_recon_acc: (Pipelines.nerf_recon_acc,
                            'damo/cv_nerf-3d-reconstruction-accelerate_damo'),
+    Tasks.nerf_recon_4k: (Pipelines.nerf_recon_4k,
+                          'damo/cv_nerf-3d-reconstruction-4k-nerf_damo'),
+    Tasks.nerf_recon_vq_compression: (
+        Pipelines.nerf_recon_vq_compression,
+        'damo/cv_nerf-3d-reconstruction-vq-compression_damo'),
     Tasks.siamese_uie: (Pipelines.siamese_uie,
                         'damo/nlp_structbert_siamese-uie_chinese-base'),
     Tasks.pedestrian_attribute_recognition: (
         Pipelines.pedestrian_attribute_recognition,
         'damo/cv_resnet50_pedestrian-attribute-recognition_image'),
+    Tasks.text_to_360panorama_image: (
+        Pipelines.text_to_360panorama_image,
+        'damo/cv_diffusion_text-to-360panorama-image_generation'),
+    Tasks.image_try_on: (Pipelines.image_try_on,
+                         'damo/cv_SAL-VTON_virtual-try-on')
 }
 
 
 class CVTrainers(object):
     # cv trainers
     image_instance_segmentation = 'image-instance-segmentation'
     image_portrait_enhancement = 'image-portrait-enhancement'
@@ -862,14 +890,15 @@
     referring_video_object_segmentation = 'referring-video-object-segmentation'
     image_classification_team = 'image-classification-team'
     image_classification = 'image-classification'
     image_fewshot_detection = 'image-fewshot-detection'
     ocr_recognition = 'ocr-recognition'
     ocr_detection_db = 'ocr-detection-db'
     nerf_recon_acc = 'nerf-recon-acc'
+    nerf_recon_4k = 'nerf-recon-4k'
     action_detection = 'action-detection'
     vision_efficient_tuning = 'vision-efficient-tuning'
 
 
 class NLPTrainers(object):
     # nlp trainers
     bert_sentiment_analysis = 'bert-sentiment-analysis'
@@ -897,14 +926,15 @@
     ofa = 'ofa'
     mplug = 'mplug'
     mgeo_ranking_trainer = 'mgeo-ranking-trainer'
     efficient_diffusion_tuning = 'efficient-diffusion-tuning'
     stable_diffusion = 'stable-diffusion'
     lora_diffusion = 'lora-diffusion'
     dreambooth_diffusion = 'dreambooth-diffusion'
+    custom_diffusion = 'custom-diffusion'
 
 
 class AudioTrainers(object):
     speech_frcrn_ans_cirm_16k = 'speech_frcrn_ans_cirm_16k'
     speech_dfsmn_kws_char_farfield = 'speech_dfsmn_kws_char_farfield'
     speech_kws_fsmn_char_ctc_nearfield = 'speech_kws_fsmn_char_ctc_nearfield'
     speech_kantts_trainer = 'speech-kantts-trainer'
@@ -977,14 +1007,16 @@
     object_detection_scrfd = 'object-detection-scrfd'
     image_sky_change_preprocessor = 'image-sky-change-preprocessor'
     image_demoire_preprocessor = 'image-demoire-preprocessor'
     ocr_recognition = 'ocr-recognition'
     ocr_detection = 'ocr-detection'
     bad_image_detecting_preprocessor = 'bad-image-detecting-preprocessor'
     nerf_recon_acc_preprocessor = 'nerf-recon-acc-preprocessor'
+    nerf_recon_4k_preprocessor = 'nerf-recon-4k-preprocessor'
+    nerf_recon_vq_compression_preprocessor = 'nerf-recon-vq-compression-preprocessor'
     controllable_image_generation_preprocessor = 'controllable-image-generation-preprocessor'
     image_classification_preprocessor = 'image-classification-preprocessor'
 
     # nlp preprocessor
     sen_sim_tokenizer = 'sen-sim-tokenizer'
     cross_encoder_tokenizer = 'cross-encoder-tokenizer'
     bert_seq_cls_tokenizer = 'bert-seq-cls-tokenizer'
```

### Comparing `modelscope-1.7.1/modelscope/metrics/__init__.py` & `modelscope-1.8.0rc0/modelscope/metrics/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/accuracy_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/accuracy_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/action_detection_evaluator.py` & `modelscope-1.8.0rc0/modelscope/metrics/action_detection_evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/audio_noise_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/audio_noise_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/base.py` & `modelscope-1.8.0rc0/modelscope/metrics/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/bleu_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/bleu_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/builder.py` & `modelscope-1.8.0rc0/modelscope/metrics/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/ciderD/ciderD.py` & `modelscope-1.8.0rc0/modelscope/metrics/ciderD/ciderD.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/ciderD/ciderD_scorer.py` & `modelscope-1.8.0rc0/modelscope/metrics/ciderD/ciderD_scorer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_color_enhance_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_color_enhance_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_colorization_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_colorization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_denoise_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_denoise_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_inpainting_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_inpainting_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_instance_segmentation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_instance_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_portrait_enhancement_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_portrait_enhancement_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_quality_assessment_degradation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_quality_assessment_degradation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/image_quality_assessment_mos_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/image_quality_assessment_mos_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/inbatch_recall_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/inbatch_recall_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/loss_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/loss_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/map_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/map_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/movie_scene_segmentation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/movie_scene_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/ned_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/ned_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/ocr_recognition_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/ocr_recognition_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/ppl_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/ppl_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/prediction_saving_wrapper.py` & `modelscope-1.8.0rc0/modelscope/metrics/prediction_saving_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/referring_video_object_segmentation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/referring_video_object_segmentation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/sequence_classification_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/sequence_classification_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/text_generation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/text_generation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/text_ranking_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/text_ranking_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/token_classification_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/token_classification_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/translation_evaluation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/translation_evaluation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_frame_interpolation_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_frame_interpolation_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_stabilization_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_stabilization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_summarization_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_summarization_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/matlab_functions.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/matlab_functions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/metric_util.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/metric_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/niqe.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/niqe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py` & `modelscope-1.8.0rc0/modelscope/metrics/video_super_resolution_metric/video_super_resolution_metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/layers/activations.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/activations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/layers/affine_transform.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/affine_transform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/layers/deep_fsmn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/layers/layer_base.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/layer_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/layers/uni_deep_fsmn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/layers/uni_deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/network/loss.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/network/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/network/modulation_loss.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/network/modulation_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/aec/network/se_net.py` & `modelscope-1.8.0rc0/modelscope/models/audio/aec/network/se_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/complex_nn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/complex_nn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/conv_stft.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/conv_stft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/denoise_net.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/denoise_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/frcrn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/frcrn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/layers/activations.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/activations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/layers/affine_transform.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/affine_transform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/layers/layer_base.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/layer_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/layers/uni_deep_fsmn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/layers/uni_deep_fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/se_module_complex.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/se_module_complex.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/ans/unet.py` & `modelscope-1.8.0rc0/modelscope/models/audio/ans/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/asr/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/audio/asr/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/asr/generic_automatic_speech_recognition.py` & `modelscope-1.8.0rc0/modelscope/models/audio/asr/generic_automatic_speech_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py` & `modelscope-1.8.0rc0/modelscope/models/audio/asr/wenet_automatic_speech_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/itn/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/audio/itn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/itn/generic_inverse_text_processing.py` & `modelscope-1.8.0rc0/modelscope/models/audio/itn/generic_inverse_text_processing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn_sele_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/fsmn_sele_v3.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/farfield/model.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/farfield/model_def.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/farfield/model_def.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/generic_key_word_spotting.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/generic_key_word_spotting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/nearfield/cmvn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/cmvn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/nearfield/fsmn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/fsmn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/kws/nearfield/model.py` & `modelscope-1.8.0rc0/modelscope/models/audio/kws/nearfield/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/punc/generic_punctuation.py` & `modelscope-1.8.0rc0/modelscope/models/audio/punc/generic_punctuation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/separation/layer_norm.py` & `modelscope-1.8.0rc0/modelscope/models/audio/separation/layer_norm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/separation/mossformer.py` & `modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/separation/mossformer_block.py` & `modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/separation/mossformer_conv_module.py` & `modelscope-1.8.0rc0/modelscope/models/audio/separation/mossformer_conv_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/DTDNN.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/DTDNN.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/DTDNN_layers.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/DTDNN_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/ERes2Net.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/ERes2Net_aug.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 """ Res2Net implementation is adapted from https://github.com/wenet-e2e/wespeaker.
-    ERes2Net incorporates both local and global feature fusion techniques to improve the performance. The local feature
-    fusion (LFF) fuses the features within one single residual block to extract the local signal.
-    The global feature fusion (GFF) takes acoustic features of different scales as input to aggregate global signal.
+    ERes2Net_aug incorporates both local and global feature fusion techniques
+    to improve the performance. The training code is located on the following
+    GitHub repository: https://github.com/alibaba-damo-academy/3D-Speaker.
 """
 import math
 import os
 from typing import Any, Dict, Union
 
 import torch
 import torch.nn as nn
@@ -49,19 +49,19 @@
         out_planes,
         kernel_size=3,
         stride=stride,
         padding=1,
         bias=False)
 
 
-class BasicBlockRes2Net(nn.Module):
-    expansion = 2
+class BasicBlockERes2Net(nn.Module):
+    expansion = 4
 
-    def __init__(self, in_planes, planes, stride=1, baseWidth=32, scale=2):
-        super(BasicBlockRes2Net, self).__init__()
+    def __init__(self, in_planes, planes, stride=1, baseWidth=24, scale=3):
+        super(BasicBlockERes2Net, self).__init__()
         width = int(math.floor(planes * (baseWidth / 64.0)))
         self.conv1 = conv1x1(in_planes, width * scale, stride)
         self.bn1 = nn.BatchNorm2d(width * scale)
         self.nums = scale
 
         convs = []
         bns = []
@@ -112,30 +112,32 @@
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
         return out
 
 
-class BasicBlockRes2Net_diff_AFF(nn.Module):
-    expansion = 2
+class BasicBlockERes2Net_diff_AFF(nn.Module):
+    expansion = 4
 
-    def __init__(self, in_planes, planes, stride=1, baseWidth=32, scale=2):
-        super(BasicBlockRes2Net_diff_AFF, self).__init__()
+    def __init__(self, in_planes, planes, stride=1, baseWidth=24, scale=3):
+        super(BasicBlockERes2Net_diff_AFF, self).__init__()
         width = int(math.floor(planes * (baseWidth / 64.0)))
         self.conv1 = conv1x1(in_planes, width * scale, stride)
         self.bn1 = nn.BatchNorm2d(width * scale)
+
         self.nums = scale
 
         convs = []
         fuse_models = []
         bns = []
         for i in range(self.nums):
             convs.append(conv3x3(width, width))
             bns.append(nn.BatchNorm2d(width))
+        # Add different fuse_model parameters
         for j in range(self.nums - 1):
             fuse_models.append(AFF(channels=width))
 
         self.convs = nn.ModuleList(convs)
         self.bns = nn.ModuleList(bns)
         self.fuse_models = nn.ModuleList(fuse_models)
         self.relu = ReLU(inplace=True)
@@ -181,29 +183,29 @@
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
         return out
 
 
-class ERes2Net(nn.Module):
+class ERes2Net_aug(nn.Module):
 
     def __init__(self,
-                 block=BasicBlockRes2Net,
-                 block_fuse=BasicBlockRes2Net_diff_AFF,
+                 block=BasicBlockERes2Net,
+                 block_fuse=BasicBlockERes2Net_diff_AFF,
                  num_blocks=[3, 4, 6, 3],
-                 m_channels=32,
+                 m_channels=64,
                  feat_dim=80,
-                 embed_dim=192,
+                 embedding_size=192,
                  pooling_func='TSTP',
                  two_emb_layer=False):
-        super(ERes2Net, self).__init__()
+        super(ERes2Net_aug, self).__init__()
         self.in_planes = m_channels
         self.feat_dim = feat_dim
-        self.embed_dim = embed_dim
+        self.embedding_size = embedding_size
         self.stats_dim = int(feat_dim / 8) * m_channels * 8
         self.two_emb_layer = two_emb_layer
 
         self.conv1 = nn.Conv2d(
             1, m_channels, kernel_size=3, stride=1, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(m_channels)
         self.layer1 = self._make_layer(
@@ -211,78 +213,72 @@
         self.layer2 = self._make_layer(
             block, m_channels * 2, num_blocks[1], stride=2)
         self.layer3 = self._make_layer(
             block_fuse, m_channels * 4, num_blocks[2], stride=2)
         self.layer4 = self._make_layer(
             block_fuse, m_channels * 8, num_blocks[3], stride=2)
 
-        # downsampling
         self.layer1_downsample = nn.Conv2d(
-            m_channels * 2,
             m_channels * 4,
+            m_channels * 8,
             kernel_size=3,
-            stride=2,
             padding=1,
+            stride=2,
             bias=False)
         self.layer2_downsample = nn.Conv2d(
-            m_channels * 4,
             m_channels * 8,
+            m_channels * 16,
             kernel_size=3,
             padding=1,
             stride=2,
             bias=False)
         self.layer3_downsample = nn.Conv2d(
-            m_channels * 8,
             m_channels * 16,
+            m_channels * 32,
             kernel_size=3,
             padding=1,
             stride=2,
             bias=False)
 
-        # bottom-up fusion
-        self.fuse_mode12 = AFF(channels=m_channels * 4)
-        self.fuse_mode123 = AFF(channels=m_channels * 8)
-        self.fuse_mode1234 = AFF(channels=m_channels * 16)
+        self.fuse_mode12 = AFF(channels=m_channels * 8)
+        self.fuse_mode123 = AFF(channels=m_channels * 16)
+        self.fuse_mode1234 = AFF(channels=m_channels * 32)
 
         self.n_stats = 1 if pooling_func == 'TAP' or pooling_func == 'TSDP' else 2
         self.pool = getattr(pooling_layers, pooling_func)(
             in_dim=self.stats_dim * block.expansion)
         self.seg_1 = nn.Linear(self.stats_dim * block.expansion * self.n_stats,
-                               embed_dim)
+                               embedding_size)
         if self.two_emb_layer:
-            self.seg_bn_1 = nn.BatchNorm1d(embed_dim, affine=False)
-            self.seg_2 = nn.Linear(embed_dim, embed_dim)
+            self.seg_bn_1 = nn.BatchNorm1d(embedding_size, affine=False)
+            self.seg_2 = nn.Linear(embedding_size, embedding_size)
         else:
             self.seg_bn_1 = nn.Identity()
             self.seg_2 = nn.Identity()
 
     def _make_layer(self, block, planes, num_blocks, stride):
         strides = [stride] + [1] * (num_blocks - 1)
         layers = []
         for stride in strides:
             layers.append(block(self.in_planes, planes, stride))
             self.in_planes = planes * block.expansion
         return nn.Sequential(*layers)
 
     def forward(self, x):
-        x = x.permute(0, 2, 1)
+        x = x.permute(0, 2, 1)  # (B,T,F) => (B,F,T)
 
         x = x.unsqueeze_(1)
         out = F.relu(self.bn1(self.conv1(x)))
         out1 = self.layer1(out)
-
-        # bottom-up fusion
         out2 = self.layer2(out1)
         out1_downsample = self.layer1_downsample(out1)
         fuse_out12 = self.fuse_mode12(out2, out1_downsample)
-
         out3 = self.layer3(out2)
         fuse_out12_downsample = self.layer2_downsample(fuse_out12)
         fuse_out123 = self.fuse_mode123(out3, fuse_out12_downsample)
-
         out4 = self.layer4(out3)
         fuse_out123_downsample = self.layer3_downsample(fuse_out123)
         fuse_out1234 = self.fuse_mode1234(out4, fuse_out123_downsample)
         stats = self.pool(fuse_out1234)
 
         embed_a = self.seg_1(stats)
         if self.two_emb_layer:
@@ -291,32 +287,32 @@
             embed_b = self.seg_2(out)
             return embed_b
         else:
             return embed_a
 
 
 @MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.eres2net_sv)
+    Tasks.speaker_verification, module_name=Models.eres2net_aug_sv)
 class SpeakerVerificationERes2Net(TorchModel):
-    r"""Enhanced Res2Net architecture with local and global feature fusion. ERes2Net is mainly composed
-    of LFF and GFF. The LFF extracts localization-preserved speaker features and strengthen the local information
-    interaction. GFF fuses multi-scale feature maps in bottom-up pathway to obtain global information.
+    r"""Enhanced Res2Net_aug architecture with local and global feature fusion.
+    ERes2Net_aug is an upgraded version of ERes2Net that uses a larger number of
+    parameters to achieve better recognition performance.
     Args:
         model_dir: A model dir.
         model_config: The model config.
     """
 
     def __init__(self, model_dir, model_config: Dict[str, Any], *args,
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
         self.other_config = kwargs
         self.feature_dim = 80
 
-        self.embedding_model = ERes2Net()
+        self.embedding_model = ERes2Net_aug()
 
         pretrained_model_name = kwargs['pretrained_model']
         self.__load_check_point(pretrained_model_name)
 
         self.embedding_model.eval()
 
     def forward(self, audio):
```

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/ERes2Net_aug.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/ERes2Net.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 """ Res2Net implementation is adapted from https://github.com/wenet-e2e/wespeaker.
-    ERes2Net_aug incorporates both local and global feature fusion techniques
-    to improve the performance. The training code is located on the following
-    GitHub repository: https://github.com/alibaba-damo-academy/3D-Speaker.
+    ERes2Net incorporates both local and global feature fusion techniques to improve the performance. The local feature
+    fusion (LFF) fuses the features within one single residual block to extract the local signal.
+    The global feature fusion (GFF) takes acoustic features of different scales as input to aggregate global signal.
 """
 import math
 import os
 from typing import Any, Dict, Union
 
 import torch
 import torch.nn as nn
@@ -49,19 +49,19 @@
         out_planes,
         kernel_size=3,
         stride=stride,
         padding=1,
         bias=False)
 
 
-class BasicBlockERes2Net(nn.Module):
-    expansion = 4
+class BasicBlockRes2Net(nn.Module):
+    expansion = 2
 
-    def __init__(self, in_planes, planes, stride=1, baseWidth=24, scale=3):
-        super(BasicBlockERes2Net, self).__init__()
+    def __init__(self, in_planes, planes, stride=1, baseWidth=32, scale=2):
+        super(BasicBlockRes2Net, self).__init__()
         width = int(math.floor(planes * (baseWidth / 64.0)))
         self.conv1 = conv1x1(in_planes, width * scale, stride)
         self.bn1 = nn.BatchNorm2d(width * scale)
         self.nums = scale
 
         convs = []
         bns = []
@@ -112,32 +112,30 @@
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
         return out
 
 
-class BasicBlockERes2Net_diff_AFF(nn.Module):
-    expansion = 4
+class BasicBlockRes2Net_diff_AFF(nn.Module):
+    expansion = 2
 
-    def __init__(self, in_planes, planes, stride=1, baseWidth=24, scale=3):
-        super(BasicBlockERes2Net_diff_AFF, self).__init__()
+    def __init__(self, in_planes, planes, stride=1, baseWidth=32, scale=2):
+        super(BasicBlockRes2Net_diff_AFF, self).__init__()
         width = int(math.floor(planes * (baseWidth / 64.0)))
         self.conv1 = conv1x1(in_planes, width * scale, stride)
         self.bn1 = nn.BatchNorm2d(width * scale)
-
         self.nums = scale
 
         convs = []
         fuse_models = []
         bns = []
         for i in range(self.nums):
             convs.append(conv3x3(width, width))
             bns.append(nn.BatchNorm2d(width))
-        # Add different fuse_model parameters
         for j in range(self.nums - 1):
             fuse_models.append(AFF(channels=width))
 
         self.convs = nn.ModuleList(convs)
         self.bns = nn.ModuleList(bns)
         self.fuse_models = nn.ModuleList(fuse_models)
         self.relu = ReLU(inplace=True)
@@ -183,29 +181,29 @@
         residual = self.shortcut(x)
         out += residual
         out = self.relu(out)
 
         return out
 
 
-class ERes2Net_aug(nn.Module):
+class ERes2Net(nn.Module):
 
     def __init__(self,
-                 block=BasicBlockERes2Net,
-                 block_fuse=BasicBlockERes2Net_diff_AFF,
+                 block=BasicBlockRes2Net,
+                 block_fuse=BasicBlockRes2Net_diff_AFF,
                  num_blocks=[3, 4, 6, 3],
-                 m_channels=64,
+                 m_channels=32,
                  feat_dim=80,
-                 embedding_size=192,
+                 embed_dim=192,
                  pooling_func='TSTP',
                  two_emb_layer=False):
-        super(ERes2Net_aug, self).__init__()
+        super(ERes2Net, self).__init__()
         self.in_planes = m_channels
         self.feat_dim = feat_dim
-        self.embedding_size = embedding_size
+        self.embed_dim = embed_dim
         self.stats_dim = int(feat_dim / 8) * m_channels * 8
         self.two_emb_layer = two_emb_layer
 
         self.conv1 = nn.Conv2d(
             1, m_channels, kernel_size=3, stride=1, padding=1, bias=False)
         self.bn1 = nn.BatchNorm2d(m_channels)
         self.layer1 = self._make_layer(
@@ -213,72 +211,78 @@
         self.layer2 = self._make_layer(
             block, m_channels * 2, num_blocks[1], stride=2)
         self.layer3 = self._make_layer(
             block_fuse, m_channels * 4, num_blocks[2], stride=2)
         self.layer4 = self._make_layer(
             block_fuse, m_channels * 8, num_blocks[3], stride=2)
 
+        # downsampling
         self.layer1_downsample = nn.Conv2d(
+            m_channels * 2,
             m_channels * 4,
-            m_channels * 8,
             kernel_size=3,
-            padding=1,
             stride=2,
+            padding=1,
             bias=False)
         self.layer2_downsample = nn.Conv2d(
+            m_channels * 4,
             m_channels * 8,
-            m_channels * 16,
             kernel_size=3,
             padding=1,
             stride=2,
             bias=False)
         self.layer3_downsample = nn.Conv2d(
+            m_channels * 8,
             m_channels * 16,
-            m_channels * 32,
             kernel_size=3,
             padding=1,
             stride=2,
             bias=False)
 
-        self.fuse_mode12 = AFF(channels=m_channels * 8)
-        self.fuse_mode123 = AFF(channels=m_channels * 16)
-        self.fuse_mode1234 = AFF(channels=m_channels * 32)
+        # bottom-up fusion
+        self.fuse_mode12 = AFF(channels=m_channels * 4)
+        self.fuse_mode123 = AFF(channels=m_channels * 8)
+        self.fuse_mode1234 = AFF(channels=m_channels * 16)
 
         self.n_stats = 1 if pooling_func == 'TAP' or pooling_func == 'TSDP' else 2
         self.pool = getattr(pooling_layers, pooling_func)(
             in_dim=self.stats_dim * block.expansion)
         self.seg_1 = nn.Linear(self.stats_dim * block.expansion * self.n_stats,
-                               embedding_size)
+                               embed_dim)
         if self.two_emb_layer:
-            self.seg_bn_1 = nn.BatchNorm1d(embedding_size, affine=False)
-            self.seg_2 = nn.Linear(embedding_size, embedding_size)
+            self.seg_bn_1 = nn.BatchNorm1d(embed_dim, affine=False)
+            self.seg_2 = nn.Linear(embed_dim, embed_dim)
         else:
             self.seg_bn_1 = nn.Identity()
             self.seg_2 = nn.Identity()
 
     def _make_layer(self, block, planes, num_blocks, stride):
         strides = [stride] + [1] * (num_blocks - 1)
         layers = []
         for stride in strides:
             layers.append(block(self.in_planes, planes, stride))
             self.in_planes = planes * block.expansion
         return nn.Sequential(*layers)
 
     def forward(self, x):
-        x = x.permute(0, 2, 1)  # (B,T,F) => (B,F,T)
+        x = x.permute(0, 2, 1)
 
         x = x.unsqueeze_(1)
         out = F.relu(self.bn1(self.conv1(x)))
         out1 = self.layer1(out)
+
+        # bottom-up fusion
         out2 = self.layer2(out1)
         out1_downsample = self.layer1_downsample(out1)
         fuse_out12 = self.fuse_mode12(out2, out1_downsample)
+
         out3 = self.layer3(out2)
         fuse_out12_downsample = self.layer2_downsample(fuse_out12)
         fuse_out123 = self.fuse_mode123(out3, fuse_out12_downsample)
+
         out4 = self.layer4(out3)
         fuse_out123_downsample = self.layer3_downsample(fuse_out123)
         fuse_out1234 = self.fuse_mode1234(out4, fuse_out123_downsample)
         stats = self.pool(fuse_out1234)
 
         embed_a = self.seg_1(stats)
         if self.two_emb_layer:
@@ -287,32 +291,35 @@
             embed_b = self.seg_2(out)
             return embed_b
         else:
             return embed_a
 
 
 @MODELS.register_module(
-    Tasks.speaker_verification, module_name=Models.eres2net_aug_sv)
+    Tasks.speaker_verification, module_name=Models.eres2net_sv)
 class SpeakerVerificationERes2Net(TorchModel):
-    r"""Enhanced Res2Net_aug architecture with local and global feature fusion.
-    ERes2Net_aug is an upgraded version of ERes2Net that uses a larger number of
-    parameters to achieve better recognition performance.
+    r"""Enhanced Res2Net architecture with local and global feature fusion. ERes2Net is mainly composed
+    of LFF and GFF. The LFF extracts localization-preserved speaker features and strengthen the local information
+    interaction. GFF fuses multi-scale feature maps in bottom-up pathway to obtain global information.
     Args:
         model_dir: A model dir.
         model_config: The model config.
     """
 
     def __init__(self, model_dir, model_config: Dict[str, Any], *args,
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
+        self.embed_dim = self.model_config['embed_dim']
+        self.m_channels = self.model_config['channels']
         self.other_config = kwargs
         self.feature_dim = 80
 
-        self.embedding_model = ERes2Net_aug()
+        self.embedding_model = ERes2Net(
+            embed_dim=self.embed_dim, m_channels=self.m_channels)
 
         pretrained_model_name = kwargs['pretrained_model']
         self.__load_check_point(pretrained_model_name)
 
         self.embedding_model.eval()
 
     def forward(self, audio):
```

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/cluster_backend.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/cluster_backend.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,36 +1,39 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
 from typing import Any, Dict, Union
 
+import hdbscan
 import numpy as np
 import scipy
 import sklearn
+import umap
 from sklearn.cluster._kmeans import k_means
 
 from modelscope.metainfo import Models
 from modelscope.models import MODELS, TorchModel
 from modelscope.utils.constant import Tasks
 
 
 class SpectralCluster:
     r"""A spectral clustering mehtod using unnormalized Laplacian of affinity matrix.
     This implementation is adapted from https://github.com/speechbrain/speechbrain.
     """
 
-    def __init__(self, min_num_spks=0, max_num_spks=30):
+    def __init__(self, min_num_spks=1, max_num_spks=15, pval=0.022):
         self.min_num_spks = min_num_spks
         self.max_num_spks = max_num_spks
+        self.pval = pval
 
-    def __call__(self, X, pval, oracle_num=None):
+    def __call__(self, X, oracle_num=None):
         # Similarity matrix computation
         sim_mat = self.get_sim_mat(X)
 
         # Refining similarity matrix with pval
-        prunned_sim_mat = self.p_pruning(sim_mat, pval)
+        prunned_sim_mat = self.p_pruning(sim_mat)
 
         # Symmetrization
         sym_prund_sim_mat = 0.5 * (prunned_sim_mat + prunned_sim_mat.T)
 
         # Laplacian calculation
         laplacian = self.get_laplacian(sym_prund_sim_mat)
 
@@ -43,15 +46,20 @@
         return labels
 
     def get_sim_mat(self, X):
         # Cosine similarities
         M = sklearn.metrics.pairwise.cosine_similarity(X, X)
         return M
 
-    def p_pruning(self, A, pval):
+    def p_pruning(self, A):
+        if A.shape[0] * self.pval < 6:
+            pval = 6. / A.shape[0]
+        else:
+            pval = self.pval
+
         n_elems = int((1 - pval) * A.shape[0])
 
         # For each row in a affinity matrix
         for i in range(A.shape[0]):
             low_indexes = np.argsort(A[i, :])
             low_indexes = low_indexes[0:n_elems]
 
@@ -62,22 +70,22 @@
     def get_laplacian(self, M):
         M[np.diag_indices(M.shape[0])] = 0
         D = np.sum(np.abs(M), axis=1)
         D = np.diag(D)
         L = D - M
         return L
 
-    def get_spec_embs(self, L, k_oracle=4):
+    def get_spec_embs(self, L, k_oracle=None):
         lambdas, eig_vecs = scipy.linalg.eigh(L)
 
         if k_oracle is not None:
             num_of_spk = k_oracle
         else:
             lambda_gap_list = self.getEigenGaps(
-                lambdas[self.min_num_spks - 1:self.max_num_spks - 1])
+                lambdas[self.min_num_spks - 1:self.max_num_spks + 1])
             num_of_spk = np.argmax(lambda_gap_list) + self.min_num_spks
 
         emb = eig_vecs[:, :num_of_spk]
         return emb, num_of_spk
 
     def cluster_embs(self, emb, k):
         _, labels, _ = k_means(emb, k)
@@ -87,14 +95,47 @@
         eig_vals_gap_list = []
         for i in range(len(eig_vals) - 1):
             gap = float(eig_vals[i + 1]) - float(eig_vals[i])
             eig_vals_gap_list.append(gap)
         return eig_vals_gap_list
 
 
+class UmapHdbscan:
+    r"""
+    Reference:
+    - Siqi Zheng, Hongbin Suo. Reformulating Speaker Diarization as Community Detection With
+      Emphasis On Topological Structure. ICASSP2022
+    """
+
+    def __init__(self,
+                 n_neighbors=20,
+                 n_components=60,
+                 min_samples=10,
+                 min_cluster_size=10,
+                 metric='cosine'):
+        self.n_neighbors = n_neighbors
+        self.n_components = n_components
+        self.min_samples = min_samples
+        self.min_cluster_size = min_cluster_size
+        self.metric = metric
+
+    def __call__(self, X):
+        umap_X = umap.UMAP(
+            n_neighbors=self.n_neighbors,
+            min_dist=0.0,
+            n_components=min(self.n_components, X.shape[0] - 2),
+            metric=self.metric,
+        ).fit_transform(X)
+        labels = hdbscan.HDBSCAN(
+            min_samples=self.min_samples,
+            min_cluster_size=self.min_cluster_size,
+            allow_single_cluster=True).fit_predict(umap_X)
+        return labels
+
+
 @MODELS.register_module(
     Tasks.speaker_diarization, module_name=Models.cluster_backend)
 class ClusterBackend(TorchModel):
     r"""Perfom clustering for input embeddings and output the labels.
     Args:
         model_dir: A model dir.
         model_config: The model config.
@@ -102,37 +143,29 @@
 
     def __init__(self, model_dir, model_config: Dict[str, Any], *args,
                  **kwargs):
         super().__init__(model_dir, model_config, *args, **kwargs)
         self.model_config = model_config
         self.other_config = kwargs
 
-        if self.model_config['cluster_type'] == 'spectral':
-            self.cluster = SpectralCluster(self.model_config['min_num_spks'],
-                                           self.model_config['max_num_spks'])
-        else:
-            raise ValueError(
-                'modelscope error: Only spectral clustering is currently supported.'
-            )
+        self.spectral_cluster = SpectralCluster()
+        self.umap_hdbscan_cluster = UmapHdbscan()
 
     def forward(self, X, **params):
         # clustering and return the labels
         k = params['oracle_num'] if 'oracle_num' in params else None
-        pval = params['pval'] if 'pval' in params else self.model_config['pval']
         assert len(
             X.shape
         ) == 2, 'modelscope error: the shape of input should be [N, C]'
-        if self.model_config['cluster_type'] == 'spectral':
-            if X.shape[0] * pval < 6:
-                pval = 6. / X.shape[0]
-            labels = self.cluster(X, pval, k)
+        if X.shape[0] < 20:
+            return np.zeros(X.shape[0], dtype='int')
+        if X.shape[0] < 2048 or k is not None:
+            labels = self.spectral_cluster(X, k)
         else:
-            raise ValueError(
-                'modelscope error: Only spectral clustering is currently supported.'
-            )
+            labels = self.umap_hdbscan_cluster(X)
 
         if k is None and 'merge_thr' in self.model_config:
             labels = self.merge_by_cos(labels, X,
                                        self.model_config['merge_thr'])
 
         return labels
 
@@ -155,10 +188,10 @@
             affinity = np.triu(affinity, 1)
             spks = np.unravel_index(np.argmax(affinity), affinity.shape)
             if affinity[spks] < cos_thr:
                 break
             for i in range(len(labels)):
                 if labels[i] == spks[1]:
                     labels[i] = spks[0]
-                elif labels[i] > merge_spks[1]:
+                elif labels[i] > spks[1]:
                     labels[i] -= 1
         return labels
```

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/ecapa_tdnn.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/ecapa_tdnn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/fusion.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/generic_speaker_verification.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/generic_speaker_verification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/pooling_layers.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/pooling_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/rdino.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/rdino.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/sv/speaker_change_locator.py` & `modelscope-1.8.0rc0/modelscope/models/audio/sv/speaker_change_locator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/tts/sambert_hifi.py` & `modelscope-1.8.0rc0/modelscope/models/audio/tts/sambert_hifi.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/audio/tts/voice.py` & `modelscope-1.8.0rc0/modelscope/models/audio/tts/voice.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/base/base_head.py` & `modelscope-1.8.0rc0/modelscope/models/base/base_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/base/base_model.py` & `modelscope-1.8.0rc0/modelscope/models/base/base_model.py`

 * *Files 2% similar despite different names*

```diff
@@ -84,14 +84,16 @@
             device(str, `optional`): The device to load the model.
             **kwargs:
                 task(str, `optional`): The `Tasks` enumeration value to replace the task value
                 read out of config in the `model_name_or_path`. This is useful when the model to be loaded is not
                 equal to the model saved.
                 For example, load a `backbone` into a `text-classification` model.
                 Other kwargs will be directly fed into the `model` key, to replace the default configs.
+                use_hf(bool): If set True, will use AutoModel in hf to initialize the model to keep compatibility
+                    with huggingface transformers.
         Returns:
             A model instance.
 
         Examples:
             >>> from modelscope.models import Model
             >>> Model.from_pretrained('damo/nlp_structbert_backbone_base_std', task='text-classification')
         """
@@ -112,14 +114,19 @@
                     'Expecting model is pre-fetched locally, but is not found.'
                 )
 
             invoked_by = '%s/%s' % (Invoke.KEY, invoked_by)
             local_model_dir = snapshot_download(
                 model_name_or_path, revision, user_agent=invoked_by)
         logger.info(f'initialize model from {local_model_dir}')
+
+        if kwargs.pop('use_hf', False):
+            from modelscope import AutoModel
+            return AutoModel.from_pretrained(local_model_dir)
+
         if cfg_dict is not None:
             cfg = cfg_dict
         else:
             cfg = Config.from_file(
                 osp.join(local_model_dir, ModelFile.CONFIGURATION))
         task_name = cfg.task
         if 'task' in kwargs:
```

### Comparing `modelscope-1.7.1/modelscope/models/base/base_torch_head.py` & `modelscope-1.8.0rc0/modelscope/models/base/base_torch_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/base/base_torch_model.py` & `modelscope-1.8.0rc0/modelscope/models/base/base_torch_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/builder.py` & `modelscope-1.8.0rc0/modelscope/models/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_detection/action_detection_onnx.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_detection/action_detection_onnx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/action_detection_pytorch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_detection/modules/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_detection/modules/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_recognition/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_recognition/models.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_recognition/s3dg.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/s3dg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_recognition/tada_convnext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/tada_convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/action_recognition/temporal_patch_shift_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/animal_recognition/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/animal_recognition/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/animal_recognition/splat.py` & `modelscope-1.8.0rc0/modelscope/models/cv/animal_recognition/splat.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py` & `modelscope-1.8.0rc0/modelscope/models/cv/bad_image_detecting/bad_image_detecting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/hrnet_basic_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/hrnet_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_2d_keypoints/w48.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_2d_keypoints/w48.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/block.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/directed_graph.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py` & `modelscope-1.8.0rc0/modelscope/models/cv/body_3d_keypoints/hdformer/skeleton.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/LK/lk.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/LK/lk.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/face_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/face_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/face_landmark.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/face_landmark.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/facelib/facer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/facelib/facer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/loss.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/model_tf.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/model_tf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/network.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cartoon/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cartoon/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/c3d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/c3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/resnet2p1d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/cmdssl_video_embedding/resnet3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/annotator.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/annotator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/api.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/midas/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/midas/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/mlsd/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/body.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/hand.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/annotator/openpose/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/controllable_image_generation/controlnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/controllable_image_generation/controlnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/crowd_counting/cc_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/cc_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py` & `modelscope-1.8.0rc0/modelscope/models/cv/crowd_counting/hrnet_aspp_relu.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/detectors.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/detectors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/mogface.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/mogface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/mogprednet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/mogprednet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mogface/models/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mogface/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/first_stage.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/mtcnn/models/get_nets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/LK/lk.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/face_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/face_landmark.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/peppa_pig_face/facer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/peppa_pig_face/facer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/detection.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/models/retinaface.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/retinaface/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/damofd_detect.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/damofd_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/preprocessor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/scrfd_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/scrfd/tinymog_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/detection.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_detection/ulfd_slim/vision/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/efficient/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/efficient/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/emotion_infer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/emotion_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/emotion_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/emotion_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/face.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/face.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_emotion/face_alignment/face_align.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_emotion/face_alignment/face_align.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_generation/op/conv2d_gradfix.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_generation/op/fused_act.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_generation/op/upfirdn2d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_generation/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_generation/stylegan2.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_generation/stylegan2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/det_infer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/det_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/ghost_pan.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/ghost_pan.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/nanodet_plus_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/one_stage_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/shufflenetv2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_human_hand_detection/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_human_hand_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/align_face.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/align_face.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/common.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/backbone/model_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_recognition/torchkit/rts_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/bfm.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/bfm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/de_retouching_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/facerecon_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/facerecon_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/losses.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/networks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/nv_diffrast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/renderer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/renderer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/models/unet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/models/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/face_reconstruction/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/face_reconstruction/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py` & `modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/facial_expression_recognition/fer/vgg.py` & `modelscope-1.8.0rc0/modelscope/models/cv/facial_expression_recognition/fer/vgg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py` & `modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/hand_static/hand_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/hand_static/hand_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/hand_static/networks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/hand_static/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/Reconstruction.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/Reconstruction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Embedding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/PixToMesh.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/PixToMesh.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Res_backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Res_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/Surface_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/Surface_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/detectors.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/detectors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/geometry.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/geometry.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/human_segmenter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/human_segmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/models/networks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/models/networks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/human_reconstruction/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/human_reconstruction/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/binary_quant_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_binary_quant_classification/bnext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_binary_quant_classification/bnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/image_body_reshaping.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/person_info.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/person_info.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/body.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/pose_estimator/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_body_reshaping/slim_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_body_reshaping/slim_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/beit_v2.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/beit_v2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/backbones/nextvit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/backbones/nextvit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/mmcls_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/mmcls_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/resnet50_cc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/resnet50_cc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_classification/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_classification/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/adaint/adaint.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/adaint/adaint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/csrnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/csrnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/deeplpf/deeplpfnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_color_enhance/image_color_enhance.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_color_enhance/image_color_enhance.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/ddcolor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/loss.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/transformer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/ddcolor/utils/vgg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/unet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_colorization/unet/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_colorization/unet/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_debanding/rrdb/rrdb_image_debanding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_deblur/nafnet_for_image_deblur.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/calibration_layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/defrcn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/fast_rcnn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/gdl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/models/roi_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/coco_register.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/register_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/requirements_check.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_defrcn_fewshot/utils/voc_register.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_denoise/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/NAFNet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet/arch_util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet/arch_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_denoise/nafnet_for_image_denoise.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/newcrf_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/networks/uper_crf_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation/newcrfs_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation/newcrfs_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/bts_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_depth_estimation_bts/networks/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_driving_perception/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/image_driving_percetion_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_driving_perception/preprocessor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_driving_perception/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_driving_perception/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/gan_wrap.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/fused_act.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facegan/op/upfirdn2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/align_trans.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/align_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/facelib/matlab_cp2tform.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/image_face_fusion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/image_face_fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/aad_layer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/aad_layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/aei_flow_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/bfm.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/bfm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/dense_motion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/dense_motion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/facerecon_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/facerecon_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/model_irse.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_face_fusion/network/ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_face_fusion/network/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/backbone/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/backbone/deeplab_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp/m2fp_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/m2fp_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/m2fp_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_human_parsing/parsing_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_human_parsing/parsing_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/default.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/default.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ade20k/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/adversarial.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/adversarial.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/feature_matching.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/feature_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/ffc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/ffc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/inception.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/inception.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/perceptual.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/perceptual.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/modules/pix2pixhd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_inpainting/refinement.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_inpainting/refinement.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/backbones/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/datasets/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/fastinst_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/fastinst_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/dino_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/maskdino_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_instance_segmentation/postprocess_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/config/default.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/config/default.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_matching/quadtree_attention_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_matching/quadtree_attention_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/cas_mvsnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/casmvs_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/depth_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/general_eval_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/module.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_mvs_depth_estimation/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_mvs_depth_estimation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_paintbyexample/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_paintbyexample/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_panoptic_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_panoptic_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_panoptic_segmentation/panseg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/align_faces.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/align_faces.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/fqa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/eqface/model_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/gpen.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/gpen.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/image_portrait_enhancement.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/helpers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/losses.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/losses/model_irse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_portrait_enhancement/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_probing_model/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_probing_model/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_probing_model/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_probing_model/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_probing_model/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/degradation_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/image_quality_assessment_man.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/maniqa.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/maniqa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_man/swin.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_man/swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/backbones/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/heads/simple_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_reid_person/pass_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/pass_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_reid_person/transreid_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_reid_person/transreid_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_restoration/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_restoration/demoire_models/nets.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/demoire_models/nets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_restoration/image_restoration_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_restoration/image_restoration_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_seg/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/semantic_seg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/preprocessor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/BlockModules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_backnone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/ptsemseg/unet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/ptsemseg/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/skychange.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/skychange.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_skychange/skychange_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_skychange/skychange_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/data/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/data/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/data/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/autoencoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/models/clip.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/models/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_generation/ops/losses.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_generation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/data/transforms.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/data/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/model_translation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/model_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/autoencoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/models/clip.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/models/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/apps.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/apps.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/degradation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/degradation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/losses.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/losses.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/metrics.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/metrics.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/random_color.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/random_color.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/random_mask.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/random_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/svd.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/svd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/image_to_image_translation/ops/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/image_to_image_translation/ops/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/fourier.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/panostretch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/misc/post_proc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/modality/layout.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/panovit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/networks/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/networks/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/indoor_layout_estimation/panovit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/indoor_layout_estimation/panovit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/summarizer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/summarizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/models.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/language_guided_video_summarization/transformer/sub_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/cfg_sampler.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/cfg_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/mdm.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/mdm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/respace.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/respace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/rotation2xyz.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/rotation2xyz.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/motion_generation/modules/smpl.py` & `modelscope-1.8.0rc0/modelscope/models/cv/motion_generation/modules/smpl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/get_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/get_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/save_op.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/movie_scene_segmentation/utils/trn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/movie_scene_segmentation/utils/trn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/dataloader/read_write_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/nerf_preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/nerf.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/nerf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/segmenter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_acc/network/segmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/nerf_recon_acc/network/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/nerf_recon_4k/network/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/necks/fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/depe_detect.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/depe_detect.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/object_detection_3d/depe/result_vis.py` & `modelscope-1.8.0rc0/modelscope/models/cv/object_detection_3d/depe/result_vis.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/dbnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/dbnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/mix_ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/mix_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/proxyless.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/proxyless.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/modules/seg_detector_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/preprocessor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_detection/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/CRNN/main_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/ocr_recognition/preprocessor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/ocr_recognition/preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/open_vocabulary_detection_vild/vild.py` & `modelscope-1.8.0rc0/modelscope/models/cv/open_vocabulary_detection_vild/vild.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/equi.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/equi.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/mobilenet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/unifuse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/networks/util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/networks/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/panorama_depth_estimation/unifuse_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/pedestrian_attribute_recognition/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/pedestrian_attribute_recognition/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py` & `modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/rcp_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py` & `modelscope-1.8.0rc0/modelscope/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_detection.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_embedding.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_retrieval_embedding/item_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_retrieval_embedding/item_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_segmentation/net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/product_segmentation/seg_infer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/product_segmentation/seg_infer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/criterion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/matcher.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/misc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/mttr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/robust_image_classification/easyrobust_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/robust_image_classification/easyrobust_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/backbone/Res2Net_v1b.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/models/modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/models/senet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/senet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/models/u2net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/u2net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/models/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/salient_detection/salient_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/salient_detection/salient_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/common.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/head_fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/head_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/models.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/models.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/neck_fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/neck_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/shop_seg_base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/shop_seg_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/shop_seg_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/shop_seg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/shop_segmentation/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/shop_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/detection_module.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/detection_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/detection_model/detection_unet_in.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/gconv.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/inpainting_model/inpainting_unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/box_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/box_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/network.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/predict_single.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/predict_single.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/prior_box.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/prior_box.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/retinaface/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/retinaface/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/unet_deploy.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/unet_deploy.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/skin_retouching/weights_init.py` & `modelscope-1.8.0rc0/modelscope/models/cv/skin_retouching/weights_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/data/data_augment.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/data/data_augment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/default/streamyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/exp/yolox_base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/exp/yolox_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/darknet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/darknet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/dfp_pafpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/network_blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/network_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/streamyolo.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/streamyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/models/tal_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/models/tal_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/realtime_video_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/realtime_video_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/stream_yolo/utils/boxes.py` & `modelscope-1.8.0rc0/modelscope/models/cv/stream_yolo/utils/boxes.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/super_resolution/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/super_resolution/arch_util.py` & `modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/arch_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/super_resolution/ecb.py` & `modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/ecb.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/super_resolution/ecbsr_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/ecbsr_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/super_resolution/rrdbnet_arch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/super_resolution/rrdbnet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/table_recognition/lineless_table_process.py` & `modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/lineless_table_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/table_recognition/model_lore.py` & `modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/model_lore.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/lore_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/lore_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/table_recognition/modules/lore_processor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/table_recognition/modules/lore_processor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/clip.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/lseg_vit.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/lseg_vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/basic_blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/basic_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/global_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/global_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/master_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/master_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/model_zoo.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/model_zoo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/plain_net_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/plain_net_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_idwexkx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_k1kxk1.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_classfication/super_res_kxkx.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/detector_evaluater.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/apis/detector_inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/base_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/core/weight_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/detectors/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/bounding_box.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/boxlist_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/structures/image_list.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/boxes.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/damo/utils/scheduler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/tinynas_damoyolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/tinynas_detector.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/tinynas_detector.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/tinynas_detection/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/tinynas_detection/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/UNet_for_video_deinterlace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/deinterlace_arch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/deinterlace_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/archs.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/archs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/deep_fourier_upsampling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/enh.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/enh.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/fre.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/fre.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_deinterlace/models/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_deinterlace/models/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/configs/default_config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/configs/default_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/dro_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/dro_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/camera.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/camera.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/camera_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/pose.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/pose.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/geometry/pose_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/model_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/sfm_model_mf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/models/sup_model_mf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/networks/optim/update.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/networks/optim/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/augmentations.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/augmentations.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/depth.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/depth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/horovod.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/horovod.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/image.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/image_gt.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/image_gt.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/load.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/load.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/misc.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/misc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_depth_estimation/utils/types.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_depth_estimation/utils/types.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/VFINet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/corr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/flow_model/update.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/flow_model/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/UNet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/flow_reversal.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/interp_model/transformer_layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/scene_change_detection.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_frame_interpolation/utils/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_frame_interpolation/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/deep_guided_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/effv2.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/effv2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/lraspp.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/lraspp.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_human_matting/models/matting.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_human_matting/models/matting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_inpainting/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_inpainting/inpainting.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/inpainting.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_inpainting/inpainting_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_inpainting/inpainting_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/neck/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/neck/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_instance_segmentation/video_knet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_instance_segmentation/video_knet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/common.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/decode.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/decode.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/models/yolo.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/models/yolo.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/basetrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/matching.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/tracker/multitracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/image.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/kalman_filter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_multi_object_tracking/utils/visualization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/aggregate.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/aggregate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/cbam.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/cbam.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/eval_network.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/eval_network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/inference_core.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/inference_core.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/inference_memory_bank.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/mod_resnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/mod_resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/modules.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/modules.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_object_segmentation/network.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_object_segmentation/network.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_update_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/kernel_updator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/mask.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/head/track_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/neck/fpn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/video_k_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_panoptic_segmentation/visualizer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_panoptic_segmentation/visualizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/config/ostrack.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/config/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/attn.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/attn_blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/procontext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/models/procontext/vit_ce.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/ostrack.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/tracker/procontext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_single_object_tracking/utils/utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_single_object_tracking/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/DUT_raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/MotionPro.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/MotionPro.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/corr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/extractor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/raft.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/RAFT/update.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/Smoother.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/Smoother.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/config.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/rf_det_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUT/rf_det_so.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/DUTRAFTStabilizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/IterativeSmooth.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/MedianFilter.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/MedianFilter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/ProjectionUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/RAFTUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/WarpUtils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/WarpUtils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/image_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/image_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_stabilization/utils/math_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_stabilization/utils/math_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/longshortnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/base_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/base_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/cpd_auto.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/cpd_auto.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/kts/cpd_nonlin.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/pgl_sum.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/pgl_sum.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_summarization/summarizer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_summarization/summarizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/basicvsr_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/basicvsr_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/common.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/msrresnet_lite_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py` & `modelscope-1.8.0rc0/modelscope/models/cv/video_super_resolution/real_basicvsr_net.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vidt/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vidt/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vidt/deformable_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vidt/deformable_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vidt/fpn_fusion.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vidt/fpn_fusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vidt/head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vidt/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vidt/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vidt/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/virual_tryon/sdafnet.py` & `modelscope-1.8.0rc0/modelscope/models/cv/virual_tryon/sdafnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/petl.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/petl.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_helpers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_vision_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/timm_weight_init.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_efficient_tuning/vision_efficient_tuning.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_middleware/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_middleware/head.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_middleware/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vision_middleware/vim.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vision_middleware/vim.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/basic_utils.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/basic_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/model.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/model_se.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/model_se.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/cv/vop_retrieval/tokenization_clip.py` & `modelscope-1.8.0rc0/modelscope/models/cv/vop_retrieval/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/clip/bert_tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/bert_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/clip/configuration_bert.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/configuration_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/clip/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/clip/modeling_bert.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/clip/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/clip_interrogator/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/clip_interrogator/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/structbert.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/structbert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_generator.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_upsampler_1024.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/diffusion/unet_upsampler_256.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/dpm_solver_pytorch.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/dpm_solver_pytorch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/efficient_diffusion_tuning/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py`

 * *Files 12% similar despite different names*

```diff
@@ -15,15 +15,19 @@
 from diffusers.utils import deprecation_utils
 from transformers import CLIPTextModel, CLIPTokenizer
 
 from modelscope.metainfo import Models
 from modelscope.models import TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.outputs import OutputKeys
+from modelscope.swift import Swift
+from modelscope.swift.adapter import AdapterConfig
 from modelscope.swift.control_sd_lora import ControlLoRATuner
+from modelscope.swift.lora import LoRAConfig
+from modelscope.swift.prompt import PromptConfig
 from modelscope.swift.sd_lora import LoRATuner
 from modelscope.utils.checkpoint import save_checkpoint, save_configuration
 from modelscope.utils.config import Config
 from modelscope.utils.constant import ModelFile, Tasks
 
 utils.deprecate = lambda *arg, **kwargs: None
 deprecation_utils.deprecate = lambda *arg, **kwargs: None
@@ -98,41 +102,84 @@
                 subfolder='unet',
                 revision=revision)
             self.unet.requires_grad_(False)
             self.vae.requires_grad_(False)
             self.text_encoder.requires_grad_(False)
         self.is_control = tuner_name.startswith('control_')
         self.tuner_name = tuner_name
-        if tuner_name in ('lora', 'control_lora'):
+
+        if tuner_name == 'swift-lora':
+            rank = tuner_config[
+                'rank'] if tuner_config and 'rank' in tuner_config else 4
+            lora_config = LoRAConfig(
+                rank=rank,
+                replace_modules=['to_q', 'to_k', 'to_v', 'to_out.0'],
+                merge_weights=False,
+                only_lora_trainable=False,
+                use_merged_linear=False,
+                pretrained_weights=pretrained_tuner)
+            self.unet = Swift.prepare_model(self.unet, lora_config)
+        elif tuner_name == 'swift-adapter':
+            adapter_length = tuner_config[
+                'adapter_length'] if tuner_config and 'adapter_length' in tuner_config else 10
+            adapter_config = AdapterConfig(
+                dim=-1,
+                hidden_pos=0,
+                module_name=r'.*ff\.net\.2$',
+                adapter_length=adapter_length,
+                only_adapter_trainable=False,
+                pretrained_weights=pretrained_tuner)
+            self.unet = Swift.prepare_model(self.unet, adapter_config)
+        elif tuner_name == 'swift-prompt':
+            prompt_length = tuner_config[
+                'prompt_length'] if tuner_config and 'prompt_length' in tuner_config else 10
+            prompt_config = PromptConfig(
+                dim=[
+                    320, 320, 640, 640, 1280, 1280, 1280, 1280, 1280, 640, 640,
+                    640, 320, 320, 320
+                ],
+                module_layer_name=
+                r'.*[down_blocks|up_blocks|mid_block]\.\d+\.attentions\.\d+\.transformer_blocks\.\d+$',
+                embedding_pos=0,
+                prompt_length=prompt_length,
+                only_prompt_trainable=False,
+                attach_front=False,
+                pretrained_weights=pretrained_tuner,
+                extract_embedding=True)
+            self.unet = Swift.prepare_model(self.unet, prompt_config)
+        elif tuner_name in ('lora', 'control_lora'):
             # if not set the config of control-tuner, we add the lora tuner directly to the original framework,
             # otherwise the control side network is also added.
             tuner_cls = __tuner_MAP__[tuner_name]
             tuner = tuner_cls.tune(
                 self,
                 tuner_config=osp.join(model_dir, tuner_config),
                 pretrained_tuner=pretrained_tuner)
             self.tuner = tuner
 
     def train(self, mode: bool = True):
         self.training = mode
         if hasattr(self, 'tuner'):
             self.tuner.train(mode=mode)
+        else:
+            super().train(mode=mode)
 
     def load_state_dict(self,
                         state_dict: Mapping[str, Any],
                         strict: bool = True):
         if hasattr(self, 'tuner'):
             self.tuner.load_state_dict(state_dict=state_dict, strict=strict)
         else:
-            return super().load_state_dict(
-                state_dict=state_dict, strict=strict)
+            super().load_state_dict(state_dict=state_dict, strict=strict)
 
     def state_dict(self):
         if hasattr(self, 'tuner'):
             return self.tuner.state_dict()
+        elif self.tuner_name.startswith('swift'):
+            return self.unet.state_dict()
         else:
             return super().state_dict()
 
     def tokenize_caption(self, captions):
         """ Convert caption text to token data.
 
         Args:
@@ -143,21 +190,29 @@
             captions,
             max_length=self.tokenizer.model_max_length,
             padding='max_length',
             truncation=True,
             return_tensors='pt')
         return inputs.input_ids
 
-    def forward(self, prompt='', cond=None, target=None):
+    def forward(self, prompt='', cond=None, target=None, **args):
         if self.inference:
-            generator = torch.Generator(device=self.device).manual_seed(0)
+            if 'generator_seed' in args and isinstance(args['generator_seed'],
+                                                       int):
+                generator = torch.Generator(device=self.device).manual_seed(
+                    args['generator_seed'])
+            else:
+                generator = None
+            num_inference_steps = args.get('num_inference_steps', 30)
             if self.is_control:
                 _ = self.tuner(cond.to(self.device)).control_states
             images = self.pipe(
-                prompt, num_inference_steps=30, generator=generator).images
+                prompt,
+                num_inference_steps=num_inference_steps,
+                generator=generator).images
             return images
         else:
             with torch.no_grad():
                 latents = self.vae.encode(
                     target.to(dtype=self.weight_dtype)).latent_dist.sample()
             latents = latents * self.vae.config.scaling_factor
             # Sample noise that we'll add to the latents
@@ -221,14 +276,15 @@
                         save_config_function: Callable = save_configuration,
                         **kwargs):
 
         if config is None and hasattr(self, 'cfg'):
             config = self.cfg
 
         config['model']['inference'] = True
+        config['model']['pretrained_tuner'] = 'pytorch_model.bin'
         super().save_pretrained(target_folder, save_checkpoint_names,
                                 save_function, config, save_config_function,
                                 **kwargs)
 
     @classmethod
     def _instantiate(cls, model_dir, **kwargs):
         config = Config.from_file(osp.join(model_dir, ModelFile.CONFIGURATION))
```

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/gemm/gemm_base.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/gemm_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/gemm/gemm_model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/gemm_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/gemm/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/gemm/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/respace.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/respace.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/script.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/script.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/guided_diffusion/unet.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/guided_diffusion/unet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mgeo/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mgeo/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mgeo/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mgeo/text_ranking.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mgeo/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mgeo/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/dataloaders/rawvideo_util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/dynamic_inverted_softmax.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/modeling.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/modeling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/module_clip.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/module_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/module_cross.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/module_cross.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/tokenization_clip.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/tokenization_clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mmr/models/until_module.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mmr/models/until_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/clip/clip.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/clip/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/configuration_mplug.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/configuration_mplug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/modeling_mplug.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/modeling_mplug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/mvit.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/mvit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug/predictor.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug/predictor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug_for_all_tasks.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_for_all_tasks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/configuration_mplug_owl.py`

 * *Files 6% similar despite different names*

```diff
@@ -70,14 +70,15 @@
         patch_size=14,
         hidden_act='quick_gelu',
         layer_norm_eps=1e-6,
         attention_dropout=0.0,
         initializer_range=0.02,
         initializer_factor=1.0,
         use_flash_attn=False,
+        use_fp32_layernorm=True,
         **kwargs,
     ):
         super().__init__(**kwargs)
 
         self.hidden_size = hidden_size
         self.intermediate_size = intermediate_size
         self.projection_dim = projection_dim
@@ -88,14 +89,15 @@
         self.image_size = image_size
         self.initializer_range = initializer_range
         self.initializer_factor = initializer_factor
         self.attention_dropout = attention_dropout
         self.layer_norm_eps = layer_norm_eps
         self.hidden_act = hidden_act
         self.use_flash_attn = use_flash_attn
+        self.use_fp32_layernorm = use_fp32_layernorm
 
     @classmethod
     def from_pretrained(cls, pretrained_model_name_or_path: Union[str,
                                                                   os.PathLike],
                         **kwargs) -> 'PretrainedConfig':
         config_dict, kwargs = cls.get_config_dict(
             pretrained_model_name_or_path, **kwargs)
@@ -125,26 +127,28 @@
         num_hidden_layers=6,
         num_attention_heads=16,
         intermediate_size=4096,
         attention_probs_dropout_prob=0.1,
         initializer_range=0.02,
         layer_norm_eps=1e-6,
         encoder_hidden_size=1024,
+        use_fp32_layernorm=True,
         **kwargs,
     ):
         super().__init__(**kwargs)
 
         self.hidden_size = hidden_size
         self.num_hidden_layers = num_hidden_layers
         self.num_attention_heads = num_attention_heads
         self.intermediate_size = intermediate_size
         self.attention_probs_dropout_prob = attention_probs_dropout_prob
         self.initializer_range = initializer_range
         self.layer_norm_eps = layer_norm_eps
         self.encoder_hidden_size = encoder_hidden_size
+        self.use_fp32_layernorm = use_fp32_layernorm
 
     @classmethod
     def from_pretrained(cls, pretrained_model_name_or_path: Union[str,
                                                                   os.PathLike],
                         **kwargs) -> 'PretrainedConfig':
         config_dict, kwargs = cls.get_config_dict(
             pretrained_model_name_or_path, **kwargs)
```

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/mplug_owl/modeling_mplug_owl.py`

 * *Files 2% similar despite different names*

```diff
@@ -81,14 +81,156 @@
     def to_tuple(self) -> Tuple[Any]:
         return tuple(
             self[k] if k not in ['vision_outputs', 'language_model_outputs'
                                  ] else getattr(self, k).to_tuple()
             for k in self.keys())
 
 
+# Hack for bloomz
+def bloom_forward(
+    self,
+    input_ids: Optional[torch.LongTensor] = None,
+    past_key_values: Optional[Tuple[Tuple[torch.Tensor, torch.Tensor],
+                                    ...]] = None,
+    attention_mask: Optional[torch.Tensor] = None,
+    head_mask: Optional[torch.LongTensor] = None,
+    inputs_embeds: Optional[torch.LongTensor] = None,
+    use_cache: Optional[bool] = None,
+    output_attentions: Optional[bool] = None,
+    output_hidden_states: Optional[bool] = None,
+    return_dict: Optional[bool] = None,
+    **deprecated_arguments,
+) -> Union[Tuple[torch.Tensor, ...],
+           BaseModelOutputWithPastAndCrossAttentions]:
+    if len(deprecated_arguments) > 0:
+        raise ValueError(f'Got unexpected arguments: {deprecated_arguments}')
+
+    output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions
+    output_hidden_states = (
+        output_hidden_states if output_hidden_states is not None else
+        self.config.output_hidden_states)
+    use_cache = use_cache if use_cache is not None else self.config.use_cache
+    return_dict = return_dict if return_dict is not None else self.config.use_return_dict
+
+    if input_ids is not None and inputs_embeds is not None:
+        raise ValueError(
+            'You cannot specify both input_ids and inputs_embeds at the same time'
+        )
+    elif input_ids is not None:
+        batch_size, seq_length = input_ids.shape
+    elif inputs_embeds is not None:
+        batch_size, seq_length, _ = inputs_embeds.shape
+    else:
+        raise ValueError(
+            'You have to specify either input_ids or inputs_embeds')
+
+    if past_key_values is None:
+        past_key_values = tuple([None] * len(self.h))
+
+    # Prepare head mask if needed
+    # 1.0 in head_mask indicate we keep the head
+    # attention_probs has shape batch_size x num_heads x N x N
+    # head_mask has shape n_layer x batch x num_heads x N x N
+    head_mask = self.get_head_mask(head_mask, self.config.n_layer)
+
+    if inputs_embeds is None:
+        inputs_embeds = self.word_embeddings(input_ids)
+        inputs_embeds = self.word_embeddings_layernorm(inputs_embeds)
+
+    hidden_states = inputs_embeds
+
+    presents = () if use_cache else None
+    all_self_attentions = () if output_attentions else None
+    all_hidden_states = () if output_hidden_states else None
+
+    # Compute alibi tensor: check build_alibi_tensor documentation
+    seq_length_with_past = seq_length
+    past_key_values_length = 0
+    if past_key_values[0] is not None:
+        past_key_values_length = past_key_values[0][0].shape[2]
+        seq_length_with_past = seq_length_with_past + past_key_values_length
+    if attention_mask is None:
+        attention_mask = torch.ones((batch_size, seq_length_with_past),
+                                    device=hidden_states.device)
+    else:
+        attention_mask = attention_mask.to(hidden_states.device)
+
+    alibi = self.build_alibi_tensor(
+        attention_mask, self.num_heads, dtype=hidden_states.dtype)
+
+    causal_mask = self._prepare_attn_mask(
+        attention_mask,
+        input_shape=(batch_size, seq_length),
+        past_key_values_length=past_key_values_length,
+    )
+
+    for i, (block, layer_past) in enumerate(zip(self.h, past_key_values)):
+        if output_hidden_states:
+            all_hidden_states = all_hidden_states + (hidden_states, )
+
+        if self.gradient_checkpointing and self.training:
+
+            def create_custom_forward(module):
+
+                def custom_forward(*inputs):
+                    # None for past_key_value
+                    return module(
+                        *inputs,
+                        use_cache=use_cache,
+                        output_attentions=output_attentions)
+
+                return custom_forward
+
+            outputs = torch.utils.checkpoint.checkpoint(
+                create_custom_forward(block),
+                hidden_states,
+                alibi,
+                causal_mask,
+                layer_past,
+                head_mask[i],
+            )
+        else:
+            outputs = block(
+                hidden_states,
+                layer_past=layer_past,
+                attention_mask=causal_mask,
+                head_mask=head_mask[i],
+                use_cache=use_cache,
+                output_attentions=output_attentions,
+                alibi=alibi,
+            )
+
+        hidden_states = outputs[0]
+        if use_cache is True:
+            presents = presents + (outputs[1], )
+
+        if output_attentions:
+            all_self_attentions = all_self_attentions + (
+                outputs[2 if use_cache else 1], )
+
+    # Add last hidden state
+    hidden_states = self.ln_f(hidden_states)
+
+    if output_hidden_states:
+        all_hidden_states = all_hidden_states + (hidden_states, )
+
+    if not return_dict:
+        return tuple(
+            v for v in
+            [hidden_states, presents, all_hidden_states, all_self_attentions]
+            if v is not None)
+
+    return BaseModelOutputWithPastAndCrossAttentions(
+        last_hidden_state=hidden_states,
+        past_key_values=presents,
+        hidden_states=all_hidden_states,
+        attentions=all_self_attentions,
+    )
+
+
 def get_ltor_masks_and_position_ids_from_embeddings(data):
     """Build masks and position id for left to right model."""
 
     # Extract batch size and sequence length.
     micro_batch_size, seq_length = data.size()[:2]
 
     # Attention mask (lower triangular).
@@ -132,15 +274,16 @@
             bias=False)
 
         self.num_patches = (self.image_size // self.patch_size)**2
 
         self.position_embedding = nn.Parameter(
             torch.randn(1, self.num_patches + 1, self.hidden_size))
 
-        self.pre_layernorm = LayerNormFp32(
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.pre_layernorm = layernorm_func(
             self.hidden_size, eps=config.layer_norm_eps)
 
     def forward(self, pixel_values: torch.FloatTensor) -> torch.Tensor:
         batch_size = pixel_values.size(0)
         image_embeds = self.patch_embed(pixel_values)
         image_embeds = image_embeds.flatten(2).transpose(1, 2)
 
@@ -273,18 +416,19 @@
 
 class MplugOwlVisionEncoderLayer(nn.Module):
 
     def __init__(self, config: MplugOwlVisionConfig):
         super().__init__()
         self.hidden_size = config.hidden_size
         self.self_attn = MplugOwlVisionAttention(config)
-        self.input_layernorm = LayerNormFp32(
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.input_layernorm = layernorm_func(
             self.hidden_size, eps=config.layer_norm_eps)
         self.mlp = MplugOwlMLP(config)
-        self.post_attention_layernorm = LayerNormFp32(
+        self.post_attention_layernorm = layernorm_func(
             self.hidden_size, eps=config.layer_norm_eps)
 
     def forward(
         self,
         hidden_states: torch.Tensor,
         attention_mask: torch.Tensor,
         output_attentions: Optional[bool] = False,
@@ -584,15 +728,16 @@
     def __init__(self, config: MplugOwlVisionConfig):
         super().__init__(config)
         self.config = config
         self.hidden_size = config.hidden_size
 
         self.embeddings = MplugOwlVisionEmbeddings(config)
         self.encoder = MplugOwlVisionEncoder(config)
-        self.post_layernorm = LayerNormFp32(
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.post_layernorm = layernorm_func(
             self.hidden_size, eps=config.layer_norm_eps)
 
         self.post_init()
 
     def forward(
         self,
         pixel_values: Optional[torch.FloatTensor] = None,
@@ -654,15 +799,17 @@
         hidden_features = multiple_of * \
             ((hidden_features + multiple_of - 1) // multiple_of)
         self.act = nn.SiLU()
 
         self.w1 = nn.Linear(in_features, hidden_features)
         self.w2 = nn.Linear(hidden_features, in_features)
         self.w3 = nn.Linear(in_features, hidden_features)
-        self.ffn_ln = LayerNormFp32(hidden_features, eps=config.layer_norm_eps)
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.ffn_ln = layernorm_func(
+            hidden_features, eps=config.layer_norm_eps)
 
     def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:
         hidden_states = self.act(
             self.w1(hidden_states)) * self.w3(hidden_states)
         hidden_states = self.ffn_ln(hidden_states)
         hidden_states = self.w2(hidden_states)
         return hidden_states
@@ -774,15 +921,16 @@
 
 class MplugOwlVisualAbstractorCrossOutput(nn.Module):
 
     def __init__(self, config: MplugOwlVisualAbstractorConfig):
         super().__init__()
         dim = config.hidden_size
         self.out_proj = nn.Linear(dim, dim, bias=True)
-        self.norm2 = LayerNormFp32(dim)
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.norm2 = layernorm_func(dim)
         self.mlp = MplugOwlVisualAbstractorMLP(config)
 
     def forward(self, hidden_states: torch.Tensor,
                 input_tensor: torch.Tensor) -> torch.Tensor:
         input_tensor = input_tensor + self.out_proj(hidden_states)
         input_tensor = input_tensor + self.mlp(self.norm2(input_tensor))
         return input_tensor
@@ -791,16 +939,17 @@
 class MplugOwlVisualAbstractorAttention(nn.Module):
 
     def __init__(self, config: MplugOwlVisualAbstractorConfig):
         super().__init__()
         self.attention = MplugOwlVisualAbstractorMultiHeadAttention(config)
         self.output = MplugOwlVisualAbstractorCrossOutput(config)
         self.pruned_heads = set()
-        self.norm1 = LayerNormFp32(config.hidden_size)
-        self.normk = LayerNormFp32(config.hidden_size)
+        layernorm_func = LayerNormFp32 if config.use_fp32_layernorm else nn.LayerNorm
+        self.norm1 = layernorm_func(config.hidden_size)
+        self.normk = layernorm_func(config.hidden_size)
 
     def prune_heads(self, heads):
         if len(heads) == 0:
             return
         heads, index = find_pruneable_heads_and_indices(
             heads, self.attention.num_attention_heads,
             self.attention.attention_head_size, self.pruned_heads)
@@ -1155,14 +1304,20 @@
         self.abstractor = MplugOwlVisualAbstractorModel(
             config.visual_abstractor_config, config.text_config.hidden_size)
 
         # if config.use_decoder_only_language_model:
         language_model = AutoModelForCausalLM.from_config(config.text_config)
         self.language_model = language_model
 
+        if config.text_config.model_type == 'bloom':
+            bound_method = bloom_forward.__get__(
+                self.language_model.transformer,
+                self.language_model.transformer.__class__)
+            setattr(self.language_model.transformer, 'forward', bound_method)
+
         # Initialize weights and apply final processing
         self.post_init()
 
     def get_input_embeddings(self):
         return self.language_model.get_input_embeddings()
 
     def set_input_embeddings(self, value):
```

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/clip.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/decoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/prior.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/prior.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/upsampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/multi_stage_diffusion/xglm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/configuration_mmspeech.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/configuration_mmspeech.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/configuration_ofa.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/configuration_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/incremental_decoding_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/multihead_attention.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/multihead_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/ngram_repeat_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/search.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/search.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/sequence_generator.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/sequence_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/token_generation_constraints.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/generate/utils.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/generate/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/modeling_mmspeech.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/modeling_mmspeech.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/modeling_ofa.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/modeling_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/resnet.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/resnet.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/tokenization_ofa.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/tokenization_ofa.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/tokenization_ofa_fast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/constant.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/constant.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/utils/utils.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa/vit.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa/vit.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa_for_all_tasks.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa_for_all_tasks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/ofa_for_text_to_image_synthesis_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/rleg/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/rleg/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/rleg/rleg.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/rleg/rleg.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/blocks.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/blocks.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/clip.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/clip.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/swin_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/swin_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/soonet/utils.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/soonet/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/stable_diffusion/stable_diffusion.py`

 * *Files 12% similar despite different names*

```diff
@@ -2,14 +2,15 @@
 import os
 from functools import partial
 from typing import Callable, List, Optional, Union
 
 import torch
 import torch.nn.functional as F
 from diffusers import AutoencoderKL, DDPMScheduler, UNet2DConditionModel
+from packaging import version
 from transformers import CLIPTextModel, CLIPTokenizer
 
 from modelscope.metainfo import Models
 from modelscope.models import TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.outputs import OutputKeys
 from modelscope.utils.checkpoint import save_checkpoint, save_configuration
@@ -30,14 +31,15 @@
         """ Initialize a vision efficient diffusion tuning model.
 
         Args:
           model_dir: model id or path
         """
         super().__init__(model_dir, *args, **kwargs)
         revision = kwargs.pop('revision', None)
+        xformers_enable = kwargs.pop('xformers_enable', False)
         self.lora_tune = kwargs.pop('lora_tune', False)
         self.dreambooth_tune = kwargs.pop('dreambooth_tune', False)
 
         self.weight_dtype = torch.float32
         self.device = torch.device(
             'cuda' if torch.cuda.is_available() else 'cpu')
 
@@ -62,14 +64,26 @@
             self.text_encoder.requires_grad_(False)
             self.text_encoder = self.text_encoder.to(self.device)
         if self.unet is not None:
             if self.lora_tune:
                 self.unet.requires_grad_(False)
             self.unet = self.unet.to(self.device)
 
+        # xformers accelerate memory efficient attention
+        if xformers_enable:
+            import xformers
+
+            xformers_version = version.parse(xformers.__version__)
+            if xformers_version == version.parse('0.0.16'):
+                logger.warn(
+                    'xFormers 0.0.16 cannot be used for training in some GPUs. '
+                    'If you observe problems during training, please update xFormers to at least 0.0.17.'
+                )
+            self.unet.enable_xformers_memory_efficient_attention()
+
     def tokenize_caption(self, captions):
         """ Convert caption text to token data.
 
         Args:
           captions: a batch of texts.
         Returns: token's data as tensor.
         """
```

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/team/team_model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/team/team_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/team/utils.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/team/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/autoencoder.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/autoencoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/diffusion.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py`

 * *Files 1% similar despite different names*

```diff
@@ -144,15 +144,16 @@
         y = input['text_emb']
         zero_y = input['text_emb_zero']
         context = torch.cat([zero_y, y], dim=0).to(self.device)
         # synthesis
         with torch.no_grad():
             num_sample = 1  # here let b = 1
             max_frames = self.config.model.model_args.max_frames
-            latent_h, latent_w = 32, 32
+            latent_h, latent_w = input['out_height'] // 8, input[
+                'out_width'] // 8
             with amp.autocast(enabled=True):
                 x0 = self.diffusion.ddim_sample_loop(
                     noise=torch.randn(num_sample, 4, max_frames, latent_h,
                                       latent_w).to(
                                           self.device),  # shape: b c f h w
                     model=self.sd_model,
                     model_kwargs=[{
```

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/video_synthesis/unet_sd.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/video_synthesis/unet_sd.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/conv_fpn_trans.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/convnext.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/model.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/modeling_layout_roberta.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/processing.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/processing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/multi_modal/vldoc/transformer_local.py` & `modelscope-1.8.0rc0/modelscope/models/multi_modal/vldoc/transformer_local.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/T5/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/T5/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/T5/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/T5/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/T5/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/T5/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/T5/text2text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/T5/text2text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -17,14 +17,15 @@
         SiameseUieModel,
     )
     from .bloom import BloomModel
     from .codegeex import CodeGeeXForCodeTranslation, CodeGeeXForCodeGeneration
     from .glm_130b import GLM130bForTextGeneration
     from .csanmt import CsanmtForTranslation
     from .canmt import CanmtForTranslation
+    from .polylm import PolyLMForTextGeneration
     from .deberta_v2 import DebertaV2ForMaskedLM, DebertaV2Model
     from .chatglm import ChatGLMForConditionalGeneration, ChatGLMTokenizer, ChatGLMConfig
     from .chatglm2 import ChatGLM2ForConditionalGeneration, ChatGLM2Tokenizer, ChatGLM2Config
     from .gpt_neo import GPTNeoModel
     from .gpt2 import GPT2Model
     from .gpt3 import GPT3ForTextGeneration, DistributedGPT3
     from .gpt_moe import GPTMoEForTextGeneration, DistributedGPTMoE
@@ -71,14 +72,15 @@
                        VecoForSequenceClassification,
                        VecoForTokenClassification, VecoModel)
     from .dgds import (DocumentGroundedDialogGenerateModel,
                        DocumentGroundedDialogRetrievalModel,
                        DocumentGroundedDialogRerankModel)
     from .xlm_roberta import XLMRobertaConfig, XLMRobertaModel
     from .llama import LlamaForTextGeneration, LlamaConfig, LlamaModel, LlamaTokenizer, LlamaTokenizerFast
+    from .llama2 import Llama2ForTextGeneration, Llama2Config, Llama2Model, Llama2Tokenizer, Llama2TokenizerFast
 
 else:
     _import_structure = {
         'bart': ['BartForTextErrorCorrection'],
         'bert': [
             'BertForMaskedLM',
             'BertForTextRanking',
@@ -89,14 +91,15 @@
             'BertModel',
             'BertConfig',
             'SiameseUieModel',
         ],
         'bloom': ['BloomModel'],
         'csanmt': ['CsanmtForTranslation'],
         'canmt': ['CanmtForTranslation'],
+        'polylm': ['PolyLMForTextGeneration'],
         'codegeex':
         ['CodeGeeXForCodeTranslation', 'CodeGeeXForCodeGeneration'],
         'glm_130b': ['GLM130bForTextGeneration'],
         'deberta_v2': ['DebertaV2ForMaskedLM', 'DebertaV2Model'],
         'chatglm': [
             'ChatGLMForConditionalGeneration', 'ChatGLMTokenizer',
             'ChatGLMConfig'
@@ -166,14 +169,18 @@
             'DocumentGroundedDialogRerankModel'
         ],
         'xlm_roberta': ['XLMRobertaConfig', 'XLMRobertaModel'],
         'llama': [
             'LlamaForTextGeneration', 'LlamaConfig', 'LlamaModel',
             'LlamaTokenizer', 'LlamaTokenizerFast'
         ],
+        'llama2': [
+            'Llama2ForTextGeneration', 'Llama2Config', 'Llama2Model',
+            'Llama2Tokenizer', 'Llama2TokenizerFast'
+        ],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bart/text_error_correction.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bart/text_error_correction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/document_segmentation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/document_segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/sentence_embedding.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/sentence_embedding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/siamese_uie.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/siamese_uie.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/text_ranking.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/bert/word_alignment.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/bert/word_alignment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/canmt/canmt_model.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/canmt/canmt_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/canmt/canmt_translation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/canmt/canmt_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/canmt/sequence_generator.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/canmt/sequence_generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/configuration.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,14 @@
 """ ChatGLM model configuration """
 
 from transformers.configuration_utils import PretrainedConfig
-from transformers.utils import logging
 
-logger = logging.get_logger(__name__)
+from modelscope.utils import logger as logging
+
+logger = logging.get_logger()
 
 
 class ChatGLMConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a [`~ChatGLMModel`].
     It is used to instantiate an ChatGLM model according to the specified arguments, defining the model
     architecture. Instantiating a configuration with the defaults will yield a similar configuration to that of
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm/quantization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/quantization.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,17 +2,18 @@
 import bz2
 import ctypes
 from typing import List
 
 import torch
 from torch.nn import Linear
 from torch.nn.parameter import Parameter
-from transformers.utils import logging
 
-logger = logging.get_logger(__name__)
+from modelscope.utils import logger as logging
+
+logger = logging.get_logger()
 
 try:
     from cpm_kernels.kernels.base import LazyKernelCModule, KernelFunction, round_up
 
     class Kernel:
 
         def __init__(self, code: bytes, function_names: List[str]):
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/text_generation.py`

 * *Files 0% similar despite different names*

```diff
@@ -20,32 +20,33 @@
                                            StoppingCriteriaList)
 from transformers.modeling_outputs import (
     BaseModelOutputWithPast, BaseModelOutputWithPastAndCrossAttentions,
     CausalLMOutputWithPast)
 from transformers.modeling_utils import PreTrainedModel
 from transformers.utils import (add_code_sample_docstrings,
                                 add_start_docstrings,
-                                add_start_docstrings_to_model_forward, logging)
+                                add_start_docstrings_to_model_forward)
 
 from modelscope.metainfo import Models
 from modelscope.models import MODELS, Model, TorchModel
 from modelscope.outputs import OutputKeys
+from modelscope.utils import logger as logging
 from modelscope.utils.constant import Tasks
 from .configuration import ChatGLMConfig
 from .tokenization import ChatGLMTokenizer
 
 # flags required to enable jit fusion kernels
 
 if sys.platform != 'darwin':
     torch._C._jit_set_profiling_mode(False)
     torch._C._jit_set_profiling_executor(False)
     torch._C._jit_override_can_fuse_on_cpu(True)
     torch._C._jit_override_can_fuse_on_gpu(True)
 
-logger = logging.get_logger(__name__)
+logger = logging.get_logger()
 
 _CHECKPOINT_FOR_DOC = 'THUDM/ChatGLM-6B'
 _CONFIG_FOR_DOC = 'ChatGLM6BConfig'
 
 CHATGLM_6B_PRETRAINED_MODEL_ARCHIVE_LIST = [
     'THUDM/chatglm-6b',
     # See all ChatGLM-6B models at https://huggingface.co/models?filter=chatglm
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm/tokenization.py`

 * *Files 1% similar despite different names*

```diff
@@ -2,17 +2,19 @@
 import os
 from typing import Dict, List, Optional, Union
 
 import numpy as np
 import sentencepiece as spm
 from transformers.tokenization_utils import PreTrainedTokenizer
 from transformers.tokenization_utils_base import BatchEncoding, EncodedInput
-from transformers.utils import PaddingStrategy, logging
+from transformers.utils import PaddingStrategy
 
-logger = logging.get_logger(__name__)
+from modelscope.utils import logger as logging
+
+logger = logging.get_logger()
 
 PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {
     'THUDM/chatglm-6b': 2048,
 }
 
 
 class TextTokenizer:
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm2/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm2/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/configuration.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 """ ChatGLM model configuration """
 
-from transformers.configuration_utils import PretrainedConfig
-from transformers.utils import logging
+from transformers import PretrainedConfig
 
-logger = logging.get_logger(__name__)
+from modelscope.utils import logger as logging
+
+logger = logging.get_logger()
 
 
 class ChatGLM2Config(PretrainedConfig):
+    model_type = 'chatglm'
 
     def __init__(self,
                  num_layers=28,
                  padded_vocab_size=65024,
                  hidden_size=4096,
                  ffn_hidden_size=13696,
                  kv_channels=128,
@@ -20,24 +22,26 @@
                  attention_dropout=0.0,
                  layernorm_epsilon=1e-5,
                  rmsnorm=True,
                  apply_residual_connection_post_layernorm=False,
                  post_layer_norm=True,
                  add_bias_linear=False,
                  add_qkv_bias=False,
-                 interleaved_qkv=False,
                  bias_dropout_fusion=True,
                  multi_query_attention=False,
                  multi_query_group_num=1,
                  apply_query_key_layer_scaling=True,
                  attention_softmax_in_fp32=True,
                  fp32_residual_connection=False,
                  quantization_bit=0,
+                 pre_seq_len=None,
+                 prefix_projection=False,
                  **kwargs):
         self.num_layers = num_layers
+        self.vocab_size = padded_vocab_size
         self.padded_vocab_size = padded_vocab_size
         self.hidden_size = hidden_size
         self.ffn_hidden_size = ffn_hidden_size
         self.kv_channels = kv_channels
         self.num_attention_heads = num_attention_heads
         self.seq_length = seq_length
         self.hidden_dropout = hidden_dropout
@@ -51,8 +55,10 @@
         self.bias_dropout_fusion = bias_dropout_fusion
         self.multi_query_attention = multi_query_attention
         self.multi_query_group_num = multi_query_group_num
         self.apply_query_key_layer_scaling = apply_query_key_layer_scaling
         self.attention_softmax_in_fp32 = attention_softmax_in_fp32
         self.fp32_residual_connection = fp32_residual_connection
         self.quantization_bit = quantization_bit
+        self.pre_seq_len = pre_seq_len
+        self.prefix_projection = prefix_projection
         super().__init__(**kwargs)
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm2/quantization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/quantization.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,19 +1,18 @@
 import base64
 import bz2
 import ctypes
-from functools import partial
 from typing import List
 
 import torch
-from torch.nn import Linear
 from torch.nn.parameter import Parameter
-from transformers.utils import logging
 
-logger = logging.get_logger(__name__)
+from modelscope.utils import logger as logging
+
+logger = logging.get_logger()
 
 try:
     from cpm_kernels.kernels.base import LazyKernelCModule, KernelFunction, round_up
 
     class Kernel:
 
         def __init__(self, code: bytes, function_names: List[str]):
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm2/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/text_generation.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,46 +1,46 @@
 """ PyTorch ChatGLM model. """
 
 import copy
 import math
-import re
 import sys
 import warnings
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+from typing import Any, Callable, Dict, List, Optional, Tuple
 
 import torch
 import torch.nn.functional as F
 import torch.utils.checkpoint
 from torch import nn
 from torch.nn import CrossEntropyLoss, LayerNorm
 from torch.nn.utils import skip_init
 from transformers.generation.logits_process import LogitsProcessor
 from transformers.generation.utils import (GenerationConfig,
                                            LogitsProcessorList, ModelOutput,
                                            StoppingCriteriaList)
 from transformers.modeling_outputs import (BaseModelOutputWithPast,
                                            CausalLMOutputWithPast)
 from transformers.modeling_utils import PreTrainedModel
-from transformers.utils import logging
 
+from modelscope import Model, TorchModel
 from modelscope.metainfo import Models
-from modelscope.models import MODELS, Model, TorchModel
 from modelscope.outputs import OutputKeys
+from modelscope.utils import logger as logging
 from modelscope.utils.constant import Tasks
+from ... import MODELS
 from .configuration import ChatGLM2Config
 
 # flags required to enable jit fusion kernels
 
 if sys.platform != 'darwin':
     torch._C._jit_set_profiling_mode(False)
     torch._C._jit_set_profiling_executor(False)
     torch._C._jit_override_can_fuse_on_cpu(True)
     torch._C._jit_override_can_fuse_on_gpu(True)
 
-logger = logging.get_logger(__name__)
+logger = logging.get_logger()
 
 _CHECKPOINT_FOR_DOC = 'THUDM/ChatGLM2-6B'
 _CONFIG_FOR_DOC = 'ChatGLM6BConfig'
 
 CHATGLM_6B_PRETRAINED_MODEL_ARCHIVE_LIST = [
     'THUDM/chatglm2-6b',
     # See all ChatGLM models at https://huggingface.co/models?filter=chatglm
@@ -57,25 +57,58 @@
                  scores: torch.FloatTensor) -> torch.FloatTensor:
         if torch.isnan(scores).any() or torch.isinf(scores).any():
             scores.zero_()
             scores[..., 5] = 5e4
         return scores
 
 
+class PrefixEncoder(torch.nn.Module):
+    """
+    The torch.nn model to encode the prefix
+    Input shape: (batch-size, prefix-length)
+    Output shape: (batch-size, prefix-length, 2*layers*hidden)
+    """
+
+    def __init__(self, config: ChatGLM2Config):
+        super().__init__()
+        self.prefix_projection = config.prefix_projection
+        if self.prefix_projection:
+            # Use a two-layer MLP to encode the prefix
+            kv_size = config.num_layers * config.kv_channels * config.multi_query_group_num * 2
+            self.embedding = torch.nn.Embedding(config.pre_seq_len, kv_size)
+            self.trans = torch.nn.Sequential(
+                torch.nn.Linear(kv_size, config.hidden_size), torch.nn.Tanh(),
+                torch.nn.Linear(config.hidden_size, kv_size))
+        else:
+            self.embedding = torch.nn.Embedding(
+                config.pre_seq_len, config.num_layers * config.kv_channels
+                * config.multi_query_group_num * 2)
+
+    def forward(self, prefix: torch.Tensor):
+        if self.prefix_projection:
+            prefix_tokens = self.embedding(prefix)
+            past_key_values = self.trans(prefix_tokens)
+        else:
+            past_key_values = self.embedding(prefix)
+        return past_key_values
+
+
 def split_tensor_along_last_dim(
     tensor: torch.Tensor,
     num_partitions: int,
     contiguous_split_chunks: bool = False,
 ) -> List[torch.Tensor]:
     """Split a tensor along its last dimension.
+
     Arguments:
         tensor: input tensor.
         num_partitions: number of partitions to split the tensor
         contiguous_split_chunks: If True, make each chunk contiguous
                                  in memory.
+
     Returns:
         A list of Tensors
     """
     # Get the size and dimension.
     last_dim = tensor.dim() - 1
     last_dim_size = tensor.size()[last_dim] // num_partitions
     # Split.
@@ -88,26 +121,27 @@
 
 
 class RotaryEmbedding(nn.Module):
 
     def __init__(self, dim, original_impl=False, device=None, dtype=None):
         super().__init__()
         inv_freq = 1.0 / (10000**(
-            torch.arange(0, dim, 2, device=device, dtype=dtype) / dim))
+            torch.arange(0, dim, 2, device=device).to(dtype=dtype) / dim))
         self.register_buffer('inv_freq', inv_freq)
         self.dim = dim
         self.original_impl = original_impl
 
     def forward_impl(self,
                      seq_len: int,
                      n_elem: int,
                      dtype: torch.dtype,
                      device: torch.device,
                      base: int = 10000):
         """Enhanced Transformer with Rotary Position Embedding.
+
         Derived from: https://github.com/labmlai/annotated_deep_learning_paper_implementations/blob/master/labml_nn/
         transformers/rope/__init__.py. MIT License:
         https://github.com/labmlai/annotated_deep_learning_paper_implementations/blob/master/license.
         """
         # $\Theta = {\theta_i = 10000^{\frac{2(i-1)}{d}}, i \in [1, 2, ..., \frac{d}{2}]}$
         theta = 1.0 / (
             base**(torch.arange(0, n_elem, 2, dtype=dtype, device=device)
@@ -321,14 +355,15 @@
             context_layer = context_layer.view(*new_context_layer_shape)
 
         return context_layer
 
 
 class SelfAttention(torch.nn.Module):
     """Parallel self-attention layer abstract class.
+
     Self-attention layer takes input with size [s, b, h]
     and returns output of the same size.
     """
 
     def __init__(self, config: ChatGLM2Config, layer_number, device=None):
         super(SelfAttention, self).__init__()
         self.layer_number = max(1, layer_number)
@@ -417,34 +452,34 @@
             key_layer = key_layer.view(key_layer.size()[:-1] + (
                 self.num_multi_query_groups_per_partition,
                 self.hidden_size_per_attention_head))
             value_layer = value_layer.view(value_layer.size()[:-1] + (
                 self.num_multi_query_groups_per_partition,
                 self.hidden_size_per_attention_head))
         else:
-            new_tensor_shape = mixed_x_layer.size()[:-1] + (
-                self.num_attention_heads_per_partition,  # noqa
-                3 * self.hidden_size_per_attention_head)  # noqa
+            new_tensor_shape = mixed_x_layer.size()[:-1] + \
+                               (self.num_attention_heads_per_partition, # noqa
+                                3 * self.hidden_size_per_attention_head) # noqa
             mixed_x_layer = mixed_x_layer.view(*new_tensor_shape)
 
             # [sq, b, np, 3 * hn] --> 3 [sq, b, np, hn]
             (query_layer, key_layer,
              value_layer) = split_tensor_along_last_dim(mixed_x_layer, 3)
 
         # apply relative positional encoding (rotary embedding)
         if rotary_pos_emb is not None:
             query_layer = apply_rotary_pos_emb(query_layer, rotary_pos_emb)
             key_layer = apply_rotary_pos_emb(key_layer, rotary_pos_emb)
 
         # adjust key and value for inference
+        if kv_cache is not None:
+            cache_k, cache_v = kv_cache
+            key_layer = torch.cat((cache_k, key_layer), dim=0)
+            value_layer = torch.cat((cache_v, value_layer), dim=0)
         if use_cache:
-            if kv_cache is not None:
-                cache_k, cache_v = kv_cache
-                key_layer = torch.cat((cache_k, key_layer), dim=0)
-                value_layer = torch.cat((cache_v, value_layer), dim=0)
             kv_cache = (key_layer, value_layer)
         else:
             kv_cache = None
 
         if self.multi_query_attention:
             key_layer = key_layer.unsqueeze(-2)
             key_layer = key_layer.expand(
@@ -483,14 +518,15 @@
         'dtype': args.torch_dtype,
     }
     return common_kwargs
 
 
 class MLP(torch.nn.Module):
     """MLP.
+
     MLP will take the input with h hidden state, project it to 4*h
     hidden dimension, perform nonlinear transformation, and project the
     state back into h hidden dimension.
     """
 
     def __init__(self, config: ChatGLM2Config, device=None):
         super(MLP, self).__init__()
@@ -526,14 +562,15 @@
         # [s, b, h]
         output = self.dense_4h_to_h(intermediate_parallel)
         return output
 
 
 class GLMBlock(torch.nn.Module):
     """A single transformer layer.
+
     Transformer layer takes input with size [s, b, h] and returns an
     output of the same size.
     """
 
     def __init__(self, config: ChatGLM2Config, layer_number, device=None):
         super(GLMBlock, self).__init__()
         self.layer_number = layer_number
@@ -638,14 +675,16 @@
             # Final layer norm before output.
             self.final_layernorm = LayerNormFunc(
                 config.hidden_size,
                 eps=config.layernorm_epsilon,
                 device=device,
                 dtype=config.torch_dtype)
 
+        self.gradient_checkpointing = False
+
     def _get_layer(self, layer_number):
         return self.layers[layer_number]
 
     def forward(
         self,
         hidden_states,
         attention_mask,
@@ -653,28 +692,40 @@
         kv_caches=None,
         use_cache: Optional[bool] = True,
         output_hidden_states: Optional[bool] = False,
     ):
         if not kv_caches:
             kv_caches = [None for _ in range(self.num_layers)]
         presents = () if use_cache else None
+        if self.gradient_checkpointing and self.training:
+            if use_cache:
+                logger.warning_once(
+                    '`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...'
+                )
+                use_cache = False
+
         all_self_attentions = None
         all_hidden_states = () if output_hidden_states else None
         for index in range(self.num_layers):
             if output_hidden_states:
                 all_hidden_states = all_hidden_states + (hidden_states, )
 
             layer = self._get_layer(index)
-
-            hidden_states, kv_cache = layer(
-                hidden_states,
-                attention_mask,
-                rotary_pos_emb,
-                kv_cache=kv_caches[index],
-                use_cache=use_cache)
+            if self.gradient_checkpointing and self.training:
+                layer_ret = torch.utils.checkpoint.checkpoint(
+                    layer, hidden_states, attention_mask, rotary_pos_emb,
+                    kv_caches[index], use_cache)
+            else:
+                layer_ret = layer(
+                    hidden_states,
+                    attention_mask,
+                    rotary_pos_emb,
+                    kv_cache=kv_caches[index],
+                    use_cache=use_cache)
+            hidden_states, kv_cache = layer_ret
             if use_cache:
                 presents = presents + (kv_cache, )
 
         if output_hidden_states:
             all_hidden_states = all_hidden_states + (hidden_states, )
 
         # Final layer norm.
@@ -720,30 +771,30 @@
                         seq_length,
                         past_length,  # noqa
                         device=input_ids.device),
                     full_attention_mask),  # noqa
                 dim=-1)  # noqa
         if padding_mask is not None:
             full_attention_mask = full_attention_mask * padding_mask.unsqueeze(
-                1)  # noqa
+                1)
         if not past_length and padding_mask is not None:
             full_attention_mask -= padding_mask.unsqueeze(-1) - 1
         full_attention_mask = (full_attention_mask < 0.5).bool()
         full_attention_mask.unsqueeze_(1)
         return full_attention_mask
 
     def get_position_ids(self, input_ids, device):
         batch_size, seq_length = input_ids.shape
         position_ids = torch.arange(
             seq_length, dtype=torch.long,
             device=device).unsqueeze(0).repeat(batch_size, 1)
         return position_ids
 
     def _set_gradient_checkpointing(self, module, value=False):
-        if isinstance(module, ChatGLMModel):
+        if isinstance(module, GLMTransformer):
             module.gradient_checkpointing = value
 
     @classmethod
     def _instantiate(cls, **kwargs):
         """Instantiate the model.
 
         Args:
@@ -797,14 +848,17 @@
             init_method = skip_init
         else:
             init_method = default_init
         init_kwargs = {}
         if device is not None:
             init_kwargs['device'] = device
         self.embedding = init_method(Embedding, config, **init_kwargs)
+        self.num_layers = config.num_layers
+        self.multi_query_group_num = config.multi_query_group_num
+        self.kv_channels = config.kv_channels
 
         # Rotary positional embeddings
         self.seq_length = config.seq_length
         rotary_dim = (
             config.hidden_size // config.num_attention_heads
             if config.kv_channels is None else config.kv_channels)
 
@@ -817,15 +871,38 @@
         self.output_layer = init_method(
             nn.Linear,
             config.hidden_size,
             config.padded_vocab_size,
             bias=False,
             dtype=config.torch_dtype,
             **init_kwargs)
-        self.gradient_checkpointing = False
+        self.pre_seq_len = config.pre_seq_len
+        self.prefix_projection = config.prefix_projection
+        if self.pre_seq_len is not None:
+            for param in self.parameters():
+                param.requires_grad = False
+            self.prefix_tokens = torch.arange(self.pre_seq_len).long()
+            self.prefix_encoder = PrefixEncoder(config)
+            self.dropout = torch.nn.Dropout(0.1)
+
+    def get_input_embeddings(self):
+        return self.embedding.word_embeddings
+
+    def get_prompt(self, batch_size, device, dtype=torch.half):
+        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size,
+                                                               -1).to(device)
+        past_key_values = self.prefix_encoder(prefix_tokens).type(dtype)
+        past_key_values = past_key_values.view(batch_size, self.pre_seq_len,
+                                               self.num_layers * 2,
+                                               self.multi_query_group_num,
+                                               self.kv_channels)
+        # seq_len, b, nh, hidden_size
+        past_key_values = self.dropout(past_key_values)
+        past_key_values = past_key_values.permute([2, 1, 0, 3, 4]).split(2)
+        return past_key_values
 
     def forward(
         self,
         input_ids,
         position_ids: Optional[torch.Tensor] = None,
         attention_mask: Optional[torch.BoolTensor] = None,
         full_attention_mask: Optional[torch.BoolTensor] = None,
@@ -843,14 +920,29 @@
         return_dict = return_dict if return_dict is not None else self.config.use_return_dict
 
         batch_size, seq_length = input_ids.shape
 
         if inputs_embeds is None:
             inputs_embeds = self.embedding(input_ids)
 
+        if self.pre_seq_len is not None:
+            if past_key_values is None:
+                past_key_values = self.get_prompt(
+                    batch_size=batch_size,
+                    device=input_ids.device,
+                    dtype=inputs_embeds.dtype)
+            if attention_mask is not None:
+                attention_mask = torch.cat(
+                    [
+                        attention_mask.new_ones(  # noqa
+                            (batch_size, self.pre_seq_len)),
+                        attention_mask  # noqa
+                    ],  # noqa
+                    dim=-1)  # noqa
+
         if full_attention_mask is None:
             if (attention_mask is not None
                     and not attention_mask.all()) or (past_key_values
                                                       and seq_length != 1):
                 full_attention_mask = self.get_masks(
                     input_ids, past_key_values, padding_mask=attention_mask)
 
@@ -919,15 +1011,15 @@
         if 'attention_mask' in model_kwargs:
             attention_mask = model_kwargs['attention_mask']
             model_kwargs['attention_mask'] = torch.cat(
                 [  # noqa
                     attention_mask,  # noqa
                     attention_mask.new_ones(
                         (attention_mask.shape[0], 1))  # noqa
-                ],
+                ],  # noqa
                 dim=-1)  # noqa
 
         # update position ids
         if 'position_ids' in model_kwargs:
             position_ids = model_kwargs['position_ids']
             new_position_id = position_ids[..., -1:].clone()
             new_position_id += 1
@@ -1028,14 +1120,15 @@
         past: Tuple[Tuple[torch.Tensor, torch.Tensor],
                     ...], beam_idx: torch.LongTensor
     ) -> Tuple[Tuple[torch.Tensor, torch.Tensor], ...]:
         """
         This function is used to re-order the `past_key_values` cache if [`~PreTrainedModel.beam_search`] or
         [`~PreTrainedModel.beam_sample`] is called. This is required to match `past_key_values` with the correct
         beam_idx at every generation step.
+
         Output shares the same memory storage as `past`.
         """
         return tuple((
             layer_past[0].index_select(1, beam_idx.to(layer_past[0].device)),
             layer_past[1].index_select(1, beam_idx.to(layer_past[1].device)),
         ) for layer_past in past)
 
@@ -1044,19 +1137,15 @@
         response = response.replace('[[]]', '2023')
         return response
 
     def build_inputs(self,
                      tokenizer,
                      query: str,
                      history: List[Tuple[str, str]] = None):
-        prompt = ''
-        for i, (old_query, response) in enumerate(history):
-            prompt += '[Round {}]\n\n{}\n\n{}\n\n'.format(
-                i + 1, old_query, response)
-        prompt += '[Round {}]\n\n{}\n\n'.format(len(history) + 1, query)
+        prompt = tokenizer.build_prompt(query, history=history)
         inputs = tokenizer([prompt], return_tensors='pt')
         inputs = inputs.to(self.device)
         return inputs
 
     def build_stream_inputs(self,
                             tokenizer,
                             query: str,
@@ -1076,15 +1165,15 @@
         return inputs
 
     @torch.no_grad()
     def _chat(self,
               tokenizer,
               query: str,
               history: List[Tuple[str, str]] = None,
-              max_length: int = 2048,
+              max_length: int = 8192,
               num_beams=1,
               do_sample=True,
               top_p=0.8,
               temperature=0.8,
               logits_processor=None,
               **kwargs):
         if history is None:
@@ -1111,15 +1200,15 @@
 
     @torch.no_grad()
     def stream_chat(self,
                     tokenizer,
                     query: str,
                     history: List[Tuple[str, str]] = None,
                     past_key_values=None,
-                    max_length: int = 2048,
+                    max_length: int = 8192,
                     do_sample=True,
                     top_p=0.8,
                     temperature=0.8,
                     logits_processor=None,
                     return_past_key_values=False,
                     **kwargs):
         if history is None:
@@ -1138,14 +1227,16 @@
         if past_key_values is None and not return_past_key_values:
             inputs = self.build_inputs(tokenizer, query, history=history)
         else:
             inputs = self.build_stream_inputs(
                 tokenizer, query, history=history)
         if past_key_values is not None:
             past_length = past_key_values[0][0].shape[0]
+            if self.transformer.pre_seq_len is not None:
+                past_length -= self.transformer.pre_seq_len
             inputs.position_ids += past_length
             attention_mask = inputs.attention_mask
             attention_mask = torch.cat(
                 (attention_mask.new_ones(1, past_length), attention_mask),
                 dim=1)
             inputs['attention_mask'] = attention_mask
         for outputs in self.stream_generate(
@@ -1153,20 +1244,21 @@
                 past_key_values=past_key_values,
                 return_past_key_values=return_past_key_values,
                 **gen_kwargs):
             if return_past_key_values:
                 outputs, past_key_values = outputs
             outputs = outputs.tolist()[0][len(inputs['input_ids'][0]):]
             response = tokenizer.decode(outputs)
-            response = self.process_response(response)
-            new_history = history + [(query, response)]
-            if return_past_key_values:
-                yield response, new_history, past_key_values
-            else:
-                yield response, new_history
+            if response and response[-1] != '':
+                response = self.process_response(response)
+                new_history = history + [(query, response)]
+                if return_past_key_values:
+                    yield response, new_history, past_key_values
+                else:
+                    yield response, new_history
 
     @torch.no_grad()
     def stream_generate(
         self,
         input_ids,
         generation_config: Optional[GenerationConfig] = None,
         logits_processor: Optional[LogitsProcessorList] = None,
@@ -1291,15 +1383,16 @@
 
         self.config.quantization_bit = bits
 
         self.transformer.encoder = quantize(
             self.transformer.encoder,
             bits,
             empty_init=empty_init,
-            device=device)
+            device=device,
+            **kwargs)
         return self
 
     def chat(self, input: Dict, tokenizer) -> Dict:
         text = input['text']
         history = input['history']
         # args
         if 'max_length' in input:
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/chatglm2/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/chatglm2/tokenization.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,31 +1,28 @@
-"""Tokenization classes for ChatGLM."""
 import os
 from typing import Dict, List, Optional, Union
 
 from sentencepiece import SentencePieceProcessor
-from transformers.tokenization_utils import PreTrainedTokenizer
+from transformers import PreTrainedTokenizer
 from transformers.tokenization_utils_base import BatchEncoding, EncodedInput
-from transformers.utils import PaddingStrategy, logging
-
-logger = logging.get_logger(__name__)
+from transformers.utils import PaddingStrategy
 
 
 class SPTokenizer:
 
     def __init__(self, model_path: str):
         # reload tokenizer
         assert os.path.isfile(model_path), model_path
         self.sp_model = SentencePieceProcessor(model_file=model_path)
 
         # BOS / EOS token IDs
         self.n_words: int = self.sp_model.vocab_size()
         self.bos_id: int = self.sp_model.bos_id()
         self.eos_id: int = self.sp_model.eos_id()
-        self.pad_id: int = self.sp_model.eos_id()
+        self.pad_id: int = self.sp_model.unk_id()
         assert self.sp_model.vocab_size() == self.sp_model.get_piece_size()
 
         special_tokens = ['[MASK]', '[gMASK]', '[sMASK]', 'sop', 'eop']
         self.special_tokens = {}
         self.index_special_tokens = {}
         for token in special_tokens:
             self.special_tokens[token] = self.n_words
@@ -58,28 +55,31 @@
         """ Converts a token (str) in an id using the vocab. """
         if token in self.special_tokens:
             return self.special_tokens[token]
         return self.sp_model.PieceToId(token)
 
     def convert_id_to_token(self, index):
         """Converts an index (integer) in a token (str) using the vocab."""
-        if index in self.index_special_tokens:
+        if index in self.index_special_tokens or index in [
+                self.eos_id, self.bos_id, self.pad_id
+        ] or index < 0:
             return ''
         return self.sp_model.IdToPiece(index)
 
 
 class ChatGLM2Tokenizer(PreTrainedTokenizer):
     vocab_files_names = {'vocab_file': 'tokenizer.model'}
 
     model_input_names = ['input_ids', 'attention_mask', 'position_ids']
 
     def __init__(self, vocab_file, padding_side='left', **kwargs):
         super().__init__(padding_side=padding_side, **kwargs)
         self.name = 'GLMTokenizer'
 
+        self.vocab_file = vocab_file
         self.tokenizer = SPTokenizer(vocab_file)
         self.special_tokens = {
             '<bos>': self.tokenizer.bos_id,
             '<eos>': self.tokenizer.eos_id,
             '<pad>': self.tokenizer.pad_id
         }
 
@@ -87,21 +87,25 @@
         if token in self.special_tokens:
             return self.special_tokens[token]
         assert token in self.tokenizer.special_tokens, f'{token} is not a special token for {self.name}'
         return self.tokenizer.special_tokens[token]
 
     @property
     def pad_token(self) -> str:
-        return '</s>'
+        return '<unk>'
 
     @property
     def pad_token_id(self):
         return self.get_command('<pad>')
 
     @property
+    def eos_token(self) -> str:
+        return '</s>'
+
+    @property
     def eos_token_id(self):
         return self.get_command('<eos>')
 
     @property
     def vocab_size(self):
         return self.tokenizer.n_words
 
@@ -127,19 +131,21 @@
 
     def convert_tokens_to_string(self, tokens: List[str]) -> str:
         return self.tokenizer.decode_tokens(tokens)
 
     def save_vocabulary(self, save_directory, filename_prefix=None):
         """
         Save the vocabulary and special tokens file to a directory.
+
         Args:
             save_directory (`str`):
                 The directory in which to save the vocabulary.
             filename_prefix (`str`, *optional*):
                 An optional prefix to add to the named of the saved files.
+
         Returns:
             `Tuple(str)`: Paths to the files saved.
         """
         if os.path.isdir(save_directory):
             vocab_file = os.path.join(save_directory,
                                       self.vocab_files_names['vocab_file'])
         else:
@@ -153,28 +159,41 @@
 
         return (vocab_file, )
 
     def get_prefix_tokens(self):
         prefix_tokens = [self.get_command('[gMASK]'), self.get_command('sop')]
         return prefix_tokens
 
+    def build_prompt(self, query, history=None):
+        if history is None:
+            history = []
+        prompt = ''
+        for i, (old_query, response) in enumerate(history):
+            prompt += '[Round {}]\n\n{}\n\n{}\n\n'.format(
+                i + 1, old_query, response)
+        prompt += '[Round {}]\n\n{}\n\n'.format(len(history) + 1, query)
+        return prompt
+
     def build_inputs_with_special_tokens(
             self,
             token_ids_0: List[int],
             token_ids_1: Optional[List[int]] = None) -> List[int]:
         """
         Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and
         adding special tokens. A BERT sequence has the following format:
+
         - single sequence: `[CLS] X [SEP]`
         - pair of sequences: `[CLS] A [SEP] B [SEP]`
+
         Args:
             token_ids_0 (`List[int]`):
                 List of IDs to which the special tokens will be added.
             token_ids_1 (`List[int]`, *optional*):
                 Optional second list of IDs for sequence pairs.
+
         Returns:
             `List[int]`: List of [input IDs](../glossary#input-ids) with the appropriate special tokens.
         """
         prefix_tokens = self.get_prefix_tokens()
         token_ids_0 = prefix_tokens + token_ids_0
         if token_ids_1 is not None:
             token_ids_0 = token_ids_0 + token_ids_1 + [
@@ -188,24 +207,27 @@
         max_length: Optional[int] = None,
         padding_strategy: PaddingStrategy = PaddingStrategy.DO_NOT_PAD,
         pad_to_multiple_of: Optional[int] = None,
         return_attention_mask: Optional[bool] = None,
     ) -> dict:
         """
         Pad encoded inputs (on left/right and up to predefined length or max length in the batch)
+
         Args:
             encoded_inputs:
                 Dictionary of tokenized inputs (`List[int]`) or batch of tokenized inputs (`List[List[int]]`).
             max_length: maximum length of the returned list and optionally padding length (see below).
                 Will truncate by taking into account the special tokens.
             padding_strategy: PaddingStrategy to use for padding.
+
                 - PaddingStrategy.LONGEST Pad to the longest sequence in the batch
                 - PaddingStrategy.MAX_LENGTH: Pad to the max length (default)
                 - PaddingStrategy.DO_NOT_PAD: Do not pad
                 The tokenizer padding sides are defined in self.padding_side:
+
                     - 'left': pads on the left of the sequences
                     - 'right': pads on the right of the sequences
             pad_to_multiple_of: (optional) Integer if set will pad the sequence to a multiple of the provided value.
                 This is especially useful to enable the use of Tensor Core on NVIDIA hardware with compute capability
                 `>= 7.5` (Volta).
             return_attention_mask:
                 (optional) Set to False to avoid returning attention mask (default: set to model specifics)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex_for_code_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/codegeex_for_code_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/inference.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/codegeex/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/codegeex/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/csanmt/translation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/csanmt/translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/deberta_v2/tokenization_fast.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/deberta_v2/tokenization_fast.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/dgds/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/dgds/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/dgds/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/dgds/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_generate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_rerank.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/dgds/document_grounded_dialog_retrieval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_T5/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_T5/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_T5/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_T5/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_plug/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_plug/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -22,18 +22,19 @@
 
 import numpy as np
 import torch
 import torch.nn.functional as F
 from torch import Tensor, nn
 from torch.nn.init import xavier_uniform_
 from transformers import (BertConfig, BertModel, BertTokenizer, RobertaConfig,
-                          RobertaModel, RobertaTokenizer, logging)
+                          RobertaModel, RobertaTokenizer)
 from transformers.activations import ACT2FN
 from transformers.modeling_utils import PreTrainedModel
 
+from modelscope.utils import logger as logging
 from .configuration import PlugConfig
 
 CONFIG_NAME = 'config.json'
 WEIGHTS_NAME = 'pytorch_model.bin'
 
 
 class MultiHeadedAttention(nn.Module):  # SelfAttention
@@ -725,15 +726,15 @@
         token_type_ids: torch.Tensor
         query_id: List[None] = None
         src_str: List[List[str]] = None
         tgt_str: List[str] = None
 
     def __init__(self, config, checkpoint=None, dataset: str = 'default'):
         super().__init__(config)
-        self.logger = logging.get_logger(__name__)
+        self.logger = logging.get_logger()
         self.config = config
         if config.encoder == 'roberta':
             tokenizer = RobertaTokenizer.from_pretrained(
                 config.encoder_pth, do_lower_case=False)
             symbols = {
                 'BOS': tokenizer.cls_token_id,
                 'EOS': tokenizer.sep_token_id,
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_plug/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/fid_plug/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/fid_plug/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/generation/strategies.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/generation/strategies.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/initialize.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/initialize.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/kernels/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/kernels/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/functional.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/functional.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/quantization/layers.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/quantization/layers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/glm_130b/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/glm_130b/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/distributed_gpt3.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/distributed_gpt3.py`

 * *Files 0% similar despite different names*

```diff
@@ -1257,15 +1257,15 @@
             for output in self.sample(tokens, *args, **kwargs):
                 last_output = output
             return last_output
         else:
             return self.beam_search(tokens, *args, **kwargs)
 
     @torch.no_grad()
-    def stream(self, tokens, *args, **kwargs):
+    def stream_generate(self, tokens, *args, **kwargs):
         return self.sample(tokens, *args, **kwargs)
 
     def state_dict(self, destination=None, prefix='', keep_vars=False):
         return self.dist_model.state_dict(destination, prefix, keep_vars)
 
     def load_state_dict(self,
                         state_dict: 'OrderedDict[str, torch.Tensor]',
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/text_generation.py`

 * *Files 2% similar despite different names*

```diff
@@ -75,12 +75,12 @@
         return self.model.state_dict(destination, prefix, keep_vars)
 
     def load_state_dict(self,
                         state_dict: 'OrderedDict[str, Tensor]',
                         strict: bool = True):
         return self.model.load_state_dict(state_dict, strict)
 
-    def stream(self, inputs, **kwargs) -> Generator:
+    def stream_generate(self, inputs, **kwargs) -> Generator:
         tokens = inputs['input_ids']
         lengths = self._get_length(inputs['attention_mask'])
         return self.model.streaming_generate(
             tokens, prompt_length=lengths, **kwargs)
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt3/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt3/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/checkpointing.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/checkpointing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/distributed_gpt_moe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/experts.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/experts.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/layer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/layer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/mappings.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/mappings.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/sharded_moe.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/moe/utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/moe/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_moe/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_moe/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/gpt_neo/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/gpt_neo/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/crf_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/crf_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/fill_mask_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/fill_mask_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/infromation_extraction_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/infromation_extraction_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/text_classification_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_classification_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/text_generation_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_generation_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/text_ranking_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/text_ranking_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/token_classification_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/token_classification_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/heads/torch_pretrain_head.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/heads/torch_pretrain_head.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/hf_transformers/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/hf_transformers/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/backbone.py`

 * *Files 0% similar despite different names*

```diff
@@ -31,15 +31,15 @@
 from modelscope.models import Model, TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.outputs import AttentionBackboneModelOutput
 from modelscope.utils.constant import Tasks
 from modelscope.utils.logger import get_logger
 from .configuration import LlamaConfig
 
-logger = get_logger(__name__)
+logger = get_logger()
 
 _CONFIG_FOR_DOC = 'LlamaConfig'
 
 
 # This file is mainly copied from the llama code of transformers
 # Copied from transformers.models.bart.modeling_bart._make_causal_mask
 def _make_causal_mask(input_ids_shape: torch.Size,
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/convert_llama_weights_to_hf.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/text_generation.py`

 * *Files 4% similar despite different names*

```diff
@@ -24,20 +24,23 @@
 from torch.nn import CrossEntropyLoss
 
 from modelscope.metainfo import Models
 from modelscope.models.base import Tensor, TorchModel
 from modelscope.models.builder import MODELS
 from modelscope.outputs import AttentionTextGenerationModelOutput
 from modelscope.utils.constant import Tasks
+from modelscope.utils.streaming_output import \
+    PretrainedModelStreamingOutputMixin
 from .backbone import LlamaModel, LlamaPreTrainedModel
 
 
 # This file is mainly copied from the llama code of transformers
 @MODELS.register_module(Tasks.text_generation, module_name=Models.llama)
-class LlamaForTextGeneration(LlamaPreTrainedModel):
+class LlamaForTextGeneration(LlamaPreTrainedModel,
+                             PretrainedModelStreamingOutputMixin):
     _keys_to_ignore_on_load_missing = [r'lm_head.weight']
 
     def __init__(self, config, **kwargs):
         super().__init__(config)
         self.model = LlamaModel(config)
 
         self.lm_head = nn.Linear(
@@ -120,15 +123,18 @@
             shift_labels = shift_labels.to(shift_logits.device)
             loss = loss_fct(shift_logits, shift_labels)
 
         if not return_dict:
             output = (logits, ) + outputs[1:]
             return (loss, ) + output if loss is not None else output
 
-        return AttentionTextGenerationModelOutput(
+        # There is a conflict between the `ModelOutputBase` in the modelscope
+        # and the `send_to_device` function in the accelerate library.
+        # Temporarily change AttentionTextGenerationModelOutput to dict
+        return dict(
             loss=loss,
             logits=logits,
             past_key_values=outputs.past_key_values,
             hidden_states=outputs.hidden_states,
             attentions=outputs.attentions,
         )
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/tokenization.py`

 * *Files 1% similar despite different names*

```diff
@@ -25,15 +25,15 @@
 
 import sentencepiece as spm
 from transformers.tokenization_utils import AddedToken, PreTrainedTokenizer
 
 from modelscope.utils.logger import get_logger
 
 # This file is mainly copied from the llama code of transformers
-logger = get_logger(__name__)
+logger = get_logger()
 
 VOCAB_FILES_NAMES = {'vocab_file': 'tokenizer.model'}
 
 PRETRAINED_VOCAB_FILES_MAP = {
     'vocab_file': {
         'hf-internal-testing/llama-tokenizer':
         'https://huggingface.co/hf-internal-testing/llama-tokenizer/resolve/main/tokenizer.model',
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/llama/tokenization_fast.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/llama/tokenization_fast.py`

 * *Files 1% similar despite different names*

```diff
@@ -27,15 +27,15 @@
 require_version('tokenizers>=0.13.3')
 
 if is_sentencepiece_available():
     from .tokenization import LlamaTokenizer
 else:
     LlamaTokenizer = None
 
-logger = get_logger(__name__)
+logger = get_logger()
 VOCAB_FILES_NAMES = {
     'vocab_file': 'tokenizer.model',
     'tokenizer_file': 'tokenizer.json'
 }
 
 
 class LlamaTokenizerFast(PreTrainedTokenizerFast):
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/lstm/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/lstm/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/lstm/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/lstm/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/lstm/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/lstm/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/megatron_bert/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/megatron_bert/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/megatron_bert/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/megatron_bert/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/megatron_bert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/arguments.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/arguments.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/blocklm_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/blocklm_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/configure_data.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/configure_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/corpora.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/corpora.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/datasets.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/datasets.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/extraction.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/file_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/lazy_loader.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/lazy_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/samplers.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/samplers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/sp_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/tokenization_gpt2.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/data_utils/wordpiece.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/data_utils/wordpiece.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/generation_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/generation_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/mglm_for_text_summarization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/mglm_for_text_summarization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/distributed.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/downstream.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/downstream.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/modeling_bert.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/modeling_bert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/modeling_glm.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/modeling_glm.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/prompt.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/prompt.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/model/transformer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/model/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/process_grid.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/process_grid.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/test/test_block.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/test_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/test/test_rel_shift.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/test/test_rel_shift.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/train_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/train_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/mglm/utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/mglm/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/palm_v2/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/palm_v2/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/palm_v2/dureader_eval.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/dureader_eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/palm_v2/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/palm_v2/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/peer/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/peer/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/peer/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/peer/backbone.py`

 * *Files 1% similar despite different names*

```diff
@@ -32,15 +32,15 @@
 
 from modelscope.models import Model, TorchModel
 from modelscope.utils import logger as logging
 from modelscope.utils.nlp.utils import parse_labels_in_order
 from .configuration import PeerConfig
 from .sas_utils import SequenceSideInfo
 
-logger = logging.get_logger(__name__)
+logger = logging.get_logger()
 
 PEER_PRETRAINED_MODEL_ARCHIVE_LIST = [
     'google/peer-small-generator',
     'google/peer-base-generator',
     'google/peer-large-generator',
     'google/peer-small-discriminator',
     'google/peer-base-discriminator',
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/peer/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/peer/configuration.py`

 * *Files 0% similar despite different names*

```diff
@@ -16,15 +16,15 @@
 """ PEER model configuration """
 
 # modified the path according to the structure in my directory csssl_4_15/cssl/ and its env
 from transformers.configuration_utils import PretrainedConfig
 
 from modelscope.utils import logger as logging
 
-logger = logging.get_logger(__name__)
+logger = logging.get_logger()
 
 
 class PeerConfig(PretrainedConfig):
     r"""
     This is the configuration class to store the configuration of a :class:`~transformers.PeerModel` or a
     :class:`~transformers.TFPeerModel`. It is used to instantiate a PEER model according to the specified
     arguments, defining the model architecture. Instantiating a configuration with the defaults will yield a similar
```

### Comparing `modelscope-1.7.1/modelscope/models/nlp/peer/sas_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/peer/sas_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/peer/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/peer/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/AnnealingLR.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/AnnealingLR.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/distributed_plug.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/distributed_plug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug/generator.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug/generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug_mental/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug_mental/adv_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/adv_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug_mental/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug_mental/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/plug_mental/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/plug_mental/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/document_segmentation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/document_segmentation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/ponet/tokenization.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/ponet/tokenization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/dialog_intent_prediction.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_intent_prediction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/dialog_modeling.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_modeling.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/dialog_state_tracking.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/dialog_state_tracking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/gen_unified_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/gen_unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/generator.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/generator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/intent_unified_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/intent_unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/model_base.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/model_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/tokenization_space.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/tokenization_space.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/model/unified_transformer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/model/unified_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/modules/embedder.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/embedder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/modules/feedforward.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/feedforward.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/modules/functions.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/functions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/modules/multihead_attention.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/multihead_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space/modules/transformer_block.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space/modules/transformer_block.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space_T_cn/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space_T_cn/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space_T_cn/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space_T_cn/table_question_answering.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space_T_cn/table_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/space_T_en/text_to_sql.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/space_T_en/text_to_sql.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/adv_utils.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/adv_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/faq_question_answering.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/faq_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/structbert/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/structbert/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/feature_extraction.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/feature_extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/information_extraction.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/information_extraction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/task_model.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/task_model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/text_generation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/text_ranking.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/text_ranking.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/task_models/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/task_models/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/unite/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/unite/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/unite/translation_evaluation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/unite/translation_evaluation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/use/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/use/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/use/transformer.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/use/transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/use/user_satisfaction_estimation.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/use/user_satisfaction_estimation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/fill_mask.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/fill_mask.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/text_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/veco/token_classification.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/veco/token_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/backbone.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/backbone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/nlp/xlm_roberta/configuration.py` & `modelscope-1.8.0rc0/modelscope/models/nlp/xlm_roberta/configuration.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/config.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/data_ops.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/data_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/msa_pairing.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/msa_pairing.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/process.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/process_multimer.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/process_multimer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/protein.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/protein.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/residue_constants.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/residue_constants.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/data/utils.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/data/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/dataset.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/model.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/model.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/alphafold.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/alphafold.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/attentions.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/attentions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/auxillary_heads.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/auxillary_heads.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/common.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/confidence.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/confidence.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/embedders.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/embedders.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/evoformer.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/evoformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/featurization.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/featurization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/frame.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/frame.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/structure_module.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/structure_module.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/template.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/template.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/modules/triangle_multiplication.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/modules/triangle_multiplication.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/mmcif.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/mmcif.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/msa_identifiers.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/msa_identifiers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/parsers.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/parsers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/pipeline.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/templates.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/templates.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/__init__.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hhblits.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hhblits.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hhsearch.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hhsearch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hmmbuild.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hmmbuild.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/hmmsearch.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/hmmsearch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/jackhmmer.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/jackhmmer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/kalign.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/kalign.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/tools/utils.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/tools/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/models/science/unifold/msa/utils.py` & `modelscope-1.8.0rc0/modelscope/models/science/unifold/msa/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/auth/auth_config.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/auth/auth_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/context/dataset_context_config.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/context/dataset_context_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/data_files/data_files_manager.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/data_files/data_files_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/data_loader/data_loader.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/data_loader/data_loader_manager.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/data_loader/data_loader_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
 import os
 
 from modelscope.msdatasets.ms_dataset import MsDataset
+from modelscope.utils.constant import DownloadMode
 
 
 class ASRDataset(MsDataset):
     """ASR dataset for speech recognition.
     support load dataset from msdataset hub or local data_dir (including wav.scp and text)
     For more details, please refer to
         https://github.com/alibaba-damo-academy/FunASR/blob/main/funasr/datasets/ms_dataset.py.
@@ -25,24 +26,31 @@
             item = {}
             item['Audio:FILE'] = wav_line.strip().split()[-1]
             item['Text:LABEL'] = ' '.join(text_line.strip().split()[1:])
             data_list.append(item)
         return data_list
 
     @classmethod
-    def load(cls,
-             dataset_name,
-             namespace='speech_asr',
-             train_set='train',
-             dev_set='validation'):
+    def load(
+        cls,
+        dataset_name,
+        namespace='speech_asr',
+        train_set='train',
+        dev_set='validation',
+        download_mode=DownloadMode.REUSE_DATASET_IF_EXISTS,
+    ):
         if os.path.exists(dataset_name):
             data_dir = dataset_name
             ds_dict = {}
             ds_dict['train'] = cls.load_core(data_dir, train_set)
             ds_dict['validation'] = cls.load_core(data_dir, dev_set)
             ds_dict['raw_data_dir'] = data_dir
             return ds_dict
         else:
             from modelscope.msdatasets import MsDataset
+
             ds_dict = MsDataset.load(
-                dataset_name=dataset_name, namespace=namespace)
+                dataset_name=dataset_name,
+                namespace=namespace,
+                download_mode=download_mode,
+            )
             return ds_dict
```

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/easycv_base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/veco_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/dataset_cls/dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/dataset_cls/dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/download/dataset_builder.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/download/dataset_builder.py`

 * *Files 4% similar despite different names*

```diff
@@ -219,19 +219,31 @@
             csv_file_path, iterator=False, delimiter=self.csv_delimiter)
 
         transform_fields = []
         for field_name in df.columns.tolist():
             if field_name.endswith(':FILE'):
                 transform_fields.append(field_name)
 
-        base_extracted_dir = self.split_path_dict.get(split_name, '')
+        base_extracted_dir: Union[str, list] = self.split_path_dict.get(
+            split_name, '')
         for field_name in transform_fields:
-            if base_extracted_dir:
+            if isinstance(base_extracted_dir,
+                          list) and len(base_extracted_dir) > 0:
+                if df.shape[0] != len(base_extracted_dir):
+                    logger.error(
+                        f"Number of lines in meta-csv file for split '{split_name}' ({df.shape[0]}) "
+                        f'does not match number of data-files({len(base_extracted_dir)})!'
+                    )
+                else:
+                    df[field_name] = base_extracted_dir
+            elif isinstance(base_extracted_dir, str) and base_extracted_dir:
                 df[field_name] = df[field_name].apply(
                     lambda x: os.path.join(base_extracted_dir, x))
+            else:
+                logger.warning(f'Nothing to do for field {field_name}')
 
         pa_data = pa.Table.from_pandas(df)
         return Dataset(arrow_table=pa_data)
 
     def as_dataset(self) -> DatasetDict:
 
         return DatasetDict({
```

### Comparing `modelscope-1.7.1/modelscope/msdatasets/download/download_config.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/download/download_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/download/download_manager.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/download/download_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/meta/data_meta_config.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/meta/data_meta_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/meta/data_meta_manager.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/meta/data_meta_manager.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/ms_dataset.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/ms_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/task_datasets/__init__.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/task_datasets/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/utils/dataset_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/utils/dataset_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/utils/delete_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/utils/delete_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/utils/maxcompute_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/utils/maxcompute_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/utils/oss_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/utils/oss_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/msdatasets/utils/upload_utils.py` & `modelscope-1.8.0rc0/modelscope/msdatasets/utils/upload_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/ops/ailut/pyinterfaces.py` & `modelscope-1.8.0rc0/modelscope/ops/ailut/pyinterfaces.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/ops/quadtree_attention/functions/quadtree_attention.py` & `modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/functions/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/ops/quadtree_attention/modules/quadtree_attention.py` & `modelscope-1.8.0rc0/modelscope/ops/quadtree_attention/modules/quadtree_attention.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/outputs/cv_outputs.py` & `modelscope-1.8.0rc0/modelscope/outputs/cv_outputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/outputs/nlp_outputs.py` & `modelscope-1.8.0rc0/modelscope/outputs/nlp_outputs.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/outputs/outputs.py` & `modelscope-1.8.0rc0/modelscope/outputs/outputs.py`

 * *Files 1% similar despite different names*

```diff
@@ -716,14 +716,15 @@
 
     # video editing task result for a single video
     # {"output_video": "path_to_rendered_video"}
     Tasks.video_frame_interpolation: [OutputKeys.OUTPUT_VIDEO],
     Tasks.video_super_resolution: [OutputKeys.OUTPUT_VIDEO],
     Tasks.video_deinterlace: [OutputKeys.OUTPUT_VIDEO],
     Tasks.nerf_recon_acc: [OutputKeys.OUTPUT],
+    Tasks.nerf_recon_vq_compression: [OutputKeys.OUTPUT],
     Tasks.video_colorization: [OutputKeys.OUTPUT_VIDEO],
 
     # image quality assessment degradation result for single image
     # {
     #       "scores": [0.885272, 0.014790631, 0.014558001]
     #       "labels": ['', '', ''],
     # }
@@ -1228,19 +1229,38 @@
     # itn result for single sample
     # {"text": "123"}
     Tasks.inverse_text_processing: [OutputKeys.TEXT],
 
     # speaker verification for single compare task
     # {'score': 84.2332}
     Tasks.speaker_verification: [OutputKeys.SCORES],
+    # speaker diarization dialogue detection for binary results: dialogue or non_dialogue
+    # {
+    #   "scores": [0.98, 0.02],
+    #   "labels": ["dialogue", "non_dialogue"],
+    # }
+    Tasks.speaker_diarization_dialogue_detection: [
+        OutputKeys.SCORES, OutputKeys.LABELS
+    ],
+    Tasks.speech_language_recognition: [OutputKeys.TEXT],
 
     # punctuation result for single sample
     # { "text": ""}
     Tasks.punctuation: [OutputKeys.TEXT],
 
+    # speaker diarization semantic speaker-turn detection
+    # {
+    #    "logits": [[0.7, 0.3], ..., [0.88, 0.12]],
+    #    "text": "",
+    #    "prediction": [-100, -100, -100, 1, -100,..., -100, 0]
+    # }
+    Tasks.speaker_diarization_semantic_speaker_turn_detection: [
+        OutputKeys.LOGITS, OutputKeys.TEXT, OutputKeys.PREDICTION
+    ],
+
     # language model result for single sample
     # { "text": " hel@@ lo     </s>
     #               p( hel@@ | <s> ) = 0.00057767 [ -7.45650959 ]
     #               p( lo | hel@@ ) = 0.99832278 [ -0.00167861 ]
     #               p(  | lo ) = 0.49116334 [ -0.71097857 ]
     #               p(  |  ) = 0.99691027 [ -0.00309453 ]
     #               p(  |  ) = 0.97999156 [ -0.02021134 ]
@@ -1481,14 +1501,21 @@
     #   }
     Tasks.vision_efficient_tuning: [OutputKeys.SCORES, OutputKeys.LABELS],
     Tasks.document_grounded_dialog_generate: [OutputKeys.TEXT],
     Tasks.document_grounded_dialog_rerank: [OutputKeys.OUTPUT],
     Tasks.document_grounded_dialog_retrieval: [OutputKeys.OUTPUT],
     Tasks.video_temporal_grounding: [OutputKeys.SCORES, OutputKeys.TBOUNDS],
     Tasks.text_to_video_synthesis: [OutputKeys.OUTPUT_VIDEO],
+    Tasks.text_to_360panorama_image: [OutputKeys.OUTPUT_IMG],
+
+    # Tasks.image_try_on result for a single sample
+    # {
+    #    "output_img": np.ndarray with shape [height, width, 3]
+    # }
+    Tasks.image_try_on: [OutputKeys.OUTPUT_IMG],
 }
 
 
 class ModelOutputBase(list):
 
     def __post_init__(self):
         self.reconstruct()
```

### Comparing `modelscope-1.7.1/modelscope/pipeline_inputs.py` & `modelscope-1.8.0rc0/modelscope/pipeline_inputs.py`

 * *Files 1% similar despite different names*

```diff
@@ -211,14 +211,19 @@
     },
     Tasks.shop_segmentation:
     InputType.IMAGE,
     Tasks.movie_scene_segmentation:
     InputType.VIDEO,
     Tasks.bad_image_detecting:
     InputType.IMAGE,
+    Tasks.image_try_on: {
+        InputKeys.IMAGE: InputType.IMAGE,
+        InputKeys.IMAGE: InputType.IMAGE,
+        InputKeys.IMAGE: InputType.IMAGE
+    },
 
     # ============ nlp tasks ===================
     Tasks.chat: {
         'text': InputType.TEXT,
         'history': InputType.LIST,
     },
     Tasks.text_classification: [
@@ -323,14 +328,20 @@
     InputType.AUDIO,
     Tasks.acoustic_noise_suppression:
     InputType.AUDIO,
     Tasks.text_to_speech:
     InputType.TEXT,
     Tasks.keyword_spotting:
     InputType.AUDIO,
+    Tasks.speaker_diarization_dialogue_detection:
+    InputType.TEXT,
+    Tasks.speech_language_recognition:
+    InputType.AUDIO,
+    Tasks.speaker_diarization_semantic_speaker_turn_detection:
+    InputType.TEXT,
     Tasks.inverse_text_processing:
     InputType.TEXT,
 
     # ============ multi-modal tasks ===================
     Tasks.image_captioning: [InputType.IMAGE, {
         'image': InputType.IMAGE,
     }],
@@ -383,8 +394,11 @@
         'video_output_path': InputType.TEXT,
         'mask_path': InputType.TEXT,
     },
     Tasks.text_to_video_synthesis: {
         'text': InputType.TEXT
     },
     Tasks.video_summarization: InputType.TEXT,
+    Tasks.text_to_360panorama_image: {
+        'prompt': InputType.TEXT,
+    },
 }
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/ans_dfsmn_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/ans_dfsmn_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/ans_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/ans_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/asr_inference_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/asr_inference_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -206,15 +206,20 @@
         self.raw_inputs = None
         if output_dir is not None:
             self.cmd['output_dir'] = output_dir
         self.cmd['param_dict'] = param_dict
 
         if isinstance(audio_in, str):
             # for funasr code, generate wav.scp from url or local path
-            self.audio_in, self.raw_inputs = generate_scp_from_url(audio_in)
+            if audio_in.startswith('http') or os.path.isfile(audio_in):
+                self.audio_in, self.raw_inputs = generate_scp_from_url(
+                    audio_in)
+            else:
+                raise FileNotFoundError(
+                    f'file {audio_in} NOT FOUND, please CHECK!')
         elif isinstance(audio_in, bytes):
             self.audio_in = audio_in
             self.raw_inputs = None
         else:
             import numpy
             import torch
             if isinstance(audio_in, torch.Tensor):
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/asr_wenet_inference_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/inverse_text_processing_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/inverse_text_processing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/kws_farfield_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/kws_farfield_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/kws_kwsbp_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/kws_kwsbp_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/linear_aec_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/linear_aec_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/lm_infer_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/lm_infer_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/punctuation_processing_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/punctuation_processing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/segmentation_clustering_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/segmentation_clustering_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -47,24 +47,21 @@
             model (str): a valid offical model id
         """
         super().__init__(model=model, **kwargs)
         self.config = self.model.other_config
         config = {
             'seg_dur': 1.5,
             'seg_shift': 0.75,
-            'batch_size': 128,
         }
         self.config.update(config)
         self.fs = self.config['sample_rate']
         self.sv_pipeline = pipeline(
             task='speaker-verification', model=self.config['speaker_model'])
 
-    def __call__(self,
-                 audio: Union[str, np.ndarray, list],
-                 output_res=False,
+    def __call__(self, audio: Union[str, np.ndarray, list],
                  **params) -> Dict[str, Any]:
         """ extract the speaker embeddings of input audio and do cluster
         Args:
             audio (str, np.ndarray, list): If it is represented as a str or a np.ndarray, it
             should be a complete speech signal and requires VAD preprocessing. If the audio
             is represented as a list, it should contain only the effective speech segments
             obtained through VAD preprocessing. The list should be formatted as [[0(s),3.2,
@@ -88,29 +85,18 @@
         labels = self.clustering(embeddings)
         # post processing
         logger.info('Post processing...')
         output = self.postprocess(segments, vad_segments, labels, embeddings)
         return {OutputKeys.TEXT: output}
 
     def forward(self, input: list) -> np.ndarray:
-        bs = self.config['batch_size']
-        x = []
         embeddings = []
-        for i, s in enumerate(input):
-            x.append(s[2])
-            if len(x) >= bs:
-                x = np.stack(x)
-                _, embs = self.sv_pipeline(x, output_emb=True)
-                embeddings.append(embs)
-                x = []
-        if len(x) > 0:
-            x = np.stack(x)
-            _, embs = self.sv_pipeline(x, output_emb=True)
+        for s in input:
+            _, embs = self.sv_pipeline([s[2]], output_emb=True)
             embeddings.append(embs)
-            x = []
         embeddings = np.concatenate(embeddings)
         return embeddings
 
     def clustering(self, embeddings: np.ndarray) -> np.ndarray:
         labels = self.model(embeddings, **self.config)
         return labels
 
@@ -182,23 +168,25 @@
                     torch.from_numpy(audio).unsqueeze(0),
                     fs,
                     effects=[['rate', str(self.fs)]])
                 audio = audio.squeeze(0).numpy()
         assert len(audio.shape) == 1, 'modelscope error: Wrong audio format.'
         if audio.dtype in ['int16', 'int32', 'int64']:
             audio = (audio / (1 << 15)).astype('float32')
+        else:
+            audio = audio.astype('float32')
         if not hasattr(self, 'vad_pipeline'):
             self.vad_pipeline = pipeline(
                 task=Tasks.voice_activity_detection,
                 model=self.config['vad_model'])
         vad_time = self.vad_pipeline(audio, audio_fs=self.fs)
         vad_segments = []
         for t in vad_time['text']:
-            st = t[0] / 1000
-            ed = t[1] / 1000
+            st = int(t[0]) / 1000
+            ed = int(t[1]) / 1000
             vad_segments.append(
                 [st, ed, audio[int(st * self.fs):int(ed * self.fs)]])
 
         return vad_segments
 
     def check_audio_list(self, audio: list):
         audio_dur = 0
@@ -211,17 +199,15 @@
                 seg[0] * self.fs
             ) == seg[2].shape[
                 0], 'modelscope error: audio data in list is inconsistent with time length.'
             if i > 0:
                 assert seg[0] >= audio[
                     i - 1][1], 'modelscope error: Wrong time stamps.'
             audio_dur += seg[1] - seg[0]
-            if audio[i][2].dtype in ['int16', 'int32', 'int64']:
-                audio[i][2] = (audio[i][2] / (1 << 15)).astype('float32')
-        assert audio_dur > 10, 'modelscope error: The effective audio duration is too short.'
+        assert audio_dur > 5, 'modelscope error: The effective audio duration is too short.'
 
     def chunk(self, vad_segments: list) -> list:
 
         def seg_chunk(seg_data):
             seg_st = seg_data[0]
             data = seg_data[2]
             chunk_len = int(self.config['seg_dur'] * self.fs)
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/separation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/separation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_change_locating_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_change_locating_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -113,14 +113,16 @@
                     data,
                     fs,
                     effects=[['rate',
                               str(self.model_config['sample_rate'])]])
         elif isinstance(input, np.ndarray):
             if input.dtype in ['int16', 'int32', 'int64']:
                 input = (input / (1 << 15)).astype('float32')
+            else:
+                input = input.astype('float32')
             data = torch.from_numpy(input)
             if len(data.shape) == 1:
                 data = data.unsqueeze(0)
         else:
             raise ValueError(
                 'modelscope error: The input type is restricted to audio file address and numpy array.'
             )
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_diarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_diarization_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -228,15 +228,21 @@
             cmd['param_dict']['sv_train_config'] = os.path.join(
                 model_dir,
                 model_cfg['model']['model_config']['sv_model_config'])
 
     def forward(self, audio_in: Union[tuple, str, Any] = None) -> list:
         """Decoding
         """
-        logger.info('Speaker Diarization Processing: {0} ...'.format(audio_in))
+        # log  file_path/url or tuple (str, str)
+        if isinstance(audio_in, str) or \
+                (isinstance(audio_in, tuple) and all(isinstance(item, str) for item in audio_in)):
+            logger.info(f'Speaker Verification Processing: {audio_in} ...')
+        else:
+            logger.info(
+                f'Speaker Verification Processing: {str(audio_in)[:100]} ...')
 
         data_cmd, raw_inputs = None, None
         if isinstance(audio_in, tuple) or isinstance(audio_in, list):
             # generate audio_scp
             if isinstance(audio_in[0], str):
                 # for scp inputs
                 if len(audio_in[0].split(',')) == 3 and audio_in[0].split(
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_light_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_light_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -66,22 +66,19 @@
         embs = self.forward(wavs)
         outputs = self.postprocess(embs, in_audios, save_dir)
         if output_emb:
             return outputs, embs.numpy()
         else:
             return outputs
 
-    def forward(self, inputs: Union[torch.Tensor, list]):
-        if isinstance(inputs, list):
-            embs = []
-            for x in inputs:
-                embs.append(self.model(x))
-            embs = torch.cat(embs)
-        else:
-            embs = self.model(inputs)
+    def forward(self, inputs: list):
+        embs = []
+        for x in inputs:
+            embs.append(self.model(x))
+        embs = torch.cat(embs)
         return embs
 
     def postprocess(self,
                     inputs: torch.Tensor,
                     in_audios: Union[np.ndarray, list],
                     save_dir=None):
         if isinstance(in_audios[0], str):
@@ -107,15 +104,15 @@
                 output = {OutputKeys.TEXT: 'No similarity score output'}
 
         else:
             output = {OutputKeys.TEXT: 'No similarity score output'}
 
         return output
 
-    def preprocess(self, inputs: Union[np.ndarray, list], **preprocess_params):
+    def preprocess(self, inputs: Union[np.ndarray, list]):
         output = []
         for i in range(len(inputs)):
             if isinstance(inputs[i], str):
                 file_bytes = File.read(inputs[i])
                 data, fs = sf.read(io.BytesIO(file_bytes), dtype='float32')
                 if len(data.shape) == 2:
                     data = data[:, 0]
@@ -135,24 +132,22 @@
             elif isinstance(inputs[i], np.ndarray):
                 assert len(
                     inputs[i].shape
                 ) == 1, 'modelscope error: Input array should be [N, T]'
                 data = inputs[i]
                 if data.dtype in ['int16', 'int32', 'int64']:
                     data = (data / (1 << 15)).astype('float32')
+                else:
+                    data = data.astype('float32')
                 data = torch.from_numpy(data)
             else:
                 raise ValueError(
                     'modelscope error: The input type is restricted to audio address and nump array.'
-                    % i)
+                )
             output.append(data)
-        try:
-            output = torch.stack(output)
-        except RuntimeError:
-            pass
         return output
 
     def compute_cos_similarity(self, emb1: Union[np.ndarray, torch.Tensor],
                                emb2: Union[np.ndarray, torch.Tensor]) -> float:
         if isinstance(emb1, np.ndarray):
             emb1 = torch.from_numpy(emb1)
         if isinstance(emb2, np.ndarray):
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_pipeline.py`

 * *Files 6% similar despite different names*

```diff
@@ -176,16 +176,21 @@
                 del extra_args[user_args]
 
         return cmd
 
     def forward(self, audio_in: Union[tuple, str, Any] = None) -> list:
         """Decoding
         """
-        logger.info(
-            'Speaker Verification Processing: {0} ...'.format(audio_in))
+        # log  file_path/url or tuple (str, str)
+        if isinstance(audio_in, str) or \
+                (isinstance(audio_in, tuple) and all(isinstance(item, str) for item in audio_in)):
+            logger.info(f'Speaker Verification Processing: {audio_in} ...')
+        else:
+            logger.info(
+                f'Speaker Verification Processing: {str(audio_in)[:100]} ...')
 
         data_cmd, raw_inputs = None, None
         if isinstance(audio_in, tuple) or isinstance(audio_in, list):
             # generate audio_scp
             assert len(audio_in) == 2
             if isinstance(audio_in[0], str):
                 # for scp inputs
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/text_to_speech_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/text_to_speech_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/timestamp_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/timestamp_pipeline.py`

 * *Files 1% similar despite different names*

```diff
@@ -89,15 +89,15 @@
             seg_dict_file=self.cmd['seg_dict_file'],
             param_dict=self.cmd['param_dict'],
             **kwargs,
         )
 
     def __call__(self,
                  audio_in: Union[str, bytes],
-                 text_in: str = None,
+                 text_in: str,
                  audio_fs: int = None,
                  recog_type: str = None,
                  audio_format: str = None,
                  output_dir: str = None,
                  param_dict: dict = None,
                  **kwargs) -> Dict[str, Any]:
         """
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/audio/voice_activity_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/audio/voice_activity_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/base.py` & `modelscope-1.8.0rc0/modelscope/pipelines/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -140,15 +140,16 @@
         def _prepare_single(model):
             if not isinstance(model, torch.nn.Module) and hasattr(
                     model, 'model'):
                 model = model.model
             if not isinstance(model, torch.nn.Module):
                 return
             model.eval()
-            if self.device_map is None:
+            from modelscope.utils.torch_utils import is_on_same_device
+            if is_on_same_device(model):
                 model.to(self.device)
 
         if not self._model_prepare:
             # prepare model for pytorch
             if self.framework == Frameworks.torch:
                 if self.has_multiple_models:
                     for m in self.models:
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/builder.py` & `modelscope-1.8.0rc0/modelscope/pipelines/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -99,18 +99,20 @@
     from .image_inpainting_sdv2_pipeline import ImageInpaintingSDV2Pipeline
     from .image_quality_assessment_mos_pipeline import ImageQualityAssessmentMosPipeline
     from .image_quality_assessment_man_pipeline import ImageQualityAssessmentMANPipeline
     from .bad_image_detecting_pipeline import BadImageDetecingPipeline
     from .mobile_image_super_resolution_pipeline import MobileImageSuperResolutionPipeline
     from .image_human_parsing_pipeline import ImageHumanParsingPipeline
     from .nerf_recon_acc_pipeline import NeRFReconAccPipeline
+    from .nerf_recon_4k_pipeline import NeRFRecon4KPipeline
     from .controllable_image_generation_pipeline import ControllableImageGenerationPipeline
     from .image_bts_depth_estimation_pipeline import ImageBTSDepthEstimationPipeline
     from .pedestrian_attribute_recognition_pipeline import PedestrainAttributeRecognitionPipeline
     from .image_panoptic_segmentation_pipeline import ImagePanopticSegmentationPipeline
+    from .text_to_360panorama_image_pipeline import Text2360PanoramaImagePipeline
 else:
     _import_structure = {
         'action_recognition_pipeline': ['ActionRecognitionPipeline'],
         'action_detection_pipeline': ['ActionDetectionPipeline'],
         'animal_recognition_pipeline': ['AnimalRecognitionPipeline'],
         'body_2d_keypoints_pipeline': ['Body2DKeypointsPipeline'],
         'body_3d_keypoints_pipeline': ['Body3DKeypointsPipeline'],
@@ -249,26 +251,30 @@
         ],
         'mobile_image_super_resolution_pipeline': [
             'MobileImageSuperResolutionPipeline'
         ],
         'bad_image_detecting_pipeline': ['BadImageDetecingPipeline'],
         'image_human_parsing_pipeline': ['ImageHumanParsingPipeline'],
         'nerf_recon_acc_pipeline': ['NeRFReconAccPipeline'],
+        'nerf_recon_4k_pipeline': ['NeRFRecon4KPipeline'],
         'controllable_image_generation_pipeline': [
             'ControllableImageGenerationPipeline'
         ],
         'image_bts_depth_estimation_pipeline': [
             'ImageBTSDepthEstimationPipeline'
         ],
         'pedestrian_attribute_recognition_pipeline': [
             'PedestrainAttributeRecognitionPipeline'
         ],
         'image_panoptic_segmentation_pipeline': [
             'ImagePanopticSegmentationPipeline',
         ],
+        'text_to_360panorama_image_pipeline': [
+            'Text2360PanoramaImagePipeline'
+        ],
     }
 
     import sys
 
     sys.modules[__name__] = LazyImportModule(
         __name__,
         globals()['__file__'],
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/action_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/action_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/action_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/action_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/animal_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/animal_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/arc_face_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/arc_face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/bad_image_detecting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/bad_image_detecting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/body_2d_keypoints_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/body_3d_keypoints_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/card_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/card_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/cmdssl_video_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/content_check_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/content_check_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/controllable_image_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/controllable_image_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/crowd_counting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/crowd_counting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ddcolor_image_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ddpm_semantic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_attribute_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_emotion_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_emotion_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_human_hand_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_image_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_image_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_liveness_ir_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_liveness_ir_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_liveness_xc_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_liveness_xc_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_processing_base_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_processing_base_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_quality_assessment_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_quality_assessment_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_onnx_fm_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_onnx_ir_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_ood_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_ood_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/face_reconstruction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/face_reconstruction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/facial_expression_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/facial_landmark_confidence_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/fast_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/general_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/general_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/hand_static_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/hand_static_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/hicossl_video_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/human_reconstruction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/human_reconstruction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_body_reshaping_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_body_reshaping_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_bts_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_cartoon_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_cartoon_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_color_enhance_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_color_enhance_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_colorization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_debanding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_debanding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_deblur_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_deblur_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_defrcn_fewshot_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_denoise_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_denoise_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_depth_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_driving_perception_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_driving_perception_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_face_fusion_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_face_fusion_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_human_parsing_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_human_parsing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_inpainting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_inpainting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_inpainting_sdv2_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_matching_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_matching_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_matting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_matting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_mvs_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_open_vocabulary_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_paintbyexample_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_paintbyexample_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_panoptic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_portrait_enhancement_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_degradation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_man_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_quality_assessment_mos_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_reid_person_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_reid_person_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_restoration_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_restoration_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_salient_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_salient_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_skychange_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_skychange_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_structured_model_probing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_style_transfer_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_style_transfer_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_super_resolution_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_to_image_generate_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_to_image_generate_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/image_to_image_translation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/image_to_image_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/license_plate_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/license_plate_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/lineless_table_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/live_category_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/live_category_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/mask_face_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/mask_face_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/mog_face_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/mog_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/motion_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/motion_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/nerf_recon_acc_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/object_detection_3d_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/object_detection_3d_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_convnext_transformer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_dla34.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_dla34.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_resnet18_half.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/model_vlpt.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/model_vlpt.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/convnext.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ocr_modules/vitstr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/ops.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/resnet18_v1.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/resnet_utils.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/resnet_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/table_process.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/table_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ocr_utils/utils.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ocr_utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/product_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/product_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/retina_face_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/retina_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/shop_segmentation_pipleline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/shop_segmentation_pipleline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/skin_retouching_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/skin_retouching_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/table_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/table_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/tbs_detection_utils/utils.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/tbs_detection_utils/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/text_driven_segmentation_pipleline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/tinynas_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/tinynas_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/tinynas_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/tinynas_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/ulfd_face_detection_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_category_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_category_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_colorization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_colorization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_deinterlace_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_deinterlace_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_depth_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_depth_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_frame_interpolation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_human_matting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_human_matting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_inpainting_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_inpainting_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_instance_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_multi_object_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_object_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_object_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_panoptic_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_single_object_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_stabilization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_stabilization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_summarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/video_super_resolution_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/video_super_resolution_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/vidt_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/vidt_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/virtual_try_on_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/virtual_try_on_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/vision_efficient_tuning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/vision_middleware_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/vision_middleware_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/vop_retrieval_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/vop_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/cv/vop_retrieval_se_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/asr_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/asr_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py`

 * *Files 3% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 
 class DiffusersPipeline(Pipeline):
 
     def __init__(self, model: str, device: str = 'gpu', **kwargs):
         """
         use `model` to create a diffusers pipeline
         Args:
-            model: model id on modelscope hub.
+            model: model id on modelscope hub or local dir.
             device: str = 'gpu'
         """
 
         self.device_name = device
         self.cfg = None
         self.preprocessor = None
         self.framework = None
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py`

 * *Files 14% similar despite different names*

```diff
@@ -142,15 +142,16 @@
             self,
             prompt,
             device,
             num_images_per_prompt,
             do_classifier_free_guidance,
             negative_prompt=None,
             prompt_embeds: Optional[torch.FloatTensor] = None,
-            negative_prompt_embeds: Optional[torch.FloatTensor] = None):
+            negative_prompt_embeds: Optional[torch.FloatTensor] = None,
+            lora_scale: Optional[float] = None):
         r"""
         Encodes the prompt into text encoder hidden states.
 
         Args:
             prompt (`str` or `list(int)`):
                 prompt to be encoded
             device: (`torch.device`):
@@ -165,15 +166,22 @@
             prompt_embeds (`torch.FloatTensor`, *optional*):
                 Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not
                 provided, text embeddings will be generated from `prompt` input argument.
             negative_prompt_embeds (`torch.FloatTensor`, *optional*):
                 Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt
                 weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input
                 argument.
+            lora_scale (`float`, *optional*):
+                A lora scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.
         """
+        # set lora scale so that monkey patched LoRA
+        # function of text encoder can correctly access it
+        if lora_scale is not None and isinstance(self, LoraLoaderMixin):
+            self._lora_scale = lora_scale
+
         if prompt is not None and isinstance(prompt, str):
             batch_size = 1
         elif prompt is not None and isinstance(prompt, list):
             batch_size = len(prompt)
         else:
             batch_size = prompt_embeds.shape[0]
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,70 +1,68 @@
-# Copyright  Alibaba, Inc. and its affiliates.
+# Copyright (c) Alibaba, Inc. and its affiliates.
+
+import io
 import os
-from typing import Any, Dict, Optional
+from typing import Any, Dict
 
-import cv2
-import numpy as np
 import torch
-import torchvision.transforms as transforms
-from diffusers import \
-    StableDiffusionPipeline as DiffuserStableDiffusionPipeline
-from PIL import Image
+from transformers import XLMRobertaTokenizer
 
 from modelscope.metainfo import Pipelines
-from modelscope.models import Model
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
-from modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline import \
-    DiffusersPipeline
-from modelscope.utils.constant import Tasks
+from modelscope.utils.constant import ModelFile, Tasks
+
+__all__ = ['TranslationQualityEstimationPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.text_to_image_synthesis,
-    module_name=Pipelines.diffusers_stable_diffusion)
-class StableDiffusionPipeline(DiffusersPipeline):
+    Tasks.sentence_similarity,
+    module_name=Pipelines.translation_quality_estimation)
+class TranslationQualityEstimationPipeline(Pipeline):
+
+    def __init__(self, model: str, device: str = 'gpu', **kwargs):
+        super().__init__(model=model, device=device)
+        model_file = os.path.join(self.model, ModelFile.TORCH_MODEL_FILE)
+        with open(model_file, 'rb') as f:
+            buffer = io.BytesIO(f.read())
+        self.tokenizer = XLMRobertaTokenizer.from_pretrained(self.model)
+        self.model = torch.jit.load(
+            buffer, map_location=self.device).to(self.device)
+
+    def preprocess(self, inputs: Dict[str, Any]):
+        src_text = inputs['source_text'].strip()
+        tgt_text = inputs['target_text'].strip()
+        encoded_inputs = self.tokenizer.batch_encode_plus(
+            [[src_text, tgt_text]],
+            return_tensors='pt',
+            padding=True,
+            truncation=True)
+        input_ids = encoded_inputs['input_ids'].to(self.device)
+        attention_mask = encoded_inputs['attention_mask'].to(self.device)
+        inputs.update({
+            'input_ids': input_ids,
+            'attention_mask': attention_mask
+        })
+        return inputs
 
-    def __init__(self, model: str, lora_dir: str = None, **kwargs):
-        """
-        use `model` to create a stable diffusion pipeline
-        Args:
-            model: model id on modelscope hub or local model dir.
-        """
+    def forward(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+        if 'input_ids' not in inputs:
+            inputs = self.preprocess(inputs)
+        res = self.model(inputs['input_ids'], inputs['attention_mask'])
+        result = {
+            OutputKeys.LABELS: '-1',
+            OutputKeys.SCORES: res[0].detach().squeeze().tolist()
+        }
+        return result
 
-        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
-        # load pipeline
-        torch_type = torch.float16 if self.device == 'cuda' else torch.float32
-        self.pipeline = DiffuserStableDiffusionPipeline.from_pretrained(
-            model, torch_dtype=torch_type)
-        self.pipeline = self.pipeline.to(self.device)
-        # load lora moudle to unet
-        if lora_dir is not None:
-            assert os.path.exists(lora_dir), f"{lora_dir} isn't exist"
-            self.pipeline.unet.load_attn_procs(lora_dir)
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, str]:
+        """process the prediction results
 
-    def preprocess(self, inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:
-        return inputs
+        Args:
+            inputs (Dict[str, Any]): input data dict
 
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        if not isinstance(inputs, dict):
-            raise ValueError(
-                f'Expected the input to be a dictionary, but got {type(input)}'
-            )
-
-        if 'text' not in inputs:
-            raise ValueError('input should contain "text", but not found')
-
-        images = self.pipeline(
-            inputs['text'], num_inference_steps=30, guidance_scale=7.5)
-
-        return images
-
-    def postprocess(self, inputs: Dict[str, Any], **kwargs) -> Dict[str, Any]:
-        images = []
-        for img in inputs.images:
-            if isinstance(img, Image.Image):
-                img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
-                images.append(img)
-        return {OutputKeys.OUTPUT_IMGS: images}
+        Returns:
+            Dict[str, str]: the prediction results
+        """
+        return inputs
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/document_vl_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -59,19 +59,22 @@
         if 'prompt' in inputs:
             result['prompt'] = inputs['prompt']
         return result
 
     def forward(self, inputs: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         with torch.no_grad():
-            results = self.model(**inputs)
+            results = self.model(**inputs, **forward_params)
             return results
 
     def postprocess(self, inputs: Dict[str, Any],
                     **post_params) -> Dict[str, Any]:
         images = []
         for idx, img in enumerate(inputs):
             if isinstance(img, Image.Image):
                 img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                 images.append(img)
                 cv2.imwrite(f'{self.model.tuner_name}_{idx}.jpg', img)
         return {OutputKeys.OUTPUT_IMGS: images}
+
+    def _sanitize_parameters(self, **pipeline_parameters):
+        return pipeline_parameters, pipeline_parameters, pipeline_parameters
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/gridvlp_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/gridvlp_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/image_captioning_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/image_captioning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/image_text_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/mgeo_ranking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/multimodal_dialogue_pipeline.py`

 * *Files 4% similar despite different names*

```diff
@@ -62,21 +62,20 @@
         """
         super().__init__(model=model, preprocessor=preprocessor, **kwargs)
         self.model.eval()
         if preprocessor is None:
             if isinstance(self.model, MplugOwlForConditionalGeneration):
                 self.preprocessor = MplugOwlPreprocessor(self.model.model_dir)
 
-    def forward(self, inputs: Dict[str, Any],
-                **forward_params) -> Dict[str, Any]:
-        """
-        the `forward_params` can be the generation configurations listed in transformers library.
-        """
+    def _sanitize_parameters(self, **pipeline_parameters):
+        return pipeline_parameters, {}, {}
+
+    def forward(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
         with torch.no_grad():
-            return super().forward(inputs, **forward_params)
+            return super().forward(inputs)
 
     def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, str]:
         """process the prediction results
 
         Args:
             inputs (Dict[str, Any]): _description_
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/ocr_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/sudoku_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/sudoku_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/text2sql_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text2sql_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text_to_image_synthesis_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/text_to_video_synthesis_pipeline.py`

 * *Files 12% similar despite different names*

```diff
@@ -48,15 +48,22 @@
 
     def preprocess(self, input: Input, **preprocess_params) -> Dict[str, Any]:
         self.model.clip_encoder.to(self.model.device)
         text_emb = self.model.clip_encoder(input['text'])
         text_emb_zero = self.model.clip_encoder('')
         if self.model.config.model.model_args.tiny_gpu == 1:
             self.model.clip_encoder.to('cpu')
-        return {'text_emb': text_emb, 'text_emb_zero': text_emb_zero}
+        out_height = input['height'] if 'height' in input else 256
+        out_width = input['width'] if 'height' in input else 256
+        return {
+            'text_emb': text_emb,
+            'text_emb_zero': text_emb_zero,
+            'out_height': out_height,
+            'out_width': out_width
+        }
 
     def forward(self, input: Dict[str, Any],
                 **forward_params) -> Dict[str, Any]:
         video = self.model(input)
         return {'video': video}
 
     def postprocess(self, inputs: Dict[str, Any],
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/video_captioning_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_captioning_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/video_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_entailment_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_grounding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/multi_modal/visual_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/__init__.py`

 * *Files 2% similar despite different names*

```diff
@@ -8,14 +8,15 @@
     from .conversational_text_to_sql_pipeline import ConversationalTextToSqlPipeline
     from .table_question_answering_pipeline import TableQuestionAnsweringPipeline
     from .dialog_intent_prediction_pipeline import DialogIntentPredictionPipeline
     from .dialog_modeling_pipeline import DialogModelingPipeline
     from .dialog_state_tracking_pipeline import DialogStateTrackingPipeline
     from .document_segmentation_pipeline import DocumentSegmentationPipeline
     from .extractive_summarization_pipeline import ExtractiveSummarizationPipeline
+    from .polylm_text_generation_pipeline import PolyLMTextGenerationPipeline
     from .fasttext_text_classification_pipeline import FasttextSequenceClassificationPipeline
     from .faq_question_answering_pipeline import FaqQuestionAnsweringPipeline
     from .feature_extraction_pipeline import FeatureExtractionPipeline
     from .fill_mask_pipeline import FillMaskPipeline
     from .information_extraction_pipeline import InformationExtractionPipeline
     from .interactive_translation_pipeline import InteractiveTranslationPipeline
     from .named_entity_recognition_pipeline import NamedEntityRecognitionPipeline
@@ -46,14 +47,15 @@
     from .language_identification_pipline import LanguageIdentificationPipeline
 
 else:
     _import_structure = {
         'automatic_post_editing_pipeline': ['AutomaticPostEditingPipeline'],
         'conversational_text_to_sql_pipeline':
         ['ConversationalTextToSqlPipeline'],
+        'polylm_text_generation_pipeline': ['PolyLMTextGenerationPipeline'],
         'dialog_intent_prediction_pipeline':
         ['DialogIntentPredictionPipeline'],
         'dialog_modeling_pipeline': ['DialogModelingPipeline'],
         'dialog_state_tracking_pipeline': ['DialogStateTrackingPipeline'],
         'fasttext_text_classification_pipeline':
         ['FasttextSequenceClassificationPipeline'],
         'document_segmentation_pipeline': ['DocumentSegmentationPipeline'],
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/automatic_post_editing_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/canmt_translation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/canmt_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/codegeex_code_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/codegeex_code_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/conversational_text_to_sql_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_intent_prediction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/dialog_modeling_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_modeling_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/dialog_state_tracking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_gpt3_pipeline.py`

 * *Files 8% similar despite different names*

```diff
@@ -90,15 +90,16 @@
             self._check_output(out)
             yield out
 
     @classmethod
     def _stream_one(cls, inputs: Dict[str, Any]) -> None:
         tokens = inputs['inputs']['input_ids'].cuda(
             torch.cuda.current_device())
-        cls._stream = cls.model.stream(tokens, **inputs['forward_params'])
+        cls._stream = cls.model.stream_generate(tokens,
+                                                **inputs['forward_params'])
 
     @classmethod
     def _next_one(cls, idx: int) -> Optional[Dict[str, Any]]:
         try:
             return next(cls._stream)
         except StopIteration:
             return None
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_gpt_moe_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/distributed_plug_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/distributed_plug_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_generate_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/document_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/document_segmentation_pipeline.py`

 * *Files 2% similar despite different names*

```diff
@@ -87,20 +87,24 @@
             predict_dataset.pop('segment_ids')
 
         labels = predict_dataset.pop('labels')
         sentences = predict_dataset.pop('sentences')
         example_ids = predict_dataset.pop(
             self.preprocessor.example_id_column_name)
 
+        if (self.model or (self.has_multiple_models and self.models[0])):
+            if not self._model_prepare:
+                self.prepare_model()
+
         with torch.no_grad():
             input = {
-                key: torch.tensor(val)
+                key: torch.tensor(val).to(self.device)
                 for key, val in predict_dataset.items()
             }
-            predictions = self.model.forward(**input).logits
+            predictions = self.model.forward(**input).logits.cpu()
 
         predictions = np.argmax(predictions, axis=2)
         assert len(sentences) == len(
             predictions), 'sample {}  infer_sample {} prediction {}'.format(
                 num_samples, len(sentences), len(predictions))
         # Remove ignored index (special tokens)
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/extractive_summarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/extractive_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/faq_question_answering_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/faq_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/fasttext_text_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/feature_extraction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/feature_extraction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/fid_dialogue_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/fid_dialogue_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/fill_mask_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/fill_mask_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/information_extraction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/information_extraction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/interactive_translation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/interactive_translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/language_identification_pipline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/language_identification_pipline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/named_entity_recognition_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/sentence_embedding_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/sentence_embedding_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/siamese_uie_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/siamese_uie_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/summarization_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/summarization_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/table_question_answering_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/table_question_answering_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/text_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/text_error_correction_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_error_correction_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/text_generation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_generation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/text_ranking_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/text_ranking_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/token_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/token_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/translation_evaluation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_evaluation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/translation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/translation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/translation_quality_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/word_alignment_pipeline.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,68 +1,68 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
-import io
-import os
-from typing import Any, Dict
+from typing import Any, Dict, Optional, Union
 
-import torch
-from transformers import XLMRobertaTokenizer
+import numpy as np
 
 from modelscope.metainfo import Pipelines
+from modelscope.models import Model
 from modelscope.outputs import OutputKeys
 from modelscope.pipelines.base import Pipeline
 from modelscope.pipelines.builder import PIPELINES
-from modelscope.utils.constant import ModelFile, Tasks
+from modelscope.preprocessors import WordAlignmentPreprocessor
+from modelscope.utils.constant import Tasks
 
-__all__ = ['TranslationQualityEstimationPipeline']
+__all__ = ['WordAlignmentPipeline']
 
 
 @PIPELINES.register_module(
-    Tasks.sentence_similarity,
-    module_name=Pipelines.translation_quality_estimation)
-class TranslationQualityEstimationPipeline(Pipeline):
-
-    def __init__(self, model: str, device: str = 'gpu', **kwargs):
-        super().__init__(model=model, device=device)
-        model_file = os.path.join(self.model, ModelFile.TORCH_MODEL_FILE)
-        with open(model_file, 'rb') as f:
-            buffer = io.BytesIO(f.read())
-        self.tokenizer = XLMRobertaTokenizer.from_pretrained(self.model)
-        self.model = torch.jit.load(
-            buffer, map_location=self.device).to(self.device)
-
-    def preprocess(self, inputs: Dict[str, Any]):
-        src_text = inputs['source_text'].strip()
-        tgt_text = inputs['target_text'].strip()
-        encoded_inputs = self.tokenizer.batch_encode_plus(
-            [[src_text, tgt_text]],
-            return_tensors='pt',
-            padding=True,
-            truncation=True)
-        input_ids = encoded_inputs['input_ids'].to(self.device)
-        attention_mask = encoded_inputs['attention_mask'].to(self.device)
-        inputs.update({
-            'input_ids': input_ids,
-            'attention_mask': attention_mask
-        })
-        return inputs
-
-    def forward(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
-        if 'input_ids' not in inputs:
-            inputs = self.preprocess(inputs)
-        res = self.model(inputs['input_ids'], inputs['attention_mask'])
-        result = {
-            OutputKeys.LABELS: '-1',
-            OutputKeys.SCORES: res[0].detach().squeeze().tolist()
-        }
-        return result
-
-    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, str]:
-        """process the prediction results
+    Tasks.word_alignment, module_name=Pipelines.word_alignment)
+class WordAlignmentPipeline(Pipeline):
 
+    def __init__(self,
+                 model: Union[Model, str],
+                 preprocessor: WordAlignmentPreprocessor = None,
+                 config_file: str = None,
+                 device: str = 'gpu',
+                 auto_collate=True,
+                 sequence_length=128,
+                 **kwargs):
+        """Use `model` and `preprocessor` to create a nlp text dual encoder then generates the text representation.
         Args:
-            inputs (Dict[str, Any]): input data dict
-
-        Returns:
-            Dict[str, str]: the prediction results
+            model (str or Model): Supply either a local model dir which supported the WS task,
+            or a model id from the model hub, or a torch model instance.
+            preprocessor (Preprocessor): A WordAlignmentPreprocessor.
+            kwargs (dict, `optional`):
+                Extra kwargs passed into the preprocessor's constructor.
+         Example:
+            >>> from modelscope.pipelines import pipeline
+            >>> from modelscope.utils.constant import Tasks
+            >>> model_id = 'damo/Third-Party-Supervised-Word-Aligner-mBERT-base-zhen'
+            >>> input = {"sentence_pair": '     ||| pele promotes autobiography in mexico .'}
+            >>> pipeline_ins = pipeline(Tasks.word_alignment, model=model_id)
+            >>> print(pipeline_ins(input)['output'])
         """
-        return inputs
+        super().__init__(
+            model=model,
+            preprocessor=preprocessor,
+            config_file=config_file,
+            device=device,
+            auto_collate=auto_collate)
+        if preprocessor is None:
+            self.preprocessor = WordAlignmentPreprocessor.from_pretrained(
+                self.model.model_dir,
+                sequence_length=sequence_length,
+                **kwargs)
+
+    def forward(self, inputs: Dict[str, Any],
+                **forward_params) -> Dict[str, Any]:
+        return self.model(**inputs, **forward_params)
+
+    def postprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
+
+        align = []
+        for k in inputs[0][0].keys():
+            align.append(f'{k[0]}-{k[1]}')
+        align = ' '.join(align)
+
+        return {OutputKeys.OUTPUT: align}
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/user_satisfaction_estimation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/word_segmentation_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/word_segmentation_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/nlp/zero_shot_classification_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/pipeline_template.py` & `modelscope-1.8.0rc0/modelscope/pipelines/pipeline_template.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/science/__init__.py` & `modelscope-1.8.0rc0/modelscope/pipelines/science/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/science/protein_structure_pipeline.py` & `modelscope-1.8.0rc0/modelscope/pipelines/science/protein_structure_pipeline.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/pipelines/util.py` & `modelscope-1.8.0rc0/modelscope/pipelines/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/asr.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/asr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/audio.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/audio.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/base.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/base.py`

 * *Files 0% similar despite different names*

```diff
@@ -28,28 +28,32 @@
     Preprocessors.document_segmentation,
     (Models.bert, Tasks.fill_mask):
     Preprocessors.fill_mask,
     (Models.bert, Tasks.sentence_embedding):
     Preprocessors.sentence_embedding,
     (Models.bert, Tasks.text_classification):
     Preprocessors.sen_cls_tokenizer,
+    (Models.bert, Tasks.speaker_diarization_dialogue_detection):
+    Preprocessors.sen_cls_tokenizer,
     (Models.bert, Tasks.nli):
     Preprocessors.sen_cls_tokenizer,
     (Models.bert, Tasks.sentiment_classification):
     Preprocessors.sen_cls_tokenizer,
     (Models.bert, Tasks.sentence_similarity):
     Preprocessors.sen_cls_tokenizer,
     (Models.bert, Tasks.zero_shot_classification):
     Preprocessors.sen_cls_tokenizer,
     (Models.bert, Tasks.text_ranking):
     Preprocessors.text_ranking,
     (Models.bert, Tasks.part_of_speech):
     Preprocessors.token_cls_tokenizer,
     (Models.bert, Tasks.token_classification):
     Preprocessors.token_cls_tokenizer,
+    (Models.bert, Tasks.speaker_diarization_semantic_speaker_turn_detection):
+    Preprocessors.token_cls_tokenizer,
     (Models.bert, Tasks.word_segmentation):
     Preprocessors.token_cls_tokenizer,
 
     # bloom
     (Models.bloom, Tasks.backbone):
     Preprocessors.text_gen_tokenizer,
```

### Comparing `modelscope-1.7.1/modelscope/preprocessors/builder.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/common.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/common.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/action_detection_mapper.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/action_detection_mapper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/controllable_image_generation.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/controllable_image_generation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/cv2_transforms.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/cv2_transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/image_classification_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/image_quality_assessment_man.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_quality_assessment_man.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/image_quality_assessment_mos.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_quality_assessment_mos.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/image_restoration_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/image_restoration_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/mmcls_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/mmcls_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/timer.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/timer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/util.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/util.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/video_stabilization.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/video_stabilization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/cv/video_super_resolution.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/cv/video_super_resolution.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/image.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/image.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/kws.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/kws.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/movie_scene_segmentation/transforms.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/movie_scene_segmentation/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/multi_modal.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/multi_modal.py`

 * *Files 0% similar despite different names*

```diff
@@ -65,15 +65,15 @@
         results = {}
         for key, value in data.items():
             if key.endswith(':FILE') or key in self.preprocessor_image_keys:
                 image = load_image(value)
                 img = self.transform_input(image)
                 results[key.replace(':FILE', '').lower()] = img
             else:
-                results[key.lower()] = value
+                results[key.lower()] = value if value else ''
         return results
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal, module_name=Preprocessors.ofa_tasks_preprocessor)
 class OfaPreprocessor(Preprocessor):
 
@@ -657,15 +657,15 @@
                  **kwargs):
         super().__init__(*args, **kwargs)
         self.model_dir = model_dir
         self.mode = mode
 
         self._tokenizer = None
         self._patch_resize_transform = None
-        self.media_token = {'<image>': 65}
+        self.media_token = {'<|image|>': 65}
         self._image_map = {}
 
     @property
     def tokenizer(self):
         from modelscope.models.nlp.llama import LlamaTokenizer
 
         if self._tokenizer is None:
@@ -741,22 +741,23 @@
                 text = f"{role}{turn['content']}"
                 texts.append(text)
             else:
                 for t in turn['content']:
                     if isinstance(t, str):
                         text = f'{role}{t}'
                     else:
-                        text = f'{role}<image>'
+                        text = f'{role}<|image|>'
                         image.append(t['image'])
                     texts.append(text)
         texts = '\n'.join(texts)
         texts += '\nAI: '
         return image, texts
 
-    def __call__(self, messages: Dict[str, Any]) -> Dict[str, Any]:
+    def __call__(self, messages: Dict[str, Any],
+                 **forward_params) -> Dict[str, Any]:
         """
         Args:
             messages: {[
                 {'role': 'system', 'content': 'message1'},
                 {'role': 'user', 'content': 'message2'},
                 {'role': 'user', 'content': ['message2', {"image": 'image_path'}, 'message3', ...]},
             ]}
@@ -779,14 +780,15 @@
 
         input_ids = self.tokenize_text(text)
         input_ids = torch.LongTensor([input_ids])
 
         output = {
             'pixel_values': pixel_values,
             'input_ids': input_ids,
+            **forward_params
         }
 
         return output
 
 
 @PREPROCESSORS.register_module(
     Fields.multi_modal,
```

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/bert_seq_cls_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/canmt_translation.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/canmt_translation.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/dialog_classification_use_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/document_segmentation_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/faq_question_answering_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/feature_extraction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/fill_mask_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/fill_mask_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/mgeo_ranking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/mglm_summarization_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/relation_extraction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/sentence_embedding_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/siamese_uie_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/args.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/args.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/batch.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/batch.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/data_loader.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/data_loader.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_modeling_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/dst_processors.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/dst_processors.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/gen_field.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/gen_field.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/fields/intent_field.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/fields/intent_field.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/lazy_dataset.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/lazy_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/preprocess.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/preprocess.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/sampler.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/sampler.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/tensorlistdataset.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/tensorlistdataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space/tokenizer.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space/tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/database.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/database.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/schema_link.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/fields/struct.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/common_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/parse.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/parse.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/space_T_en/fields/process_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/text_classification_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/text_clean.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_clean.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/text_error_correction.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_error_correction.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/text_generation_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_generation_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/text_ranking_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/text_ranking_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_thai_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/token_classification_viet_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/transformers_tokenizer.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/transformers_tokenizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/translation_evaluation_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/utils.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/word_alignment_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/word_alignment_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/nlp/zero_shot_classification_preprocessor.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/__init__.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/asr.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/asr.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/base.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/image_captioning.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/image_captioning.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/image_classification.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/image_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/ocr_recognition.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/ocr_recognition.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/sudoku.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/sudoku.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/summarization.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/summarization.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/text2sql.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text2sql.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/text_classification.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text_classification.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/text_to_image_synthesis.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/text_to_image_synthesis.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/audio_helper.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/audio_helper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/bridge_content_encoder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/collate.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/collate.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/constant.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/constant.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/get_tables.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/get_tables.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/random_help.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/random_help.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/text2phone.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/text2phone.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/transforms.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/transforms.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/utils/vision_helper.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/utils/vision_helper.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/visual_entailment.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_entailment.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/visual_grounding.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_grounding.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/ofa/visual_question_answering.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/ofa/visual_question_answering.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/science/uni_fold.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/science/uni_fold.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/tts.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/tts.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/preprocessors/video.py` & `modelscope-1.8.0rc0/modelscope/preprocessors/video.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/__init__.py` & `modelscope-1.8.0rc0/modelscope/swift/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/adapter.py` & `modelscope-1.8.0rc0/modelscope/swift/adapter.py`

 * *Files 2% similar despite different names*

```diff
@@ -108,15 +108,21 @@
                     inspect.signature(module.forward_origin).parameters)
                 if config.method_name == 'feed_forward_chunk' and num_args_in_forward_chunk_fn == 1:
                     setattr(module, config.method_name,
                             types.MethodType(_feed_forward_chunk, module))
                 else:
                     setattr(module, config.method_name,
                             types.MethodType(_forward, module))
-                adapter_module = AdapterModule(config.dim,
+
+                if isinstance(module, torch.nn.Linear):
+                    input_dim = module.out_features
+                else:
+                    input_dim = config.dim
+
+                adapter_module = AdapterModule(input_dim,
                                                config.adapter_length,
                                                config.act_layer)
                 setattr(module, 'adapter', adapter_module)
 
         if config.only_adapter_trainable:
             for n, p in model.named_parameters():
                 if 'adapter' not in n:
```

### Comparing `modelscope-1.7.1/modelscope/swift/base.py` & `modelscope-1.8.0rc0/modelscope/swift/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/control_sd_lora.py` & `modelscope-1.8.0rc0/modelscope/swift/control_sd_lora.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/lora.py` & `modelscope-1.8.0rc0/modelscope/swift/lora.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py` & `modelscope-1.8.0rc0/modelscope/swift/optimizers/child_tuning_adamw_optimizer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/swift/prompt.py` & `modelscope-1.8.0rc0/modelscope/swift/prompt.py`

 * *Files 8% similar despite different names*

```diff
@@ -29,14 +29,15 @@
         module_layer_name: The layer module to be replaced, in regex format
         embedding_pos: The position of the embedding tensor
         attention_mask_pos: The position of the attention mask
         attention_mask_value: The value to pad to the attention mask
         prompt_length: The length of the prompt tokens
         only_prompt_trainable: Whether to train only prompt
         attach_front: When set to True, prompt is attached in front of the embedding
+        extract_embedding: Whether the embedding is extracted at final stage to keep the same dims with inputs
         pretrained_weights: The pretrained prompt weights. Can be a local dir, local file,
             or a model id from modelscope
     """
 
     dim: int = field(metadata={'help': 'The dimension of the hidden states'})
 
     module_layer_name: str = field(
@@ -61,27 +62,35 @@
     attach_front: bool = field(
         default=True,
         metadata={
             'help':
             'When set to True, prompt is attached in front of the embedding'
         })
 
+    extract_embedding: bool = field(
+        default=False,
+        metadata={
+            'help':
+            'Whether the embedding is extracted at final stage to keep the same dims with inputs'
+        })
+
     pretrained_weights: str = field(
         default=None,
         metadata={
             'help':
             'The pretrained prompt weights. Can be a local dir, local file, or a model id from modelscope'
         })
 
 
 class Prompt:
 
     @staticmethod
     def prepare_model(model: nn.Module, config: PromptConfig):
         module_keys = [key for key, _ in model.named_modules()]
+        match_module_keys = []
         for module_key in module_keys:
             if re.fullmatch(config.module_layer_name, module_key):  # noqa
                 module = model.get_submodule(module_key)
 
                 def _forward(self, *args, **kwargs):
                     if isinstance(config.embedding_pos, int):
                         input_embedding = args[config.embedding_pos]
@@ -112,24 +121,36 @@
                             args = type(args)(
                                 args[0:config.attention_mask_pos]
                                 + (attention_mask, )
                                 + args[config.attention_mask_pos + 1:])
                         else:
                             kwargs[config.attention_mask_pos] = attention_mask
 
-                    return self.forward_origin(*args, **kwargs)
+                    forward_output = self.forward_origin(*args, **kwargs)
+                    if config.extract_embedding:
+                        forward_output = getattr(
+                            self, 'prompt').extract(forward_output)
+
+                    return forward_output
 
                 module.forward_origin = module.forward
                 module.forward = types.MethodType(_forward, module)
-                prompt_module = PromptModule(config.dim,
+
+                if isinstance(config.dim, list):
+                    input_dim = config.dim[len(match_module_keys)]
+                else:
+                    input_dim = config.dim
+
+                prompt_module = PromptModule(input_dim,
                                              int(module_key.rsplit('.')[-1]),
                                              config.prompt_length,
                                              config.attention_mask_value,
                                              config.attach_front)
                 setattr(module, 'prompt', prompt_module)
+                match_module_keys.append(module_key)
 
         if config.only_prompt_trainable:
             for n, p in model.named_parameters():
                 if 'prompt' not in n:
                     p.requires_grad = False
 
         def state_dict_hook(module, destination, prefix, local_metadata):
@@ -208,7 +229,13 @@
                               dim=1)
         return x
 
     def patch_attention_mask(self, m):
         prefix_attention_mask = torch.full((*m.shape[:-1], self.prompt_length),
                                            self.mask_values).to(m.device)
         return torch.cat((prefix_attention_mask, m), dim=-1)
+
+    def extract(self, x):
+        if self.attach_front:
+            return x[:, self.prompt_length:, :]
+        else:
+            return x[:, :-self.prompt_length, :]
```

### Comparing `modelscope-1.7.1/modelscope/swift/sd_lora.py` & `modelscope-1.8.0rc0/modelscope/swift/sd_lora.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/tools/eval.py` & `modelscope-1.8.0rc0/modelscope/tools/eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/tools/speech_tts_autolabel.py` & `modelscope-1.8.0rc0/modelscope/tools/speech_tts_autolabel.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/tools/train.py` & `modelscope-1.8.0rc0/modelscope/tools/train.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/ans_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/ans_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/asr_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/asr_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_farfield_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_farfield_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_nearfield_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_nearfield_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/batch_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/batch_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/det_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/det_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/file_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/model_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/model_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/kws_utils/runtime_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/kws_utils/runtime_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/separation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/separation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/audio/tts_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/audio/tts_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/base.py` & `modelscope-1.8.0rc0/modelscope/trainers/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/builder.py` & `modelscope-1.8.0rc0/modelscope/trainers/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cli_argument_parser.py` & `modelscope-1.8.0rc0/modelscope/trainers/cli_argument_parser.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/action_detection_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/action_detection_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/card_detection_scrfd_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/card_detection_scrfd_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/cartoon_translation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/cartoon_translation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/face_detection_scrfd_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/face_detection_scrfd_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_classifition_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_classifition_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_defrcn_fewshot_detection_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_detection_damoyolo_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_detection_damoyolo_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_inpainting_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_inpainting_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_instance_segmentation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_instance_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/image_portrait_enhancement_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/image_portrait_enhancement_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/movie_scene_segmentation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/movie_scene_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/nerf_recon_acc_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/nerf_recon_acc_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/ocr_detection_db_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/ocr_detection_db_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/ocr_recognition_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/ocr_recognition_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/referring_video_object_segmentation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/cv/vision_efficient_tuning_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/cv/vision_efficient_tuning_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/default_config.py` & `modelscope-1.8.0rc0/modelscope/trainers/default_config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/checkpoint_hook.py`

 * *Files 4% similar despite different names*

```diff
@@ -46,14 +46,15 @@
         push_to_hub (bool): Whether push the checkpoint to modelhub.
         hub_repo_id (str): The hub repo id.
         hub_token (str): The token of the modelhub. You can also set the environment variable `MODELSCOPE_API_TOKEN`.
         private_hub (bool): Whether push to a private hub, default True.
         hub_revision (str): Which branch to push the model to, default is `master`.
         upload_strategy (str): The action adopted when the previous uploading is not done
         and the next one is coming, can be `cancel` or `wait`.
+        save_trainer_state (bool): Save the trainer state for continue training, default True.
         kwargs:
             by_epoch (bool): Same with `save_strategy`, but has a higher priority, legacy argument.
             output_sub_dir (str): The folder under the `save_dir` to save the output checkpoint for inference.
                 This argument is kept to fit the existing configs.
     """
 
     PRIORITY = Priority.LOW
@@ -71,14 +72,15 @@
                  max_checkpoint_num: Optional[int] = None,
                  push_to_hub: Optional[bool] = False,
                  hub_repo_id: Optional[str] = None,
                  hub_token: Optional[str] = None,
                  private_hub: Optional[bool] = True,
                  hub_revision: Optional[str] = DEFAULT_REPOSITORY_REVISION,
                  upload_strategy: Optional[str] = UploadStrategy.cancel,
+                 save_trainer_state: bool = True,
                  **kwargs):
         self.interval = interval
         self.save_dir = save_dir
         if 'by_epoch' in kwargs:
             self.save_strategy = CheckpointStrategy.by_epoch if kwargs[
                 'by_epoch'] else CheckpointStrategy.by_step
         else:
@@ -93,14 +95,15 @@
         self.rng_state = None
         self.push_to_hub = push_to_hub
         self.hub_repo_id = hub_repo_id
         self.hub_token = hub_token
         self.private_hub = private_hub
         self.hub_revision = hub_revision
         self.upload_strategy = upload_strategy
+        self.save_trainer_state = save_trainer_state
         self.tag = -1
         self.is_model_id = None
         self.max_checkpoint_num = None
         if max_checkpoint_num is not None:
             self.max_checkpoint_num = max(int(max_checkpoint_num), 1)
         self.history_checkpoints = []
         self.processor = CheckpointProcessor()
@@ -215,15 +218,16 @@
 
     def _save_checkpoint(self, trainer, prefix):
         """Save checkpoint files and remove obsolete ones
         """
         checkpoint_path_prefix = os.path.join(self.save_dir, prefix)
         meta = self._create_training_state(trainer)
         self.processor.save_checkpoints(trainer, checkpoint_path_prefix,
-                                        self.output_dir, meta)
+                                        self.output_dir, meta,
+                                        self.save_trainer_state)
         self.save_evaluate_results(trainer)
         self.history_checkpoints.append(checkpoint_path_prefix)
         self._remove_obsolete_checkpoints(trainer)
         return prefix
 
     def _remove_obsolete_checkpoints(self, trainer):
         if self.max_checkpoint_num is not None and \
@@ -294,14 +298,15 @@
             at the maximum `metric_key` will be saved, If rule is "min", the checkpoint at the minimum `metric_key`
             will be saved.
         save_file_name: The manual specified saving file name.
         restore_best (bool): Whether to restore the best checkpoint after training.
         max_checkpoint_num (int): The max number of checkpoint files, default None which means never delete anything.
             If the number exceeding the limit, checkpoints with worse metric will be deleted, which is judged by the
             `rule` and `metric_key` arguments.
+        save_trainer_state (bool): Save the trainer state for continue training, default True.
 
     The `BestCkptSaverHook` class accepts `output_sub_dir` and `output_dir` argument as its super class do.
     If neither of them are passed, the default value is `{save_dir}/output_best`.
 
     This class will not accept the `interval` or `save_strategy` or `by_epoch` argument, because the saving interval
     will follow the `EvaluationHook`.
     """
@@ -312,23 +317,25 @@
     def __init__(self,
                  metric_key: str,
                  save_best: Optional[bool] = True,
                  rule: Optional[str] = 'max',
                  save_file_name: Optional[str] = None,
                  restore_best: Optional[bool] = False,
                  max_checkpoint_num: Optional[int] = 1,
+                 save_trainer_state: bool = True,
                  **kwargs):
         assert rule in ['max', 'min'], 'Only support "max" or "min" rule now.'
         output_kwargs = {}
         if 'output_sub_dir' not in kwargs and 'output_dir' not in kwargs:
             output_kwargs['output_sub_dir'] = ModelFile.TRAIN_BEST_OUTPUT_DIR
         kwargs.pop('interval', None)
         kwargs.pop('save_strategy', None)
         super().__init__(
             max_checkpoint_num=max_checkpoint_num,
+            save_trainer_state=save_trainer_state,
             **kwargs,
             **output_kwargs,
         )
         self.save_best = save_best
         self.metric_key = metric_key
         self.rule = rule
         self._best_metric = None
@@ -395,15 +402,16 @@
         else:
             checkpoint_path_prefix = os.path.join(self.save_dir,
                                                   checkpoint_path_prefix)
 
         self._best_ckpt_file = checkpoint_path_prefix
         meta = self._create_training_state(trainer)
         self.processor.save_checkpoints(trainer, checkpoint_path_prefix,
-                                        self.output_dir, meta)
+                                        self.output_dir, meta,
+                                        self.save_trainer_state)
         self.save_evaluate_results(trainer)
         self.history_checkpoints.add(checkpoint_path_prefix)
         self._remove_obsolete_checkpoints(trainer)
         return prefix
 
     def _remove_obsolete_checkpoints(self, trainer):
```

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/checkpoint_processor.py`

 * *Files 10% similar despite different names*

```diff
@@ -100,32 +100,35 @@
             default_bin_file = ModelFile.TORCH_MODEL_FILE
         return default_bin_file
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
-                         meta=None):
+                         meta=None,
+                         save_optimizers=True):
         """Save the state dict for trainer and model.
 
         This is a strategic function which can be registered by other hook's function.
 
         Args:
             trainer(`EpochBasedTrainer`): The trainer instance.
             checkpoint_path_prefix(`str`): The saving dir with a prefix.
                 like: /tmp/test/epoch_0
             output_dir(`str`): The output dir for inference.
             meta: (`dict`): The meta info needed to be saved into files.
+            save_optimizers: (`bool`): Do save the optimizers state
         """
         model = trainer.unwrap_module(trainer.model)
         _model_file, _train_state_file = self._get_state_file_name(
             checkpoint_path_prefix)
 
         # Save pth file without model state_dict
-        self.save_trainer_state(trainer, model, _train_state_file, meta)
+        self.save_trainer_state(trainer, model, _train_state_file, meta,
+                                save_optimizers)
         self.save_model_state(model, _model_file)
         self.link(model, _model_file, output_dir)
 
     def remove_checkpoints(self, trainer, checkpoint_path_prefix):
         """Remove obsolete checkpoint files.
 
         This is a strategic function which can be registered by other hook's function.
@@ -171,28 +174,30 @@
             os.link(src_file, dest_file)
         except OSError as e:
             get_logger().error(
                 f'Link {src_file} to {dest_file} error: {e}, '
                 'changing to copy the bin file, this may use more disk space.')
             shutil.copyfile(src_file, dest_file)
 
-    def save_trainer_state(self, trainer, model, train_state_file, meta):
+    def save_trainer_state(self, trainer, model, train_state_file, meta,
+                           save_optimizers):
         """Save the trainer state, including optimizer/lr_scheduler's state dict, random states etc.
 
         Args:
             trainer: The trainer instance.
             model: The model instance.
             train_state_file: The target file name for saving trainer states.
             meta: Some extra meta info.
+            save_optimizers: Save optimizers state or not.
         """
         save_checkpoint(
             model,
             train_state_file,
-            trainer.optimizer,
-            trainer.lr_scheduler,
+            trainer.optimizer if save_optimizers else None,
+            trainer.lr_scheduler if save_optimizers else None,
             meta=meta,
             with_model=False)
 
     def save_model_state(self, model, model_file):
         """Save the model state.
 
         Args:
```

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/checkpoint/load_checkpoint_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/clip_clamp_logit_scale_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/compression/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/compression/sparsity_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/sparsity_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/compression/utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/compression/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/distributed/ddp_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/ddp_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/distributed/deepspeed_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/deepspeed_hook.py`

 * *Files 1% similar despite different names*

```diff
@@ -152,15 +152,16 @@
             rank = '{:02d}'.format(mp_rank)
             return f'mp_rank_{rank}_model_states.pt'
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
-                         meta=None):
+                         meta=None,
+                         save_optimizers=True):
         model = trainer.unwrap_module(trainer.model)
         _train_state_file = checkpoint_path_prefix + self.rank_name(
         ) + CheckpointProcessor.TRAINER_STATE_SUFFIX
         # Save pth file without model state_dict
         save_checkpoint(
             model, _train_state_file, None, None, meta=meta, with_model=False)
```

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/distributed/megatron_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/distributed/megatron_hook.py`

 * *Files 6% similar despite different names*

```diff
@@ -53,24 +53,25 @@
         os.makedirs(
             os.path.join(output_dir, self._BIN_FILE_DIR), exist_ok=True)
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
-                         meta=None):
+                         meta=None,
+                         save_optimizers=True):
         model = trainer.unwrap_module(trainer.model)
         _train_state_file = checkpoint_path_prefix + self.rank_name(
         ) + CheckpointProcessor.TRAINER_STATE_SUFFIX
         # Save pth file without model state_dict
         save_checkpoint(
             model,
             _train_state_file,
-            trainer.optimizer,
-            trainer.lr_scheduler,
+            trainer.optimizer if save_optimizers else None,
+            trainer.lr_scheduler if save_optimizers else None,
             meta=meta,
             with_model=False)
 
         save_dir = os.path.dirname(checkpoint_path_prefix)
         prefix = os.path.basename(checkpoint_path_prefix)
         bin_file = self.get_bin_filename()
         prefix_bin_file = os.path.join(save_dir, prefix + '_' + bin_file)
```

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/early_stop_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/early_stop_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/evaluation_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/evaluation_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/iter_timer_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/iter_timer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/logger/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/logger/base.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/logger/tensorboard_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/tensorboard_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/logger/text_logger_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/logger/text_logger_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/lr_scheduler_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/lr_scheduler_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/optimizer/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/apex_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/optimizer/base.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/optimizer/torch_optimizer_hook.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/hooks/priority.py` & `modelscope-1.8.0rc0/modelscope/trainers/hooks/priority.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/lrscheduler/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/lrscheduler/builder.py` & `modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/base.py` & `modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/base.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/lrscheduler/warmup/warmup.py` & `modelscope-1.8.0rc0/modelscope/trainers/lrscheduler/warmup/warmup.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/clip/clip_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/clip_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/clip/clip_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -6,16 +6,14 @@
 from collections.abc import Mapping
 from pathlib import Path
 from typing import Union
 
 import torch
 import torch.nn.functional as F
 from diffusers import DiffusionPipeline
-from diffusers.loaders import AttnProcsLayers
-from diffusers.models.attention_processor import LoRAAttnProcessor
 from PIL import Image
 from PIL.ImageOps import exif_transpose
 from torch.utils.data import Dataset
 from torchvision import transforms
 from tqdm.auto import tqdm
 
 from modelscope.metainfo import Trainers
@@ -37,15 +35,16 @@
     def __init__(self, model_dir):
         self.model_dir = model_dir
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
-                         meta=None):
+                         meta=None,
+                         save_optimizers=True):
         """Save the state dict for dreambooth model.
         """
         pipeline_args = {}
         if trainer.model.text_encoder is not None:
             pipeline_args['text_encoder'] = trainer.model.text_encoder
         pipeline = DiffusionPipeline.from_pretrained(
             self.model_dir,
```

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py`

 * *Files 6% similar despite different names*

```diff
@@ -29,16 +29,20 @@
         if not isinstance(model, nn.Module) and hasattr(model, 'model'):
             return model.model
         elif isinstance(model, nn.Module):
             return model
 
     def build_optimizer(self, cfg: ConfigDict, default_args: dict = None):
         try:
-            return build_optimizer(
-                self.model.tuner, cfg=cfg, default_args=default_args)
+            if hasattr(self, 'tuner'):
+                return build_optimizer(
+                    self.model.tuner, cfg=cfg, default_args=default_args)
+            else:
+                return build_optimizer(
+                    self.model, cfg=cfg, default_args=default_args)
         except KeyError as e:
             self.logger.error(
                 f'Build optimizer error, the optimizer {cfg} is a torch native component, '
                 f'please check if your torch with version: {torch.__version__} matches the config.'
             )
             raise e
```

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py`

 * *Files 7% similar despite different names*

```diff
@@ -17,26 +17,35 @@
 
 class LoraDiffusionCheckpointProcessor(CheckpointProcessor):
 
     def save_checkpoints(self,
                          trainer,
                          checkpoint_path_prefix,
                          output_dir,
-                         meta=None):
+                         meta=None,
+                         save_optimizers=True):
         """Save the state dict for lora tune model.
         """
         trainer.model.unet = trainer.model.unet.to(torch.float32)
         trainer.model.unet.save_attn_procs(output_dir)
 
 
 @TRAINERS.register_module(module_name=Trainers.lora_diffusion)
 class LoraDiffusionTrainer(EpochBasedTrainer):
 
     def __init__(self, *args, **kwargs):
         super().__init__(*args, **kwargs)
+        """Lora trainers for fine-tuning stable diffusion
+
+        Args:
+            lora_rank: The rank size of lora intermediate linear.
+
+        """
+        lora_rank = kwargs.pop('lora_rank', 4)
+
         # set lora save checkpoint processor
         ckpt_hook = list(
             filter(lambda hook: isinstance(hook, CheckpointHook),
                    self.hooks))[0]
         ckpt_hook.set_processor(LoraDiffusionCheckpointProcessor())
         # Set correct lora layers
         lora_attn_procs = {}
@@ -54,15 +63,16 @@
             elif name.startswith('down_blocks'):
                 block_id = int(name[len('down_blocks.')])
                 hidden_size = self.model.unet.config.block_out_channels[
                     block_id]
 
             lora_attn_procs[name] = LoRAAttnProcessor(
                 hidden_size=hidden_size,
-                cross_attention_dim=cross_attention_dim)
+                cross_attention_dim=cross_attention_dim,
+                rank=lora_rank)
 
         self.model.unet.set_attn_processor(lora_attn_procs)
 
         self.lora_layers = AttnProcsLayers(self.model.unet.attn_processors)
 
     def build_optimizer(self, cfg: ConfigDict, default_args: dict = None):
         try:
```

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mgeo_ranking_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/mplug/mplug_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/mplug/mplug_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/ofa_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/ofa_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/ofa/ofa_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/team/team_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/team_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/multi_modal/team/team_trainer_utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/multi_modal/team/team_trainer_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/__init__.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/__init__.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/csanmt_translation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/csanmt_translation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_generate_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_rerank_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/document_grounded_dialog_retrieval_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/faq_question_answering_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/faq_question_answering_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/gpt3_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/gpt3_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/gpt_moe_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/gpt_moe_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/plug_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/plug_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/sentence_embedding_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/sentence_embedding_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/sequence_classification_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/sequence_classification_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/siamese_uie_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/siamese_uie_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/dialog_intent_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/dialog_intent_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/dialog_modeling_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/dialog_modeling_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/eval.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/eval.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/metrics/metrics_tracker.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/metrics/metrics_tracker.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/gen_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/gen_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/space/trainer/intent_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/space/trainer/intent_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/table_question_answering_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/table_question_answering_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/text_generation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/text_generation_trainer.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,31 +1,38 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 
-from collections.abc import Mapping
+from typing import Any, Dict
 
 import torch
 
-from modelscope.metainfo import Trainers
+from modelscope.metainfo import Metrics, Trainers
+from modelscope.outputs.outputs import ModelOutputBase
 from modelscope.trainers import NlpEpochBasedTrainer
 from modelscope.trainers.builder import TRAINERS
-from modelscope.utils.file_utils import func_receive_dict_inputs
 
 
 @TRAINERS.register_module(module_name=Trainers.text_generation_trainer)
 class TextGenerationTrainer(NlpEpochBasedTrainer):
 
     def _decode(self, tokens):
         return self.eval_preprocessor.decode(
             tokens.tolist(), skip_special_tokens=True)
 
     def evaluation_step(self, data):
         model = self.model.module if self._dist else self.model
         model.eval()
+        output = dict()
 
         with torch.no_grad():
-            result = model.generate(data)
-
+            output.update(self._eval_genarate(model, data))
+            if Metrics.PPL in self.metrics or Metrics.loss_metric in self.metrics:
+                output.update(model.forward(**data))
+        return output
+
+    def _eval_genarate(self, model, data) -> Dict[str, Any]:
+        result = model.generate(data)
+        if isinstance(result, ModelOutputBase):
+            result = result.to_dict()
         result['preds'] = [self._decode(seq) for seq in result['sequences']]
         data['tgts'] = [self._decode(seq) for seq in data['labels']]
         assert len(result['preds']) == len(data['tgts'])
-
         return result
```

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/text_ranking_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/text_ranking_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp/translation_evaluation_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp/translation_evaluation_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/nlp_trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/nlp_trainer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/optimizer/builder.py` & `modelscope-1.8.0rc0/modelscope/trainers/optimizer/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/parallel/builder.py` & `modelscope-1.8.0rc0/modelscope/trainers/parallel/builder.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/parallel/utils.py` & `modelscope-1.8.0rc0/modelscope/trainers/parallel/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/trainer.py` & `modelscope-1.8.0rc0/modelscope/trainers/trainer.py`

 * *Files 1% similar despite different names*

```diff
@@ -11,44 +11,46 @@
 import torch
 from torch import distributed as dist
 from torch import nn
 from torch.utils.data import DataLoader, Dataset, Sampler
 from torch.utils.data.dataloader import default_collate
 from torch.utils.data.distributed import DistributedSampler
 
+from modelscope.hub.check_model import check_local_model_is_latest
 from modelscope.metainfo import Trainers
 from modelscope.metrics import build_metric, task_default_metrics
 from modelscope.metrics.prediction_saving_wrapper import \
     PredictionSavingWrapper
 from modelscope.models.base import Model, TorchModel
 from modelscope.msdatasets.dataset_cls.custom_datasets import \
     TorchCustomDataset
 from modelscope.msdatasets.dataset_cls.custom_datasets.builder import \
     build_custom_dataset
 from modelscope.msdatasets.ms_dataset import MsDataset
 from modelscope.outputs import ModelOutputBase
 from modelscope.preprocessors.base import Preprocessor
+from modelscope.swift import Swift
 from modelscope.trainers.hooks.builder import HOOKS
 from modelscope.trainers.hooks.priority import Priority, get_priority
 from modelscope.trainers.lrscheduler.builder import build_lr_scheduler
 from modelscope.trainers.optimizer.builder import build_optimizer
 from modelscope.utils.config import Config, ConfigDict, JSONIteratorEncoder
 from modelscope.utils.constant import (DEFAULT_MODEL_REVISION, ConfigFields,
                                        ConfigKeys, DistributedParallelType,
-                                       ModeKeys, ModelFile, ThirdParty,
+                                       Invoke, ModeKeys, ModelFile, ThirdParty,
                                        TrainerStages)
 from modelscope.utils.data_utils import to_device
 from modelscope.utils.device import create_device
 from modelscope.utils.file_utils import func_receive_dict_inputs
 from modelscope.utils.logger import get_logger
 from modelscope.utils.registry import build_from_cfg
 from modelscope.utils.torch_utils import (compile_model, get_dist_info,
                                           get_local_rank, init_dist, is_dist,
-                                          is_master, set_random_seed)
-from ..swift import Swift
+                                          is_master, is_on_same_device,
+                                          set_random_seed)
 from .base import BaseTrainer
 from .builder import TRAINERS
 from .default_config import merge_cfg, merge_hooks, update_cfg
 from .hooks.hook import Hook
 from .parallel.builder import build_parallel
 from .parallel.utils import is_parallel
 
@@ -147,14 +149,18 @@
                 cfg_file = os.path.join(self.model_dir,
                                         ModelFile.CONFIGURATION)
             self.input_model_id = model
         else:
             assert cfg_file is not None, 'Config file should not be None if model is not from pretrained!'
             self.model_dir = os.path.dirname(cfg_file)
             self.input_model_id = None
+            if hasattr(model, 'model_dir'):
+                check_local_model_is_latest(
+                    model.model_dir,
+                    user_agent={Invoke.KEY: Invoke.LOCAL_TRAINER})
 
         super().__init__(cfg_file, arg_parse_fn)
         self.cfg_modify_fn = cfg_modify_fn
         # add default config
         merge_cfg(self.cfg)
         self.cfg = self.rebuild_config(self.cfg)
         if 'cfg_options' in kwargs:
@@ -253,15 +259,15 @@
 
         self.metrics = self.get_metrics()
 
         if not self.parallel_groups:
             # If not working in parallel scenario, put model to device as a default logic.
             device_name = self.device if self.device is not None else 'gpu'
             self.device = create_device(device_name)
-            if self.device.type == 'cuda':
+            if self.device.type == 'cuda' and is_on_same_device(self.model):
                 self.model.to(self.device)
 
         self.print_cfg()
 
     def tune_module(self, efficient_tuners):
         if efficient_tuners is not None:
             for tuner in efficient_tuners:
```

### Comparing `modelscope-1.7.1/modelscope/trainers/training_args.py` & `modelscope-1.8.0rc0/modelscope/trainers/training_args.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/utils/inference.py` & `modelscope-1.8.0rc0/modelscope/trainers/utils/inference.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/trainers/utils/log_buffer.py` & `modelscope-1.8.0rc0/modelscope/trainers/utils/log_buffer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/ast_index_file.py` & `modelscope-1.8.0rc0/modelscope/utils/ast_index_file.py`

 * *Files 8% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.7622113562228957%*

 * *Differences: {"'files_mtime'": "{'TEMPLATE_PATH/models/audio/aec/network/modulation_loss.py': "*

 * *                  "1690807232.3182962, 'TEMPLATE_PATH/models/audio/aec/network/loss.py': "*

 * *                  "1690807232.3182962, 'TEMPLATE_PATH/models/audio/aec/network/se_net.py': "*

 * *                  "1690807232.3182962, 'TEMPLATE_PATH/models/audio/aec/layers/deep_fsmn.py': "*

 * *                  '1690807232.3182962, '*

 * *                  "'TEMPLATE_PATH/models/audio/aec/layers/affine_transform.py': "*

 * *                  "16908072 []*

```diff
@@ -1,1696 +1,1751 @@
 {
     "files_mtime": {
-        "TEMPLATE_PATH/exporters/audio/ans_dfsmn_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/base.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/builder.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/multi_modal/stable_diffusion_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/tf_model_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/exporters/torch_model_exporter.py": 1688487705.50829,
-        "TEMPLATE_PATH/metrics/accuracy_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/action_detection_evaluator.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/audio_noise_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/base.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/bleu_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/builder.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/ciderD/ciderD.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/ciderD/ciderD_scorer.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_color_enhance_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_colorization_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_denoise_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_inpainting_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/inbatch_recall_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/loss_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/map_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/movie_scene_segmentation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/ned_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/ocr_recognition_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/ppl_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/sequence_classification_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/text_generation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/text_ranking_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/token_classification_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/translation_evaluation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_stabilization_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_summarization_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/matlab_functions.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/metric_util.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/niqe.py": 1688487705.51229,
-        "TEMPLATE_PATH/metrics/video_super_resolution_metric/video_super_resolution_metric.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/layers/activations.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/layers/affine_transform.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/layers/deep_fsmn.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/layers/layer_base.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/layers/uni_deep_fsmn.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/network/loss.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/network/modulation_loss.py": 1688487705.51229,
-        "TEMPLATE_PATH/models/audio/aec/network/se_net.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/complex_nn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/conv_stft.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/denoise_net.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/frcrn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/layers/activations.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/layers/affine_transform.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/layers/layer_base.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/layers/uni_deep_fsmn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/se_module_complex.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/ans/unet.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v2.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v3.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/farfield/model.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/farfield/model_def.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/cmvn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/fsmn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/kws/nearfield/model.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/separation/layer_norm.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/separation/mossformer.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/separation/mossformer_block.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/separation/mossformer_conv_module.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/DTDNN.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/DTDNN_layers.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/ERes2Net.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/ERes2Net_aug.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/cluster_backend.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/fusion.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/pooling_layers.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/rdino.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/audio/tts/voice.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/base/base_head.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/base/base_model.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/base/base_torch_head.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/base/base_torch_model.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/builder.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/action_detection/action_detection_onnx.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/action_detection/modules/action_detection_pytorch.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/action_detection/modules/resnet.py": 1688487705.5162902,
-        "TEMPLATE_PATH/models/cv/action_recognition/models.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/action_recognition/s3dg.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/action_recognition/tada_convnext.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/action_recognition/temporal_patch_shift_transformer.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/animal_recognition/resnet.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/animal_recognition/splat.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_basic_modules.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_2d_keypoints/w48.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/backbone.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/block.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/directed_graph.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/skeleton.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/LK/lk.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/config.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_detector.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_landmark.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/facelib/facer.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/loss.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/model_tf.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/network.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cartoon/utils.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/c3d.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet2p1d.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet3d.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/annotator.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/api.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/vit.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/utils.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/utils.py": 1688487705.5202904,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/body.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/hand.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/model.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/util.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/crowd_counting/hrnet_aspp_relu.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogface.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogprednet.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/resnet.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/utils.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/box_utils.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/first_stage.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/get_nets.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/LK/lk.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_detector.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_landmark.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/facer.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/net.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/retinaface.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/retinaface/utils.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/box_utils.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py": 1688487705.5242903,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/transforms.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/efficient/model.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/efficient/utils.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/emotion_infer.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face_align.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_generation/op/conv2d_gradfix.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_generation/op/fused_act.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_generation/op/upfirdn2d.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_generation/stylegan2.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/ghost_pan.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/nanodet_plus_head.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/one_stage_detector.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/shufflenetv2.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_human_hand_detection/utils.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/align_face.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/common.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_irse.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_resnet.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/bfm.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/de_retouching_module.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/losses.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/networks.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/nv_diffrast.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/opt.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/networks.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/renderer.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/models/unet.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/face_reconstruction/utils.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/transforms.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/vgg.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py": 1688487705.5282905,
-        "TEMPLATE_PATH/models/cv/hand_static/hand_model.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/hand_static/networks.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Embedding.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/PixToMesh.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Res_backbone.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Surface_head.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/detectors.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/geometry.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/human_segmenter.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/models/networks.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/human_reconstruction/utils.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/bnext.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/model.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/person_info.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/body.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/model.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/util.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_body_reshaping/slim_utils.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_classification/utils.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/csrnet.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpfnet.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/loss.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/convnext.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/position_encoding.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/transformer_utils.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/unet.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/vgg.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/unet/unet.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_colorization/unet/utils.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/evaluator.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/calibration_layer.py": 1688487705.5322907,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/defrcn.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/fast_rcnn.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/gdl.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/resnet.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/roi_heads.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/coco_register.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/register_data.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/requirements_check.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/voc_register.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/NAFNet_arch.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/arch_util.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_depth.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_layers.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_utils.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/swin_transformer.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/uper_crf_head.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/bts_model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/decoder.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/encoder.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/utils.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_driving_perception/utils.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/gan_wrap.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/fused_act.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/upfirdn2d.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/align_trans.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/matlab_cp2tform.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aad_layer.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aei_flow_net.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/bfm.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/dense_motion.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/facerecon_model.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/model_irse.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_face_fusion/network/ops.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/backbone/deeplab_resnet.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_decoder.py": 1688487705.5362906,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_encoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_human_parsing/parsing_utils.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/base.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/default.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/base.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/resnet.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/adversarial.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/feature_matching.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ffc.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/inception.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/perceptual.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/modules/pix2pixhd.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_inpainting/refinement.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/resnet.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/swin_transformer.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/datasets/transforms.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/dino_decoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/position_encoding.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/utils.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_swin.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_instance_segmentation/postprocess_utils.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/config/default.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_matching/utils/misc.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/cas_mvsnet.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/depth_filter.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/general_eval_dataset.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/module.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/utils.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py": 1688487705.5402908,
-        "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/align_faces.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/fqa.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/model_resnet.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/gpen.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/helpers.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/losses.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/model_irse.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/detection.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/net.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/utils.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_probing_model/backbone.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_probing_model/model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_probing_model/utils.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/degradation_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/maniqa.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/swin.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/backbones/resnet.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/heads/simple_head.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_reid_person/transreid_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_restoration/demoire_models/nets.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/utils.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py": 1688487705.544291,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/BlockModules.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_backnone.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/unet.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_skychange/skychange.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/data/transforms.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/model.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/autoencoder.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/clip.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/diffusion.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/losses.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/data/transforms.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/model_translation.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/autoencoder.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/clip.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/apps.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/degradation.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/diffusion.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/losses.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/metrics.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_color.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_mask.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/svd.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/utils.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/fourier.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/panostretch.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/post_proc.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/modality/layout.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/panovit.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/utils.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/layers.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/models.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/modules.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/sub_layers.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/model.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/cfg_sampler.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/gaussian_diffusion.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/mdm.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/respace.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/rotation2xyz.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/motion_generation/modules/smpl.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/get_model.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/head.py": 1688487705.548291,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/save_op.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/shot_encoder.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/trn.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/read_write_model.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/nerf.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/segmenter.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/utils.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/checkpoint.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/result_vis.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/ocr_detection/model.py": 1688487705.5522912,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/dbnet.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/layers.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/mix_ops.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/proxyless.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/modules/seg_detector_loss.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_detection/utils.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/CRNN/main_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/equi.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/layers.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/mobilenet.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/resnet.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/unifuse.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/util.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/common.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_detection.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_embedding.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/product_segmentation/net.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/backbone.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/criterion.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/matcher.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/misc.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/mttr.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/postprocessing.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/segmentation.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/swin_transformer.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/robust_image_classification/easyrobust_model.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/backbone/Res2Net_v1b.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/modules.py": 1688487705.556291,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/senet.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/u2net.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/salient_detection/models/utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/common.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/head_fpn.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/models.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/neck_fpn.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_base.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/shop_segmentation/utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_module.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_unet_in.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/gconv.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/inpainting_unet.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/box_utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/net.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/network.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/predict_single.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/prior_box.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/unet_deploy.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/skin_retouching/weights_init.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/data/data_augment.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/base_exp.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/build.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/default/streamyolo.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/exp/yolox_base.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/darknet.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/dfp_pafpn.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/network_blocks.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/streamyolo.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/models/tal_head.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/utils/boxes.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/stream_yolo/utils/format.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/super_resolution/arch_util.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/super_resolution/ecb.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/super_resolution/rrdbnet_arch.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/table_recognition/lineless_table_process.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_detector.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_processor.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/clip.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_base.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_blocks.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_net.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_vit.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/model.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/text_driven_segmentation/simple_tokenizer.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/basic_blocks.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/global_utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/master_net.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/model_zoo.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/plain_net_utils.py": 1688487705.5602913,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_blocks.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_idwexkx.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_k1kxk1.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_kxkx.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_evaluater.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_inference.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/base_ops.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ops.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/weight_init.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/detectors/detector.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/bounding_box.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/boxlist_ops.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/image_list.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/boxes.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/model_utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/scheduler.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/detector.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_detector.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/tinynas_detection/utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/deinterlace_arch.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/archs.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/deep_fourier_upsampling.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/enh.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/fre.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_deinterlace/models/utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/configs/default_config.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera_utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose_utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_checkpoint.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_utils.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_wrapper.py": 1688487705.5642915,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sfm_model_mf.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sup_model_mf.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/layers.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/extractor.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/update.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/augmentations.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/config.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/depth.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/horovod.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image_gt.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/load.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/misc.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/types.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_arch.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/corr.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/extractor.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/raft.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/update.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/UNet.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/flow_reversal.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/transformer_layers.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/scene_change_detection.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/utils.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/model.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/decoder.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/deep_guided_filter.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/effv2.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/lraspp.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_human_matting/models/matting.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py": 1688487705.5682914,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/utils.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/common.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/decode.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/model.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/yolo.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/basetrack.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/matching.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/multitracker.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/image.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/kalman_filter.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/utils.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/visualization.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/aggregate.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/cbam.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/eval_network.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_core.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_memory_bank.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/mod_resnet.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/modules.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_object_segmentation/network.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_head.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_updator.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/mask.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/track_heads.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/neck/fpn.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/visualizer.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/config/ostrack.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn_blocks.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/head.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/patch_embed.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/ostrack.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/utils.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/procontext.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/utils.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/vit_ce.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/ostrack.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/procontext.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_single_object_tracking/utils/utils.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/DUT_raft.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/MotionPro.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/corr.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/extractor.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/raft.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/update.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/Smoother.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/config.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_module.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_so.py": 1688487705.5722916,
-        "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/IterativeSmooth.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/MedianFilter.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/ProjectionUtils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/RAFTUtils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/WarpUtils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/image_utils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_stabilization/utils/math_utils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_summarization/base_model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_auto.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_nonlin.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_summarization/pgl_sum.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/basicvsr_net.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/common.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_net.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vidt/backbone.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vidt/deformable_transformer.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vidt/fpn_fusion.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vidt/head.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vidt/model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/virual_tryon/sdafnet.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/backbone.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/head.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/petl.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_helpers.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_vision_transformer.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_weight_init.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/vision_efficient_tuning.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_middleware/backbone.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_middleware/head.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_middleware/model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vision_middleware/vim.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/backbone.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/basic_utils.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/model.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/model_se.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/cv/vop_retrieval/tokenization_clip.py": 1688487705.5762918,
-        "TEMPLATE_PATH/models/multi_modal/clip/bert_tokenizer.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/clip/configuration_bert.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/clip/model.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/clip/modeling_bert.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/diffusion.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/model.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/structbert.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/tokenizer.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_generator.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_1024.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_256.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/dpm_solver_pytorch.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_base.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/gemm/tokenizer.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/gaussian_diffusion.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/respace.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/script.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/unet.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/text_classification.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/text_ranking.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mgeo/token_classification.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mmr/dataloaders/rawvideo_util.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/dynamic_inverted_softmax.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/modeling.py": 1688487705.5802917,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_clip.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_cross.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/tokenization_clip.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mmr/models/until_module.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug/clip/clip.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug/configuration_mplug.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug/modeling_mplug.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug/mvit.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug/predictor.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug_owl/configuration_mplug_owl.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/clip.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/decoder.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/prior.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/tokenizer.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/upsampler.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/xglm.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_mmspeech.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_ofa.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/incremental_decoding_utils.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/multihead_attention.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/ngram_repeat_block.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/search.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/sequence_generator.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/token_generation_constraints.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/generate/utils.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_mmspeech.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_ofa.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/resnet.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa.py": 1688487705.584292,
-        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa_fast.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/ofa/utils/constant.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/ofa/utils/utils.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/ofa/vit.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/rleg/model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/blocks.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/clip.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/swin_transformer.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/tokenizer.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/soonet/utils.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/stable_diffusion/stable_diffusion.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/team/team_model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/team/utils.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/autoencoder.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/diffusion.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/video_synthesis/unet_sd.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/conv_fpn_trans.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/convnext.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/model.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/modeling_layout_roberta.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/processing.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/tokenization.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/multi_modal/vldoc/transformer_local.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/T5/backbone.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/T5/configuration.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/backbone.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/configuration.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/fill_mask.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/text_classification.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/text_ranking.py": 1688487705.5882921,
-        "TEMPLATE_PATH/models/nlp/bert/token_classification.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/bert/word_alignment.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/bloom/backbone.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/canmt/canmt_model.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/canmt/sequence_generator.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm/configuration.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm/quantization.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm/text_generation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm/tokenization.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm2/configuration.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm2/quantization.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm2/text_generation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/chatglm2/tokenization.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/codegeex/inference.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/codegeex/tokenizer.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/csanmt/translation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/configuration.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization_fast.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/dgds/backbone.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py": 1688487705.592292,
-        "TEMPLATE_PATH/models/nlp/fid_plug/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/fid_plug/configuration.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/glm_130b/generation/strategies.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/glm_130b/initialize.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/functional.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/layers.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt2/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt3/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt3/configuration.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt3/distributed_gpt3.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt3/tokenizer.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/checkpointing.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/configuration.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/distributed_gpt_moe.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/experts.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/layer.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/mappings.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/sharded_moe.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/utils.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_moe/tokenizer.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/gpt_neo/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/crf_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/configuration.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/convert_llama_weights_to_hf.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/text_generation.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/tokenization.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/llama/tokenization_fast.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/lstm/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/lstm/token_classification.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/configuration.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/megatron_bert/fill_mask.py": 1688487705.5962923,
-        "TEMPLATE_PATH/models/nlp/mglm/arguments.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/blocklm_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/configure_data.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/corpora.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/datasets.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/extraction.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/file_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/lazy_loader.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/samplers.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/sp_tokenizer.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization_gpt2.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/data_utils/wordpiece.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/generation_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/distributed.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/downstream.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_bert.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_glm.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/prompt.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/model/transformer.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/process_grid.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/run_test.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/data_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/eval_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/dataset.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/detokenizer.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/finetune.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/dataset.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/evaluate.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/finetune.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/dataset.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/evaluate.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/finetune.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/pvp.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/test/test_block.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/test/test_rel_shift.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/train_utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/mglm/utils.py": 1688487705.6002924,
-        "TEMPLATE_PATH/models/nlp/palm_v2/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/palm_v2/dureader_eval.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/peer/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/peer/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/peer/sas_utils.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/peer/text_classification.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug/AnnealingLR.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug/distributed_plug.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug/generator.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug_mental/adv_utils.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug_mental/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/ponet/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/ponet/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/ponet/fill_mask.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/ponet/tokenization.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/gen_unified_transformer.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/generator.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/intent_unified_transformer.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/model_base.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/tokenization_space.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/model/unified_transformer.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/modules/embedder.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/modules/feedforward.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/modules/functions.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/modules/multihead_attention.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space/modules/transformer_block.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/adv_utils.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/backbone.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/configuration.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/fill_mask.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/text_classification.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/structbert/token_classification.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py": 1688487705.6042924,
-        "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/task_model.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/text_classification.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/text_generation.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/text_ranking.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/task_models/token_classification.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/unite/configuration.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/use/transformer.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/veco/backbone.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/veco/configuration.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/veco/fill_mask.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/veco/text_classification.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/veco/token_classification.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/nlp/xlm_roberta/configuration.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/config.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/data_ops.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/msa_pairing.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/process.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/process_multimer.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/protein.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/residue_constants.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/data/utils.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/dataset.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/model.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/alphafold.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/attentions.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/auxillary_heads.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/common.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/confidence.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/embedders.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/evoformer.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/featurization.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/frame.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/structure_module.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/template.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/modules/triangle_multiplication.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/msa/mmcif.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/msa/msa_identifiers.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/msa/parsers.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/msa/pipeline.py": 1688487705.6082926,
-        "TEMPLATE_PATH/models/science/unifold/msa/templates.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhblits.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhsearch.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmbuild.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmsearch.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/jackhmmer.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/kalign.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/tools/utils.py": 1688487705.6122928,
-        "TEMPLATE_PATH/models/science/unifold/msa/utils.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/audio/asr_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/auth/auth_config.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/context/dataset_context_config.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/data_files/data_files_manager.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/data_loader/data_loader.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/data_loader/data_loader_manager.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/builder.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/easycv_base.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py": 1688487705.6122928,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/dataset_cls/dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/download/dataset_builder.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/download/download_config.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/download/download_manager.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/meta/data_meta_config.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/meta/data_meta_manager.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/ms_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/task_datasets/gopro_image_deblurring_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/task_datasets/reds_image_deblurring_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/task_datasets/sidd_image_denoising.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/task_datasets/torch_base_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/task_datasets/video_summarization_dataset.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/utils/dataset_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/utils/delete_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/utils/maxcompute_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/utils/oss_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/msdatasets/utils/upload_utils.py": 1688487705.6162927,
-        "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py": 1688487705.6162927,
-        "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py": 1688487705.6162927,
-        "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py": 1688487705.6162927,
-        "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/segmentation_clustering_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/base.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/builder.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_human_hand_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_processing_base_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/hand_static_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py": 1688487705.620293,
-        "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_panoptic_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/nerf_recon_acc_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_convnext_transformer.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_dla34.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet18_half.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_vlpt.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/convnext.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/vitstr.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ops.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet18_v1.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet_utils.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/table_process.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ocr_utils/utils.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/shop_segmentation_pipleline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/tbs_detection_utils/utils.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/text_driven_segmentation_pipleline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py": 1688487705.624293,
-        "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/image_captioning_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_translation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_modeling_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/dialog_state_tracking_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/sentence_embedding_pipeline.py": 1688487705.628293,
-        "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/text_ranking_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/user_satisfaction_estimation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/pipeline_template.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py": 1688487705.6322932,
-        "TEMPLATE_PATH/pipelines/util.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/asr.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/audio.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/base.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/builder.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/common.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/action_detection_mapper.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/cv2_transforms.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/timer.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/util.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/video_stabilization.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/cv/video_super_resolution.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/image.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/kws.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/movie_scene_segmentation/transforms.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/multi_modal.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/canmt_translation.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/relation_extraction_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/sentence_embedding_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/args.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/batch.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/data_loader.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py": 1688487705.6322932,
-        "TEMPLATE_PATH/preprocessors/nlp/space/dst_processors.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/fields/gen_field.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/fields/intent_field.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/lazy_dataset.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/preprocess.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/sampler.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/tensorlistdataset.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space/tokenizer.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/database.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/schema_link.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/struct.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/common_utils.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/parse.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/process_dataset.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/text_clean.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/transformers_tokenizer.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/utils.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/asr.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/base.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/image_captioning.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/image_classification.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/ocr_recognition.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/sudoku.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/summarization.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/text2sql.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/text_classification.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/text_to_image_synthesis.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/audio_helper.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/bridge_content_encoder.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/collate.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/constant.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/get_tables.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/random_help.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/text2phone.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/transforms.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/utils/vision_helper.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_entailment.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_grounding.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/ofa/visual_question_answering.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/science/uni_fold.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/tts.py": 1688487705.6362934,
-        "TEMPLATE_PATH/preprocessors/video.py": 1688487705.6362934,
-        "TEMPLATE_PATH/trainers/audio/ans_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/asr_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/batch_utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/det_utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/file_utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/model_utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/kws_utils/runtime_utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/separation_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/audio/tts_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/base.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/builder.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cli_argument_parser.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/default_config.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/builder.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_processor.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/compression/sparsity_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/compression/utils.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/distributed/ddp_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/evaluation_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/iter_timer_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/logger/base.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py": 1688487705.6402934,
-        "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/base.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/hooks/priority.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/lrscheduler/builder.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/lrscheduler/warmup/base.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/lrscheduler/warmup/warmup.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer_utils.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer_utils.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer_utils.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/plug_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/eval.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/metrics/metrics_tracker.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/trainer/gen_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/space/trainer/intent_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/nlp_trainer.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/optimizer/builder.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/parallel/builder.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/parallel/utils.py": 1688487705.6442935,
-        "TEMPLATE_PATH/trainers/trainer.py": 1688487705.6482937,
-        "TEMPLATE_PATH/trainers/training_args.py": 1688487705.6482937,
-        "TEMPLATE_PATH/trainers/utils/inference.py": 1688487705.6482937,
-        "TEMPLATE_PATH/trainers/utils/log_buffer.py": 1688487705.6482937
+        "TEMPLATE_PATH/exporters/audio/ans_dfsmn_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/base.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/builder.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/multi_modal/stable_diffusion_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/tf_model_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/exporters/torch_model_exporter.py": 1690807232.3142962,
+        "TEMPLATE_PATH/metrics/accuracy_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/action_detection_evaluator.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/audio_noise_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/base.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/bleu_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/builder.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/ciderD/ciderD.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/ciderD/ciderD_scorer.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_color_enhance_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_colorization_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_denoise_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_inpainting_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/inbatch_recall_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/loss_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/map_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/movie_scene_segmentation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/ned_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/ocr_recognition_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/ppl_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/sequence_classification_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/text_generation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/text_ranking_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/token_classification_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/translation_evaluation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_stabilization_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_summarization_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/matlab_functions.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/metric_util.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/niqe.py": 1690807232.3182962,
+        "TEMPLATE_PATH/metrics/video_super_resolution_metric/video_super_resolution_metric.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/layers/activations.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/layers/affine_transform.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/layers/deep_fsmn.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/layers/layer_base.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/layers/uni_deep_fsmn.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/network/loss.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/network/modulation_loss.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/aec/network/se_net.py": 1690807232.3182962,
+        "TEMPLATE_PATH/models/audio/ans/complex_nn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/conv_stft.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/denoise_net.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/frcrn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/layers/activations.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/layers/affine_transform.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/layers/layer_base.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/layers/uni_deep_fsmn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/se_module_complex.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/ans/unet.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v2.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/farfield/fsmn_sele_v3.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/farfield/model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/farfield/model_def.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/cmvn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/fsmn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/kws/nearfield/model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/separation/layer_norm.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/separation/mossformer.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/separation/mossformer_block.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/separation/mossformer_conv_module.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/DTDNN.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/DTDNN_layers.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/ERes2Net.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/ERes2Net_aug.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/cluster_backend.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/fusion.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/lanuage_recognition_model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/pooling_layers.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/rdino.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/speaker_diarization_dialogue_detection.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/audio/tts/voice.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/base/base_head.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/base/base_model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/base/base_torch_head.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/base/base_torch_model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/builder.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/action_detection/action_detection_onnx.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/action_detection/modules/action_detection_pytorch.py": 1690807232.3222961,
+        "TEMPLATE_PATH/models/cv/action_detection/modules/resnet.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/action_recognition/models.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/action_recognition/s3dg.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/action_recognition/tada_convnext.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/action_recognition/temporal_patch_shift_transformer.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/animal_recognition/resnet.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/animal_recognition/splat.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_basic_modules.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_2d_keypoints/w48.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/canonical_pose_modules.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/backbone.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/block.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/directed_graph.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/skeleton.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/LK/lk.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/config.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_detector.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/face_landmark.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/facelib/facer.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/loss.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/model_tf.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/align_trans.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/mtcnn_pytorch/src/matlab_cp2tform.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/network.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cartoon/utils.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/c3d.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet2p1d.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/cmdssl_video_embedding/resnet3d.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/annotator.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/api.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/base_model.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/blocks.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/dpt_depth.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/midas_net_custom.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/transforms.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/midas/vit.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/midas/utils.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/mbv2_mlsd_large.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/mlsd/utils.py": 1690807232.3262963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/body.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/hand.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/model.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/annotator/openpose/util.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/crowd_counting/hrnet_aspp_relu.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogface.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/mogprednet.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/resnet.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mogface/models/utils.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/box_utils.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/first_stage.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/get_nets.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/LK/lk.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_detector.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/face_landmark.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/peppa_pig_face/facer.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/net.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/models/retinaface.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/retinaface/utils.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/bbox/transforms.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/core/post_processing/bbox_nms.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/base.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py": 1690807232.3302963,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/box_utils.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/mb_tiny.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/data_preprocessing.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/fd_config.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/mb_tiny_fd.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/predictor.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/ssd/ssd.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/vision/transforms.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/efficient/model.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/efficient/utils.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/emotion_infer.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_emotion/face_alignment/face_align.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_generation/op/conv2d_gradfix.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_generation/op/fused_act.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_generation/op/upfirdn2d.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_generation/stylegan2.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/ghost_pan.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/nanodet_plus_head.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/one_stage_detector.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/shufflenetv2.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_human_hand_detection/utils.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/align_face.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/arcface_backbone.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/common.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/facemask_backbone.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_irse.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/backbone/model_resnet.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/bfm.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/de_retouching_module.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/large_base_lmks_infer.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_base_lmks_net.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facelandmark/nets/large_eyeball_net.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/losses.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/networks.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/nv_diffrast.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/opt.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/networks.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_model.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/pix2pix/pix2pix_options.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/renderer.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/models/unet.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/face_reconstruction/utils.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/transforms.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/vgg.py": 1690807232.3342962,
+        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/manual_landmark_net.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/hand_static/hand_model.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/hand_static/networks.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Embedding.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/PixToMesh.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Res_backbone.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/Surface_head.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/detectors.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/geometry.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/human_segmenter.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/models/networks.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/human_reconstruction/utils.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_binary_quant_classification/bnext.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/model.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/person_info.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/body.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/model.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/pose_estimator/util.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_body_reshaping/slim_utils.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_classification/utils.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/csrnet.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpfnet.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/loss.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/convnext.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/position_encoding.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/transformer_utils.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/unet.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/utils/vgg.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/unet/unet.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_colorization/unet/utils.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py": 1690807232.3382962,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/coco_evaluation.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/evaluator.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/evaluation/pascal_voc_evaluation.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/calibration_layer.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/defrcn.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/fast_rcnn.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/gdl.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/resnet.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/models/roi_heads.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/coco_register.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/configuration_mapper.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/model_surgery_op.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/register_data.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/requirements_check.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/utils/voc_register.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/NAFNet_arch.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet/arch_util.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_depth.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_layers.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/newcrf_utils.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/swin_transformer.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/networks/uper_crf_head.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/bts_model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/decoder.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/encoder.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/networks/utils.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_driving_perception/utils.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/gan_wrap.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/conv2d_gradfix.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/fused_act.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facegan/op/upfirdn2d.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/align_trans.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/facelib/matlab_cp2tform.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aad_layer.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/aei_flow_net.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/bfm.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/dense_motion.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/facerecon_model.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/model_irse.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_face_fusion/network/ops.py": 1690807232.3422961,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/backbone/deeplab_resnet.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_decoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp/m2fp_encoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_human_parsing/parsing_utils.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/base.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/default.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/model.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/base.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ade20k/resnet.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/adversarial.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/feature_matching.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/ffc.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/inception.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/perceptual.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/modules/pix2pixhd.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_inpainting/refinement.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/resnet.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/backbones/swin_transformer.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/cascade_mask_rcnn_swin.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/datasets/transforms.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_decoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst/fastinst_encoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/dino_decoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_decoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/maskdino_encoder.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/ms_deform_attn.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/position_encoding.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino/utils.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_swin.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_instance_segmentation/postprocess_utils.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/config/default.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/backbone/resnet_fpn.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/fine_preprocess.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/linear_attention.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/quadtree_attention.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/loftr_module/transformer.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/coarse_matching.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/fine_matching.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/loftr_quadtree/utils/position_encoding.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_matching/utils/misc.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/cas_mvsnet.py": 1690807232.3462963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/colmap2mvsnet.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/depth_filter.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/general_eval_dataset.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/module.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/utils.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/align_faces.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/fqa.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/eqface/model_resnet.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/gpen.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/helpers.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/losses.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/losses/model_irse.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/detection.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/net.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/models/retinaface.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_portrait_enhancement/retinaface/utils.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_probing_model/backbone.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_probing_model/model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_probing_model/utils.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/degradation_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/maniqa.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_man/swin.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/backbones/resnet.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/censeo_ivqa_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/heads/simple_head.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_reid_person/transreid_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_restoration/demoire_models/nets.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/data_util.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/feature_extractors.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/pixel_classifier.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_seg/utils.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/base_panoptic_fusion_head.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/adapter_modules.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py": 1690807232.3502963,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/base_decode_head.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/base_segmentor.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/builder.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/seg_func.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/BlockModules.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_backnone.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/hrnet_super_and_ocr.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/ptsemseg/unet.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/skychange.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/data/transforms.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/model.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/autoencoder.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/models/clip.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/diffusion.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_generation/ops/losses.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/data/transforms.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/model_translation.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/autoencoder.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/models/clip.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/apps.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/degradation.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/diffusion.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/losses.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/metrics.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_color.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/random_mask.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/svd.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_to_image_translation/ops/utils.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_try_on/generator.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_try_on/landmark.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_try_on/try_on_infer.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/image_try_on/warping.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/backbone/vit_horizon_pry_image.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/fourier.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/panostretch.py": 1690807232.3542962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/misc/post_proc.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/modality/layout.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/panovit.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/networks/utils.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/layers.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/models.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/modules.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/language_guided_video_summarization/transformer/sub_layers.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/model.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/cfg_sampler.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/gaussian_diffusion.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/mdm.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/respace.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/rotation2xyz.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/motion_generation/modules/smpl.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/get_model.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/head.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/save_op.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/shot_encoder.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/movie_scene_segmentation/utils/trn.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/dataloader/load_blender.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/dataloader/load_data.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/dataloader/load_llff.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/dataloader/load_tankstemple.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/dataloader/read_write_model.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/nerf_preprocess.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/nerf_recon_4k.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/network/dvgo.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_4k/network/utils.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/dataloader/read_write_model.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/nerf.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/segmenter.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_acc/network/utils.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/dataloader/blender.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/dataloader/llff.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/dataloader/nsvf.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/dataloader/ray_utils.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/dataloader/tankstemple.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/nerf_recon_vq_compression.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/network/tensoRF.py": 1690807232.3582962,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/network/tensoRF_VQ.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/network/tensorBase.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/network/weighted_vq.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/renderer.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/utils.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/checkpoint.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/utils/convModule_norm.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/util.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/depth_net.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/object_detection_3d/depe/result_vis.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/ocr_detection/model.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/dbnet.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/layers.py": 1690807232.362296,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/mix_ops.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/proxyless.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_detection/modules/seg_detector_loss.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_detection/utils.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/CRNN/main_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/convnext.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/main_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/timm_tinyc.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/ConvNextViT/vitstr.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/main_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/layers.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/mix_ops.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/modules/LightweightEdge/nas_block/proxyless.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/equi.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/layers.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/mobilenet.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/resnet.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/unifuse.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/networks/util.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/common.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/pointnet2_utils.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/sf_rcp.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_detection.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_embedding.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/product_segmentation/net.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/backbone.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/criterion.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/matcher.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/misc.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/mttr.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/postprocessing.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/segmentation.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/utils/swin_transformer.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/robust_image_classification/easyrobust_model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/config.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/decoder.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/model.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/resnet.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/swin_transformer.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/networks/util_helper.py": 1690807232.3662963,
+        "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/s2net_model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/backbone/Res2Net_v1b.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/modules.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/senet.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/u2net.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/models/utils.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/common.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/head_fpn.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/models.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/neck_fpn.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_base.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/shop_segmentation/utils.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_module.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/detection_model/detection_unet_in.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/gconv.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/inpainting_model/inpainting_unet.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/box_utils.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/net.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/network.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/predict_single.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/prior_box.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/retinaface/utils.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/unet_deploy.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/utils.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/skin_retouching/weights_init.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/data/data_augment.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/base_exp.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/build.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/default/streamyolo.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/exp/yolox_base.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/darknet.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/dfp_pafpn.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/network_blocks.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/streamyolo.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/models/tal_head.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/utils/boxes.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/stream_yolo/utils/format.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/super_resolution/arch_util.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/super_resolution/ecb.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/super_resolution/rrdbnet_arch.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/table_recognition/lineless_table_process.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_detector.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/table_recognition/modules/lore_processor.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/clip.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_base.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_blocks.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_net.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_vit.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/model.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_driven_segmentation/simple_tokenizer.py": 1690807232.3702962,
+        "TEMPLATE_PATH/models/cv/text_to_360panorama_image/pipeline_base.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/text_to_360panorama_image/pipeline_sr.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/basic_blocks.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/global_utils.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/master_net.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/model_zoo.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/plain_net_utils.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_blocks.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_idwexkx.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_k1kxk1.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_classfication/super_res_kxkx.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_evaluater.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/apis/detector_inference.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/box_level_augs.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/color_augs.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/gaussian_maps.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/box_level_augs/geometric_augs.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/augmentations/scale_aware_aug.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/darknet.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_csp.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/backbones/tinynas_res.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/base_ops.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/neck_ops.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ops.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/ota_assigner.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/repvgg_block.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/utils.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/core/weight_init.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/gfocal_v2_tiny.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/heads/zero_head.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/distill_loss.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/losses/gfocal_loss.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_config.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/base_models/necks/giraffe_fpn_btn.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/detectors/detector.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/bounding_box.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/boxlist_ops.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/structures/image_list.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/boxes.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/model_utils.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/damo/utils/scheduler.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/detector.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_detector.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/tinynas_detection/utils.py": 1690807232.3742962,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/deinterlace_arch.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/archs.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/deep_fourier_upsampling.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/enh.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/fre.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_deinterlace/models/utils.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/configs/default_config.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/camera_utils.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/geometry/pose_utils.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_checkpoint.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_utils.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/model_wrapper.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sfm_model_mf.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/models/sup_model_mf.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/depth_pose/depth_pose_net.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/depth_decoder.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/layers.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/pose_decoder.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/layers/resnet/resnet_encoder.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/extractor.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/networks/optim/update.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/augmentations.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/config.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/depth.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/horovod.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/image_gt.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/load.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/misc.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_depth_estimation/utils/types.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_arch.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/corr.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/extractor.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/raft.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/flow_model/update.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/IFNet_swin.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/UNet.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/flow_reversal.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/refinenet_arch.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/interp_model/transformer_layers.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/scene_change_detection.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_frame_interpolation/utils/utils.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/model.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/decoder.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/deep_guided_filter.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/effv2.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/lraspp.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_human_matting/models/matting.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py": 1690807232.3782961,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/utils.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/common.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/decode.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/model.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/models/yolo.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/basetrack.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/matching.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/tracker/multitracker.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/image.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/kalman_filter.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/utils.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_multi_object_tracking/utils/visualization.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/aggregate.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/cbam.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/eval_network.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_core.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/inference_memory_bank.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/mod_resnet.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/modules.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_object_segmentation/network.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_checkpoint.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/backbone/swin_transformer.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_updator.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/mask.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/track_heads.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/neck/fpn.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/visualizer.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/config/ostrack.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/attn_blocks.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/head.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/layers/patch_embed.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/base_backbone.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/ostrack.py": 1690807232.3822963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/utils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/ostrack/vit_ce.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/procontext.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/utils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/models/procontext/vit_ce.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/ostrack.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/tracker/procontext.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_single_object_tracking/utils/utils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/DUT_raft.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/MotionPro.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/corr.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/extractor.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/raft.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/RAFT/update.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/Smoother.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/config.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_module.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUT/rf_det_so.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/IterativeSmooth.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/MedianFilter.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/ProjectionUtils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/RAFTUtils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/WarpUtils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/image_utils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_stabilization/utils/math_utils.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/exp/longshortnet_base.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_long.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/dfp_pafpn_short.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/models/longshort_backbone_neck.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_summarization/base_model.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_auto.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_summarization/kts/cpd_nonlin.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_summarization/pgl_sum.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/basicvsr_net.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/common.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_net.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vidt/backbone.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vidt/deformable_transformer.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vidt/fpn_fusion.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vidt/head.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vidt/model.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/virual_tryon/sdafnet.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/backbone.py": 1690807232.3862963,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/head.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/petl.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_helpers.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_vision_transformer.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/timm_weight_init.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_efficient_tuning/vision_efficient_tuning.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_middleware/backbone.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_middleware/head.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_middleware/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vision_middleware/vim.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/backbone.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/basic_utils.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/model_se.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/cv/vop_retrieval/tokenization_clip.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/clip/bert_tokenizer.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/clip/configuration_bert.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/clip/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/clip/modeling_bert.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/diffusion.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/structbert.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/tokenizer.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_generator.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_1024.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/diffusion/unet_upsampler_256.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/dpm_solver_pytorch.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_base.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/gemm/tokenizer.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/gaussian_diffusion.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/respace.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/script.py": 1690807232.3902962,
+        "TEMPLATE_PATH/models/multi_modal/guided_diffusion/unet.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/text_classification.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/text_ranking.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mgeo/token_classification.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/dataloaders/rawvideo_util.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/dynamic_inverted_softmax.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/modeling.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_clip.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/module_cross.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/tokenization_clip.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mmr/models/until_module.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug/clip/clip.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug/configuration_mplug.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug/modeling_mplug.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug/mvit.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug/predictor.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug_owl/configuration_mplug_owl.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/clip.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/decoder.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/gaussian_diffusion.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/prior.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/tokenizer.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/upsampler.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/xglm.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_mmspeech.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/ofa/configuration_ofa.py": 1690807232.3942962,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/incremental_decoding_utils.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/multihead_attention.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/ngram_repeat_block.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/search.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/sequence_generator.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/token_generation_constraints.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/generate/utils.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_mmspeech.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/modeling_ofa.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/resnet.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/tokenization_ofa_fast.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/utils/constant.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/utils/utils.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa/vit.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/rleg/model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/blocks.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/clip.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/swin_transformer.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/tokenizer.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/soonet/utils.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/stable_diffusion/stable_diffusion.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/team/team_model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/team/utils.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/autoencoder.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/diffusion.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/video_synthesis/unet_sd.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/conv_fpn_trans.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/convnext.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/model.py": 1690807232.398296,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/modeling_layout_roberta.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/processing.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/tokenization.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/multi_modal/vldoc/transformer_local.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/T5/backbone.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/T5/configuration.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/backbone.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/configuration.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/fill_mask.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/text_classification.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/text_ranking.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/token_classification.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bert/word_alignment.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/bloom/backbone.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/canmt/canmt_model.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/canmt/sequence_generator.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm/configuration.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm/quantization.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm/text_generation.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm/tokenization.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm2/configuration.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm2/quantization.py": 1690807232.4022963,
+        "TEMPLATE_PATH/models/nlp/chatglm2/text_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/chatglm2/tokenization.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/codegeex/inference.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/codegeex/tokenizer.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/csanmt/translation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/configuration.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/deberta_v2/tokenization_fast.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/dgds/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/fid_plug/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/fid_plug/configuration.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/glm_130b/generation/strategies.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/glm_130b/initialize.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/functional.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/glm_130b/quantization/layers.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt2/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt3/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt3/configuration.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt3/distributed_gpt3.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt3/tokenizer.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/backbone.py": 1690807232.4062963,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/checkpointing.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/configuration.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/distributed_gpt_moe.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/experts.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/layer.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/mappings.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/sharded_moe.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/moe/utils.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_moe/tokenizer.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/gpt_neo/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/crf_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/configuration.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/convert_llama_weights_to_hf.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/text_generation.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/tokenization.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama/tokenization_fast.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama2/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama2/configuration.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama2/text_generation.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama2/tokenization.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/llama2/tokenization_fast.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/lstm/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/lstm/token_classification.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/configuration.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/megatron_bert/fill_mask.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/arguments.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/blocklm_utils.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/configure_data.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/corpora.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/datasets.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/extraction.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/file_utils.py": 1690807232.4102962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/lazy_loader.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/samplers.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/sp_tokenizer.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/tokenization_gpt2.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/data_utils/wordpiece.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/generation_utils.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/distributed.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/downstream.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_bert.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/modeling_glm.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/prompt.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/model/transformer.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/process_grid.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/run_test.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/data_utils.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/eval_utils.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/dataset.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/detokenizer.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/language_model/finetune.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/dataset.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/evaluate.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/seq2seq/finetune.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/dataset.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/evaluate.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/finetune.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/tasks/superglue/pvp.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/test/test_block.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/test/test_rel_shift.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/train_utils.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/mglm/utils.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/palm_v2/configuration.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/palm_v2/dureader_eval.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py": 1690807232.4142962,
+        "TEMPLATE_PATH/models/nlp/peer/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/peer/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/peer/sas_utils.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/peer/text_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug/AnnealingLR.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug/distributed_plug.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug/generator.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug_mental/adv_utils.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug_mental/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/plug_mental/text_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/polylm/text_generation.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/ponet/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/ponet/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/ponet/fill_mask.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/ponet/tokenization.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/gen_unified_transformer.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/generator.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/intent_unified_transformer.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/model_base.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/tokenization_space.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/model/unified_transformer.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/modules/embedder.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/modules/feedforward.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/modules/functions.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/modules/multihead_attention.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space/modules/transformer_block.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/adv_utils.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/backbone.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/fill_mask.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/text_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/structbert/token_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/task_model.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/text_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/text_generation.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/text_ranking.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/task_models/token_classification.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/unite/configuration.py": 1690807232.418296,
+        "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/use/transformer.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/veco/backbone.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/veco/configuration.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/veco/fill_mask.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/veco/text_classification.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/veco/token_classification.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/nlp/xlm_roberta/configuration.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/config.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/data_ops.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/msa_pairing.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/process.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/process_multimer.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/protein.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/residue_constants.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/data/utils.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/dataset.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/model.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/alphafold.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/attentions.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/auxillary_heads.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/common.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/confidence.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/embedders.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/evoformer.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/featurization.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/frame.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/structure_module.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/template.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/modules/triangle_multiplication.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/mmcif.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/msa_identifiers.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/parsers.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/pipeline.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/templates.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhblits.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hhsearch.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmbuild.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/hmmsearch.py": 1690807232.4222963,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/jackhmmer.py": 1690807232.4262962,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/kalign.py": 1690807232.4262962,
+        "TEMPLATE_PATH/models/science/unifold/msa/tools/utils.py": 1690807232.4262962,
+        "TEMPLATE_PATH/models/science/unifold/msa/utils.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/audio/asr_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/auth/auth_config.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/context/dataset_context_config.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/data_files/data_files_manager.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/data_loader/data_loader.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/data_loader/data_loader_manager.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/asr_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_farfield_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/audio/kws_nearfield_processor.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/builder.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/build.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/collate_batch.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/coco.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/datasets/mosaic_wrapper.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/evaluation/coco/coco_eval.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/distributed.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/grouped_batch_sampler.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/samplers/iteration_based_batch_sampler.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/build.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/damoyolo/transforms/transforms.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/easycv_base.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/aug.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/data_utils.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/sampler.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/augmenter.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/data_loader.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/image_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/iou_evaluator.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/measures/quad_measurer.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/augment_data.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/data_process.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_border_map.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_icdar_data.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/make_seg_detection_data.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/normalize_image.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_detection/processes/random_crop_data.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/transformers.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/data_utils.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py": 1690807232.4262962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/transforms.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/torch_custom_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/data_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_summarization_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/dataset_cls/dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/download/dataset_builder.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/download/download_config.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/download/download_manager.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/meta/data_meta_config.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/meta/data_meta_manager.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/ms_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/task_datasets/gopro_image_deblurring_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/task_datasets/reds_image_deblurring_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/task_datasets/sidd_image_denoising.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/task_datasets/torch_base_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/task_datasets/video_summarization_dataset.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/utils/dataset_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/utils/delete_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/utils/maxcompute_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/utils/oss_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/msdatasets/utils/upload_utils.py": 1690807232.4302962,
+        "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py": 1690807232.4302962,
+        "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py": 1690807232.4302962,
+        "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py": 1690807232.4302962,
+        "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/language_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/segmentation_clustering_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_dialogue_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_diarization_semantic_speaker_turn_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/base.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/builder.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_human_hand_detection_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_processing_base_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/hand_static_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py": 1690807232.4342961,
+        "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_panoptic_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/image_try_on_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/nerf_recon_4k_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/nerf_recon_acc_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/nerf_recon_vq_compression_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_convnext_transformer.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_dla34.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet18_half.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_resnet_mutex_v4_linewithchar.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/model_vlpt.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/convnext.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/timm_tinyc.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ocr_modules/vitstr.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/ops.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet18_v1.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/resnet_utils.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/table_process.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/ocr_utils/utils.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_s2net_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/shop_segmentation_pipleline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py": 1690807232.4382963,
+        "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/tbs_detection_utils/utils.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/text_driven_segmentation_pipleline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/text_to_360panorama_image_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/diffusers_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/utils.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/image_captioning_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/team_multi_modal_similarity_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/codegeex_code_translation_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_modeling_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/dialog_state_tracking_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py": 1690807232.4422963,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/llama2_text_generation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/polylm_text_generation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/sentence_embedding_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/text_ranking_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/user_satisfaction_estimation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/pipeline_template.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py": 1690807232.4462962,
+        "TEMPLATE_PATH/pipelines/util.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/asr.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/audio.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/base.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/builder.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/common.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/action_detection_mapper.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/cv2_transforms.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/timer.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/util.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/video_stabilization.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/cv/video_super_resolution.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/image.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/kws.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/movie_scene_segmentation/transforms.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/multi_modal.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/canmt_translation.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py": 1690807232.4462962,
+        "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/relation_extraction_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/sentence_embedding_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/args.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/batch.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/data_loader.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/dst_processors.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/fields/gen_field.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/fields/intent_field.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/lazy_dataset.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/preprocess.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/sampler.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/tensorlistdataset.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space/tokenizer.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/database.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/schema_link.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/fields/struct.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/common_utils.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/parse.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/preprocess_dataset.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/space_T_en/fields/process_dataset.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/text_clean.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/transformers_tokenizer.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/utils.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/asr.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/base.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/image_captioning.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/image_classification.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/ocr_recognition.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/sudoku.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/summarization.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/text2sql.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/text_classification.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/text_to_image_synthesis.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/audio_helper.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/bridge_content_encoder.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/collate.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/constant.py": 1690807232.4502962,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/get_tables.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/random_help.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/text2phone.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/transforms.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/utils/vision_helper.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_entailment.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_grounding.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/ofa/visual_question_answering.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/science/uni_fold.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/speaker.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/tts.py": 1690807232.454296,
+        "TEMPLATE_PATH/preprocessors/video.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/ans_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/asr_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/batch_utils.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/det_utils.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/file_utils.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/model_utils.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/kws_utils/runtime_utils.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/separation_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/audio/tts_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/base.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/builder.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cli_argument_parser.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py": 1690807232.454296,
+        "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/default_config.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/builder.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_processor.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/compression/sparsity_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/compression/utils.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/distributed/ddp_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/evaluation_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/iter_timer_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/logger/base.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/base.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/hooks/priority.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/lrscheduler/builder.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/lrscheduler/warmup/base.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/lrscheduler/warmup/warmup.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer_utils.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/custom_diffusion/custom_diffusion_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer_utils.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer_utils.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/plug_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py": 1690807232.4582963,
+        "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/eval.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/metrics/metrics_tracker.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/trainer/gen_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/space/trainer/intent_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/nlp_trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/optimizer/builder.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/parallel/builder.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/parallel/utils.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/trainer.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/training_args.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/utils/inference.py": 1690807232.4622962,
+        "TEMPLATE_PATH/trainers/utils/log_buffer.py": 1690807232.4622962
     },
     "index": {
         "('ATTENTION', 'default', 'PETRMultiheadAttention')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "mmcv",
-                "copy",
                 "torch",
+                "mmcv",
                 "warnings",
+                "mmdet",
+                "copy",
                 "math",
-                "typing",
-                "mmdet"
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('BACKBONES', 'backbone', 'bloom')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bloom/backbone.py",
             "imports": [
                 "transformers"
@@ -1710,197 +1765,197 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.gpt2.backbone"
         },
         "('BACKBONES', 'default', 'BASEBEiT')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/base/beit.py",
             "imports": [
-                "mmcv",
+                "functools",
                 "torch",
+                "mmcv",
                 "mmdet",
-                "functools",
-                "math",
-                "timm"
+                "timm",
+                "math"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.base.beit"
         },
         "('BACKBONES', 'default', 'BEiTAdapter')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/backbone/beit_adapter.py",
             "imports": [
-                "mmdet",
-                "math",
+                "logging",
                 "timm",
+                "math",
                 "torch",
-                "logging"
+                "mmdet"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.beit_adapter"
         },
         "('BACKBONES', 'default', 'BEiTv2')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/backbones/beit_v2.py",
             "imports": [
+                "collections",
+                "functools",
+                "einops",
                 "mmcv",
+                "mmcls",
+                "os",
                 "warnings",
-                "functools",
                 "math",
-                "itertools",
+                "typing",
                 "torch",
-                "collections",
-                "os",
-                "einops",
-                "mmcls",
-                "typing"
+                "itertools"
             ],
             "module": "modelscope.models.cv.image_classification.backbones.beit_v2"
         },
         "('BACKBONES', 'default', 'MasterNet')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/master_net.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.master_net"
         },
         "('BACKBONES', 'default', 'MobileNetV1')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/mobilenet.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.mobilenet"
         },
         "('BACKBONES', 'default', 'NextViT')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/backbones/nextvit.py",
             "imports": [
+                "collections",
+                "functools",
+                "einops",
                 "mmcv",
+                "mmcls",
+                "os",
                 "warnings",
-                "functools",
                 "math",
-                "itertools",
+                "typing",
                 "torch",
-                "collections",
-                "os",
-                "einops",
-                "mmcls",
-                "typing"
+                "itertools"
             ],
             "module": "modelscope.models.cv.image_classification.backbones.nextvit"
         },
         "('BACKBONES', 'default', 'ResNetV1e')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/backbones/resnet.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.resnet"
         },
         "('BACKBONES', 'default', 'ViT')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/backbones/vit.py",
             "imports": [
-                "mmdet",
                 "functools",
-                "math",
                 "timm",
-                "torch"
+                "math",
+                "torch",
+                "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.backbones.vit"
         },
         "('BACKBONES', 'default', 'VoVNet')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/backbones/vovnet.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "collections",
-                "mmdet"
+                "mmdet",
+                "torch",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.backbones.vovnet"
         },
         "('BBOX_ASSIGNERS', 'default', 'HungarianAssigner3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/assigners/hungarian_assigner_3d.py",
             "imports": [
-                "torch",
                 "mmdet",
+                "torch",
                 "scipy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d"
         },
         "('BBOX_ASSIGNERS', 'default', 'MaskHungarianAssignerVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py",
             "imports": [
-                "numpy",
+                "mmdet",
                 "torch",
                 "scipy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner"
         },
         "('BBOX_CODERS', 'default', 'NMSFreeCoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/coders/nms_free_coder.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.coders.nms_free_coder"
         },
         "('CUSTOM_DATASETS', 'bad-image-detecting', 'bad-image-detecting')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/bad_image_detecting/bad_image_detecting_dataset.py",
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.bad_image_detecting.bad_image_detecting_dataset"
         },
         "('CUSTOM_DATASETS', 'image-colorization', 'ddcolor')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_colorization/image_colorization_dataset.py",
             "imports": [
+                "cv2",
                 "numpy",
-                "torch",
-                "cv2"
+                "torch"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_colorization.image_colorization_dataset"
         },
         "('CUSTOM_DATASETS', 'image-deblurring', 'GoproDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/gopro_image_deblurring_dataset.py",
             "imports": [
-                "numpy",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.gopro_image_deblurring_dataset"
         },
         "('CUSTOM_DATASETS', 'image-deblurring', 'RedsDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/reds_image_deblurring_dataset.py",
             "imports": [
-                "numpy",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.reds_image_deblurring_dataset"
         },
         "('CUSTOM_DATASETS', 'image-denoising', 'SiddDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/sidd_image_denoising/sidd_image_denoising_dataset.py",
             "imports": [
-                "numpy",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.sidd_image_denoising_dataset"
         },
         "('CUSTOM_DATASETS', 'image-inpainting', 'FFTInpainting')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_inpainting/image_inpainting_dataset.py",
             "imports": [
-                "numpy",
-                "glob",
-                "albumentations",
+                "enum",
                 "os",
+                "albumentations",
+                "glob",
                 "cv2",
-                "enum"
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.image_inpainting_dataset"
         },
         "('CUSTOM_DATASETS', 'image-portrait-enhancement', 'PairedDataset')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_portrait_enhancement/image_portrait_enhancement_dataset.py",
             "imports": [
-                "numpy",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_portrait_enhancement.image_portrait_enhancement_dataset"
         },
         "('CUSTOM_DATASETS', 'image-quality-assessment-degradation', 'image-quality-assessment-degradation')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assessment_degradation/image_quality_assessment_degradation_dataset.py",
             "imports": [
                 "torchvision"
@@ -1911,805 +1966,819 @@
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_quality_assmessment_mos/image_quality_assessment_mos_dataset.py",
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assmessment_mos.image_quality_assessment_mos_dataset"
         },
         "('CUSTOM_DATASETS', 'image-segmentation', 'cascade_mask_rcnn_swin')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/image_instance_segmentation_coco_dataset.py",
             "imports": [
-                "numpy",
                 "os",
-                "pycocotools"
+                "pycocotools",
+                "numpy"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.image_instance_segmentation_coco_dataset"
         },
         "('CUSTOM_DATASETS', 'language-guided-video-summarization', 'clip-it-language-guided-video-summarization')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/language_guided_video_summarization_dataset.py",
             "imports": [
-                "numpy",
+                "os",
                 "h5py",
                 "torch",
-                "os",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.language_guided_video_summarization_dataset"
         },
         "('CUSTOM_DATASETS', 'movie-scene-segmentation', 'resnet50-bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/movie_scene_segmentation/movie_scene_segmentation_dataset.py",
             "imports": [
-                "torchvision",
-                "random",
+                "os",
                 "copy",
                 "torch",
-                "os",
+                "random",
+                "torchvision",
                 "json"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.movie_scene_segmentation_dataset"
         },
         "('CUSTOM_DATASETS', 'nli', 'veco')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/veco_dataset.py",
             "imports": [
-                "typing",
+                "numpy",
                 "datasets",
-                "numpy"
+                "typing"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.veco_dataset"
         },
         "('CUSTOM_DATASETS', 'ocr-recognition', 'OCRRecognition')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/ocr_recognition_dataset.py",
             "imports": [
-                "numpy",
                 "six",
+                "os",
                 "lmdb",
                 "torch",
-                "cv2",
-                "os",
                 "PIL",
+                "cv2",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_recognition_dataset"
         },
         "('CUSTOM_DATASETS', 'referring-video-object-segmentation', 'swinT-referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/referring_video_object_segmentation/referring_video_object_segmentation_dataset.py",
             "imports": [
-                "numpy",
-                "tqdm",
                 "torchvision",
-                "glob",
+                "os",
+                "tqdm",
                 "h5py",
                 "torch",
-                "pandas",
-                "os",
                 "pycocotools",
+                "glob",
+                "pandas",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.referring_video_object_segmentation_dataset"
         },
         "('CUSTOM_DATASETS', 'sentence-embedding', 'bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py",
             "imports": [
-                "typing",
+                "random",
                 "torch",
-                "random"
+                "typing"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'text-ranking', 'bert')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/text_ranking_dataset.py",
             "imports": [
-                "typing",
+                "random",
                 "torch",
-                "random"
+                "typing"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'text-ranking', 'mgeo')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/mgeo_ranking_dataset.py",
             "imports": [
-                "typing",
                 "torch",
                 "random",
-                "json"
+                "json",
+                "typing"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.mgeo_ranking_dataset"
         },
         "('CUSTOM_DATASETS', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_frame_interpolation/video_frame_interpolation_dataset.py",
             "imports": [
+                "cv2",
                 "numpy",
-                "torch",
-                "cv2"
+                "torch"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.video_frame_interpolation_dataset"
         },
         "('CUSTOM_DATASETS', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_stabilization/video_stabilization_dataset.py",
             "imports": [],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_stabilization.video_stabilization_dataset"
         },
         "('CUSTOM_DATASETS', 'video-super-resolution', 'real-basicvsr')": {
             "filepath": "TEMPLATE_PATH/msdatasets/dataset_cls/custom_datasets/video_super_resolution/video_super_resolution_dataset.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
+                "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.msdatasets.dataset_cls.custom_datasets.video_super_resolution.video_super_resolution_dataset"
         },
         "('DATASETS', 'default', 'CustomNuScenesDataset')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/nuscenes_dataset.py",
             "imports": [
-                "numpy",
+                "mmdet",
                 "mmdet3d",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.nuscenes_dataset"
         },
         "('DATASETS', 'default', 'RetinaFaceDataset')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/retinaface.py",
             "imports": [
-                "numpy",
-                "mmdet"
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.retinaface"
         },
         "('DETECTORS', 'default', 'CustomSingleStageDetector')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/single_stage.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.single_stage"
         },
         "('DETECTORS', 'default', 'EncoderDecoderMask2Former')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/segmentors/encoder_decoder_mask2former.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.encoder_decoder_mask2former"
         },
         "('DETECTORS', 'default', 'Petr3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/detectors/petr3d.py",
             "imports": [
                 "mmcv",
-                "numpy",
-                "mmdet3d",
+                "torch",
                 "mmdet",
-                "torch"
+                "mmdet3d",
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors.petr3d"
         },
         "('DETECTORS', 'default', 'SCRFD')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/scrfd.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.scrfd"
         },
         "('DETECTORS', 'default', 'TinyMog')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/detectors/tinymog.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.tinymog"
         },
         "('EXPORTERS', 'acoustic-noise-suppression', 'speech_dfsmn_ans')": {
             "filepath": "TEMPLATE_PATH/exporters/audio/ans_dfsmn_exporter.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.exporters.audio.ans_dfsmn_exporter"
         },
         "('EXPORTERS', 'default', 'cartoon-translation')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/cartoon_translation_exporter.py",
             "imports": [
-                "tensorflow",
-                "packaging",
                 "os",
+                "packaging",
+                "tensorflow",
                 "typing"
             ],
             "module": "modelscope.exporters.cv.cartoon_translation_exporter"
         },
         "('EXPORTERS', 'domain-specific-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py",
             "imports": [
-                "numpy",
                 "functools",
-                "onnx",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "onnx",
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.object_detection_damoyolo_exporter"
         },
         "('EXPORTERS', 'face-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/face_detection_scrfd_exporter.py",
             "imports": [
-                "numpy",
                 "functools",
-                "onnx",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "onnx",
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.face_detection_scrfd_exporter"
         },
         "('EXPORTERS', 'image-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/exporters/cv/object_detection_damoyolo_exporter.py",
             "imports": [
-                "numpy",
                 "functools",
-                "onnx",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "onnx",
+                "numpy"
             ],
             "module": "modelscope.exporters.cv.object_detection_damoyolo_exporter"
         },
         "('EXPORTERS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'nli', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'nli', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'sentence-similarity', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentence-similarity', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentiment-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'sentiment-classification', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'text-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'text-classification', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_sequence_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter"
         },
         "('EXPORTERS', 'text-to-image-synthesis', 'stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/exporters/multi_modal/stable_diffusion_exporter.py",
             "imports": [
-                "diffusers",
-                "shutil",
-                "packaging",
-                "onnx",
-                "torch",
-                "os",
                 "collections",
-                "argparse",
+                "os",
                 "typing",
-                "pathlib"
+                "argparse",
+                "pathlib",
+                "torch",
+                "onnx",
+                "diffusers",
+                "packaging",
+                "shutil"
             ],
             "module": "modelscope.exporters.multi_modal.stable_diffusion_exporter"
         },
         "('EXPORTERS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/csanmt_for_translation_exporter.py",
             "imports": [
+                "os",
                 "tensorflow",
-                "typing",
-                "os"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.csanmt_for_translation_exporter"
         },
         "('EXPORTERS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/model_for_token_classification_exporter.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.model_for_token_classification_exporter"
         },
         "('EXPORTERS', 'zero-shot-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py",
             "imports": [
-                "typing",
-                "collections"
+                "collections",
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_zero_shot_classification_exporter"
         },
         "('EXPORTERS', 'zero-shot-classification', 'structbert')": {
             "filepath": "TEMPLATE_PATH/exporters/nlp/sbert_for_zero_shot_classification_exporter.py",
             "imports": [
-                "typing",
-                "collections"
+                "collections",
+                "typing"
             ],
             "module": "modelscope.exporters.nlp.sbert_for_zero_shot_classification_exporter"
         },
         "('HEADS', 'default', 'AnchorNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py",
             "imports": [
                 "mmdet"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.anchor_head"
         },
         "('HEADS', 'default', 'ConvFCBBoxNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head"
         },
         "('HEADS', 'default', 'ConvKernelHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_head.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_head"
         },
         "('HEADS', 'default', 'FCNMaskNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/mask_heads/fcn_mask_head.py",
             "imports": [
                 "mmcv",
-                "numpy",
                 "warnings",
+                "torch",
                 "mmdet",
-                "torch"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.mask_heads.fcn_mask_head"
         },
         "('HEADS', 'default', 'KernelFrameIterHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_frame_iter_head.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_frame_iter_head"
         },
         "('HEADS', 'default', 'KernelIterHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_iter_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_iter_head"
         },
         "('HEADS', 'default', 'KernelUpdateHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_update_head.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "mmdet",
+                "torch",
+                "mmcv",
                 "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_update_head"
         },
         "('HEADS', 'default', 'KernelUpdateHeadVideo')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/kernel_update_head.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "mmdet",
+                "torch",
+                "mmcv",
                 "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.kernel_update_head"
         },
         "('HEADS', 'default', 'Mask2FormerHeadFromMMSeg')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/models/decode_heads/mask2former_head_from_mmseg.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "copy",
-                "torch",
-                "mmdet"
+                "mmcv",
+                "torch"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.mask2former_head_from_mmseg"
         },
         "('HEADS', 'default', 'MaskFormerSemanticHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/pan_merge/maskformer_semantic_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.pan_merge.maskformer_semantic_head"
         },
         "('HEADS', 'default', 'MaskScoringNRoIHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/mask_scoring_roi_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.mask_scoring_roi_head"
         },
         "('HEADS', 'default', 'PETRv2DEDNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/dense_heads/petrv2_dednhead.py",
             "imports": [
                 "mmcv",
-                "numpy",
-                "mmdet3d",
-                "mmdet",
-                "math",
                 "copy",
-                "torch"
+                "math",
+                "torch",
+                "mmdet",
+                "mmdet3d",
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.petrv2_dednhead"
         },
         "('HEADS', 'default', 'RPNNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/dense_heads/rpn_head.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "copy",
-                "torch",
-                "mmdet"
+                "mmcv",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.rpn_head"
         },
         "('HEADS', 'default', 'SCRFDHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/models/dense_heads/scrfd_head.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "mmdet",
+                "torch",
+                "mmcv",
                 "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads.scrfd_head"
         },
         "('HEADS', 'default', 'Shared2FCBBoxNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head"
         },
         "('HEADS', 'default', 'Shared4Conv1FCBBoxNHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/roi_heads/bbox_heads/convfc_bbox_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head"
         },
         "('HEADS', 'default', 'VideoKernelIterHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_iter_head.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.kernel_iter_head"
         },
         "('HEADS', 'default', 'VideoKernelUpdateHead')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/kernel_update_head.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "mmdet",
+                "torch",
+                "mmcv",
                 "numpy"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.kernel_update_head"
         },
         "('HEADS', 'fill-mask', 'bert-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'fill-mask', 'roberta-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/torch_pretrain_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.torch_pretrain_head"
         },
         "('HEADS', 'fill-mask', 'xlm-roberta-mlm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/fill_mask_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.fill_mask_head"
         },
         "('HEADS', 'information-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.heads.infromation_extraction_head"
         },
         "('HEADS', 'named-entity-recognition', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'named-entity-recognition', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'nli', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'part-of-speech', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'part-of-speech', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'relation-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/infromation_extraction_head.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.heads.infromation_extraction_head"
         },
         "('HEADS', 'sentence-similarity', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'sentiment-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
+        "('HEADS', 'speaker-diarization-dialogue-detection', 'text-classification')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_dialogue_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_dialogue_detection"
+        },
+        "('HEADS', 'speaker-diarization-semantic-speaker-turn-detection', 'token-classification')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_semantic_speaker_turn_detection"
+        },
         "('HEADS', 'text-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_classification_head"
         },
         "('HEADS', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_generation_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_generation_head"
         },
         "('HEADS', 'text-ranking', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/text_ranking_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.text_ranking_head"
         },
         "('HEADS', 'token-classification', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'token-classification', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/token_classification_head.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.token_classification_head"
         },
         "('HEADS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'word-segmentation', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HEADS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/heads/crf_head.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.heads.crf_head"
         },
         "('HOOKS', 'default', 'ApexAMPOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/apex_optimizer_hook.py",
             "imports": [
+                "logging",
                 "packaging",
-                "torch",
-                "logging"
+                "torch"
             ],
             "module": "modelscope.trainers.hooks.optimizer.apex_optimizer_hook"
         },
         "('HOOKS', 'default', 'BestCkptSaverHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py",
             "imports": [
-                "numpy",
-                "random",
-                "shutil",
-                "torch",
                 "os",
                 "typing",
+                "torch",
+                "shutil",
+                "random",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.checkpoint_hook"
         },
         "('HOOKS', 'default', 'CheckpointHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/checkpoint_hook.py",
             "imports": [
-                "numpy",
-                "random",
-                "shutil",
-                "torch",
                 "os",
                 "typing",
+                "torch",
+                "shutil",
+                "random",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.checkpoint_hook"
         },
         "('HOOKS', 'default', 'ClipClampLogitScaleHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/clip_clamp_logit_scale_hook.py",
             "imports": [
@@ -2721,91 +2790,91 @@
             "filepath": "TEMPLATE_PATH/trainers/hooks/distributed/ddp_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.distributed.ddp_hook"
         },
         "('HOOKS', 'default', 'DeepspeedHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/distributed/deepspeed_hook.py",
             "imports": [
+                "megatron_util",
                 "functools",
-                "math",
+                "deepspeed",
+                "os",
                 "transformers",
-                "shutil",
+                "math",
                 "torch",
-                "os",
-                "megatron_util",
-                "deepspeed"
+                "shutil"
             ],
             "module": "modelscope.trainers.hooks.distributed.deepspeed_hook"
         },
         "('HOOKS', 'default', 'EarlyStopHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/early_stop_hook.py",
             "imports": [
                 "numpy"
             ],
             "module": "modelscope.trainers.hooks.early_stop_hook"
         },
         "('HOOKS', 'default', 'EvaluationHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/evaluation_hook.py",
             "imports": [
-                "typing",
-                "collections"
+                "collections",
+                "typing"
             ],
             "module": "modelscope.trainers.hooks.evaluation_hook"
         },
         "('HOOKS', 'default', 'IterTimerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/iter_timer_hook.py",
             "imports": [
                 "time"
             ],
             "module": "modelscope.trainers.hooks.iter_timer_hook"
         },
         "('HOOKS', 'default', 'LoadCheckpointHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/checkpoint/load_checkpoint_hook.py",
             "imports": [
-                "numpy",
-                "random",
-                "packaging",
+                "typing",
                 "torch",
-                "typing"
+                "packaging",
+                "random",
+                "numpy"
             ],
             "module": "modelscope.trainers.hooks.checkpoint.load_checkpoint_hook"
         },
         "('HOOKS', 'default', 'LrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
         },
         "('HOOKS', 'default', 'MegatronHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/distributed/megatron_hook.py",
             "imports": [
-                "shutil",
                 "megatron_util",
+                "shutil",
                 "torch",
                 "os"
             ],
             "module": "modelscope.trainers.hooks.distributed.megatron_hook"
         },
         "('HOOKS', 'default', 'NoneLrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
         },
         "('HOOKS', 'default', 'NoneOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/base.py",
             "imports": [
-                "torch",
-                "logging"
+                "logging",
+                "torch"
             ],
             "module": "modelscope.trainers.hooks.optimizer.base"
         },
         "('HOOKS', 'default', 'OptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/base.py",
             "imports": [
-                "torch",
-                "logging"
+                "logging",
+                "torch"
             ],
             "module": "modelscope.trainers.hooks.optimizer.base"
         },
         "('HOOKS', 'default', 'PlateauLrSchedulerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/lr_scheduler_hook.py",
             "imports": [],
             "module": "modelscope.trainers.hooks.lr_scheduler_hook"
@@ -2816,27 +2885,27 @@
                 "os"
             ],
             "module": "modelscope.trainers.hooks.compression.sparsity_hook"
         },
         "('HOOKS', 'default', 'TensorboardHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/logger/tensorboard_hook.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.trainers.hooks.logger.tensorboard_hook"
         },
         "('HOOKS', 'default', 'TextLoggerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/logger/text_logger_hook.py",
             "imports": [
-                "datetime",
-                "torch",
                 "collections",
+                "datetime",
                 "os",
+                "torch",
                 "json"
             ],
             "module": "modelscope.trainers.hooks.logger.text_logger_hook"
         },
         "('HOOKS', 'default', 'TorchAMPOptimizerHook')": {
             "filepath": "TEMPLATE_PATH/trainers/hooks/optimizer/torch_optimizer_hook.py",
             "imports": [
@@ -2858,253 +2927,253 @@
             "filepath": "TEMPLATE_PATH/trainers/lrscheduler/warmup/warmup.py",
             "imports": [],
             "module": "modelscope.trainers.lrscheduler.warmup.warmup"
         },
         "('MATCH_COST', 'default', 'BBox3DL1Cost')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/core/bbox/match_costs/match_cost.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.match_costs.match_cost"
         },
         "('MATCH_COST', 'default', 'MaskCost')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/track/mask_hungarian_assigner.py",
             "imports": [
-                "numpy",
+                "mmdet",
                 "torch",
                 "scipy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner"
         },
         "('METRICS', 'default', 'accuracy')": {
             "filepath": "TEMPLATE_PATH/metrics/accuracy_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.accuracy_metric"
         },
         "('METRICS', 'default', 'audio-noise-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/audio_noise_metric.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.metrics.audio_noise_metric"
         },
         "('METRICS', 'default', 'bleu')": {
             "filepath": "TEMPLATE_PATH/metrics/bleu_metric.py",
             "imports": [
-                "typing",
                 "itertools",
-                "sacrebleu"
+                "sacrebleu",
+                "typing"
             ],
             "module": "modelscope.metrics.bleu_metric"
         },
         "('METRICS', 'default', 'image-color-enhance-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_color_enhance_metric.py",
             "imports": [
-                "typing",
+                "cv2",
                 "numpy",
-                "cv2"
+                "typing"
             ],
             "module": "modelscope.metrics.image_color_enhance_metric"
         },
         "('METRICS', 'default', 'image-colorization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_colorization_metric.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "scipy",
+                "typing",
                 "torch",
                 "cv2",
-                "typing",
-                "scipy"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.metrics.image_colorization_metric"
         },
         "('METRICS', 'default', 'image-denoise-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_denoise_metric.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "cv2"
+                "numpy",
+                "cv2",
+                "typing"
             ],
             "module": "modelscope.metrics.image_denoise_metric"
         },
         "('METRICS', 'default', 'image-inpainting-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_inpainting_metric.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "scipy"
+                "scipy",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.image_inpainting_metric"
         },
         "('METRICS', 'default', 'image-ins-seg-coco-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_instance_segmentation_metric.py",
             "imports": [
-                "numpy",
                 "collections",
                 "os",
+                "typing",
                 "pycocotools",
                 "tempfile",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.metrics.image_instance_segmentation_metric"
         },
         "('METRICS', 'default', 'image-portrait-enhancement-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_portrait_enhancement_metric.py",
             "imports": [
-                "typing",
+                "cv2",
                 "numpy",
-                "cv2"
+                "typing"
             ],
             "module": "modelscope.metrics.image_portrait_enhancement_metric"
         },
         "('METRICS', 'default', 'image-quality-assessment-degradation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_quality_assessment_degradation_metric.py",
             "imports": [
-                "numpy",
-                "tqdm",
-                "torch",
                 "collections",
-                "cv2",
+                "sys",
                 "os",
-                "tempfile",
+                "tqdm",
+                "scipy",
                 "typing",
-                "sys",
-                "scipy"
+                "torch",
+                "tempfile",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.metrics.image_quality_assessment_degradation_metric"
         },
         "('METRICS', 'default', 'image-quality-assessment-mos-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/image_quality_assessment_mos_metric.py",
             "imports": [
                 "numpy",
-                "torch",
                 "os",
-                "cv2",
-                "tempfile",
+                "tqdm",
                 "scipy",
                 "typing",
-                "sys",
-                "tqdm"
+                "torch",
+                "tempfile",
+                "cv2",
+                "sys"
             ],
             "module": "modelscope.metrics.image_quality_assessment_mos_metric"
         },
         "('METRICS', 'default', 'inbatch_recall')": {
             "filepath": "TEMPLATE_PATH/metrics/inbatch_recall_metric.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.metrics.inbatch_recall_metric"
         },
         "('METRICS', 'default', 'loss-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/loss_metric.py",
             "imports": [
-                "typing",
+                "sklearn",
                 "numpy",
-                "sklearn"
+                "typing"
             ],
             "module": "modelscope.metrics.loss_metric"
         },
         "('METRICS', 'default', 'mAP')": {
             "filepath": "TEMPLATE_PATH/metrics/map_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.map_metric"
         },
         "('METRICS', 'default', 'movie-scene-segmentation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/movie_scene_segmentation_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.movie_scene_segmentation_metric"
         },
         "('METRICS', 'default', 'ned')": {
             "filepath": "TEMPLATE_PATH/metrics/ned_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.ned_metric"
         },
         "('METRICS', 'default', 'ocr-recognition-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/ocr_recognition_metric.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
                 "edit_distance",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.metrics.ocr_recognition_metric"
         },
         "('METRICS', 'default', 'ppl')": {
             "filepath": "TEMPLATE_PATH/metrics/ppl_metric.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "math"
+                "numpy",
+                "math",
+                "typing"
             ],
             "module": "modelscope.metrics.ppl_metric"
         },
         "('METRICS', 'default', 'prediction-saving-wrapper')": {
             "filepath": "TEMPLATE_PATH/metrics/prediction_saving_wrapper.py",
             "imports": [
-                "typing",
+                "sklearn",
                 "numpy",
-                "sklearn"
+                "typing"
             ],
             "module": "modelscope.metrics.prediction_saving_wrapper"
         },
         "('METRICS', 'default', 'referring-video-object-segmentation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/referring_video_object_segmentation_metric.py",
             "imports": [
-                "numpy",
+                "tqdm",
+                "typing",
                 "torch",
                 "pycocotools",
-                "typing",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.metrics.referring_video_object_segmentation_metric"
         },
         "('METRICS', 'default', 'seq-cls-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/sequence_classification_metric.py",
             "imports": [
-                "typing",
+                "sklearn",
                 "numpy",
-                "sklearn"
+                "typing"
             ],
             "module": "modelscope.metrics.sequence_classification_metric"
         },
         "('METRICS', 'default', 'text-gen-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/text_generation_metric.py",
             "imports": [
-                "rouge",
+                "contextlib",
                 "nltk",
+                "rouge",
                 "typing",
-                "sys",
-                "contextlib"
+                "sys"
             ],
             "module": "modelscope.metrics.text_generation_metric"
         },
         "('METRICS', 'default', 'text-ranking-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/text_ranking_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.text_ranking_metric"
         },
         "('METRICS', 'default', 'token-cls-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/token_classification_metric.py",
             "imports": [
                 "importlib",
@@ -3113,212 +3182,222 @@
             ],
             "module": "modelscope.metrics.token_classification_metric"
         },
         "('METRICS', 'default', 'translation-evaluation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/translation_evaluation_metric.py",
             "imports": [
                 "importlib",
-                "typing",
-                "pandas"
+                "pandas",
+                "typing"
             ],
             "module": "modelscope.metrics.translation_evaluation_metric"
         },
         "('METRICS', 'default', 'video-frame-interpolation-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_frame_interpolation_metric.py",
             "imports": [
-                "numpy",
                 "lpips",
                 "math",
+                "typing",
                 "torch",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.metrics.video_frame_interpolation_metric"
         },
         "('METRICS', 'default', 'video-stabilization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_stabilization_metric.py",
             "imports": [
                 "numpy",
                 "os",
-                "cv2",
-                "tempfile",
+                "tqdm",
                 "typing",
-                "sys",
-                "tqdm"
+                "tempfile",
+                "cv2",
+                "sys"
             ],
             "module": "modelscope.metrics.video_stabilization_metric"
         },
         "('METRICS', 'default', 'video-summarization-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_summarization_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.video_summarization_metric"
         },
         "('METRICS', 'default', 'video-super-resolution-metric')": {
             "filepath": "TEMPLATE_PATH/metrics/video_super_resolution_metric/video_super_resolution_metric.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.metrics.video_super_resolution_metric.video_super_resolution_metric"
         },
         "('MODELS', 'acoustic-noise-suppression', 'speech_dfsmn_ans')": {
             "filepath": "TEMPLATE_PATH/models/audio/ans/denoise_net.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.audio.ans.denoise_net"
         },
         "('MODELS', 'acoustic-noise-suppression', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/models/audio/ans/frcrn.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.audio.ans.frcrn"
         },
         "('MODELS', 'auto-speech-recognition', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'auto-speech-recognition', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'auto-speech-recognition', 'wenet-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/wenet_automatic_speech_recognition.py",
             "imports": [
-                "wenetruntime",
-                "typing",
                 "os",
-                "json"
+                "wenetruntime",
+                "json",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.wenet_automatic_speech_recognition"
         },
         "('MODELS', 'backbone', 'T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/T5/backbone.py",
             "imports": [
+                "os",
                 "warnings",
-                "math",
                 "transformers",
                 "copy",
-                "torch",
-                "os",
-                "typing"
+                "math",
+                "typing",
+                "torch"
             ],
             "module": "modelscope.models.nlp.T5.backbone"
         },
         "('MODELS', 'backbone', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/backbone.py",
             "imports": [
+                "transformers",
                 "packaging",
                 "torch",
-                "math",
-                "transformers"
+                "math"
             ],
             "module": "modelscope.models.nlp.bert.backbone"
         },
         "('MODELS', 'backbone', 'deberta_v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/deberta_v2/backbone.py",
             "imports": [
-                "typing",
-                "torch",
                 "collections",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.models.nlp.deberta_v2.backbone"
         },
         "('MODELS', 'backbone', 'llama')": {
             "filepath": "TEMPLATE_PATH/models/nlp/llama/backbone.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
                 "math",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.llama.backbone"
         },
+        "('MODELS', 'backbone', 'llama2')": {
+            "filepath": "TEMPLATE_PATH/models/nlp/llama2/backbone.py",
+            "imports": [
+                "transformers",
+                "torch",
+                "math",
+                "typing"
+            ],
+            "module": "modelscope.models.nlp.llama2.backbone"
+        },
         "('MODELS', 'backbone', 'lstm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/lstm/backbone.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.models.nlp.lstm.backbone"
         },
         "('MODELS', 'backbone', 'megatron-bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/megatron_bert/backbone.py",
             "imports": [
+                "transformers",
                 "torch",
-                "math",
-                "transformers"
+                "math"
             ],
             "module": "modelscope.models.nlp.megatron_bert.backbone"
         },
         "('MODELS', 'backbone', 'mgeo')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mgeo/backbone.py",
             "imports": [
-                "dataclasses",
+                "os",
                 "warnings",
-                "math",
-                "random",
                 "transformers",
+                "dataclasses",
+                "math",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "random"
             ],
             "module": "modelscope.models.multi_modal.mgeo.backbone"
         },
         "('MODELS', 'backbone', 'plug-mental')": {
             "filepath": "TEMPLATE_PATH/models/nlp/plug_mental/backbone.py",
             "imports": [
-                "dataclasses",
-                "math",
                 "transformers",
-                "packaging",
+                "math",
+                "typing",
                 "torch",
-                "typing"
+                "packaging",
+                "dataclasses"
             ],
             "module": "modelscope.models.nlp.plug_mental.backbone"
         },
         "('MODELS', 'backbone', 'ponet')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/backbone.py",
             "imports": [
-                "math",
+                "distutils",
                 "transformers",
-                "packaging",
+                "math",
                 "torch",
-                "distutils"
+                "packaging"
             ],
             "module": "modelscope.models.nlp.ponet.backbone"
         },
         "('MODELS', 'backbone', 'structbert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/structbert/backbone.py",
             "imports": [
-                "dataclasses",
-                "math",
                 "transformers",
-                "packaging",
+                "math",
+                "typing",
                 "torch",
-                "typing"
+                "packaging",
+                "dataclasses"
             ],
             "module": "modelscope.models.nlp.structbert.backbone"
         },
         "('MODELS', 'backbone', 'transformers')": {
             "filepath": "TEMPLATE_PATH/models/nlp/hf_transformers/backbone.py",
             "imports": [
                 "transformers"
@@ -3331,822 +3410,821 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.backbone"
         },
         "('MODELS', 'backbone', 'xlm-roberta')": {
             "filepath": "TEMPLATE_PATH/models/nlp/xlm_roberta/backbone.py",
             "imports": [
+                "transformers",
                 "packaging",
                 "torch",
-                "math",
-                "transformers"
+                "math"
             ],
             "module": "modelscope.models.nlp.xlm_roberta.backbone"
         },
         "('MODELS', 'bad-image-detecting', 'bad-image-detecting')": {
             "filepath": "TEMPLATE_PATH/models/cv/bad_image_detecting/bad_image_detecting.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.bad_image_detecting.bad_image_detecting"
         },
         "('MODELS', 'body-2d-keypoints', 'body-2d-keypoints')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_2d_keypoints/hrnet_v2.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.body_2d_keypoints.hrnet_v2"
         },
         "('MODELS', 'body-3d-keypoints', 'body-3d-keypoints')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_3d_keypoints/cannonical_pose/body_3d_pose.py",
             "imports": [
-                "numpy",
-                "torch",
                 "logging",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose"
         },
         "('MODELS', 'body-3d-keypoints', 'hdformer')": {
             "filepath": "TEMPLATE_PATH/models/cv/body_3d_keypoints/hdformer/hdformer_detector.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer_detector"
         },
         "('MODELS', 'card-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py",
             "imports": [
-                "numpy",
-                "torch",
-                "copy",
                 "os",
-                "typing"
+                "copy",
+                "typing",
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.scrfd_detect"
         },
         "('MODELS', 'chat', 'chatglm2-6b')": {
             "filepath": "TEMPLATE_PATH/models/nlp/chatglm2/text_generation.py",
             "imports": [
-                "re",
-                "warnings",
-                "math",
                 "transformers",
+                "warnings",
                 "copy",
-                "torch",
                 "typing",
+                "math",
+                "torch",
                 "sys"
             ],
             "module": "modelscope.models.nlp.chatglm2.text_generation"
         },
         "('MODELS', 'chat', 'chatglm6b')": {
             "filepath": "TEMPLATE_PATH/models/nlp/chatglm/text_generation.py",
             "imports": [
-                "re",
+                "os",
                 "warnings",
-                "math",
                 "transformers",
                 "copy",
-                "torch",
-                "os",
+                "math",
                 "typing",
+                "torch",
+                "re",
                 "sys"
             ],
             "module": "modelscope.models.nlp.chatglm.text_generation"
         },
         "('MODELS', 'code-generation', 'codegeex')": {
             "filepath": "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_generation.py",
             "imports": [
-                "typing",
                 "copy",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.codegeex.codegeex_for_code_generation"
         },
         "('MODELS', 'code-translation', 'codegeex')": {
             "filepath": "TEMPLATE_PATH/models/nlp/codegeex/codegeex_for_code_translation.py",
             "imports": [
-                "typing",
                 "copy",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.codegeex.codegeex_for_code_translation"
         },
         "('MODELS', 'competency-aware-translation', 'canmt')": {
             "filepath": "TEMPLATE_PATH/models/nlp/canmt/canmt_translation.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.nlp.canmt.canmt_translation"
         },
         "('MODELS', 'controllable-image-generation', 'controllable-image-generation')": {
             "filepath": "TEMPLATE_PATH/models/cv/controllable_image_generation/controlnet.py",
             "imports": [
                 "numpy",
-                "control_ldm",
-                "math",
-                "random",
-                "torch",
                 "einops",
                 "os",
                 "cv2",
-                "tempfile",
-                "PIL",
+                "math",
                 "typing",
+                "torch",
+                "PIL",
+                "control_ldm",
+                "tempfile",
+                "random",
                 "sys"
             ],
             "module": "modelscope.models.cv.controllable_image_generation.controlnet"
         },
         "('MODELS', 'crowd-counting', 'HRNetCrowdCounting')": {
             "filepath": "TEMPLATE_PATH/models/cv/crowd_counting/cc_model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.crowd_counting.cc_model"
         },
         "('MODELS', 'document-grounded-dialog-generate', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_generate.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_generate"
         },
         "('MODELS', 'document-grounded-dialog-rerank', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_rerank.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_rerank"
         },
         "('MODELS', 'document-grounded-dialog-retrieval', 'doc2bot')": {
             "filepath": "TEMPLATE_PATH/models/nlp/dgds/document_grounded_dialog_retrieval.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.nlp.dgds.document_grounded_dialog_retrieval"
         },
         "('MODELS', 'document-segmentation', 'bert-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.bert.document_segmentation"
         },
         "('MODELS', 'document-segmentation', 'ponet-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.ponet.document_segmentation"
         },
         "('MODELS', 'document-vl-embedding', 'vldoc')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/vldoc/model.py",
             "imports": [
-                "re",
-                "math",
-                "torchvision",
-                "copy",
                 "logging",
                 "os",
+                "copy",
+                "math",
                 "torch",
+                "re",
+                "torchvision",
                 "sys",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.vldoc.model"
         },
         "('MODELS', 'domain-specific-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py",
             "imports": [],
             "module": "modelscope.models.cv.tinynas_detection.tinynas_damoyolo"
         },
         "('MODELS', 'efficient-diffusion-tuning', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/efficient_diffusion_tuning/efficient_stable_diffusion.py",
             "imports": [
                 "functools",
-                "diffusers",
+                "os",
                 "transformers",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "diffusers"
             ],
             "module": "modelscope.models.multi_modal.efficient_diffusion_tuning.efficient_stable_diffusion"
         },
         "('MODELS', 'extractive-summarization', 'ponet-for-document-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/document_segmentation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.ponet.document_segmentation"
         },
         "('MODELS', 'face-2d-keypoints', 'flc')": {
             "filepath": "TEMPLATE_PATH/models/cv/facial_landmark_confidence/flc/facial_landmark_confidence.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "torch",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.facial_landmark_confidence.flc.facial_landmark_confidence"
         },
         "('MODELS', 'face-attribute-recognition', 'fairface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_attribute_recognition/fair_face/face_attribute_recognition.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
+                "torch",
+                "PIL",
                 "cv2",
-                "PIL"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_attribute_recognition.fair_face.face_attribute_recognition"
         },
         "('MODELS', 'face-detection', 'damofd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/damofd_detect.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "copy",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.damofd_detect"
         },
         "('MODELS', 'face-detection', 'mogface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/mogface/models/detectors.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.mogface.models.detectors"
         },
         "('MODELS', 'face-detection', 'mtcnn')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/mtcnn/models/detector.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
+                "numpy",
                 "PIL"
             ],
             "module": "modelscope.models.cv.face_detection.mtcnn.models.detector"
         },
         "('MODELS', 'face-detection', 'retinaface')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/retinaface/detection.py",
             "imports": [
-                "numpy",
                 "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.retinaface.detection"
         },
         "('MODELS', 'face-detection', 'scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/scrfd_detect.py",
             "imports": [
-                "numpy",
-                "torch",
-                "copy",
                 "os",
-                "typing"
+                "copy",
+                "typing",
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.scrfd_detect"
         },
         "('MODELS', 'face-detection', 'tinymog')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/tinymog_detect.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "copy",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.tinymog_detect"
         },
         "('MODELS', 'face-detection', 'ulfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/ulfd_slim/detection.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.ulfd_slim.detection"
         },
         "('MODELS', 'face-emotion', 'face-emotion')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_emotion/emotion_model.py",
             "imports": [
-                "sys",
+                "os",
                 "torch",
-                "os"
+                "sys"
             ],
             "module": "modelscope.models.cv.face_emotion.emotion_model"
         },
         "('MODELS', 'face-human-hand-detection', 'face-human-hand-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_human_hand_detection/det_infer.py",
             "imports": [
-                "numpy",
                 "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.models.cv.face_human_hand_detection.det_infer"
         },
         "('MODELS', 'face-recognition', 'rts-backbone')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_recognition/torchkit/rts_backbone.py",
             "imports": [
-                "os",
-                "torch",
                 "collections",
+                "torch",
+                "os",
                 "math"
             ],
             "module": "modelscope.models.cv.face_recognition.torchkit.rts_backbone"
         },
         "('MODELS', 'face-reconstruction', 'face_reconstruction')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_reconstruction/models/facerecon_model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
                 "os",
-                "cv2"
+                "torch",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_reconstruction.models.facerecon_model"
         },
         "('MODELS', 'facial-expression-recognition', 'fer')": {
             "filepath": "TEMPLATE_PATH/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "torch",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.facial_expression_recognition.fer.facial_expression_recognition"
         },
         "('MODELS', 'faq-question-answering', 'structbert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/structbert/faq_question_answering.py",
             "imports": [
-                "math",
-                "torch",
                 "collections",
                 "os",
-                "typing"
+                "math",
+                "typing",
+                "torch"
             ],
             "module": "modelscope.models.nlp.structbert.faq_question_answering"
         },
         "('MODELS', 'feature-extraction', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/feature_extraction.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.feature_extraction"
         },
         "('MODELS', 'fid-dialogue', 'fid-T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/fid_T5/text_generation.py",
             "imports": [
-                "torch",
                 "os",
-                "io",
-                "transformers"
+                "torch",
+                "transformers",
+                "io"
             ],
             "module": "modelscope.models.nlp.fid_T5.text_generation"
         },
         "('MODELS', 'fid-dialogue', 'fid-plug')": {
             "filepath": "TEMPLATE_PATH/models/nlp/fid_plug/text_generation.py",
             "imports": [
-                "torch",
                 "os",
-                "io",
-                "transformers"
+                "torch",
+                "transformers",
+                "io"
             ],
             "module": "modelscope.models.nlp.fid_plug.text_generation"
         },
         "('MODELS', 'fill-mask', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/fill_mask.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.fill_mask"
         },
         "('MODELS', 'fill-mask', 'deberta_v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/deberta_v2/fill_mask.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.deberta_v2.fill_mask"
         },
         "('MODELS', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/fill_mask.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.fill_mask"
         },
         "('MODELS', 'fill-mask', 'megatron-bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/megatron_bert/fill_mask.py",
             "imports": [
-                "torch",
-                "transformers"
+                "transformers",
+                "torch"
             ],
             "module": "modelscope.models.nlp.megatron_bert.fill_mask"
         },
         "('MODELS', 'fill-mask', 'ponet')": {
             "filepath": "TEMPLATE_PATH/models/nlp/ponet/fill_mask.py",
             "imports": [
-                "torch",
-                "transformers"
+                "transformers",
+                "torch"
             ],
             "module": "modelscope.models.nlp.ponet.fill_mask"
         },
         "('MODELS', 'fill-mask', 'structbert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/structbert/fill_mask.py",
             "imports": [
-                "torch",
-                "transformers"
+                "transformers",
+                "torch"
             ],
             "module": "modelscope.models.nlp.structbert.fill_mask"
         },
         "('MODELS', 'fill-mask', 'veco')": {
             "filepath": "TEMPLATE_PATH/models/nlp/veco/fill_mask.py",
             "imports": [
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.fill_mask"
         },
         "('MODELS', 'generative-multi-modal-embedding', 'gemm-generative-multi-modal')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/gemm/gemm_model.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "PIL",
                 "typing",
+                "torch",
+                "PIL",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.gemm.gemm_model"
         },
         "('MODELS', 'generative-multi-modal-embedding', 'rleg-generative-multi-modal')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/rleg/rleg.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.rleg.rleg"
         },
         "('MODELS', 'hand-static', 'hand-static')": {
             "filepath": "TEMPLATE_PATH/models/cv/hand_static/hand_model.py",
             "imports": [
                 "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "cv2",
+                "torch",
                 "PIL",
+                "cv2",
+                "torchvision",
                 "sys"
             ],
             "module": "modelscope.models.cv.hand_static.hand_model"
         },
         "('MODELS', 'human-detection', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_model"
         },
         "('MODELS', 'human-reconstruction', 'human-reconstruction')": {
             "filepath": "TEMPLATE_PATH/models/cv/human_reconstruction/Reconstruction.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
-                "PIL",
                 "os",
                 "typing",
-                "skimage"
+                "skimage",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.human_reconstruction.Reconstruction"
         },
         "('MODELS', 'image-body-reshaping', 'image-body-reshaping')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_body_reshaping/image_body_reshaping.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_body_reshaping.image_body_reshaping"
         },
         "('MODELS', 'image-captioning', 'clip-interrogator')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/clip_interrogator/model.py",
             "imports": [
-                "safetensors",
                 "hashlib",
-                "math",
-                "torchvision",
-                "torch",
-                "os",
-                "typing",
+                "safetensors",
                 "open_clip",
                 "tqdm",
-                "numpy",
+                "math",
+                "time",
+                "torch",
+                "PIL",
                 "dataclasses",
+                "torchvision",
+                "numpy",
+                "os",
                 "requests",
-                "time",
                 "transformers",
-                "PIL"
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.clip_interrogator.model"
         },
         "('MODELS', 'image-captioning', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'image-captioning', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'image-classification', 'ClassificationModel')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/mmcls_model.py",
             "imports": [
                 "os"
             ],
             "module": "modelscope.models.cv.image_classification.mmcls_model"
         },
         "('MODELS', 'image-classification', 'EasyRobustModel')": {
             "filepath": "TEMPLATE_PATH/models/cv/robust_image_classification/easyrobust_model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.robust_image_classification.easyrobust_model"
         },
         "('MODELS', 'image-classification', 'bnext')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_binary_quant_classification/binary_quant_model.py",
             "imports": [
-                "torch",
                 "collections",
+                "torch",
                 "os"
             ],
             "module": "modelscope.models.cv.image_binary_quant_classification.binary_quant_model"
         },
         "('MODELS', 'image-classification', 'content-check')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_classification/resnet50_cc.py",
             "imports": [
-                "torchvision",
+                "collections",
+                "os",
                 "math",
                 "torch",
-                "collections",
-                "os"
+                "torchvision"
             ],
             "module": "modelscope.models.cv.image_classification.resnet50_cc"
         },
         "('MODELS', 'image-classification', 'image-probing-model')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_probing_model/model.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "json"
+                "torch",
+                "json",
+                "typing"
             ],
             "module": "modelscope.models.cv.image_probing_model.model"
         },
         "('MODELS', 'image-classification', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'image-color-enhancement', 'adaint')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/adaint/adaint.py",
             "imports": [
-                "torchvision",
-                "torch",
                 "os",
                 "typing",
+                "torch",
+                "torchvision",
                 "numbers"
             ],
             "module": "modelscope.models.cv.image_color_enhance.adaint.adaint"
         },
         "('MODELS', 'image-color-enhancement', 'csrnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/image_color_enhance.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_color_enhance.image_color_enhance"
         },
         "('MODELS', 'image-color-enhancement', 'deeplpfnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_color_enhance/deeplpf/deeplpf_image_color_enhance.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_color_enhance.deeplpf.deeplpf_image_color_enhance"
         },
         "('MODELS', 'image-colorization', 'ddcolor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_colorization/ddcolor/ddcolor_for_image_colorization.py",
             "imports": [
-                "numpy",
-                "torch",
-                "copy",
                 "os",
-                "typing"
+                "copy",
+                "typing",
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_colorization.ddcolor.ddcolor_for_image_colorization"
         },
         "('MODELS', 'image-debanding', 'rrdb')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_debanding/rrdb/rrdb_image_debanding.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_debanding.rrdb.rrdb_image_debanding"
         },
         "('MODELS', 'image-deblurring', 'nafnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_deblur/nafnet_for_image_deblur.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_deblur.nafnet_for_image_deblur"
         },
         "('MODELS', 'image-demoireing', 'image-restoration')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_restoration/image_restoration_model.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
+                "numpy",
                 "cv2"
             ],
             "module": "modelscope.models.cv.image_restoration.image_restoration_model"
         },
         "('MODELS', 'image-denoising', 'nafnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_denoise/nafnet_for_image_denoise.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_denoise.nafnet_for_image_denoise"
         },
         "('MODELS', 'image-depth-estimation', 'bts-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_depth_estimation_bts/depth_estimation_bts_model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.image_depth_estimation_bts.depth_estimation_bts_model"
         },
         "('MODELS', 'image-depth-estimation', 'newcrfs-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_depth_estimation/newcrfs_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_depth_estimation.newcrfs_model"
         },
         "('MODELS', 'image-driving-perception', 'yolopv2')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_driving_perception/image_driving_percetion_model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_driving_perception.image_driving_percetion_model"
         },
         "('MODELS', 'image-face-fusion', 'image-face-fusion')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_face_fusion/image_face_fusion.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "collections",
-                "cv2",
-                "PIL",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_face_fusion.image_face_fusion"
         },
         "('MODELS', 'image-fewshot-detection', 'defrcn')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_defrcn_fewshot/defrcn_for_fewshot.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_defrcn_fewshot.defrcn_for_fewshot"
         },
         "('MODELS', 'image-inpainting', 'FFTInpainting')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_inpainting/model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_inpainting.model"
         },
         "('MODELS', 'image-matching', 'quadtree-attention-image-matching')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_matching/quadtree_attention_model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "pathlib",
+                "torch",
                 "cv2",
-                "pathlib"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_matching.quadtree_attention_model"
         },
         "('MODELS', 'image-multi-view-depth-estimation', 'image-casmvs-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_mvs_depth_estimation/casmvs_model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "easydict",
+                "torch",
                 "cv2",
-                "easydict"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_mvs_depth_estimation.casmvs_model"
         },
         "('MODELS', 'image-object-detection', 'MaskScoring')": {
             "filepath": "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_model"
         },
         "('MODELS', 'image-object-detection', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_model"
         },
         "('MODELS', 'image-object-detection', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_damoyolo.py",
             "imports": [],
             "module": "modelscope.models.cv.tinynas_detection.tinynas_damoyolo"
@@ -4155,367 +4233,410 @@
             "filepath": "TEMPLATE_PATH/models/cv/tinynas_detection/tinynas_detector.py",
             "imports": [],
             "module": "modelscope.models.cv.tinynas_detection.tinynas_detector"
         },
         "('MODELS', 'image-object-detection', 'vidt')": {
             "filepath": "TEMPLATE_PATH/models/cv/vidt/model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.vidt.model"
         },
         "('MODELS', 'image-paintbyexample', 'Stablediffusion-Paintbyexample')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_paintbyexample/model.py",
             "imports": [
-                "torch",
+                "omegaconf",
                 "os",
                 "typing",
-                "paint_ldm",
-                "omegaconf"
+                "torch",
+                "paint_ldm"
             ],
             "module": "modelscope.models.cv.image_paintbyexample.model"
         },
         "('MODELS', 'image-portrait-enhancement', 'gpen')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_portrait_enhancement/image_portrait_enhancement.py",
             "imports": [
-                "typing",
                 "os",
                 "torch",
-                "math"
+                "math",
+                "typing"
             ],
             "module": "modelscope.models.cv.image_portrait_enhancement.image_portrait_enhancement"
         },
         "('MODELS', 'image-quality-assessment-degradation', 'image-quality-assessment-degradation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_degradation/image_quality_assessment_degradation.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_degradation.image_quality_assessment_degradation"
         },
         "('MODELS', 'image-quality-assessment-mos', 'image-quality-assessment-man')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_man/image_quality_assessment_man.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_man.image_quality_assessment_man"
         },
         "('MODELS', 'image-quality-assessment-mos', 'image-quality-assessment-mos')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_quality_assessment_mos/image_quality_assessment_mos.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_quality_assessment_mos.image_quality_assessment_mos"
         },
         "('MODELS', 'image-reid-person', 'passvitb')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_reid_person/pass_model.py",
             "imports": [
+                "os",
                 "enum",
-                "torch",
-                "os"
+                "torch"
             ],
             "module": "modelscope.models.cv.image_reid_person.pass_model"
         },
         "('MODELS', 'image-segmentation', 'cascade_mask_rcnn_swin')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.model"
         },
         "('MODELS', 'image-segmentation', 'fastinst')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/fastinst_model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.fastinst_model"
         },
         "('MODELS', 'image-segmentation', 'm2fp')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_human_parsing/m2fp_net.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_human_parsing.m2fp_net"
         },
         "('MODELS', 'image-segmentation', 'maskdino_swin')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_instance_segmentation/maskdino_model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.image_instance_segmentation.maskdino_model"
         },
         "('MODELS', 'image-segmentation', 'swinL-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_panoptic_segmentation/panseg_model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.image_panoptic_segmentation.panseg_model"
         },
         "('MODELS', 'image-segmentation', 'swinL-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model"
         },
         "('MODELS', 'image-segmentation', 'vision-middleware')": {
             "filepath": "TEMPLATE_PATH/models/cv/vision_middleware/model.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "json"
+                "torch",
+                "json",
+                "typing"
             ],
             "module": "modelscope.models.cv.vision_middleware.model"
         },
         "('MODELS', 'image-segmentation', 'vitadapter-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/semantic_seg_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model"
         },
         "('MODELS', 'image-skychange', 'image-skychange')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_skychange/skychange_model.py",
             "imports": [
-                "time",
-                "math",
-                "torch",
                 "collections",
-                "os",
-                "cv2",
                 "pdb",
+                "os",
+                "math",
+                "time",
                 "typing",
+                "torch",
+                "cv2",
                 "json"
             ],
             "module": "modelscope.models.cv.image_skychange.skychange_model"
         },
         "('MODELS', 'image-super-resolution', 'ecbsr')": {
             "filepath": "TEMPLATE_PATH/models/cv/super_resolution/ecbsr_model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.super_resolution.ecbsr_model"
         },
         "('MODELS', 'image-text-retrieval', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
+        "('MODELS', 'image-try-on', 'image-try-on')": {
+            "filepath": "TEMPLATE_PATH/models/cv/image_try_on/try_on_infer.py",
+            "imports": [
+                "os",
+                "yaml",
+                "argparse",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy"
+            ],
+            "module": "modelscope.models.cv.image_try_on.try_on_infer"
+        },
         "('MODELS', 'indoor-layout-estimation', 'panovit-layout-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/indoor_layout_estimation/panovit.py",
             "imports": [
-                "yacs",
+                "os",
                 "numpy",
                 "torch",
-                "os"
+                "yacs"
             ],
             "module": "modelscope.models.cv.indoor_layout_estimation.panovit"
         },
         "('MODELS', 'information-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.information_extraction"
         },
         "('MODELS', 'inverse-text-processing', 'generic-itn')": {
             "filepath": "TEMPLATE_PATH/models/audio/itn/generic_inverse_text_processing.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.itn.generic_inverse_text_processing"
         },
         "('MODELS', 'keyword-spotting', 'kws-kwsbp')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/generic_key_word_spotting.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.kws.generic_key_word_spotting"
         },
         "('MODELS', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/farfield/model.py",
             "imports": [
-                "typing",
                 "os",
-                "tempfile"
+                "tempfile",
+                "typing"
             ],
             "module": "modelscope.models.audio.kws.farfield.model"
         },
         "('MODELS', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield_iot')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/farfield/model.py",
             "imports": [
-                "typing",
                 "os",
-                "tempfile"
+                "tempfile",
+                "typing"
             ],
             "module": "modelscope.models.audio.kws.farfield.model"
         },
         "('MODELS', 'keyword-spotting', 'speech_kws_fsmn_char_ctc_nearfield')": {
             "filepath": "TEMPLATE_PATH/models/audio/kws/nearfield/model.py",
             "imports": [
-                "torch",
                 "os",
-                "tempfile",
                 "typing",
+                "torch",
+                "tempfile",
                 "sys"
             ],
             "module": "modelscope.models.audio.kws.nearfield.model"
         },
         "('MODELS', 'language-guided-video-summarization', 'clip-it-language-guided-video-summarization')": {
             "filepath": "TEMPLATE_PATH/models/cv/language_guided_video_summarization/summarizer.py",
             "imports": [
-                "numpy",
-                "videofeatures_clipit",
-                "torch",
                 "os",
-                "argparse",
                 "typing",
+                "argparse",
+                "videofeatures_clipit",
+                "torch",
+                "numpy",
                 "bmt_clipit"
             ],
             "module": "modelscope.models.cv.language_guided_video_summarization.summarizer"
         },
         "('MODELS', 'language-score-prediction', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'lineless-table-recognition', 'LoreModel')": {
             "filepath": "TEMPLATE_PATH/models/cv/table_recognition/model_lore.py",
             "imports": [
-                "numpy",
-                "math",
+                "os",
                 "copy",
+                "typing",
+                "math",
                 "torch",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.cv.table_recognition.model_lore"
         },
         "('MODELS', 'movie-scene-segmentation', 'resnet50-bert')": {
             "filepath": "TEMPLATE_PATH/models/cv/movie_scene_segmentation/model.py",
             "imports": [
-                "numpy",
-                "math",
-                "torchvision",
-                "torch",
                 "einops",
                 "os",
-                "PIL",
-                "shotdetect_scenedetect_lgss",
+                "tqdm",
+                "math",
                 "typing",
-                "tqdm"
+                "shotdetect_scenedetect_lgss",
+                "torch",
+                "PIL",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.movie_scene_segmentation.model"
         },
         "('MODELS', 'multi-modal-embedding', 'clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/clip/model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
                 "os",
                 "typing",
+                "torch",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.clip.model"
         },
         "('MODELS', 'multi-modal-similarity', 'team-multi-modal-similarity')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/team/team_model.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "tokenizers",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "tokenizers",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.multi_modal.team.team_model"
         },
         "('MODELS', 'multimodal-dialogue', 'mplug-owl')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_owl/modeling_mplug_owl.py",
             "imports": [
-                "dataclasses",
-                "math",
-                "random",
-                "transformers",
-                "copy",
                 "logging",
                 "os",
-                "torch",
+                "transformers",
+                "copy",
+                "dataclasses",
+                "math",
                 "typing",
-                "io"
+                "torch",
+                "io",
+                "random"
             ],
             "module": "modelscope.models.multi_modal.mplug_owl.modeling_mplug_owl"
         },
         "('MODELS', 'named-entity-recognition', 'lstm-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/lstm/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.lstm.token_classification"
         },
         "('MODELS', 'named-entity-recognition', 'token-classification-for-ner')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'named-entity-recognition', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
+        "('MODELS', 'nerf-recon-4k', 'nerf-recon-4k')": {
+            "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_4k/nerf_recon_4k.py",
+            "imports": [
+                "mmcv",
+                "os",
+                "tqdm",
+                "time",
+                "argparse",
+                "torch",
+                "imageio",
+                "random",
+                "numpy"
+            ],
+            "module": "modelscope.models.cv.nerf_recon_4k.nerf_recon_4k"
+        },
         "('MODELS', 'nerf-recon-acc', 'nerf-recon-acc')": {
             "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_recon_acc.py",
             "imports": [
-                "numpy",
+                "os",
+                "tqdm",
                 "time",
-                "glob",
                 "torch",
+                "glob",
                 "cv2",
-                "os",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.models.cv.nerf_recon_acc.nerf_recon_acc"
         },
+        "('MODELS', 'nerf-recon-vq-compression', 'nerf-recon-vq-compression')": {
+            "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_vq_compression/nerf_recon_vq_compression.py",
+            "imports": [
+                "functools",
+                "os",
+                "tqdm",
+                "time",
+                "torch",
+                "glob",
+                "cv2",
+                "numpy"
+            ],
+            "module": "modelscope.models.cv.nerf_recon_vq_compression.nerf_recon_vq_compression"
+        },
         "('MODELS', 'nli', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
         },
         "('MODELS', 'nli', 'mgeo')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mgeo/text_classification.py",
@@ -4552,73 +4673,83 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'object-detection-3d', 'depe')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/depe_detect.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.depe_detect"
         },
         "('MODELS', 'ocr-detection', 'OCRDetection')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_detection/model.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.cv.ocr_detection.model"
         },
         "('MODELS', 'ocr-recognition', 'OCRRecognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_recognition/model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.ocr_recognition.model"
         },
         "('MODELS', 'ocr-recognition', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'open-vocabulary-detection', 'open-vocabulary-detection-vild')": {
             "filepath": "TEMPLATE_PATH/models/cv/open_vocabulary_detection_vild/vild.py",
             "imports": [
-                "numpy",
+                "os",
                 "clip",
+                "scipy",
+                "typing",
                 "tensorflow",
                 "torch",
-                "os",
-                "typing",
-                "scipy"
+                "numpy"
             ],
             "module": "modelscope.models.cv.open_vocabulary_detection_vild.vild"
         },
+        "('MODELS', 'panorama-depth-estimation', 's2net-depth-estimation')": {
+            "filepath": "TEMPLATE_PATH/models/cv/s2net_panorama_depth_estimation/s2net_model.py",
+            "imports": [
+                "os",
+                "torch",
+                "torchvision",
+                "numpy"
+            ],
+            "module": "modelscope.models.cv.s2net_panorama_depth_estimation.s2net_model"
+        },
         "('MODELS', 'panorama-depth-estimation', 'unifuse-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/panorama_depth_estimation/unifuse_model.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.panorama_depth_estimation.unifuse_model"
         },
         "('MODELS', 'part-of-speech', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.token_classification"
@@ -4641,119 +4772,119 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'part-of-speech', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'part-of-speech', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'pedestrian-attribute-recognition', 'pedestrian-attribute-recognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/pedestrian_attribute_recognition/model.py",
             "imports": [
-                "numpy",
                 "os",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.pedestrian_attribute_recognition.model"
         },
         "('MODELS', 'pointcloud-sceneflow-estimation', 'rcp-sceneflow-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/pointcloud_sceneflow_estimation/rcp_model.py",
             "imports": [
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy"
             ],
             "module": "modelscope.models.cv.pointcloud_sceneflow_estimation.rcp_model"
         },
         "('MODELS', 'product-retrieval-embedding', 'product-retrieval-embedding')": {
             "filepath": "TEMPLATE_PATH/models/cv/product_retrieval_embedding/item_model.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.cv.product_retrieval_embedding.item_model"
         },
         "('MODELS', 'product-segmentation', 'product-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/product_segmentation/seg_infer.py",
             "imports": [
                 "numpy",
-                "cv2",
                 "torch",
+                "cv2",
                 "PIL"
             ],
             "module": "modelscope.models.cv.product_segmentation.seg_infer"
         },
         "('MODELS', 'protein-structure', 'unifold')": {
             "filepath": "TEMPLATE_PATH/models/science/unifold/model.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "argparse"
+                "torch",
+                "argparse",
+                "typing"
             ],
             "module": "modelscope.models.science.unifold.model"
         },
         "('MODELS', 'punctuation', 'generic-punc')": {
             "filepath": "TEMPLATE_PATH/models/audio/punc/generic_punctuation.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.punc.generic_punctuation"
         },
         "('MODELS', 'referring-video-object-segmentation', 'swinT-referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/referring_video_object_segmentation/model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.referring_video_object_segmentation.model"
         },
         "('MODELS', 'relation-extraction', 'information-extraction')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/information_extraction.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.information_extraction"
         },
         "('MODELS', 'semantic-segmentation', 'ddpm')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/ddpm_segmentation_model.py",
             "imports": [
-                "ddpm_guided_diffusion",
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "ddpm_guided_diffusion",
+                "typing"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.ddpm_segmentation_model"
         },
         "('MODELS', 'semantic-segmentation', 'detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/salient_detection/salient_model.py",
             "imports": [
-                "torchvision",
-                "torch",
                 "os",
+                "torch",
+                "PIL",
                 "cv2",
-                "PIL"
+                "torchvision"
             ],
             "module": "modelscope.models.cv.salient_detection.salient_model"
         },
         "('MODELS', 'sentence-embedding', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/sentence_embedding.py",
             "imports": [
                 "torch"
@@ -4841,201 +4972,242 @@
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'shop-segmentation', 'shop-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/shop_segmentation/shop_seg_model.py",
             "imports": [
-                "numpy",
-                "torch",
-                "PIL",
                 "os",
                 "typing",
+                "torch",
+                "PIL",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.cv.shop_segmentation.shop_seg_model"
         },
         "('MODELS', 'siamese-uie', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/siamese_uie.py",
             "imports": [
-                "torch",
-                "copy"
+                "copy",
+                "torch"
             ],
             "module": "modelscope.models.nlp.bert.siamese_uie"
         },
         "('MODELS', 'speaker-diarization', 'cluster-backend')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/cluster_backend.py",
             "imports": [
-                "typing",
-                "numpy",
+                "hdbscan",
                 "sklearn",
-                "scipy"
+                "scipy",
+                "umap",
+                "typing",
+                "numpy"
             ],
             "module": "modelscope.models.audio.sv.cluster_backend"
         },
         "('MODELS', 'speaker-diarization', 'generic-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.sv.generic_speaker_verification"
         },
         "('MODELS', 'speaker-diarization', 'scl-sd')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_change_locator.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
                 "os",
                 "typing",
-                "torchaudio"
+                "torch",
+                "torchaudio",
+                "numpy"
             ],
             "module": "modelscope.models.audio.sv.speaker_change_locator"
         },
+        "('MODELS', 'speaker-diarization-dialogue-detection', 'bert')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_dialogue_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_dialogue_detection"
+        },
+        "('MODELS', 'speaker-diarization-dialogue-detection', 'text-classification')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_dialogue_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_dialogue_detection"
+        },
+        "('MODELS', 'speaker-diarization-semantic-speaker-turn-detection', 'bert')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_semantic_speaker_turn_detection"
+        },
+        "('MODELS', 'speaker-diarization-semantic-speaker-turn-detection', 'token-classification')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py",
+            "imports": [
+                "torch"
+            ],
+            "module": "modelscope.models.audio.sv.speaker_diarization_semantic_speaker_turn_detection"
+        },
         "('MODELS', 'speaker-verification', 'cam++-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/DTDNN.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
                 "os",
                 "typing",
-                "torchaudio"
+                "torch",
+                "torchaudio",
+                "numpy"
             ],
             "module": "modelscope.models.audio.sv.DTDNN"
         },
         "('MODELS', 'speaker-verification', 'ecapa-tdnn-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/ecapa_tdnn.py",
             "imports": [
-                "numpy",
-                "math",
-                "torch",
                 "os",
                 "typing",
-                "torchaudio"
+                "math",
+                "torch",
+                "torchaudio",
+                "numpy"
             ],
             "module": "modelscope.models.audio.sv.ecapa_tdnn"
         },
         "('MODELS', 'speaker-verification', 'eres2net-aug-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/ERes2Net_aug.py",
             "imports": [
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
                 "torchaudio"
             ],
             "module": "modelscope.models.audio.sv.ERes2Net_aug"
         },
         "('MODELS', 'speaker-verification', 'eres2net-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/ERes2Net.py",
             "imports": [
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
                 "torchaudio"
             ],
             "module": "modelscope.models.audio.sv.ERes2Net"
         },
         "('MODELS', 'speaker-verification', 'generic-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/generic_speaker_verification.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.sv.generic_speaker_verification"
         },
         "('MODELS', 'speaker-verification', 'rdino_ecapa-tdnn-sv')": {
             "filepath": "TEMPLATE_PATH/models/audio/sv/rdino.py",
             "imports": [
-                "math",
-                "torch",
                 "os",
+                "math",
                 "typing",
+                "torch",
                 "torchaudio"
             ],
             "module": "modelscope.models.audio.sv.rdino"
         },
+        "('MODELS', 'speech-language-recognition', 'cam++-lre')": {
+            "filepath": "TEMPLATE_PATH/models/audio/sv/lanuage_recognition_model.py",
+            "imports": [
+                "os",
+                "typing",
+                "torch",
+                "torchaudio",
+                "numpy"
+            ],
+            "module": "modelscope.models.audio.sv.lanuage_recognition_model"
+        },
         "('MODELS', 'speech-separation', 'speech_mossformer_separation_temporal_8k')": {
             "filepath": "TEMPLATE_PATH/models/audio/separation/mossformer.py",
             "imports": [
-                "typing",
-                "copy",
                 "os",
-                "torch"
+                "copy",
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.audio.separation.mossformer"
         },
         "('MODELS', 'speech-timestamp', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'sudoku', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'table-question-answering', 'space-T-cn')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space_T_cn/table_question_answering.py",
             "imports": [
-                "numpy",
+                "os",
                 "transformers",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.nlp.space_T_cn.table_question_answering"
         },
         "('MODELS', 'table-question-answering', 'space-T-en')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space_T_en/text_to_sql.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
                 "text2sql_lgesql",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.nlp.space_T_en.text_to_sql"
         },
         "('MODELS', 'task-oriented-conversation', 'space-dst')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_state_tracking.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.models.nlp.space.dialog_state_tracking"
         },
         "('MODELS', 'task-oriented-conversation', 'space-intent')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_intent_prediction.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.nlp.space.dialog_intent_prediction"
         },
         "('MODELS', 'task-oriented-conversation', 'space-modeling')": {
             "filepath": "TEMPLATE_PATH/models/nlp/space/dialog_modeling.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.nlp.space.dialog_modeling"
         },
         "('MODELS', 'text-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
@@ -5046,21 +5218,21 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_classification"
         },
         "('MODELS', 'text-classification', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text-classification', 'peer')": {
             "filepath": "TEMPLATE_PATH/models/nlp/peer/text_classification.py",
             "imports": [
@@ -5082,125 +5254,144 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.text_classification"
         },
         "('MODELS', 'text-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/text_classification.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.text_classification"
         },
         "('MODELS', 'text-classification', 'user-satisfaction-estimation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/use/user_satisfaction_estimation.py",
             "imports": [
-                "numpy",
+                "os",
                 "transformers",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.models.nlp.use.user_satisfaction_estimation"
         },
         "('MODELS', 'text-classification', 'veco')": {
             "filepath": "TEMPLATE_PATH/models/nlp/veco/text_classification.py",
             "imports": [
                 "transformers"
             ],
             "module": "modelscope.models.nlp.veco.text_classification"
         },
         "('MODELS', 'text-driven-segmentation', 'text-driven-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/text_driven_segmentation/lseg_model.py",
             "imports": [
-                "numpy",
-                "torch",
-                "PIL",
                 "os",
                 "typing",
+                "torch",
+                "PIL",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.cv.text_driven_segmentation.lseg_model"
         },
         "('MODELS', 'text-error-correction', 'bart')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bart/text_error_correction.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.nlp.bart.text_error_correction"
         },
         "('MODELS', 'text-generation', 'glm130b')": {
             "filepath": "TEMPLATE_PATH/models/nlp/glm_130b/text_generation.py",
             "imports": [
-                "re",
                 "functools",
-                "time",
-                "SwissArmyTransformer",
-                "random",
+                "os",
                 "copy",
+                "typing",
+                "time",
                 "torch",
                 "stat",
-                "os",
-                "typing",
+                "re",
+                "SwissArmyTransformer",
+                "random",
                 "sys"
             ],
             "module": "modelscope.models.nlp.glm_130b.text_generation"
         },
         "('MODELS', 'text-generation', 'gpt-moe')": {
             "filepath": "TEMPLATE_PATH/models/nlp/gpt_moe/text_generation.py",
             "imports": [
-                "typing",
-                "transformers"
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.models.nlp.gpt_moe.text_generation"
         },
         "('MODELS', 'text-generation', 'gpt3')": {
             "filepath": "TEMPLATE_PATH/models/nlp/gpt3/text_generation.py",
             "imports": [
-                "typing",
-                "torch",
                 "collections",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.models.nlp.gpt3.text_generation"
         },
         "('MODELS', 'text-generation', 'llama')": {
             "filepath": "TEMPLATE_PATH/models/nlp/llama/text_generation.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.llama.text_generation"
         },
+        "('MODELS', 'text-generation', 'llama2')": {
+            "filepath": "TEMPLATE_PATH/models/nlp/llama2/text_generation.py",
+            "imports": [
+                "transformers",
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.models.nlp.llama2.text_generation"
+        },
         "('MODELS', 'text-generation', 'palm-v2')": {
             "filepath": "TEMPLATE_PATH/models/nlp/palm_v2/text_generation.py",
             "imports": [
-                "numpy",
-                "dataclasses",
-                "subprocess",
-                "codecs",
-                "math",
+                "os",
                 "transformers",
                 "copy",
-                "torch",
-                "os",
+                "math",
                 "typing",
+                "codecs",
+                "torch",
+                "dataclasses",
+                "subprocess",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.nlp.palm_v2.text_generation"
         },
+        "('MODELS', 'text-generation', 'polylm')": {
+            "filepath": "TEMPLATE_PATH/models/nlp/polylm/text_generation.py",
+            "imports": [
+                "collections",
+                "torch",
+                "transformers",
+                "typing"
+            ],
+            "module": "modelscope.models.nlp.polylm.text_generation"
+        },
         "('MODELS', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/text_generation.py",
             "imports": [
-                "typing",
-                "numpy",
+                "transformers",
                 "torch",
-                "transformers"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.text_generation"
         },
         "('MODELS', 'text-ranking', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_ranking.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_ranking"
@@ -5211,145 +5402,146 @@
                 "torch"
             ],
             "module": "modelscope.models.multi_modal.mgeo.text_ranking"
         },
         "('MODELS', 'text-ranking', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/text_ranking.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.text_ranking"
         },
         "('MODELS', 'text-summarization', 'mglm')": {
             "filepath": "TEMPLATE_PATH/models/nlp/mglm/mglm_for_text_summarization.py",
             "imports": [
-                "numpy",
-                "random",
-                "torch",
+                "megatron_util",
                 "os",
                 "typing",
-                "megatron_util"
+                "torch",
+                "random",
+                "numpy"
             ],
             "module": "modelscope.models.nlp.mglm.mglm_for_text_summarization"
         },
         "('MODELS', 'text-summarization', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text-to-image-synthesis', 'diffusion-text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/diffusion/model.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
                 "typing",
+                "torch",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.diffusion.model"
         },
         "('MODELS', 'text-to-image-synthesis', 'multi-stage-diffusion-text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/multi_stage_diffusion/model.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
                 "PIL",
-                "typing",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.multi_stage_diffusion.model"
         },
         "('MODELS', 'text-to-image-synthesis', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_text_to_image_synthesis_model.py",
             "imports": [
-                "numpy",
+                "taming",
+                "os",
+                "typing",
                 "pkg_resources",
-                "torchvision",
                 "torch",
-                "os",
                 "PIL",
-                "typing",
-                "taming",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_text_to_image_synthesis_model"
         },
         "('MODELS', 'text-to-image-synthesis', 'stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/stable_diffusion/stable_diffusion.py",
             "imports": [
                 "functools",
-                "diffusers",
+                "os",
                 "transformers",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "diffusers",
+                "packaging"
             ],
             "module": "modelscope.models.multi_modal.stable_diffusion.stable_diffusion"
         },
         "('MODELS', 'text-to-speech', 'sambert-hifigan')": {
             "filepath": "TEMPLATE_PATH/models/audio/tts/sambert_hifi.py",
             "imports": [
-                "numpy",
-                "zipfile",
                 "wave",
+                "zipfile",
                 "datetime",
-                "shutil",
-                "matplotlib",
                 "os",
-                "yaml",
                 "__future__",
+                "matplotlib",
+                "yaml",
+                "shutil",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.audio.tts.sambert_hifi"
         },
         "('MODELS', 'text-to-video-synthesis', 'latent-text-to-video-synthesis')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/video_synthesis/text_to_video_synthesis_model.py",
             "imports": [
-                "torch",
                 "einops",
                 "os",
                 "open_clip",
-                "typing"
+                "typing",
+                "torch"
             ],
             "module": "modelscope.models.multi_modal.video_synthesis.text_to_video_synthesis_model"
         },
         "('MODELS', 'text2sql', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'text2text-generation', 'T5')": {
             "filepath": "TEMPLATE_PATH/models/nlp/T5/text2text_generation.py",
             "imports": [
-                "warnings",
                 "transformers",
+                "warnings",
                 "copy",
-                "torch",
-                "typing"
+                "typing",
+                "torch"
             ],
             "module": "modelscope.models.nlp.T5.text2text_generation"
         },
         "('MODELS', 'token-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/token_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.token_classification"
@@ -5372,348 +5564,348 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'token-classification', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'transformer-crf-for-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'token-classification', 'veco')": {
             "filepath": "TEMPLATE_PATH/models/nlp/veco/token_classification.py",
             "imports": [
-                "torch",
-                "transformers"
+                "transformers",
+                "torch"
             ],
             "module": "modelscope.models.nlp.veco.token_classification"
         },
         "('MODELS', 'transformer-crf', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/csanmt/translation.py",
             "imports": [
-                "tensorflow",
-                "typing",
                 "collections",
-                "math"
+                "tensorflow",
+                "math",
+                "typing"
             ],
             "module": "modelscope.models.nlp.csanmt.translation"
         },
         "('MODELS', 'translation-evaluation', 'unite')": {
             "filepath": "TEMPLATE_PATH/models/nlp/unite/translation_evaluation.py",
             "imports": [
-                "numpy",
-                "dataclasses",
+                "transformers",
                 "warnings",
                 "math",
-                "transformers",
-                "packaging",
+                "typing",
                 "torch",
-                "typing"
+                "packaging",
+                "dataclasses",
+                "numpy"
             ],
             "module": "modelscope.models.nlp.unite.translation_evaluation"
         },
         "('MODELS', 'video-captioning', 'hitea')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'video-deinterlace', 'video-deinterlace')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_deinterlace/UNet_for_video_deinterlace.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "copy",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.video_deinterlace.UNet_for_video_deinterlace"
         },
         "('MODELS', 'video-depth-estimation', 'dro-resnet18-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_depth_estimation/dro_model.py",
             "imports": [
-                "numpy",
-                "glob",
-                "torch",
                 "os",
+                "tqdm",
+                "torch",
+                "glob",
                 "cv2",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_depth_estimation.dro_model"
         },
         "('MODELS', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_frame_interpolation/VFINet_for_video_frame_interpolation.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "copy",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation"
         },
         "('MODELS', 'video-human-matting', 'video-human-matting')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_human_matting/model.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.models.cv.video_human_matting.model"
         },
         "('MODELS', 'video-inpainting', 'video-inpainting')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_inpainting/inpainting_model.py",
             "imports": [
-                "math",
-                "numpy",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy",
+                "math"
             ],
             "module": "modelscope.models.cv.video_inpainting.inpainting_model"
         },
         "('MODELS', 'video-instance-segmentation', 'swinb-video-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/video_knet.py",
             "imports": [
-                "torch",
-                "mmdet"
+                "mmdet",
+                "torch"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.video_knet"
         },
         "('MODELS', 'video-multi-modal-embedding', 'video-clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mmr/models/clip_for_mm_video_embedding.py",
             "imports": [
-                "uuid",
-                "numpy",
                 "urllib",
-                "random",
-                "torch",
                 "os",
-                "PIL",
-                "tempfile",
                 "typing",
                 "decord",
+                "torch",
+                "uuid",
+                "PIL",
+                "tempfile",
+                "random",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.mmr.models.clip_for_mm_video_embedding"
         },
         "('MODELS', 'video-object-detection', 'longshortnet')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_streaming_perception/longshortnet/longshortnet.py",
             "imports": [
-                "numpy",
-                "time",
-                "torch",
                 "logging",
-                "cv2",
                 "os",
+                "tqdm",
+                "time",
                 "argparse",
-                "json",
-                "tqdm"
+                "torch",
+                "cv2",
+                "numpy",
+                "json"
             ],
             "module": "modelscope.models.cv.video_streaming_perception.longshortnet.longshortnet"
         },
         "('MODELS', 'video-object-detection', 'realtime-video-object-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/stream_yolo/realtime_video_detector.py",
             "imports": [
-                "numpy",
-                "time",
-                "torch",
                 "logging",
-                "cv2",
                 "os",
+                "tqdm",
+                "time",
                 "argparse",
-                "json",
-                "tqdm"
+                "torch",
+                "cv2",
+                "numpy",
+                "json"
             ],
             "module": "modelscope.models.cv.stream_yolo.realtime_video_detector"
         },
         "('MODELS', 'video-object-segmentation', 'video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_object_segmentation/model.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.video_object_segmentation.model"
         },
         "('MODELS', 'video-panoptic-segmentation', 'swinb-video-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/video_k_net.py",
             "imports": [
-                "mmcv",
-                "torch",
                 "mmdet",
+                "torch",
+                "mmcv",
                 "numpy"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.video_k_net"
         },
         "('MODELS', 'video-question-answering', 'hitea')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_stabilization/DUTRAFTStabilizer.py",
             "imports": [
                 "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "cv2",
-                "os",
                 "tempfile",
-                "typing",
+                "cv2",
                 "sys"
             ],
             "module": "modelscope.models.cv.video_stabilization.DUTRAFTStabilizer"
         },
         "('MODELS', 'video-summarization', 'pgl-video-summarization')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_summarization/summarizer.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.models.cv.video_summarization.summarizer"
         },
         "('MODELS', 'video-super-resolution', 'msrresnet-lite')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_super_resolution/msrresnet_lite_model.py",
             "imports": [
+                "os",
                 "functools",
-                "typing",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.video_super_resolution.msrresnet_lite_model"
         },
         "('MODELS', 'video-super-resolution', 'real-basicvsr')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_super_resolution/real_basicvsr_for_video_super_resolution.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.models.cv.video_super_resolution.real_basicvsr_for_video_super_resolution"
         },
         "('MODELS', 'video-temporal-grounding', 'soonet')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/soonet/model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.multi_modal.soonet.model"
         },
         "('MODELS', 'video-text-retrieval', 'vop-retrieval-model')": {
             "filepath": "TEMPLATE_PATH/models/cv/vop_retrieval/model.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.vop_retrieval.model"
         },
         "('MODELS', 'video-text-retrieval', 'vop-retrieval-model-se')": {
             "filepath": "TEMPLATE_PATH/models/cv/vop_retrieval/model_se.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.models.cv.vop_retrieval.model_se"
         },
         "('MODELS', 'vision-efficient-tuning', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/models/cv/vision_efficient_tuning/model.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.cv.vision_efficient_tuning.model"
         },
         "('MODELS', 'visual-entailment', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'visual-grounding', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'visual-question-answering', 'mplug')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/mplug_for_all_tasks.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.multi_modal.mplug_for_all_tasks"
         },
         "('MODELS', 'visual-question-answering', 'ofa')": {
             "filepath": "TEMPLATE_PATH/models/multi_modal/ofa_for_all_tasks.py",
             "imports": [
-                "re",
                 "functools",
                 "string",
-                "math",
-                "torch",
                 "os",
                 "typing",
+                "math",
+                "torch",
+                "re",
                 "json"
             ],
             "module": "modelscope.models.multi_modal.ofa_for_all_tasks"
         },
         "('MODELS', 'voice-activity-detection', 'generic-asr')": {
             "filepath": "TEMPLATE_PATH/models/audio/asr/generic_automatic_speech_recognition.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.models.audio.asr.generic_automatic_speech_recognition"
         },
         "('MODELS', 'word-alignment', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/word_alignment.py",
             "imports": [
                 "torch"
@@ -5748,24 +5940,24 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.token_classification"
         },
         "('MODELS', 'word-segmentation', 'transformer-crf')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'word-segmentation', 'transformer-crf-for-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/models/nlp/task_models/token_classification.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.models.nlp.task_models.token_classification"
         },
         "('MODELS', 'zero-shot-classification', 'bert')": {
             "filepath": "TEMPLATE_PATH/models/nlp/bert/text_classification.py",
             "imports": [],
             "module": "modelscope.models.nlp.bert.text_classification"
@@ -5798,221 +5990,221 @@
                 "torch"
             ],
             "module": "modelscope.models.nlp.structbert.text_classification"
         },
         "('NECKS', 'default', 'CPFPN')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/necks/cp_fpn.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.necks.cp_fpn"
         },
         "('NECKS', 'default', 'FPNF')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection/mmdet_ms/necks/fpn.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.object_detection.mmdet_ms.necks.fpn"
         },
         "('NECKS', 'default', 'MSDeformAttnPixelDecoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/neck/msdeformattn_decoder.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.neck.msdeformattn_decoder"
         },
         "('NECKS', 'default', 'SemanticFPNWrapper')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/head/semantic_fpn_wrapper.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.head.semantic_fpn_wrapper"
         },
         "('PARALLEL', 'default', 'DistributedDataParallel')": {
             "filepath": "TEMPLATE_PATH/trainers/parallel/builder.py",
             "imports": [
                 "torch"
             ],
             "module": "modelscope.trainers.parallel.builder"
         },
         "('PIPELINES', 'acoustic-echo-cancellation', 'speech-dfsmn-aec-psm-16k')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/linear_aec_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "scipy",
+                "typing",
                 "yaml",
                 "importlib",
-                "typing",
-                "scipy"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.linear_aec_pipeline"
         },
         "('PIPELINES', 'acoustic-noise-suppression', 'speech_dfsmn_ans_psm_48k_causal')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/ans_dfsmn_pipeline.py",
             "imports": [
-                "numpy",
-                "librosa",
-                "torch",
                 "collections",
-                "os",
+                "librosa",
+                "numpy",
                 "soundfile",
+                "os",
                 "typing",
-                "sys",
-                "io"
+                "torch",
+                "io",
+                "sys"
             ],
             "module": "modelscope.pipelines.audio.ans_dfsmn_pipeline"
         },
         "('PIPELINES', 'acoustic-noise-suppression', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/ans_pipeline.py",
             "imports": [
-                "numpy",
                 "librosa",
-                "torch",
                 "soundfile",
                 "typing",
-                "io"
+                "torch",
+                "io",
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.ans_pipeline"
         },
         "('PIPELINES', 'action-detection', 'ResNetC3D-action-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_detection_pipeline.py",
             "imports": [
+                "os",
                 "math",
-                "typing",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.action_detection_pipeline"
         },
         "('PIPELINES', 'action-recognition', 'TAdaConv_action-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py",
             "imports": [
-                "typing",
                 "os",
                 "torch",
-                "math"
+                "math",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.action_recognition_pipeline"
         },
         "('PIPELINES', 'action-recognition', 'patchshift-action-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/action_recognition_pipeline.py",
             "imports": [
-                "typing",
                 "os",
                 "torch",
-                "math"
+                "math",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.action_recognition_pipeline"
         },
         "('PIPELINES', 'animal-recognition', 'resnet101-animal-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/animal_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.animal_recognition_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'asr-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/asr_inference_pipeline.py",
             "imports": [
-                "typing",
                 "os",
                 "yaml",
-                "json"
+                "json",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.asr_inference_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'asr-wenet-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/asr_wenet_inference_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.audio.asr_wenet_inference_pipeline"
         },
         "('PIPELINES', 'auto-speech-recognition', 'ofa-asr')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/asr_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.asr_pipeline"
         },
         "('PIPELINES', 'bad-image-detecting', 'bad-image-detecting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/bad_image_detecting_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.bad_image_detecting_pipeline"
         },
         "('PIPELINES', 'body-2d-keypoints', 'hrnetv2w32_body-2d-keypoints_image')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/body_2d_keypoints_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
-                "PIL",
                 "typing",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.cv.body_2d_keypoints_pipeline"
         },
         "('PIPELINES', 'body-3d-keypoints', 'canonical_body-3d-keypoints_video')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/body_3d_keypoints_pipeline.py",
             "imports": [
-                "numpy",
-                "matplotlib",
                 "datetime",
-                "torch",
-                "cv2",
                 "os",
-                "tempfile",
+                "mpl_toolkits",
+                "matplotlib",
                 "typing",
-                "mpl_toolkits"
+                "torch",
+                "tempfile",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.body_3d_keypoints_pipeline"
         },
         "('PIPELINES', 'card-detection', 'resnet-card-detection-scrfd34gkps')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/card_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.card_detection_pipeline"
         },
         "('PIPELINES', 'chat', 'chatglm2_6b-text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'chat', 'chatglm6b-text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'code-generation', 'codegeex-code-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/codegeex_code_generation_pipeline.py",
             "imports": [
                 "typing"
@@ -6025,1327 +6217,1336 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.codegeex_code_translation_pipeline"
         },
         "('PIPELINES', 'competency-aware-translation', 'canmt-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/canmt_translation_pipeline.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "sacremoses",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.canmt_translation_pipeline"
         },
         "('PIPELINES', 'controllable-image-generation', 'controllable-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/controllable_image_generation_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
+                "os",
+                "tempfile",
                 "math",
-                "glob",
+                "typing",
                 "torch",
-                "os",
+                "glob",
                 "cv2",
-                "tempfile",
-                "typing"
+                "subprocess",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.controllable_image_generation_pipeline"
         },
         "('PIPELINES', 'crowd-counting', 'hrnet-crowd-counting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/crowd_counting_pipeline.py",
             "imports": [
-                "numpy",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
                 "PIL",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.crowd_counting_pipeline"
         },
         "('PIPELINES', 'default', 'DefaultFormatBundleV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/formating.py",
             "imports": [
-                "mmcv",
-                "numpy",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.formating"
         },
         "('PIPELINES', 'default', 'LoadAnnotationsV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/loading.py",
             "imports": [
-                "pycocotools",
-                "numpy",
                 "os",
-                "mmdet"
+                "pycocotools",
+                "mmdet",
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.loading"
         },
         "('PIPELINES', 'default', 'LoadMultiViewImageFromMultiSweepsFiles')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/loading.py",
             "imports": [
+                "mmdet",
                 "mmcv",
-                "numpy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.loading"
         },
         "('PIPELINES', 'default', 'NormalizeMultiviewImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "mmcv",
-                "numpy",
-                "copy",
                 "torch",
+                "mmcv",
                 "PIL",
+                "mmdet",
+                "copy",
                 "mmdet3d",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'PadMultiViewImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "mmcv",
-                "numpy",
-                "copy",
                 "torch",
+                "mmcv",
                 "PIL",
+                "mmdet",
+                "copy",
                 "mmdet3d",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'RandomFlipV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
+                "mmdet",
                 "mmcv",
-                "numpy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'RandomSquareCrop')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
+                "mmdet",
                 "mmcv",
-                "numpy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'ResizeCropFlipImage')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/datasets/pipelines/transform_3d.py",
             "imports": [
-                "mmcv",
-                "numpy",
-                "copy",
                 "torch",
+                "mmcv",
                 "PIL",
+                "mmdet",
+                "copy",
                 "mmdet3d",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d"
         },
         "('PIPELINES', 'default', 'ResizeToMultiple')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_semantic_segmentation/vit_adapter/utils/data_process_func.py",
             "imports": [
-                "mmcv",
-                "mmdet"
+                "mmdet",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.data_process_func"
         },
         "('PIPELINES', 'default', 'ResizeV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/transforms.py",
             "imports": [
+                "mmdet",
                 "mmcv",
-                "numpy",
-                "mmdet"
+                "numpy"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms"
         },
         "('PIPELINES', 'default', 'RotateV2')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/mmdet_patch/datasets/pipelines/auto_augment.py",
             "imports": [
                 "mmcv",
-                "numpy",
+                "mmdet",
                 "copy",
-                "cv2",
-                "mmdet"
+                "numpy",
+                "cv2"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.auto_augment"
         },
         "('PIPELINES', 'document-grounded-dialog-generate', 'document-grounded-dialog-generate')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_generate_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_generate_pipeline"
         },
         "('PIPELINES', 'document-grounded-dialog-rerank', 'document-grounded-dialog-rerank')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_rerank_pipeline.py",
             "imports": [
+                "collections",
                 "numpy",
-                "re",
-                "time",
-                "ujson",
-                "random",
-                "transformers",
-                "torch",
                 "pprint",
+                "ujson",
                 "os",
-                "collections",
+                "transformers",
                 "typing",
+                "time",
+                "torch",
+                "re",
+                "random",
                 "sys"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_rerank_pipeline"
         },
         "('PIPELINES', 'document-grounded-dialog-retrieval', 'document-grounded-dialog-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_grounded_dialog_retrieval_pipeline.py",
             "imports": [
-                "numpy",
-                "faiss",
                 "os",
                 "typing",
+                "faiss",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.nlp.document_grounded_dialog_retrieval_pipeline"
         },
         "('PIPELINES', 'document-segmentation', 'document-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/document_segmentation_pipeline.py",
             "imports": [
                 "numpy",
-                "re",
-                "torch",
                 "typing",
+                "torch",
+                "re",
                 "datasets"
             ],
             "module": "modelscope.pipelines.nlp.document_segmentation_pipeline"
         },
         "('PIPELINES', 'document-vl-embedding', 'document-vl-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/document_vl_embedding_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.document_vl_embedding_pipeline"
         },
         "('PIPELINES', 'domain-specific-object-detection', 'tinynas-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.tinynas_detection_pipeline"
         },
         "('PIPELINES', 'efficient-diffusion-tuning', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/efficient_diffusion_tuning_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.efficient_diffusion_tuning_pipeline"
         },
         "('PIPELINES', 'extractive-summarization', 'extractive-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/extractive_summarization_pipeline.py",
             "imports": [
                 "numpy",
-                "re",
-                "torch",
                 "typing",
+                "torch",
+                "re",
                 "datasets"
             ],
             "module": "modelscope.pipelines.nlp.extractive_summarization_pipeline"
         },
         "('PIPELINES', 'face-2d-keypoints', 'manual-facial-landmark-confidence-flcm')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/facial_landmark_confidence_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.facial_landmark_confidence_pipeline"
         },
         "('PIPELINES', 'face-attribute-recognition', 'resnet34-face-attribute-recognition-fairface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_attribute_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_attribute_recognition_pipeline"
         },
         "('PIPELINES', 'face-detection', 'manual-face-detection-mtcnn')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mtcnn_face_detection_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.mtcnn_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'manual-face-detection-ulfd')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ulfd_face_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.ulfd_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet-face-detection-scrfd10gkps')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet101-face-detection-cvpr22papermogface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mog_face_detection_pipeline.py",
             "imports": [
-                "typing",
                 "os",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.mog_face_detection_pipeline"
         },
         "('PIPELINES', 'face-detection', 'resnet50-face-detection-retinaface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/retina_face_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.retina_face_detection_pipeline"
         },
         "('PIPELINES', 'face-emotion', 'face-emotion')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_emotion_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.face_emotion_pipeline"
         },
         "('PIPELINES', 'face-human-hand-detection', 'face-human-hand-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_human_hand_detection_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.face_human_hand_detection_pipeline"
         },
         "('PIPELINES', 'face-image-generation', 'gan-face-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_image_generation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_image_generation_pipeline"
         },
         "('PIPELINES', 'face-liveness', 'manual-face-liveness-flir')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_liveness_ir_pipeline.py",
             "imports": [
-                "onnxruntime",
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "PIL",
+                "onnxruntime",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_liveness_ir_pipeline"
         },
         "('PIPELINES', 'face-liveness', 'manual-face-liveness-flxc')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_liveness_xc_pipeline.py",
             "imports": [
-                "onnxruntime",
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "PIL",
+                "onnxruntime",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_liveness_xc_pipeline"
         },
         "('PIPELINES', 'face-quality-assessment', 'manual-face-quality-assessment-fqa')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_quality_assessment_pipeline.py",
             "imports": [
-                "onnxruntime",
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "PIL",
+                "onnxruntime",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_quality_assessment_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir-face-recognition-rts')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_ood_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_ood_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir101-face-recognition-cfglint')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'ir50-face-recognition-arcface')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/arc_face_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.arc_face_recognition_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'manual-face-recognition-frfm')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_fm_pipeline.py",
             "imports": [
-                "onnxruntime",
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "PIL",
+                "onnxruntime",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_onnx_fm_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'manual-face-recognition-frir')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_recognition_onnx_ir_pipeline.py",
             "imports": [
-                "onnxruntime",
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "PIL",
+                "onnxruntime",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_recognition_onnx_ir_pipeline"
         },
         "('PIPELINES', 'face-recognition', 'resnet-face-recognition-facemask')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mask_face_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "collections",
+                "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.mask_face_recognition_pipeline"
         },
         "('PIPELINES', 'face-reconstruction', 'resnet50-face-reconstruction')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/face_reconstruction_pipeline.py",
             "imports": [
-                "numpy",
-                "io",
-                "shutil",
-                "tensorflow",
-                "torch",
-                "cv2",
                 "os",
-                "PIL",
+                "scipy",
                 "typing",
                 "face_alignment",
-                "scipy"
+                "tensorflow",
+                "torch",
+                "io",
+                "PIL",
+                "shutil",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.face_reconstruction_pipeline"
         },
         "('PIPELINES', 'facial-expression-recognition', 'vgg19-facial-expression-recognition-fer')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/facial_expression_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.facial_expression_recognition_pipeline"
         },
         "('PIPELINES', 'faq-question-answering', 'faq-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/faq_question_answering_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.faq_question_answering_pipeline"
         },
         "('PIPELINES', 'feature-extraction', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/feature_extraction_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.feature_extraction_pipeline"
         },
         "('PIPELINES', 'fid-dialogue', 'fid-dialogue')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fid_dialogue_pipeline.py",
             "imports": [
-                "typing",
                 "re",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.fid_dialogue_pipeline"
         },
         "('PIPELINES', 'fill-mask', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.fill_mask_pipeline"
         },
         "('PIPELINES', 'fill-mask', 'fill-mask-ponet')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fill_mask_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.fill_mask_pipeline"
         },
         "('PIPELINES', 'general-recognition', 'resnet101-general-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/general_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.general_recognition_pipeline"
         },
         "('PIPELINES', 'generative-multi-modal-embedding', 'generative-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/generative_multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.generative_multi_modal_embedding_pipeline"
         },
         "('PIPELINES', 'hand-static', 'hand-static')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/hand_static_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.hand_static_pipeline"
         },
         "('PIPELINES', 'human-detection', 'resnet18-human-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'human-reconstruction', 'human-reconstruction')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/human_reconstruction_pipeline.py",
             "imports": [
-                "numpy",
-                "shutil",
                 "trimesh",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "shutil",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.human_reconstruction_pipeline"
         },
         "('PIPELINES', 'image-body-reshaping', 'flow-based-body-reshaping')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_body_reshaping_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_body_reshaping_pipeline"
         },
         "('PIPELINES', 'image-captioning', 'image-captioning')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/image_captioning_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.image_captioning_pipeline"
         },
         "('PIPELINES', 'image-classification', 'bnext-small_image-classification_ImageNet-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'common-image-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'convnext-base_image-classification_garbage')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'easyrobust-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'image-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'image-structured-model-probing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_structured_model_probing_pipeline.py",
             "imports": [
-                "numpy",
                 "mmcv",
-                "torchvision",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_structured_model_probing_pipeline"
         },
         "('PIPELINES', 'image-classification', 'nextvit-small_image-classification_Dailylife-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'resnet50-image-classification-cc')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/content_check_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "os",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "os",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.content_check_pipeline"
         },
         "('PIPELINES', 'image-classification', 'tinynas-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_classification_pipeline.py",
             "imports": [
+                "os",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.tinynas_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'vit-base_image-classification_Dailylife-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-classification', 'vit-base_image-classification_ImageNet-labels')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_classification_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'adaint-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'csrnet-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-color-enhancement', 'deeplpf-image-color-enhance')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_color_enhance_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_color_enhance_pipeline"
         },
         "('PIPELINES', 'image-colorization', 'ddcolor-image-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ddcolor_image_colorization_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "typing",
                 "torch",
                 "cv2",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.ddcolor_image_colorization_pipeline"
         },
         "('PIPELINES', 'image-colorization', 'unet-image-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_colorization_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_colorization_pipeline"
         },
         "('PIPELINES', 'image-debanding', 'rrdb-image-debanding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_debanding_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_debanding_pipeline"
         },
         "('PIPELINES', 'image-deblurring', 'nafnet-image-deblur')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_deblur_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_deblur_pipeline"
         },
         "('PIPELINES', 'image-demoireing', 'uhdm-image-demoireing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_restoration_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_restoration_pipeline"
         },
         "('PIPELINES', 'image-denoising', 'nafnet-image-denoise')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_denoise_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_denoise_pipeline"
         },
         "('PIPELINES', 'image-depth-estimation', 'image-bts-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_bts_depth_estimation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "albumentations",
+                "typing",
+                "torch",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_bts_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-depth-estimation', 'image-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_depth_estimation_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-driving-perception', 'yolopv2_image-driving-percetion_bdd100k')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_driving_perception_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "os",
-                "cv2"
+                "cv2",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_driving_perception_pipeline"
         },
         "('PIPELINES', 'image-face-fusion', 'image-face-fusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_face_fusion_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_face_fusion_pipeline"
         },
         "('PIPELINES', 'image-fewshot-detection', 'image-fewshot-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_defrcn_fewshot_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_defrcn_fewshot_pipeline"
         },
         "('PIPELINES', 'image-inpainting', 'fft-inpainting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_inpainting_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_inpainting_pipeline"
         },
         "('PIPELINES', 'image-inpainting', 'image-inpainting-sdv2')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_inpainting_sdv2_pipeline.py",
             "imports": [
                 "numpy",
-                "diffusers",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "cv2",
-                "os",
+                "diffusers",
                 "tempfile",
-                "typing",
+                "cv2",
                 "sys"
             ],
             "module": "modelscope.pipelines.cv.image_inpainting_sdv2_pipeline"
         },
         "('PIPELINES', 'image-matching', 'image-matching')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matching_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matching_pipeline"
         },
         "('PIPELINES', 'image-multi-view-depth-estimation', 'image-multi-view-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_mvs_depth_estimation_pipeline.py",
             "imports": [
-                "shutil",
-                "typing",
                 "os",
-                "tempfile"
+                "tempfile",
+                "shutil",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_mvs_depth_estimation_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'abnormal-object-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'tbs-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tbs_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "colorsys",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
+                "colorsys",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.tbs_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'tinynas-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/tinynas_detection_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.tinynas_detection_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'vidt')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vidt_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.vidt_pipeline"
         },
         "('PIPELINES', 'image-object-detection', 'vit-object-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_detection_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_detection_pipeline"
         },
         "('PIPELINES', 'image-paintbyexample', 'stablediffusion-paintbyexample')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_paintbyexample_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "einops",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_paintbyexample_pipeline"
         },
         "('PIPELINES', 'image-portrait-enhancement', 'gpen-image-portrait-enhancement')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_portrait_enhancement_pipeline.py",
             "imports": [
-                "numpy",
+                "scipy",
                 "math",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing",
-                "scipy"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_portrait_enhancement_pipeline"
         },
         "('PIPELINES', 'image-portrait-stylization', 'unet-person-image-cartoon')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_cartoon_pipeline.py",
             "imports": [
-                "numpy",
-                "tensorflow",
                 "os",
+                "typing",
+                "tensorflow",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_cartoon_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-degradation', 'image-quality-assessment-degradation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_degradation_pipeline.py",
             "imports": [
-                "numpy",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "cv2",
                 "tempfile",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_degradation_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-mos', 'image-quality-assessment-man')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_man_pipeline.py",
             "imports": [
-                "numpy",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "cv2",
                 "tempfile",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_man_pipeline"
         },
         "('PIPELINES', 'image-quality-assessment-mos', 'image-quality-assessment-mos')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_quality_assessment_mos_pipeline.py",
             "imports": [
-                "numpy",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "cv2",
                 "tempfile",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_quality_assessment_mos_pipeline"
         },
         "('PIPELINES', 'image-reid-person', 'passvitb-image-reid-person')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_reid_person_pipeline.py",
             "imports": [
+                "os",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "os",
                 "PIL",
-                "typing"
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.image_reid_person_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'cascade-mask-rcnn-swin-image-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_instance_segmentation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'fast-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/fast_instance_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.fast_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'image-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_panoptic_segmentation_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_panoptic_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'image-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_semantic_segmentation_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_semantic_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'm2fp-image-human-parsing')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_human_parsing_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_human_parsing_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'maskdino-swin-image-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/maskdino_instance_segmentation_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.maskdino_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'image-segmentation', 'vision-middleware-multi-task')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vision_middleware_pipeline.py",
             "imports": [
-                "numpy",
                 "mmcv",
-                "torchvision",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.vision_middleware_pipeline"
         },
         "('PIPELINES', 'image-skychange', 'image-skychange')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_skychange_pipeline.py",
             "imports": [
-                "numpy",
+                "pdb",
+                "typing",
                 "time",
-                "cv2",
                 "PIL",
-                "pdb",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_skychange_pipeline"
         },
         "('PIPELINES', 'image-style-transfer', 'AAMS-style-transfer')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_style_transfer_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "os",
-                "cv2"
+                "cv2",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.image_style_transfer_pipeline"
         },
         "('PIPELINES', 'image-super-resolution', 'mobile-image-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/mobile_image_super_resolution_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "typing",
-                "skimage"
+                "torch",
+                "skimage",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.mobile_image_super_resolution_pipeline"
         },
         "('PIPELINES', 'image-super-resolution', 'rrdb-image-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_super_resolution_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_super_resolution_pipeline"
         },
         "('PIPELINES', 'image-text-retrieval', 'image-text-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/image_text_retrieval_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.image_text_retrieval_pipeline"
         },
         "('PIPELINES', 'image-text-retrieval', 'multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.multi_modal_embedding_pipeline"
         },
         "('PIPELINES', 'image-to-image-generation', 'image-to-image-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_to_image_generate_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "os",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "os",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_to_image_generate_pipeline"
         },
         "('PIPELINES', 'image-to-image-translation', 'image-to-image-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_to_image_translation_pipeline.py",
             "imports": [
                 "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
-                "PIL",
                 "typing",
-                "sys",
-                "io"
+                "torch",
+                "io",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "sys"
             ],
             "module": "modelscope.pipelines.cv.image_to_image_translation_pipeline"
         },
+        "('PIPELINES', 'image-try-on', 'image-try-on')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/image_try_on_pipeline.py",
+            "imports": [
+                "torch",
+                "numpy",
+                "typing"
+            ],
+            "module": "modelscope.pipelines.cv.image_try_on_pipeline"
+        },
         "('PIPELINES', 'indoor-layout-estimation', 'indoor-layout-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/indoor_layout_estimation_pipeline.py",
             "imports": [
-                "typing",
                 "cv2",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.indoor_layout_estimation_pipeline"
         },
         "('PIPELINES', 'information-extraction', 'relation-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.information_extraction_pipeline"
         },
         "('PIPELINES', 'inverse-text-processing', 'itn-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/inverse_text_processing_pipeline.py",
             "imports": [
-                "shutil",
-                "typing",
                 "os",
-                "yaml"
+                "yaml",
+                "shutil",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.inverse_text_processing_pipeline"
         },
         "('PIPELINES', 'keyword-spotting', 'kws-kwsbp')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/kws_kwsbp_pipeline.py",
             "imports": [
-                "typing",
                 "os",
-                "json"
+                "json",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.kws_kwsbp_pipeline"
         },
         "('PIPELINES', 'keyword-spotting', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/kws_farfield_pipeline.py",
             "imports": [
-                "numpy",
                 "wave",
                 "soundfile",
                 "typing",
-                "io"
+                "io",
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.kws_farfield_pipeline"
         },
         "('PIPELINES', 'language-guided-video-summarization', 'clip-it-video-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/language_guided_video_summarization_pipeline.py",
             "imports": [
-                "numpy",
-                "clip",
-                "random",
-                "shutil",
-                "torch",
                 "os",
-                "cv2",
+                "clip",
                 "tempfile",
+                "cv2",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "shutil",
+                "random",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.language_guided_video_summarization_pipeline"
         },
         "('PIPELINES', 'language-score-prediction', 'language-score-prediction')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/lm_infer_pipeline.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.lm_infer_pipeline"
         },
         "('PIPELINES', 'license-plate-detection', 'resnet18-license-plate-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/license_plate_detection_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.license_plate_detection_pipeline"
         },
         "('PIPELINES', 'lineless-table-recognition', 'lore-lineless-table-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/lineless_table_recognition_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.lineless_table_recognition_pipeline"
         },
         "('PIPELINES', 'live-category', 'live-category')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/live_category_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "PIL",
                 "typing",
-                "decord"
+                "decord",
+                "torch",
+                "PIL",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.live_category_pipeline"
         },
         "('PIPELINES', 'motion-generation', 'mdm-motion-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/motion_generation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "tempfile",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.motion_generation_pipeline"
         },
         "('PIPELINES', 'movie-scene-segmentation', 'resnet50-bert-movie-scene-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/movie_scene_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.movie_scene_segmentation_pipeline"
         },
         "('PIPELINES', 'multi-modal-embedding', 'gridvlp-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py",
             "imports": [
-                "numpy",
-                "time",
-                "traceback",
+                "os",
                 "transformers",
+                "typing",
+                "time",
                 "torch",
-                "os",
+                "traceback",
                 "PIL",
-                "typing",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.multi_modal.gridvlp_pipeline"
         },
         "('PIPELINES', 'multi-modal-embedding', 'multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multi_modal_embedding_pipeline.py",
             "imports": [
@@ -7359,16 +7560,16 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.team_multi_modal_similarity_pipeline"
         },
         "('PIPELINES', 'multimodal-dialogue', 'multimodal-dialogue')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/multimodal_dialogue_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.multimodal_dialogue_pipeline"
         },
         "('PIPELINES', 'named-entity-recognition', 'named-entity-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py",
             "imports": [
                 "typing"
@@ -7385,210 +7586,235 @@
         "('PIPELINES', 'named-entity-recognition', 'named-entity-recognition-viet')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/named_entity_recognition_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.named_entity_recognition_pipeline"
         },
+        "('PIPELINES', 'nerf-recon-4k', 'nerf-recon-4k')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/nerf_recon_4k_pipeline.py",
+            "imports": [
+                "typing"
+            ],
+            "module": "modelscope.pipelines.cv.nerf_recon_4k_pipeline"
+        },
         "('PIPELINES', 'nerf-recon-acc', 'nerf-recon-acc')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/nerf_recon_acc_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.nerf_recon_acc_pipeline"
         },
+        "('PIPELINES', 'nerf-recon-vq-compression', 'nerf-recon-vq-compression')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/nerf_recon_vq_compression_pipeline.py",
+            "imports": [
+                "typing"
+            ],
+            "module": "modelscope.pipelines.cv.nerf_recon_vq_compression_pipeline"
+        },
         "('PIPELINES', 'nli', 'nli')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'object-detection-3d', 'object-detection-3d-depe')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/object_detection_3d_pipeline.py",
             "imports": [
-                "numpy",
-                "tempfile",
+                "os",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "os",
-                "typing"
+                "tempfile",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.object_detection_3d_pipeline"
         },
         "('PIPELINES', 'ocr-detection', 'resnet18-ocr-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ocr_detection_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
+                "typing",
                 "math",
                 "tensorflow",
                 "torch",
-                "os",
+                "tf_slim",
                 "cv2",
-                "typing",
-                "tf_slim"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.ocr_detection_pipeline"
         },
         "('PIPELINES', 'ocr-recognition', 'convnextTiny-ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ocr_recognition_pipeline.py",
             "imports": [],
             "module": "modelscope.pipelines.cv.ocr_recognition_pipeline"
         },
         "('PIPELINES', 'ocr-recognition', 'ofa-ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/ocr_recognition_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.ocr_recognition_pipeline"
         },
         "('PIPELINES', 'open-vocabulary-detection', 'open-vocabulary-detection-vild')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_open_vocabulary_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_open_vocabulary_detection_pipeline"
         },
         "('PIPELINES', 'panorama-depth-estimation', 'panorama-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_pipeline.py",
             "imports": [
-                "numpy",
+                "typing",
                 "torch",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.panorama_depth_estimation_pipeline"
         },
-        "('PIPELINES', 'part-of-speech', 'part-of-speech')": {
-            "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
+        "('PIPELINES', 'panorama-depth-estimation', 'panorama-depth-estimation-s2net')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/panorama_depth_estimation_s2net_pipeline.py",
             "imports": [
                 "typing",
                 "torch",
+                "PIL",
+                "cv2",
                 "numpy"
             ],
+            "module": "modelscope.pipelines.cv.panorama_depth_estimation_s2net_pipeline"
+        },
+        "('PIPELINES', 'part-of-speech', 'part-of-speech')": {
+            "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
+            "imports": [
+                "torch",
+                "numpy",
+                "typing"
+            ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'pedestrian-attribute-recognition', 'resnet50_pedestrian-attribute-recognition_image')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/pedestrian_attribute_recognition_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
-                "PIL",
                 "typing",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.cv.pedestrian_attribute_recognition_pipeline"
         },
         "('PIPELINES', 'pointcloud-sceneflow-estimation', 'pointcloud-sceneflow-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "plyfile",
-                "torch"
+                "numpy",
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.pointcloud_sceneflow_estimation_pipeline"
         },
         "('PIPELINES', 'portrait-matting', 'unet-image-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py",
             "imports": [
-                "numpy",
-                "tensorflow",
                 "os",
+                "typing",
+                "tensorflow",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matting_pipeline"
         },
         "('PIPELINES', 'product-retrieval-embedding', 'resnet50-product-retrieval-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/product_retrieval_embedding_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.product_retrieval_embedding_pipeline"
         },
         "('PIPELINES', 'product-segmentation', 'product-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/product_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.product_segmentation_pipeline"
         },
         "('PIPELINES', 'protein-structure', 'unifold-protein-structure')": {
             "filepath": "TEMPLATE_PATH/pipelines/science/protein_structure_pipeline.py",
             "imports": [
-                "numpy",
-                "unicore",
-                "time",
-                "torch",
                 "os",
                 "typing",
+                "time",
+                "torch",
+                "unicore",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.science.protein_structure_pipeline"
         },
         "('PIPELINES', 'punctuation', 'punc-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/punctuation_processing_pipeline.py",
             "imports": [
-                "shutil",
-                "typing",
                 "os",
-                "yaml"
+                "yaml",
+                "shutil",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.punctuation_processing_pipeline"
         },
         "('PIPELINES', 'referring-video-object-segmentation', 'referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/referring_video_object_segmentation_pipeline.py",
             "imports": [
-                "numpy",
+                "einops",
+                "tqdm",
                 "moviepy",
-                "torchvision",
+                "typing",
                 "torch",
-                "einops",
                 "PIL",
                 "tempfile",
-                "typing",
-                "tqdm"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.referring_video_object_segmentation_pipeline"
         },
         "('PIPELINES', 'relation-extraction', 'relation-extraction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/information_extraction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.information_extraction_pipeline"
         },
         "('PIPELINES', 'semantic-segmentation', 'ddpm-image-semantic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/ddpm_semantic_segmentation_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.ddpm_semantic_segmentation_pipeline"
         },
         "('PIPELINES', 'semantic-segmentation', 'res2net-camouflaged-detection')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_salient_detection_pipeline.py",
             "imports": [
                 "typing"
@@ -7608,193 +7834,223 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.image_salient_detection_pipeline"
         },
         "('PIPELINES', 'sentence-embedding', 'sentence-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/sentence_embedding_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.sentence_embedding_pipeline"
         },
         "('PIPELINES', 'sentence-similarity', 'sentence-similarity')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'sentence-similarity', 'translation-quality-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_quality_estimation_pipeline.py",
             "imports": [
-                "transformers",
-                "torch",
                 "os",
+                "transformers",
                 "typing",
+                "torch",
                 "io"
             ],
             "module": "modelscope.pipelines.nlp.translation_quality_estimation_pipeline"
         },
         "('PIPELINES', 'sentiment-classification', 'sentiment-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'shop-segmentation', 'shop-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/shop_segmentation_pipleline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.shop_segmentation_pipleline"
         },
         "('PIPELINES', 'siamese-uie', 'siamese-uie')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/siamese_uie_pipeline.py",
             "imports": [
-                "tqdm",
-                "time",
-                "math",
-                "torch",
                 "logging",
                 "os",
+                "tqdm",
                 "copy",
                 "scipy",
+                "math",
+                "time",
                 "typing",
                 "pathlib",
+                "torch",
                 "json"
             ],
             "module": "modelscope.pipelines.nlp.siamese_uie_pipeline"
         },
         "('PIPELINES', 'skin-retouching', 'unet-skin-retouching')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/skin_retouching_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
+                "os",
+                "typing",
                 "tensorflow",
                 "torch",
-                "cv2",
                 "PIL",
-                "os",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.skin_retouching_pipeline"
         },
         "('PIPELINES', 'speaker-diarization', 'segmentation-clustering')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/segmentation_clustering_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "soundfile",
                 "typing",
+                "torch",
+                "io",
                 "torchaudio",
-                "io"
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.segmentation_clustering_pipeline"
         },
         "('PIPELINES', 'speaker-diarization', 'speaker-change-locating')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_change_locating_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "soundfile",
                 "typing",
+                "torch",
+                "io",
                 "torchaudio",
-                "io"
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.speaker_change_locating_pipeline"
         },
         "('PIPELINES', 'speaker-diarization', 'speaker-diarization-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_diarization_pipeline.py",
             "imports": [
-                "numpy",
-                "shutil",
                 "os",
-                "yaml",
                 "typing",
+                "yaml",
+                "shutil",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.audio.speaker_diarization_pipeline"
         },
-        "('PIPELINES', 'speaker-verification', 'speaker-verification')": {
-            "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py",
+        "('PIPELINES', 'speaker-diarization-dialogue-detection', 'speaker-diarization-dialogue-detection')": {
+            "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_diarization_dialogue_detection_pipeline.py",
             "imports": [
                 "numpy",
+                "typing"
+            ],
+            "module": "modelscope.pipelines.audio.speaker_diarization_dialogue_detection_pipeline"
+        },
+        "('PIPELINES', 'speaker-diarization-semantic-speaker-turn-detection', 'speaker-diarization-semantic-speaker-turn-detection')": {
+            "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_diarization_semantic_speaker_turn_detection_pipeline.py",
+            "imports": [
                 "torch",
-                "os",
+                "numpy",
+                "typing"
+            ],
+            "module": "modelscope.pipelines.audio.speaker_diarization_semantic_speaker_turn_detection_pipeline"
+        },
+        "('PIPELINES', 'speaker-verification', 'speaker-verification')": {
+            "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_light_pipeline.py",
+            "imports": [
                 "soundfile",
+                "os",
                 "typing",
+                "torch",
+                "io",
                 "torchaudio",
-                "io"
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_light_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'speaker-verification-eres2net')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_eres2net_pipeline.py",
             "imports": [
                 "soundfile",
-                "typing",
+                "io",
                 "torch",
-                "io"
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_eres2net_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'speaker-verification-rdino')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_rdino_pipeline.py",
             "imports": [
                 "soundfile",
-                "typing",
+                "io",
                 "torch",
-                "io"
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_rdino_pipeline"
         },
         "('PIPELINES', 'speaker-verification', 'sv-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/speaker_verification_pipeline.py",
             "imports": [
-                "shutil",
-                "typing",
                 "os",
-                "yaml"
+                "yaml",
+                "shutil",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.speaker_verification_pipeline"
         },
+        "('PIPELINES', 'speech-language-recognition', 'speech-language-recognition')": {
+            "filepath": "TEMPLATE_PATH/pipelines/audio/language_recognition_pipeline.py",
+            "imports": [
+                "soundfile",
+                "os",
+                "typing",
+                "torch",
+                "io",
+                "torchaudio",
+                "numpy"
+            ],
+            "module": "modelscope.pipelines.audio.language_recognition_pipeline"
+        },
         "('PIPELINES', 'speech-separation', 'speech-separation')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/separation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "soundfile",
                 "typing",
-                "io"
+                "torch",
+                "io",
+                "numpy"
             ],
             "module": "modelscope.pipelines.audio.separation_pipeline"
         },
         "('PIPELINES', 'speech-timestamp', 'speech-timestamp-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/timestamp_pipeline.py",
             "imports": [
-                "funasr",
                 "os",
-                "yaml",
+                "funasr",
                 "typing",
+                "yaml",
                 "json"
             ],
             "module": "modelscope.pipelines.audio.timestamp_pipeline"
         },
         "('PIPELINES', 'sudoku', 'ofa-sudoku')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/sudoku_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.sudoku_pipeline"
         },
         "('PIPELINES', 'table-question-answering', 'conversational-text-to-sql')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/conversational_text_to_sql_pipeline.py",
             "imports": [
                 "typing",
@@ -7802,32 +8058,32 @@
                 "text2sql_lgesql"
             ],
             "module": "modelscope.pipelines.nlp.conversational_text_to_sql_pipeline"
         },
         "('PIPELINES', 'table-question-answering', 'table-question-answering-pipeline')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/table_question_answering_pipeline.py",
             "imports": [
-                "transformers",
-                "torch",
                 "os",
+                "transformers",
                 "typing",
+                "torch",
                 "json"
             ],
             "module": "modelscope.pipelines.nlp.table_question_answering_pipeline"
         },
         "('PIPELINES', 'table-recognition', 'dla34-table-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/table_recognition_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.table_recognition_pipeline"
         },
         "('PIPELINES', 'task-oriented-conversation', 'dialog-intent-prediction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/dialog_intent_prediction_pipeline.py",
             "imports": [
                 "typing"
@@ -7847,1689 +8103,1736 @@
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.dialog_state_tracking_pipeline"
         },
         "('PIPELINES', 'task-template', 'pipeline-template')": {
             "filepath": "TEMPLATE_PATH/pipelines/pipeline_template.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.pipeline_template"
         },
         "('PIPELINES', 'text-classification', 'domain-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/fasttext_text_classification_pipeline.py",
             "imports": [
-                "numpy",
                 "fasttext",
                 "os",
+                "sentencepiece",
                 "typing",
-                "sentencepiece"
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.fasttext_text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'language_identification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/language_identification_pipline.py",
             "imports": [
-                "numpy",
-                "re",
-                "tensorflow",
                 "os",
-                "typing"
+                "typing",
+                "tensorflow",
+                "re",
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.language_identification_pipline"
         },
         "('PIPELINES', 'text-classification', 'sentence-similarity')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'sentiment-analysis')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'sentiment-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'text-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_classification_pipeline"
         },
         "('PIPELINES', 'text-classification', 'user-satisfaction-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/user_satisfaction_estimation_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.user_satisfaction_estimation_pipeline"
         },
         "('PIPELINES', 'text-driven-segmentation', 'text-driven-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/text_driven_segmentation_pipleline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.text_driven_segmentation_pipleline"
         },
         "('PIPELINES', 'text-error-correction', 'text-error-correction')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_error_correction_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_error_correction_pipeline"
         },
         "('PIPELINES', 'text-generation', 'glm130b-text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/glm130b_text_generation_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.nlp.glm130b_text_generation_pipeline"
         },
         "('PIPELINES', 'text-generation', 'gpt-moe-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_gpt_moe_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_gpt_moe_pipeline"
         },
         "('PIPELINES', 'text-generation', 'gpt3-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_gpt3_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_gpt3_pipeline"
         },
+        "('PIPELINES', 'text-generation', 'llama2-text-generation-pipeline')": {
+            "filepath": "TEMPLATE_PATH/pipelines/nlp/llama2_text_generation_pipeline.py",
+            "imports": [
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.pipelines.nlp.llama2_text_generation_pipeline"
+        },
         "('PIPELINES', 'text-generation', 'plug-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/distributed_plug_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.distributed_plug_pipeline"
         },
+        "('PIPELINES', 'text-generation', 'polylm-text-generation')": {
+            "filepath": "TEMPLATE_PATH/pipelines/nlp/polylm_text_generation_pipeline.py",
+            "imports": [
+                "os",
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.pipelines.nlp.polylm_text_generation_pipeline"
+        },
         "('PIPELINES', 'text-generation', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text-ranking', 'mgeo-ranking')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/mgeo_ranking_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.mgeo_ranking_pipeline"
         },
         "('PIPELINES', 'text-ranking', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_ranking_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_ranking_pipeline"
         },
         "('PIPELINES', 'text-summarization', 'mglm-text-summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/mglm_text_summarization_pipeline.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.mglm_text_summarization_pipeline"
         },
         "('PIPELINES', 'text-summarization', 'text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/summarization_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.summarization_pipeline"
         },
+        "('PIPELINES', 'text-to-360panorama-image', 'text-to-360panorama-image')": {
+            "filepath": "TEMPLATE_PATH/pipelines/cv/text_to_360panorama_image_pipeline.py",
+            "imports": [
+                "basicsr",
+                "realesrgan",
+                "typing",
+                "torch",
+                "diffusers",
+                "PIL",
+                "random",
+                "numpy"
+            ],
+            "module": "modelscope.pipelines.cv.text_to_360panorama_image_pipeline"
+        },
         "('PIPELINES', 'text-to-image-synthesis', 'chinese-stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/chinese_stable_diffusion_pipeline.py",
             "imports": [
-                "numpy",
-                "diffusers",
                 "transformers",
+                "typing",
                 "torch",
-                "cv2",
+                "diffusers",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.chinese_stable_diffusion_pipeline"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'diffusers-stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/diffusers_wrapped/stable_diffusion/stable_diffusion_pipeline.py",
             "imports": [
-                "numpy",
-                "diffusers",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
+                "diffusers",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.stable_diffusion_pipeline"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'disco_guided_diffusion')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/disco_guided_diffusion_pipeline/disco_guided_diffusion.py",
             "imports": [
-                "numpy",
+                "os",
                 "clip",
                 "math",
-                "torchvision",
-                "gc",
+                "importlib",
                 "torch",
-                "os",
-                "cv2",
+                "gc",
                 "PIL",
-                "importlib",
+                "cv2",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.disco_guided_diffusion"
         },
         "('PIPELINES', 'text-to-image-synthesis', 'text-to-image-synthesis')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text_to_image_synthesis_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.text_to_image_synthesis_pipeline"
         },
         "('PIPELINES', 'text-to-speech', 'sambert-hifigan-tts')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/text_to_speech_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.audio.text_to_speech_pipeline"
         },
         "('PIPELINES', 'text-to-video-synthesis', 'latent-text-to-video-synthesis')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text_to_video_synthesis_pipeline.py",
             "imports": [
-                "torch",
                 "einops",
                 "os",
-                "cv2",
+                "typing",
+                "torch",
                 "tempfile",
-                "typing"
+                "cv2"
             ],
             "module": "modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline"
         },
         "('PIPELINES', 'text2sql', 'ofa-text2sql')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/text2sql_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.text2sql_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'text2text-generation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_de')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_fr')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'text2text-generation', 'translation_en_to_ro')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/text_generation_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.text_generation_pipeline"
         },
         "('PIPELINES', 'token-classification', 'named-entity-recognition')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'token-classification', 'part-of-speech')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'token-classification', 'token-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'token-classification', 'word-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/token_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.token_classification_pipeline"
         },
         "('PIPELINES', 'translation', 'automatic-post-editing')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/automatic_post_editing_pipeline.py",
             "imports": [
-                "numpy",
-                "jieba",
-                "html",
                 "sacremoses",
-                "tensorflow",
+                "jieba",
                 "os",
+                "sentencepiece",
                 "typing",
-                "sentencepiece"
+                "tensorflow",
+                "numpy",
+                "html"
             ],
             "module": "modelscope.pipelines.nlp.automatic_post_editing_pipeline"
         },
         "('PIPELINES', 'translation', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_pipeline.py",
             "imports": [
-                "numpy",
-                "jieba",
                 "sacremoses",
+                "jieba",
+                "os",
+                "typing",
                 "subword_nmt",
                 "tensorflow",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.translation_pipeline"
         },
         "('PIPELINES', 'translation', 'interactive-translation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/interactive_translation_pipeline.py",
             "imports": [
-                "numpy",
-                "jieba",
                 "sacremoses",
+                "jieba",
+                "os",
+                "typing",
                 "subword_nmt",
                 "tensorflow",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.interactive_translation_pipeline"
         },
         "('PIPELINES', 'translation-evaluation', 'translation-evaluation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/translation_evaluation_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
+                "enum",
                 "os",
                 "typing",
-                "enum"
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.pipelines.nlp.translation_evaluation_pipeline"
         },
         "('PIPELINES', 'universal-matting', 'unet-universal-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/image_matting_pipeline.py",
             "imports": [
-                "numpy",
-                "tensorflow",
                 "os",
+                "typing",
+                "tensorflow",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.image_matting_pipeline"
         },
         "('PIPELINES', 'video-captioning', 'video-captioning')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_captioning_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_captioning_pipeline"
         },
         "('PIPELINES', 'video-category', 'video-category')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_category_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "PIL",
                 "typing",
                 "decord",
+                "torch",
+                "PIL",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.cv.video_category_pipeline"
         },
         "('PIPELINES', 'video-colorization', 'video-colorization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_colorization_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
-                "tempfile",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "tempfile",
+                "cv2",
+                "subprocess",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.video_colorization_pipeline"
         },
         "('PIPELINES', 'video-deinterlace', 'video-deinterlace')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_deinterlace_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
+                "os",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "tempfile",
-                "typing"
+                "cv2",
+                "subprocess",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.video_deinterlace_pipeline"
         },
         "('PIPELINES', 'video-depth-estimation', 'video-depth-estimation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_depth_estimation_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.video_depth_estimation_pipeline"
         },
         "('PIPELINES', 'video-embedding', 'cmdssl-r2p1d_video_embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/cmdssl_video_embedding_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "PIL",
                 "typing",
-                "decord"
+                "decord",
+                "torch",
+                "PIL",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.cmdssl_video_embedding_pipeline"
         },
         "('PIPELINES', 'video-embedding', 'hicossl-s3dg-video_embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/hicossl_video_embedding_pipeline.py",
             "imports": [
-                "typing",
                 "os",
                 "torch",
-                "math"
+                "math",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.hicossl_video_embedding_pipeline"
         },
         "('PIPELINES', 'video-frame-interpolation', 'video-frame-interpolation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_frame_interpolation_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
+                "os",
+                "tempfile",
                 "math",
-                "torchvision",
-                "glob",
+                "typing",
                 "torch",
-                "os",
+                "glob",
                 "cv2",
-                "tempfile",
-                "typing"
+                "subprocess",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.video_frame_interpolation_pipeline"
         },
         "('PIPELINES', 'video-human-matting', 'video-human-matting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_human_matting_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
                 "moviepy",
+                "typing",
                 "torch",
-                "os",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_human_matting_pipeline"
         },
         "('PIPELINES', 'video-inpainting', 'video-inpainting')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_inpainting_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.cv.video_inpainting_pipeline"
         },
         "('PIPELINES', 'video-instance-segmentation', 'video-instance-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_instance_segmentation_pipeline.py",
             "imports": [
                 "mmcv",
-                "numpy",
-                "torch",
-                "cv2",
                 "os",
+                "tqdm",
                 "typing",
-                "tqdm"
+                "torch",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_instance_segmentation_pipeline"
         },
         "('PIPELINES', 'video-multi-modal-embedding', 'video-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_multi_modal_embedding_pipeline.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_multi_modal_embedding_pipeline"
         },
         "('PIPELINES', 'video-multi-object-tracking', 'video-multi-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_multi_object_tracking_pipeline.py",
             "imports": [
-                "typing",
+                "os",
                 "torch",
-                "os"
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.video_multi_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-object-detection', 'cspnet_realtime-video-object-detection_streamyolo')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/realtime_video_object_detection_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
-                "PIL",
                 "typing",
+                "torch",
+                "PIL",
+                "cv2",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.cv.realtime_video_object_detection_pipeline"
         },
         "('PIPELINES', 'video-object-segmentation', 'video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_object_segmentation_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_object_segmentation_pipeline"
         },
         "('PIPELINES', 'video-panoptic-segmentation', 'video-panoptic-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_panoptic_segmentation_pipeline.py",
             "imports": [
                 "mmcv",
-                "numpy",
-                "torch",
-                "cv2",
                 "os",
+                "tqdm",
                 "typing",
-                "tqdm"
+                "torch",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_panoptic_segmentation_pipeline"
         },
         "('PIPELINES', 'video-question-answering', 'video-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/video_question_answering_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.video_question_answering_pipeline"
         },
         "('PIPELINES', 'video-single-object-tracking', 'ostrack-vitb-video-single-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py",
             "imports": [
-                "typing",
                 "os",
-                "cv2"
+                "cv2",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.video_single_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-single-object-tracking', 'procontext-vitb-video-single-object-tracking')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_single_object_tracking_pipeline.py",
             "imports": [
-                "typing",
                 "os",
-                "cv2"
+                "cv2",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.video_single_object_tracking_pipeline"
         },
         "('PIPELINES', 'video-stabilization', 'video-stabilization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_stabilization_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
+                "os",
+                "tempfile",
                 "math",
-                "glob",
+                "typing",
                 "torch",
-                "os",
+                "glob",
                 "cv2",
-                "tempfile",
-                "typing"
+                "subprocess",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_stabilization_pipeline"
         },
         "('PIPELINES', 'video-summarization', 'googlenet_pgl_video_summarization')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_summarization_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
-                "cv2",
+                "tqdm",
                 "typing",
-                "tqdm"
+                "torch",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.video_summarization_pipeline"
         },
         "('PIPELINES', 'video-super-resolution', 'realbasicvsr-video-super-resolution')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/video_super_resolution_pipeline.py",
             "imports": [
-                "numpy",
-                "subprocess",
+                "os",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "tempfile",
-                "typing"
+                "cv2",
+                "subprocess",
+                "numpy",
+                "torchvision"
             ],
             "module": "modelscope.pipelines.cv.video_super_resolution_pipeline"
         },
         "('PIPELINES', 'video-temporal-grounding', 'soonet-video-temporal-grounding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/soonet_video_temporal_grounding_pipeline.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.pipelines.multi_modal.soonet_video_temporal_grounding_pipeline"
         },
         "('PIPELINES', 'video-text-retrieval', 'vop-video-text-retrieval')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vop_retrieval_pipeline.py",
             "imports": [
-                "numpy",
-                "pickle",
+                "collections",
+                "os",
+                "tqdm",
                 "math",
-                "random",
+                "typing",
+                "pickle",
                 "torch",
                 "gzip",
-                "os",
-                "collections",
-                "typing",
-                "tqdm"
+                "random",
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.vop_retrieval_pipeline"
         },
         "('PIPELINES', 'video-text-retrieval', 'vop-video-text-retrieval-se')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vop_retrieval_se_pipeline.py",
             "imports": [
-                "numpy",
+                "os",
+                "typing",
                 "torch",
                 "gzip",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.vop_retrieval_se_pipeline"
         },
         "('PIPELINES', 'virtual-try-on', 'virtual-try-on')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/virtual_try_on_pipeline.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
                 "cv2",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.pipelines.cv.virtual_try_on_pipeline"
         },
         "('PIPELINES', 'vision-efficient-tuning', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/pipelines/cv/vision_efficient_tuning_pipeline.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "torchvision"
+                "torchvision",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.cv.vision_efficient_tuning_pipeline"
         },
         "('PIPELINES', 'visual-entailment', 'visual-entailment')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_entailment_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_entailment_pipeline"
         },
         "('PIPELINES', 'visual-grounding', 'visual-grounding')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_grounding_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_grounding_pipeline"
         },
         "('PIPELINES', 'visual-question-answering', 'gridvlp-multi-modal-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/gridvlp_pipeline.py",
             "imports": [
-                "numpy",
-                "time",
-                "traceback",
+                "os",
                 "transformers",
+                "typing",
+                "time",
                 "torch",
-                "os",
+                "traceback",
                 "PIL",
-                "typing",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.pipelines.multi_modal.gridvlp_pipeline"
         },
         "('PIPELINES', 'visual-question-answering', 'visual-question-answering')": {
             "filepath": "TEMPLATE_PATH/pipelines/multi_modal/visual_question_answering_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.multi_modal.visual_question_answering_pipeline"
         },
         "('PIPELINES', 'voice-activity-detection', 'vad-inference')": {
             "filepath": "TEMPLATE_PATH/pipelines/audio/voice_activity_detection_pipeline.py",
             "imports": [
-                "funasr",
                 "os",
-                "yaml",
+                "funasr",
                 "typing",
+                "yaml",
                 "json"
             ],
             "module": "modelscope.pipelines.audio.voice_activity_detection_pipeline"
         },
         "('PIPELINES', 'word-alignment', 'word-alignment')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_alignment_pipeline.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_alignment_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'multilingual-word-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'word-segmentation')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'word-segmentation', 'word-segmentation-thai')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/word_segmentation_pipeline.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.word_segmentation_pipeline"
         },
         "('PIPELINES', 'zero-shot-classification', 'zero-shot-classification')": {
             "filepath": "TEMPLATE_PATH/pipelines/nlp/zero_shot_classification_pipeline.py",
             "imports": [
-                "typing",
                 "torch",
-                "scipy"
+                "scipy",
+                "typing"
             ],
             "module": "modelscope.pipelines.nlp.zero_shot_classification_pipeline"
         },
         "('POSITIONAL_ENCODING', 'default', 'SinePositionalEncoding3D')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/positional_encoding.py",
             "imports": [
-                "mmcv",
                 "torch",
+                "mmcv",
                 "math"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.positional_encoding"
         },
         "('PREPROCESSORS', 'audio', 'LinearAECAndFbank')": {
             "filepath": "TEMPLATE_PATH/preprocessors/audio.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "scipy",
                 "typing",
+                "torch",
                 "io",
-                "scipy"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.audio"
         },
+        "('PREPROCESSORS', 'audio', 'sen-cls-tokenizer')": {
+            "filepath": "TEMPLATE_PATH/preprocessors/speaker.py",
+            "imports": [
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.preprocessors.speaker"
+        },
+        "('PREPROCESSORS', 'audio', 'token-cls-tokenizer')": {
+            "filepath": "TEMPLATE_PATH/preprocessors/speaker.py",
+            "imports": [
+                "torch",
+                "typing"
+            ],
+            "module": "modelscope.preprocessors.speaker"
+        },
         "('PREPROCESSORS', 'audio', 'wav-to-lists')": {
             "filepath": "TEMPLATE_PATH/preprocessors/kws.py",
             "imports": [
-                "typing",
                 "os",
-                "yaml"
+                "yaml",
+                "typing"
             ],
             "module": "modelscope.preprocessors.kws"
         },
         "('PREPROCESSORS', 'audio', 'wav-to-scp')": {
             "filepath": "TEMPLATE_PATH/preprocessors/asr.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.preprocessors.asr"
         },
         "('PREPROCESSORS', 'cv', 'CenterCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'ImageToTensor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'Normalize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomHorizontalFlip')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'RandomResizedCrop')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'Resize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'bad-image-detecting-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/bad_image_detecting_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
                 "math",
+                "typing",
                 "torch",
                 "PIL",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.bad_image_detecting_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'controllable-image-generation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/controllable_image_generation.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
-                "torchvision",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.controllable_image_generation"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-bypass-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-mmcv-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/mmcls_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.cv.mmcls_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-classification-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_classification_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "os",
+                "typing",
+                "torch",
                 "PIL",
-                "typing"
+                "cv2",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_classification_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-color-enhance-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-deblur-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-demoire-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_restoration_preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
                 "math",
+                "typing",
                 "torch",
                 "PIL",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_restoration_preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-denoise-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-driving-perception-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_driving_perception/preprocessor.py",
             "imports": [
-                "typing",
-                "numpy",
                 "torch",
-                "cv2"
+                "numpy",
+                "cv2",
+                "typing"
             ],
             "module": "modelscope.models.cv.image_driving_perception.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'image-instance-segmentation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-portrait-enhancement-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'image-quality_assessment-man-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_man.py",
             "imports": [
-                "numpy",
-                "torchvision",
                 "math",
+                "typing",
                 "torch",
                 "PIL",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_quality_assessment_man"
         },
         "('PREPROCESSORS', 'cv', 'image-quality_assessment-mos-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/cv/image_quality_assessment_mos.py",
             "imports": [
-                "numpy",
                 "math",
-                "torchvision",
+                "typing",
                 "cv2",
-                "typing"
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.cv.image_quality_assessment_mos"
         },
         "('PREPROCESSORS', 'cv', 'image-sky-change-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/image_skychange/preprocessor.py",
             "imports": [
-                "numpy",
-                "torchvision",
-                "torch",
-                "cv2",
                 "pdb",
                 "typing",
+                "torch",
+                "cv2",
+                "torchvision",
+                "numpy",
                 "numbers",
                 "json"
             ],
             "module": "modelscope.models.cv.image_skychange.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'load-image')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'movie-scene-segmentation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/video.py",
             "imports": [
-                "uuid",
-                "numpy",
                 "urllib",
+                "os",
                 "math",
-                "random",
-                "torchvision",
+                "decord",
                 "torch",
-                "os",
+                "uuid",
                 "tempfile",
-                "decord"
+                "random",
+                "torchvision",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.video"
         },
         "('PREPROCESSORS', 'cv', 'nerf-recon-acc-preprocessor')": {
             "filepath": "TEMPLATE_PATH/models/cv/nerf_recon_acc/nerf_preprocess.py",
             "imports": [
-                "numpy",
-                "subprocess",
-                "glob",
+                "os",
+                "typing",
                 "tensorflow",
+                "glob",
                 "cv2",
-                "os",
-                "typing"
+                "subprocess",
+                "numpy"
             ],
             "module": "modelscope.models.cv.nerf_recon_acc.nerf_preprocess"
         },
         "('PREPROCESSORS', 'cv', 'object-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/models/cv/face_detection/scrfd/preprocessor.py",
             "imports": [
-                "typing",
+                "numpy",
                 "PIL",
-                "numpy"
+                "typing"
             ],
             "module": "modelscope.models.cv.face_detection.scrfd.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'object-detection-tinynas-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'cv', 'ocr-detection')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_detection/preprocessor.py",
             "imports": [
-                "numpy",
+                "os",
                 "math",
+                "typing",
                 "torch",
-                "os",
-                "cv2",
                 "PIL",
-                "typing"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.ocr_detection.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/models/cv/ocr_recognition/preprocessor.py",
             "imports": [
-                "numpy",
-                "torch",
                 "os",
+                "torch",
                 "PIL",
-                "cv2"
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.models.cv.ocr_recognition.preprocessor"
         },
         "('PREPROCESSORS', 'cv', 'video-summarization-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/image.py",
             "imports": [
-                "numpy",
-                "cv2",
-                "PIL",
                 "typing",
-                "io"
+                "io",
+                "PIL",
+                "cv2",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.image"
         },
         "('PREPROCESSORS', 'default', 'Compose')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Filter')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Identity')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'Rename')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'ToNumpy')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'default', 'ToTensor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/common.py",
             "imports": [
-                "numpy",
+                "collections",
+                "typing",
                 "time",
                 "torch",
-                "collections",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.preprocessors.common"
         },
         "('PREPROCESSORS', 'multi-modal', 'clip-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'diffusion-image-generation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'hitea-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'image-captioning-clip-interrogator-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'mplug-owl-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'mplug-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'ofa-tasks-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'multi-modal', 'vldoc-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/multi_modal.py",
             "imports": [
-                "numpy",
-                "re",
-                "torchvision",
-                "timm",
-                "torch",
                 "os",
-                "PIL",
+                "timm",
                 "typing",
                 "decord",
+                "torch",
                 "io",
+                "PIL",
+                "re",
+                "torchvision",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.preprocessors.multi_modal"
         },
         "('PREPROCESSORS', 'nlp', 'Tokenize')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/bert_seq_cls_tokenizer.py",
             "imports": [
-                "typing",
-                "transformers"
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.bert_seq_cls_tokenizer"
         },
         "('PREPROCESSORS', 'nlp', 'bert-seq-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'canmt-translation')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/canmt_translation.py",
             "imports": [
-                "jieba",
                 "sacremoses",
-                "subword_nmt",
-                "torch",
+                "jieba",
                 "os",
-                "typing"
+                "typing",
+                "subword_nmt",
+                "torch"
             ],
             "module": "modelscope.preprocessors.nlp.canmt_translation"
         },
         "('PREPROCESSORS', 'nlp', 'conversational-text-to-sql')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space_T_en/conversational_text_to_sql_preprocessor.py",
             "imports": [
-                "text2sql_lgesql",
-                "torch",
+                "json",
                 "os",
                 "typing",
-                "json"
+                "torch",
+                "text2sql_lgesql"
             ],
             "module": "modelscope.preprocessors.nlp.space_T_en.conversational_text_to_sql_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-intent-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_intent_prediction_preprocessor.py",
             "imports": [
-                "typing",
                 "os",
-                "json"
+                "json",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_intent_prediction_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-modeling-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_modeling_preprocessor.py",
             "imports": [
-                "typing",
-                "os"
+                "os",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_modeling_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-state-tracking-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space/dialog_state_tracking_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space.dialog_state_tracking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'dialog-use-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/dialog_classification_use_preprocessor.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.dialog_classification_use_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-generate')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_generate_preprocessor.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_generate_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-rerank')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_rerank_preprocessor.py",
             "imports": [
+                "os",
                 "transformers",
                 "copy",
-                "torch",
-                "os",
-                "typing"
+                "typing",
+                "torch"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_rerank_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-grounded-dialog-retrieval')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_grounded_dialog_retrieval_preprocessor.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.document_grounded_dialog_retrieval_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'document-segmentation')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/document_segmentation_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.document_segmentation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'faq-question-answering-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/faq_question_answering_preprocessor.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.faq_question_answering_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'feature-extraction')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/feature_extraction_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.feature_extraction_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'fill-mask')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py",
             "imports": [
-                "numpy",
-                "re",
+                "os",
                 "abc",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "re",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.fill_mask_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'fill-mask-ponet')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/fill_mask_preprocessor.py",
             "imports": [
-                "numpy",
-                "re",
+                "os",
                 "abc",
+                "typing",
                 "torch",
-                "os",
-                "typing"
+                "re",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.fill_mask_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'mgeo-ranking')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/mgeo_ranking_preprocessor.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.mgeo_ranking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'mglm-summarization')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/mglm_summarization_preprocessor.py",
             "imports": [
-                "typing",
+                "os",
                 "re",
-                "os"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.mglm_summarization_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'nli-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 're-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/relation_extraction_preprocessor.py",
             "imports": [
-                "typing",
-                "transformers"
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.relation_extraction_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sen-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sen-sim-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_classification_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sentence-embedding')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/sentence_embedding_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.sentence_embedding_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sentence-piece')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'sequence-labeling-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'siamese-uie-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/siamese_uie_preprocessor.py",
             "imports": [
-                "typing",
-                "transformers"
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.siamese_uie_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'table-question-answering-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/space_T_cn/table_question_answering_preprocessor.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.space_T_cn.table_question_answering_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-error-correction')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_error_correction.py",
             "imports": [
-                "typing",
-                "torch",
                 "os",
-                "transformers"
+                "torch",
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_error_correction"
         },
         "('PREPROCESSORS', 'nlp', 'text-gen-jieba-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-gen-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text-ranking')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_ranking_preprocessor.py",
             "imports": [
-                "typing",
-                "transformers"
+                "transformers",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_ranking_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'text2text-gen-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/text_generation_preprocessor.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.text_generation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'thai-ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_thai_preprocessor.py",
             "imports": [
                 "typing"
@@ -9542,325 +9845,345 @@
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_thai_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'token-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'translation-evaluation-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/translation_evaluation_preprocessor.py",
             "imports": [
-                "typing",
+                "transformers",
                 "torch",
-                "transformers"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.translation_evaluation_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'viet-ner-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_viet_preprocessor.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_viet_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'word-alignment')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/word_alignment_preprocessor.py",
             "imports": [
-                "numpy",
-                "itertools",
-                "torch",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "itertools",
+                "numpy"
             ],
             "module": "modelscope.preprocessors.nlp.word_alignment_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'word-segment-text-to-label-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/token_classification_preprocessor.py",
             "imports": [
-                "typing",
+                "torch",
                 "numpy",
-                "torch"
+                "typing"
             ],
             "module": "modelscope.preprocessors.nlp.token_classification_preprocessor"
         },
         "('PREPROCESSORS', 'nlp', 'zero-shot-cls-tokenizer')": {
             "filepath": "TEMPLATE_PATH/preprocessors/nlp/zero_shot_classification_preprocessor.py",
             "imports": [
                 "typing"
             ],
             "module": "modelscope.preprocessors.nlp.zero_shot_classification_preprocessor"
         },
         "('PREPROCESSORS', 'science', 'unifold-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/science/uni_fold.py",
             "imports": [
-                "pickle",
-                "hashlib",
                 "tarfile",
-                "torch",
-                "gzip",
-                "os",
+                "hashlib",
                 "logging",
-                "typing",
-                "json",
                 "tqdm",
-                "numpy",
+                "time",
+                "pickle",
+                "torch",
+                "gzip",
                 "re",
+                "numpy",
+                "ipdb",
+                "os",
                 "requests",
-                "time",
+                "typing",
+                "pathlib",
                 "random",
                 "unittest",
-                "ipdb",
-                "pathlib"
+                "json"
             ],
             "module": "modelscope.preprocessors.science.uni_fold"
         },
         "('PREPROCESSORS', 'text-to-speech', 'kantts-data-preprocessor')": {
             "filepath": "TEMPLATE_PATH/preprocessors/tts.py",
             "imports": [
-                "typing",
+                "os",
                 "kantts",
-                "os"
+                "typing"
             ],
             "module": "modelscope.preprocessors.tts"
         },
         "('ROI_EXTRACTORS', 'default', 'SingleRoINExtractor')": {
             "filepath": "TEMPLATE_PATH/models/cv/abnormal_object_detection/mmdet_ms/roi_head/roi_extractors/single_level_roi_extractor.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.roi_extractors.single_level_roi_extractor"
         },
         "('TRACKERS', 'default', 'QuasiDenseEmbedTracker')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_panoptic_segmentation/track/quasi_dense_embed_tracker.py",
             "imports": [
-                "mmcv",
+                "mmdet",
                 "torch",
-                "mmdet"
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_panoptic_segmentation.track.quasi_dense_embed_tracker"
         },
         "('TRAINERS', 'default', 'action-detection')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/action_detection_trainer.py",
             "imports": [
-                "fvcore",
-                "detectron2",
-                "torch",
                 "os",
-                "typing"
+                "detectron2",
+                "fvcore",
+                "typing",
+                "torch"
             ],
             "module": "modelscope.trainers.cv.action_detection_trainer"
         },
         "('TRAINERS', 'default', 'bert-sentiment-analysis')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/sequence_classification_trainer.py",
             "imports": [
-                "typing",
                 "time",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.sequence_classification_trainer"
         },
         "('TRAINERS', 'default', 'card-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/card_detection_scrfd_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.card_detection_scrfd_trainer"
         },
         "('TRAINERS', 'default', 'cartoon-translation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/cartoon_translation_trainer.py",
             "imports": [
-                "numpy",
-                "tensorflow",
-                "packaging",
                 "os",
+                "tqdm",
                 "typing",
-                "tqdm"
+                "tensorflow",
+                "packaging",
+                "numpy"
             ],
             "module": "modelscope.trainers.cv.cartoon_translation_trainer"
         },
         "('TRAINERS', 'default', 'clip-multi-modal-embedding')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/clip/clip_trainer.py",
             "imports": [
-                "typing",
                 "os",
                 "torch",
-                "math"
+                "math",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.clip.clip_trainer"
         },
         "('TRAINERS', 'default', 'csanmt-translation')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/csanmt_translation_trainer.py",
             "imports": [
-                "tensorflow",
-                "time",
                 "os",
+                "time",
+                "tensorflow",
                 "typing"
             ],
             "module": "modelscope.trainers.nlp.csanmt_translation_trainer"
         },
+        "('TRAINERS', 'default', 'custom-diffusion')": {
+            "filepath": "TEMPLATE_PATH/trainers/multi_modal/custom_diffusion/custom_diffusion_trainer.py",
+            "imports": [
+                "hashlib",
+                "os",
+                "warnings",
+                "tqdm",
+                "typing",
+                "pathlib",
+                "torch",
+                "diffusers",
+                "PIL",
+                "itertools",
+                "random",
+                "torchvision",
+                "numpy",
+                "json"
+            ],
+            "module": "modelscope.trainers.multi_modal.custom_diffusion.custom_diffusion_trainer"
+        },
         "('TRAINERS', 'default', 'dialog-intent-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/space/dialog_intent_trainer.py",
             "imports": [
-                "typing",
                 "os",
-                "numpy"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.space.dialog_intent_trainer"
         },
         "('TRAINERS', 'default', 'dialog-modeling-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/space/dialog_modeling_trainer.py",
             "imports": [
-                "typing",
-                "numpy",
                 "os",
-                "time"
+                "time",
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.space.dialog_modeling_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-generate-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_generate_trainer.py",
             "imports": [
-                "tqdm",
-                "re",
-                "rouge",
+                "collections",
+                "sacrebleu",
                 "string",
+                "os",
+                "tqdm",
                 "transformers",
+                "rouge",
                 "torch",
-                "collections",
-                "os",
-                "sacrebleu",
+                "re",
                 "json"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_generate_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-rerank-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_rerank_trainer.py",
             "imports": [
-                "numpy",
-                "time",
-                "random",
+                "os",
                 "transformers",
+                "typing",
+                "time",
                 "torch",
-                "os",
-                "typing"
+                "random",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_rerank_trainer"
         },
         "('TRAINERS', 'default', 'document-grounded-dialog-retrieval-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/document_grounded_dialog_retrieval_trainer.py",
             "imports": [
-                "numpy",
+                "os",
                 "tqdm",
-                "faiss",
                 "transformers",
                 "torch",
-                "os",
+                "faiss",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.trainers.nlp.document_grounded_dialog_retrieval_trainer"
         },
         "('TRAINERS', 'default', 'dreambooth-diffusion')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py",
             "imports": [
-                "warnings",
-                "hashlib",
-                "diffusers",
-                "torchvision",
-                "shutil",
-                "itertools",
-                "torch",
                 "collections",
-                "PIL",
+                "hashlib",
+                "tqdm",
+                "warnings",
                 "typing",
                 "pathlib",
-                "tqdm"
+                "torch",
+                "diffusers",
+                "PIL",
+                "itertools",
+                "shutil",
+                "torchvision"
             ],
             "module": "modelscope.trainers.multi_modal.dreambooth_diffusion.dreambooth_diffusion_trainer"
         },
         "('TRAINERS', 'default', 'dummy')": {
             "filepath": "TEMPLATE_PATH/trainers/base.py",
             "imports": [
-                "typing",
+                "os",
                 "time",
                 "abc",
-                "os"
+                "typing"
             ],
             "module": "modelscope.trainers.base"
         },
         "('TRAINERS', 'default', 'efficient-diffusion-tuning')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.efficient_diffusion_tuning.efficient_diffusion_tuning_trainer"
         },
         "('TRAINERS', 'default', 'face-detection-scrfd')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/face_detection_scrfd_trainer.py",
             "imports": [
-                "typing",
+                "os",
                 "time",
                 "copy",
-                "os"
+                "typing"
             ],
             "module": "modelscope.trainers.cv.face_detection_scrfd_trainer"
         },
         "('TRAINERS', 'default', 'faq-question-answering-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/faq_question_answering_trainer.py",
             "imports": [
-                "numpy",
-                "dataclasses",
-                "functools",
-                "torch",
                 "collections",
+                "functools",
                 "distutils",
+                "contextlib",
                 "typing",
-                "contextlib"
+                "torch",
+                "dataclasses",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.faq_question_answering_trainer"
         },
         "('TRAINERS', 'default', 'image-classification')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_classifition_trainer.py",
             "imports": [
-                "numpy",
-                "time",
+                "os",
                 "copy",
+                "typing",
+                "time",
                 "torch",
-                "os",
-                "typing"
+                "numpy"
             ],
             "module": "modelscope.trainers.cv.image_classifition_trainer"
         },
         "('TRAINERS', 'default', 'image-classification-team')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/team/team_trainer.py",
             "imports": [
-                "numpy",
-                "sklearn",
-                "torch",
                 "collections",
+                "sklearn",
                 "os",
-                "typing"
+                "typing",
+                "torch",
+                "numpy"
             ],
             "module": "modelscope.trainers.multi_modal.team.team_trainer"
         },
         "('TRAINERS', 'default', 'image-fewshot-detection')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_defrcn_fewshot_detection_trainer.py",
             "imports": [
-                "detectron2",
-                "torch",
                 "collections",
                 "os",
-                "typing"
+                "detectron2",
+                "typing",
+                "torch"
             ],
             "module": "modelscope.trainers.cv.image_defrcn_fewshot_detection_trainer"
         },
         "('TRAINERS', 'default', 'image-inpainting')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_inpainting_trainer.py",
             "imports": [
                 "time",
@@ -9873,157 +10196,157 @@
             "filepath": "TEMPLATE_PATH/trainers/cv/image_instance_segmentation_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.image_instance_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'image-portrait-enhancement')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_portrait_enhancement_trainer.py",
             "imports": [
-                "torch",
-                "collections"
+                "collections",
+                "torch"
             ],
             "module": "modelscope.trainers.cv.image_portrait_enhancement_trainer"
         },
         "('TRAINERS', 'default', 'lora-diffusion')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py",
             "imports": [
-                "typing",
                 "torch",
-                "diffusers"
+                "diffusers",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.lora_diffusion.lora_diffusion_trainer"
         },
         "('TRAINERS', 'default', 'mgeo-ranking-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/mgeo_ranking_trainer.py",
             "imports": [
-                "typing",
                 "dataclasses",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.mgeo_ranking_trainer"
         },
         "('TRAINERS', 'default', 'movie-scene-segmentation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/movie_scene_segmentation_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.cv.movie_scene_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'mplug')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/mplug/mplug_trainer.py",
             "imports": [
-                "typing",
+                "collections",
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.mplug.mplug_trainer"
         },
         "('TRAINERS', 'default', 'nerf-recon-acc')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/nerf_recon_acc_trainer.py",
             "imports": [
-                "numpy",
-                "time",
-                "random",
-                "glob",
                 "datetime",
-                "torch",
-                "cv2",
                 "os",
+                "tqdm",
+                "cv2",
                 "typing",
-                "tqdm"
+                "time",
+                "torch",
+                "glob",
+                "random",
+                "numpy"
             ],
             "module": "modelscope.trainers.cv.nerf_recon_acc_trainer"
         },
         "('TRAINERS', 'default', 'nlp-base-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp_trainer.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp_trainer"
         },
         "('TRAINERS', 'default', 'nlp-gpt-moe-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/gpt_moe_trainer.py",
             "imports": [
-                "torch",
+                "megatron_util",
                 "collections",
                 "os",
                 "typing",
-                "megatron_util"
+                "torch"
             ],
             "module": "modelscope.trainers.nlp.gpt_moe_trainer"
         },
         "('TRAINERS', 'default', 'nlp-gpt3-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/gpt3_trainer.py",
             "imports": [
-                "typing",
-                "torch",
+                "os",
                 "copy",
-                "os"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.gpt3_trainer"
         },
         "('TRAINERS', 'default', 'nlp-plug-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/plug_trainer.py",
             "imports": [
-                "torch",
+                "megatron_util",
+                "deepspeed",
                 "os",
                 "typing",
-                "megatron_util",
-                "deepspeed"
+                "torch"
             ],
             "module": "modelscope.trainers.nlp.plug_trainer"
         },
         "('TRAINERS', 'default', 'nlp-sentence-embedding-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/sentence_embedding_trainer.py",
             "imports": [
-                "numpy",
-                "dataclasses",
-                "time",
+                "tqdm",
                 "transformers",
-                "torch",
                 "typing",
-                "tqdm"
+                "time",
+                "torch",
+                "dataclasses",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.sentence_embedding_trainer"
         },
         "('TRAINERS', 'default', 'nlp-text-ranking-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/text_ranking_trainer.py",
             "imports": [
-                "numpy",
-                "dataclasses",
+                "tqdm",
+                "typing",
                 "time",
                 "torch",
-                "typing",
-                "tqdm"
+                "dataclasses",
+                "numpy"
             ],
             "module": "modelscope.trainers.nlp.text_ranking_trainer"
         },
         "('TRAINERS', 'default', 'nlp-veco-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp_trainer.py",
             "imports": [
-                "typing",
-                "numpy",
+                "os",
                 "torch",
-                "os"
+                "numpy",
+                "typing"
             ],
             "module": "modelscope.trainers.nlp_trainer"
         },
         "('TRAINERS', 'default', 'ocr-detection-db')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/ocr_detection_db_trainer.py",
             "imports": [
-                "numpy",
-                "time",
-                "math",
                 "datetime",
-                "copy",
-                "torch",
                 "os",
+                "tqdm",
+                "copy",
+                "math",
+                "time",
                 "typing",
+                "torch",
                 "easydict",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.trainers.cv.ocr_detection_db_trainer"
         },
         "('TRAINERS', 'default', 'ocr-recognition')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/ocr_recognition_trainer.py",
             "imports": [
                 "time",
@@ -10032,835 +10355,850 @@
             ],
             "module": "modelscope.trainers.cv.ocr_recognition_trainer"
         },
         "('TRAINERS', 'default', 'ofa')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/ofa/ofa_trainer.py",
             "imports": [
                 "functools",
-                "math",
+                "os",
                 "shutil",
+                "typing",
+                "math",
                 "torch",
-                "os",
                 "tempfile",
-                "typing",
                 "json"
             ],
             "module": "modelscope.trainers.multi_modal.ofa.ofa_trainer"
         },
         "('TRAINERS', 'default', 'referring-video-object-segmentation')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/referring_video_object_segmentation_trainer.py",
             "imports": [
-                "torch",
-                "os"
+                "os",
+                "torch"
             ],
             "module": "modelscope.trainers.cv.referring_video_object_segmentation_trainer"
         },
         "('TRAINERS', 'default', 'siamese-uie-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/siamese_uie_trainer.py",
             "imports": [
-                "numpy",
-                "time",
-                "math",
-                "random",
-                "torch",
                 "collections",
                 "os",
                 "typing",
+                "time",
+                "math",
+                "torch",
+                "random",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.trainers.nlp.siamese_uie_trainer"
         },
         "('TRAINERS', 'default', 'speech-asr-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/asr_trainer.py",
             "imports": [
-                "shutil",
-                "funasr",
                 "os",
-                "tempfile",
+                "funasr",
+                "shutil",
                 "typing",
+                "tempfile",
                 "json"
             ],
             "module": "modelscope.trainers.audio.asr_trainer"
         },
         "('TRAINERS', 'default', 'speech-kantts-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/tts_trainer.py",
             "imports": [
                 "zipfile",
-                "shutil",
                 "os",
-                "tempfile",
+                "shutil",
                 "typing",
+                "tempfile",
                 "json"
             ],
             "module": "modelscope.trainers.audio.tts_trainer"
         },
         "('TRAINERS', 'default', 'speech-separation')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/separation_trainer.py",
             "imports": [
-                "numpy",
-                "speechbrain",
-                "torch",
-                "os",
                 "csv",
+                "os",
+                "tqdm",
                 "typing",
+                "speechbrain",
+                "torch",
                 "torchaudio",
-                "tqdm"
+                "numpy"
             ],
             "module": "modelscope.trainers.audio.separation_trainer"
         },
         "('TRAINERS', 'default', 'speech_dfsmn_kws_char_farfield')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/kws_farfield_trainer.py",
             "imports": [
-                "numpy",
-                "pickle",
-                "math",
-                "glob",
                 "datetime",
-                "torch",
                 "os",
-                "typing"
+                "math",
+                "typing",
+                "pickle",
+                "torch",
+                "glob",
+                "numpy"
             ],
             "module": "modelscope.trainers.audio.kws_farfield_trainer"
         },
         "('TRAINERS', 'default', 'speech_frcrn_ans_cirm_16k')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/ans_trainer.py",
             "imports": [],
             "module": "modelscope.trainers.audio.ans_trainer"
         },
         "('TRAINERS', 'default', 'speech_kws_fsmn_char_ctc_nearfield')": {
             "filepath": "TEMPLATE_PATH/trainers/audio/kws_nearfield_trainer.py",
             "imports": [
-                "re",
                 "datetime",
-                "copy",
-                "torch",
                 "os",
-                "yaml",
+                "copy",
                 "typing",
+                "yaml",
+                "torch",
+                "re",
                 "tensorboardX"
             ],
             "module": "modelscope.trainers.audio.kws_nearfield_trainer"
         },
         "('TRAINERS', 'default', 'stable-diffusion')": {
             "filepath": "TEMPLATE_PATH/trainers/multi_modal/stable_diffusion/stable_diffusion_trainer.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.multi_modal.stable_diffusion.stable_diffusion_trainer"
         },
         "('TRAINERS', 'default', 'table-question-answering-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/table_question_answering_trainer.py",
             "imports": [
-                "numpy",
+                "os",
                 "tqdm",
+                "typing",
                 "time",
                 "torch",
-                "os",
-                "typing",
+                "numpy",
                 "json"
             ],
             "module": "modelscope.trainers.nlp.table_question_answering_trainer"
         },
         "('TRAINERS', 'default', 'text-generation-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/text_generation_trainer.py",
             "imports": [
                 "torch",
-                "collections"
+                "typing"
             ],
             "module": "modelscope.trainers.nlp.text_generation_trainer"
         },
         "('TRAINERS', 'default', 'tinynas-damoyolo')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/image_detection_damoyolo_trainer.py",
             "imports": [
-                "time",
-                "math",
                 "datetime",
-                "torch",
                 "os",
+                "math",
+                "time",
                 "typing",
+                "torch",
                 "easydict"
             ],
             "module": "modelscope.trainers.cv.image_detection_damoyolo_trainer"
         },
         "('TRAINERS', 'default', 'trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/trainer.py",
             "imports": [
-                "functools",
-                "inspect",
-                "torch",
                 "collections",
+                "functools",
+                "distutils",
                 "os",
                 "copy",
-                "distutils",
                 "typing",
+                "torch",
+                "inspect",
                 "json"
             ],
             "module": "modelscope.trainers.trainer"
         },
         "('TRAINERS', 'default', 'translation-evaluation-trainer')": {
             "filepath": "TEMPLATE_PATH/trainers/nlp/translation_evaluation_trainer.py",
             "imports": [
-                "math",
-                "random",
-                "transformers",
-                "torch",
                 "os",
-                "pandas",
+                "tqdm",
+                "transformers",
                 "typing",
-                "tqdm"
+                "math",
+                "torch",
+                "random",
+                "pandas"
             ],
             "module": "modelscope.trainers.nlp.translation_evaluation_trainer"
         },
         "('TRAINERS', 'default', 'vision-efficient-tuning')": {
             "filepath": "TEMPLATE_PATH/trainers/cv/vision_efficient_tuning_trainer.py",
             "imports": [
-                "typing",
-                "torch"
+                "torch",
+                "typing"
             ],
             "module": "modelscope.trainers.cv.vision_efficient_tuning_trainer"
         },
         "('TRANSFORMER', 'default', 'PETRDNTransformer')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "mmcv",
-                "copy",
                 "torch",
+                "mmcv",
                 "warnings",
+                "mmdet",
+                "copy",
                 "math",
-                "typing",
-                "mmdet"
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER', 'default', 'KernelUpdator')": {
             "filepath": "TEMPLATE_PATH/models/cv/video_instance_segmentation/head/kernel_updator.py",
             "imports": [
-                "mmcv",
-                "torch"
+                "torch",
+                "mmcv"
             ],
             "module": "modelscope.models.cv.video_instance_segmentation.head.kernel_updator"
         },
         "('TRANSFORMER_LAYER', 'default', 'PETRTransformerDecoderLayer')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "mmcv",
-                "copy",
                 "torch",
+                "mmcv",
                 "warnings",
+                "mmdet",
+                "copy",
                 "math",
-                "typing",
-                "mmdet"
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER_SEQUENCE', 'default', 'PETRTransformerDecoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "mmcv",
-                "copy",
                 "torch",
+                "mmcv",
                 "warnings",
+                "mmdet",
+                "copy",
                 "math",
-                "typing",
-                "mmdet"
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         },
         "('TRANSFORMER_LAYER_SEQUENCE', 'default', 'PETRTransformerEncoder')": {
             "filepath": "TEMPLATE_PATH/models/cv/object_detection_3d/depe/mmdet3d_plugin/models/utils/petr_transformer.py",
             "imports": [
-                "mmcv",
-                "copy",
                 "torch",
+                "mmcv",
                 "warnings",
+                "mmdet",
+                "copy",
                 "math",
-                "typing",
-                "mmdet"
+                "typing"
             ],
             "module": "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer"
         }
     },
-    "md5": "be3ded6cc329edf0b55b1db385b151fd",
+    "md5": "4b40ac8d80a58f5de056693197bb6d18",
     "modelscope_path": "TEMPLATE_PATH",
     "requirements": {
         "modelscope.exporters.audio.ans_dfsmn_exporter": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.exporters.base": [
-            "typing",
+            "os",
             "abc",
-            "os"
+            "typing"
         ],
         "modelscope.exporters.builder": [],
         "modelscope.exporters.cv.cartoon_translation_exporter": [
-            "tensorflow",
-            "packaging",
             "os",
+            "packaging",
+            "tensorflow",
             "typing"
         ],
         "modelscope.exporters.cv.face_detection_scrfd_exporter": [
-            "numpy",
             "functools",
-            "onnx",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "onnx",
+            "numpy"
         ],
         "modelscope.exporters.cv.object_detection_damoyolo_exporter": [
-            "numpy",
             "functools",
-            "onnx",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "onnx",
+            "numpy"
         ],
         "modelscope.exporters.multi_modal.stable_diffusion_exporter": [
-            "diffusers",
-            "shutil",
-            "packaging",
-            "onnx",
-            "torch",
-            "os",
             "collections",
-            "argparse",
+            "os",
             "typing",
-            "pathlib"
+            "argparse",
+            "pathlib",
+            "torch",
+            "onnx",
+            "diffusers",
+            "packaging",
+            "shutil"
         ],
         "modelscope.exporters.nlp.csanmt_for_translation_exporter": [
+            "os",
             "tensorflow",
-            "typing",
-            "os"
+            "typing"
         ],
         "modelscope.exporters.nlp.model_for_token_classification_exporter": [
-            "typing",
+            "collections",
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.exporters.nlp.sbert_for_sequence_classification_exporter": [
-            "typing",
+            "collections",
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.exporters.nlp.sbert_for_zero_shot_classification_exporter": [
-            "typing",
-            "collections"
+            "collections",
+            "typing"
         ],
         "modelscope.exporters.tf_model_exporter": [
+            "os",
             "tensorflow",
-            "typing",
-            "os"
+            "typing"
         ],
         "modelscope.exporters.torch_model_exporter": [
-            "itertools",
-            "torch",
+            "contextlib",
             "os",
             "typing",
-            "contextlib"
+            "torch",
+            "itertools"
         ],
         "modelscope.metrics.accuracy_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.action_detection_evaluator": [
-            "numpy",
+            "collections",
+            "logging",
+            "os",
             "detectron2",
             "copy",
-            "logging",
+            "scipy",
             "pandas",
-            "os",
-            "collections",
-            "scipy"
+            "numpy"
         ],
         "modelscope.metrics.audio_noise_metric": [
             "typing"
         ],
         "modelscope.metrics.base": [
-            "typing",
-            "abc"
+            "abc",
+            "typing"
         ],
         "modelscope.metrics.bleu_metric": [
-            "typing",
             "itertools",
-            "sacrebleu"
+            "sacrebleu",
+            "typing"
         ],
         "modelscope.metrics.builder": [
             "typing"
         ],
         "modelscope.metrics.ciderD.ciderD": [
             "__future__"
         ],
         "modelscope.metrics.ciderD.ciderD_scorer": [
-            "numpy",
-            "six",
-            "math",
-            "copy",
             "collections",
-            "os",
             "pdb",
-            "__future__"
+            "os",
+            "__future__",
+            "copy",
+            "math",
+            "six",
+            "numpy"
         ],
         "modelscope.metrics.image_color_enhance_metric": [
-            "typing",
+            "cv2",
             "numpy",
-            "cv2"
+            "typing"
         ],
         "modelscope.metrics.image_colorization_metric": [
-            "numpy",
-            "torchvision",
+            "scipy",
+            "typing",
             "torch",
             "cv2",
-            "typing",
-            "scipy"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.metrics.image_denoise_metric": [
-            "typing",
-            "numpy",
             "torch",
-            "cv2"
+            "numpy",
+            "cv2",
+            "typing"
         ],
         "modelscope.metrics.image_inpainting_metric": [
-            "typing",
-            "numpy",
             "torch",
-            "scipy"
+            "scipy",
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.image_instance_segmentation_metric": [
-            "numpy",
             "collections",
             "os",
+            "typing",
             "pycocotools",
             "tempfile",
-            "typing"
+            "numpy"
         ],
         "modelscope.metrics.image_portrait_enhancement_metric": [
-            "typing",
+            "cv2",
             "numpy",
-            "cv2"
+            "typing"
         ],
         "modelscope.metrics.image_quality_assessment_degradation_metric": [
-            "numpy",
-            "tqdm",
-            "torch",
             "collections",
-            "cv2",
+            "sys",
             "os",
-            "tempfile",
+            "tqdm",
+            "scipy",
             "typing",
-            "sys",
-            "scipy"
+            "torch",
+            "tempfile",
+            "cv2",
+            "numpy"
         ],
         "modelscope.metrics.image_quality_assessment_mos_metric": [
             "numpy",
-            "torch",
             "os",
-            "cv2",
-            "tempfile",
+            "tqdm",
             "scipy",
             "typing",
-            "sys",
-            "tqdm"
+            "torch",
+            "tempfile",
+            "cv2",
+            "sys"
         ],
         "modelscope.metrics.inbatch_recall_metric": [
-            "typing",
+            "torch",
             "numpy",
-            "torch"
+            "typing"
         ],
         "modelscope.metrics.loss_metric": [
-            "typing",
+            "sklearn",
             "numpy",
-            "sklearn"
+            "typing"
         ],
         "modelscope.metrics.map_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.movie_scene_segmentation_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.ned_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.ocr_recognition_metric": [
-            "typing",
+            "torch",
             "numpy",
             "edit_distance",
-            "torch"
+            "typing"
         ],
         "modelscope.metrics.ppl_metric": [
-            "typing",
-            "numpy",
             "torch",
-            "math"
+            "numpy",
+            "math",
+            "typing"
         ],
         "modelscope.metrics.prediction_saving_wrapper": [
-            "typing",
+            "sklearn",
             "numpy",
-            "sklearn"
+            "typing"
         ],
         "modelscope.metrics.referring_video_object_segmentation_metric": [
-            "numpy",
+            "tqdm",
+            "typing",
             "torch",
             "pycocotools",
-            "typing",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.metrics.sequence_classification_metric": [
-            "typing",
+            "sklearn",
             "numpy",
-            "sklearn"
+            "typing"
         ],
         "modelscope.metrics.text_generation_metric": [
-            "rouge",
+            "contextlib",
             "nltk",
+            "rouge",
             "typing",
-            "sys",
-            "contextlib"
+            "sys"
         ],
         "modelscope.metrics.text_ranking_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.token_classification_metric": [
             "importlib",
             "numpy",
             "typing"
         ],
         "modelscope.metrics.translation_evaluation_metric": [
             "importlib",
-            "typing",
-            "pandas"
+            "pandas",
+            "typing"
         ],
         "modelscope.metrics.video_frame_interpolation_metric": [
-            "numpy",
             "lpips",
             "math",
+            "typing",
             "torch",
-            "typing"
+            "numpy"
         ],
         "modelscope.metrics.video_stabilization_metric": [
             "numpy",
             "os",
-            "cv2",
-            "tempfile",
+            "tqdm",
             "typing",
-            "sys",
-            "tqdm"
+            "tempfile",
+            "cv2",
+            "sys"
         ],
         "modelscope.metrics.video_summarization_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.metrics.video_super_resolution_metric.matlab_functions": [
-            "numpy",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.metrics.video_super_resolution_metric.metric_util": [
             "numpy"
         ],
         "modelscope.metrics.video_super_resolution_metric.niqe": [
-            "numpy",
             "cv2",
-            "math",
-            "scipy"
+            "scipy",
+            "numpy",
+            "math"
         ],
         "modelscope.metrics.video_super_resolution_metric.video_super_resolution_metric": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.audio.aec.layers.activations": [
             "torch"
         ],
         "modelscope.models.audio.aec.layers.affine_transform": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.audio.aec.layers.deep_fsmn": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.audio.aec.layers.layer_base": [
+            "torch",
             "numpy",
             "abc",
-            "re",
-            "torch"
+            "re"
         ],
         "modelscope.models.audio.aec.layers.uni_deep_fsmn": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.audio.aec.network.loss": [
             "torch"
         ],
         "modelscope.models.audio.aec.network.modulation_loss": [
+            "torchaudio",
             "torch",
-            "math",
-            "torchaudio"
+            "math"
         ],
         "modelscope.models.audio.aec.network.se_net": [
             "torch"
         ],
         "modelscope.models.audio.ans.complex_nn": [
             "torch"
         ],
         "modelscope.models.audio.ans.conv_stft": [
-            "numpy",
             "torch",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.audio.ans.denoise_net": [
             "torch"
         ],
         "modelscope.models.audio.ans.frcrn": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.audio.ans.layers.activations": [
             "torch"
         ],
         "modelscope.models.audio.ans.layers.affine_transform": [
             "torch"
         ],
         "modelscope.models.audio.ans.layers.layer_base": [
+            "six",
             "numpy",
             "abc",
-            "six",
             "torch"
         ],
         "modelscope.models.audio.ans.layers.uni_deep_fsmn": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.audio.ans.se_module_complex": [
             "torch"
         ],
         "modelscope.models.audio.ans.unet": [
             "torch"
         ],
         "modelscope.models.audio.asr.generic_automatic_speech_recognition": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.asr.wenet_automatic_speech_recognition": [
-            "wenetruntime",
-            "typing",
             "os",
-            "json"
+            "wenetruntime",
+            "json",
+            "typing"
         ],
         "modelscope.models.audio.itn.generic_inverse_text_processing": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.kws.farfield.fsmn": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.audio.kws.farfield.fsmn_sele_v2": [
             "torch"
         ],
         "modelscope.models.audio.kws.farfield.fsmn_sele_v3": [
             "torch"
         ],
         "modelscope.models.audio.kws.farfield.model": [
-            "typing",
             "os",
-            "tempfile"
+            "tempfile",
+            "typing"
         ],
         "modelscope.models.audio.kws.farfield.model_def": [
-            "math",
             "enum",
-            "struct"
+            "struct",
+            "math"
         ],
         "modelscope.models.audio.kws.generic_key_word_spotting": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.kws.nearfield.cmvn": [
+            "torch",
             "numpy",
-            "re",
-            "torch"
+            "re"
         ],
         "modelscope.models.audio.kws.nearfield.fsmn": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.audio.kws.nearfield.model": [
-            "torch",
             "os",
-            "tempfile",
             "typing",
+            "torch",
+            "tempfile",
             "sys"
         ],
         "modelscope.models.audio.punc.generic_punctuation": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.audio.separation.layer_norm": [
-            "torch",
-            "__future__"
+            "__future__",
+            "torch"
         ],
         "modelscope.models.audio.separation.mossformer": [
-            "typing",
-            "copy",
             "os",
-            "torch"
+            "copy",
+            "torch",
+            "typing"
         ],
         "modelscope.models.audio.separation.mossformer_block": [
             "torch"
         ],
         "modelscope.models.audio.separation.mossformer_conv_module": [
             "torch"
         ],
         "modelscope.models.audio.sv.DTDNN": [
-            "numpy",
-            "torch",
             "collections",
             "os",
             "typing",
-            "torchaudio"
+            "torch",
+            "torchaudio",
+            "numpy"
         ],
         "modelscope.models.audio.sv.DTDNN_layers": [
             "torch"
         ],
         "modelscope.models.audio.sv.ERes2Net": [
-            "math",
-            "torch",
             "os",
             "typing",
+            "math",
+            "torch",
             "torchaudio"
         ],
         "modelscope.models.audio.sv.ERes2Net_aug": [
-            "math",
-            "torch",
             "os",
             "typing",
+            "math",
+            "torch",
             "torchaudio"
         ],
         "modelscope.models.audio.sv.cluster_backend": [
-            "typing",
-            "numpy",
+            "hdbscan",
             "sklearn",
-            "scipy"
+            "scipy",
+            "umap",
+            "typing",
+            "numpy"
         ],
         "modelscope.models.audio.sv.ecapa_tdnn": [
-            "numpy",
-            "math",
-            "torch",
             "os",
             "typing",
-            "torchaudio"
+            "math",
+            "torch",
+            "torchaudio",
+            "numpy"
         ],
         "modelscope.models.audio.sv.fusion": [
             "torch"
         ],
         "modelscope.models.audio.sv.generic_speaker_verification": [
+            "os",
+            "typing"
+        ],
+        "modelscope.models.audio.sv.lanuage_recognition_model": [
+            "os",
             "typing",
-            "os"
+            "torch",
+            "torchaudio",
+            "numpy"
         ],
         "modelscope.models.audio.sv.pooling_layers": [
             "torch"
         ],
         "modelscope.models.audio.sv.rdino": [
-            "math",
-            "torch",
             "os",
+            "math",
             "typing",
+            "torch",
             "torchaudio"
         ],
         "modelscope.models.audio.sv.speaker_change_locator": [
-            "numpy",
-            "torch",
             "collections",
             "os",
             "typing",
-            "torchaudio"
+            "torch",
+            "torchaudio",
+            "numpy"
+        ],
+        "modelscope.models.audio.sv.speaker_diarization_dialogue_detection": [
+            "torch"
+        ],
+        "modelscope.models.audio.sv.speaker_diarization_semantic_speaker_turn_detection": [
+            "torch"
         ],
         "modelscope.models.audio.tts.sambert_hifi": [
-            "numpy",
-            "zipfile",
             "wave",
+            "zipfile",
             "datetime",
-            "shutil",
-            "matplotlib",
             "os",
-            "yaml",
             "__future__",
+            "matplotlib",
+            "yaml",
+            "shutil",
+            "numpy",
             "json"
         ],
         "modelscope.models.audio.tts.voice": [
-            "numpy",
-            "pickle",
-            "threading",
-            "time",
-            "kantts",
-            "torch",
             "collections",
             "os",
+            "time",
             "yaml",
+            "kantts",
+            "pickle",
+            "torch",
+            "threading",
+            "numpy",
             "json"
         ],
         "modelscope.models.base.base_head": [
-            "typing",
-            "abc"
+            "abc",
+            "typing"
         ],
         "modelscope.models.base.base_model": [
-            "typing",
+            "os",
             "abc",
-            "os"
+            "typing"
         ],
         "modelscope.models.base.base_torch_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.base.base_torch_model": [
             "functools",
-            "packaging",
-            "torch",
-            "copy",
             "os",
-            "typing"
+            "copy",
+            "typing",
+            "torch",
+            "packaging"
         ],
         "modelscope.models.builder": [],
         "modelscope.models.cv.abnormal_object_detection.mmdet_model": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.mask_scoring_roi_head": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.abnormal_object_detection.mmdet_ms.roi_head.roi_extractors.single_level_roi_extractor": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.action_detection.action_detection_onnx": [
+            "urllib",
+            "os",
+            "tempfile",
             "uuid",
-            "numpy",
             "onnxruntime",
-            "urllib",
-            "subprocess",
             "shutil",
             "cv2",
-            "os",
-            "tempfile"
+            "subprocess",
+            "numpy"
         ],
         "modelscope.models.cv.action_detection.modules.action_detection_pytorch": [
-            "fvcore",
-            "detectron2",
-            "torch",
             "logging",
-            "typing"
+            "detectron2",
+            "fvcore",
+            "typing",
+            "torch"
         ],
         "modelscope.models.cv.action_detection.modules.resnet": [
             "detectron2",
             "torch"
         ],
         "modelscope.models.cv.action_recognition.models": [
             "torch"
@@ -10869,157 +11207,157 @@
             "torch"
         ],
         "modelscope.models.cv.action_recognition.tada_convnext": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.action_recognition.temporal_patch_shift_transformer": [
-            "numpy",
             "functools",
-            "torchvision",
+            "operator",
+            "einops",
             "timm",
             "abc",
             "torch",
-            "einops",
-            "operator"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.animal_recognition.resnet": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.animal_recognition.splat": [
             "torch"
         ],
         "modelscope.models.cv.bad_image_detecting.bad_image_detecting": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.body_2d_keypoints.hrnet_basic_modules": [
             "torch"
         ],
         "modelscope.models.cv.body_2d_keypoints.hrnet_v2": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.body_2d_keypoints.w48": [],
         "modelscope.models.cv.body_3d_keypoints.cannonical_pose.body_3d_pose": [
-            "numpy",
-            "torch",
             "logging",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.body_3d_keypoints.cannonical_pose.canonical_pose_modules": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.backbone": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.block": [
             "torch",
-            "einops",
-            "math"
+            "math",
+            "einops"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.directed_graph": [
-            "typing",
             "sys",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer": [
             "torch"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.hdformer_detector": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.body_3d_keypoints.hdformer.skeleton": [
             "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.LK.lk": [
             "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.config": [
-            "numpy",
             "os",
-            "easydict"
+            "easydict",
+            "numpy"
         ],
         "modelscope.models.cv.cartoon.facelib.face_detector": [
+            "time",
             "tensorflow",
             "numpy",
-            "cv2",
-            "time"
+            "cv2"
         ],
         "modelscope.models.cv.cartoon.facelib.face_landmark": [
             "tensorflow",
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.cartoon.facelib.facer": [
             "time",
             "cv2",
             "numpy"
         ],
         "modelscope.models.cv.cartoon.loss": [
-            "numpy",
+            "os",
+            "scipy",
             "joblib",
             "tensorflow",
-            "os",
             "skimage",
-            "scipy"
+            "numpy"
         ],
         "modelscope.models.cv.cartoon.model_tf": [
             "tensorflow",
             "typing"
         ],
         "modelscope.models.cv.cartoon.mtcnn_pytorch.src.align_trans": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.cartoon.mtcnn_pytorch.src.matlab_cp2tform": [
             "numpy"
         ],
         "modelscope.models.cv.cartoon.network": [
             "tensorflow"
         ],
         "modelscope.models.cv.cartoon.utils": [
             "tensorflow",
-            "numpy",
-            "cv2",
+            "random",
             "os",
-            "random"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.c3d": [
             "torch"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.resnet2p1d": [
             "torch"
         ],
         "modelscope.models.cv.cmdssl_video_embedding.resnet3d": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.annotator": [
+            "einops",
             "mmcv",
-            "numpy",
+            "os",
             "mmseg",
             "torch",
-            "einops",
             "cv2",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.api": [
             "os",
-            "cv2",
             "torch",
-            "torchvision"
+            "torchvision",
+            "cv2"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.base_model": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.blocks": [
             "torch"
         ],
@@ -11029,149 +11367,149 @@
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.midas_net": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.midas_net_custom": [
             "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.transforms": [
-            "math",
+            "cv2",
             "numpy",
-            "cv2"
+            "math"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.midas.vit": [
-            "torch",
             "timm",
-            "math",
-            "types"
+            "types",
+            "torch",
+            "math"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.midas.utils": [
             "numpy",
-            "re",
             "torch",
+            "re",
             "cv2",
             "sys"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.mlsd.mbv2_mlsd_large": [
-            "sys",
+            "os",
             "torch",
-            "os"
+            "sys"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.mlsd.utils": [
-            "numpy",
+            "os",
             "cv2",
-            "torch",
-            "os"
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.body": [
-            "numpy",
-            "time",
-            "math",
-            "torchvision",
+            "scipy",
             "matplotlib",
+            "math",
+            "time",
             "torch",
             "cv2",
-            "scipy"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.hand": [
-            "numpy",
-            "time",
-            "math",
+            "scipy",
             "matplotlib",
+            "math",
+            "time",
+            "skimage",
             "torch",
             "cv2",
-            "scipy",
-            "skimage",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.model": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.controllable_image_generation.annotator.openpose.util": [
-            "numpy",
             "cv2",
-            "math",
-            "matplotlib"
+            "numpy",
+            "matplotlib",
+            "math"
         ],
         "modelscope.models.cv.controllable_image_generation.controlnet": [
             "numpy",
-            "control_ldm",
-            "math",
-            "random",
-            "torch",
             "einops",
             "os",
             "cv2",
-            "tempfile",
-            "PIL",
+            "math",
             "typing",
+            "torch",
+            "PIL",
+            "control_ldm",
+            "tempfile",
+            "random",
             "sys"
         ],
         "modelscope.models.cv.crowd_counting.cc_model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.crowd_counting.hrnet_aspp_relu": [
-            "numpy",
             "functools",
-            "torch",
             "logging",
-            "os"
+            "os",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.face_attribute_recognition.fair_face.face_attribute_recognition": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
+            "torch",
+            "PIL",
             "cv2",
-            "PIL"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.mogface.models.detectors": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_detection.mogface.models.mogface": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.mogface.models.mogprednet": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.face_detection.mogface.models.resnet": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.mogface.models.utils": [
-            "numpy",
             "itertools",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.box_utils": [
             "numpy",
             "PIL"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.detector": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "PIL"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.first_stage": [
-            "numpy",
             "torch",
+            "numpy",
             "PIL",
             "math"
         ],
         "modelscope.models.cv.face_detection.mtcnn.models.get_nets": [
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.LK.lk": [
             "numpy"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.face_detector": [
             "tensorflow",
             "numpy",
@@ -11179,141 +11517,141 @@
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.face_landmark": [
             "tensorflow",
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_detection.peppa_pig_face.facer": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.retinaface.detection": [
-            "numpy",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_detection.retinaface.models.net": [
             "time",
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.face_detection.retinaface.models.retinaface": [
-            "torch",
             "collections",
+            "torch",
             "torchvision"
         ],
         "modelscope.models.cv.face_detection.retinaface.utils": [
-            "numpy",
             "itertools",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.face_detection.scrfd.damofd_detect": [
-            "typing",
-            "torch",
+            "os",
             "copy",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.core.bbox.transforms": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.core.post_processing.bbox_nms": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.auto_augment": [
             "mmcv",
-            "numpy",
+            "mmdet",
             "copy",
-            "cv2",
-            "mmdet"
+            "numpy",
+            "cv2"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.formating": [
-            "mmcv",
-            "numpy",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.loading": [
-            "pycocotools",
-            "numpy",
             "os",
-            "mmdet"
+            "pycocotools",
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.pipelines.transforms": [
+            "mmdet",
             "mmcv",
-            "numpy",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.datasets.retinaface": [
-            "numpy",
-            "mmdet"
+            "mmdet",
+            "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.master_net": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.mobilenet": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.backbones.resnet": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.dense_heads.scrfd_head": [
-            "mmcv",
-            "torch",
             "mmdet",
+            "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.base": [
+            "collections",
+            "torch",
             "mmcv",
+            "mmdet",
             "numpy",
-            "abc",
-            "torch",
-            "collections",
-            "mmdet"
+            "abc"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.scrfd": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.single_stage": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.mmdet_patch.models.detectors.tinymog": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.face_detection.scrfd.preprocessor": [
-            "typing",
+            "numpy",
             "PIL",
-            "numpy"
+            "typing"
         ],
         "modelscope.models.cv.face_detection.scrfd.scrfd_detect": [
-            "numpy",
-            "torch",
-            "copy",
             "os",
-            "typing"
-        ],
-        "modelscope.models.cv.face_detection.scrfd.tinymog_detect": [
+            "copy",
             "typing",
             "torch",
+            "numpy"
+        ],
+        "modelscope.models.cv.face_detection.scrfd.tinymog_detect": [
+            "os",
             "copy",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.detection": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.box_utils": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.mb_tiny": [
@@ -11326,611 +11664,611 @@
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.mb_tiny_fd": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.predictor": [
             "torch"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.ssd.ssd": [
-            "typing",
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.face_detection.ulfd_slim.vision.transforms": [
-            "numpy",
-            "torch",
             "cv2",
-            "types"
+            "types",
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.face_emotion.efficient.model": [
             "torch"
         ],
         "modelscope.models.cv.face_emotion.efficient.utils": [
-            "re",
-            "torch",
             "collections",
             "functools",
+            "torch",
+            "re",
             "math"
         ],
         "modelscope.models.cv.face_emotion.emotion_infer": [
             "torch",
-            "PIL",
-            "torchvision"
+            "torchvision",
+            "PIL"
         ],
         "modelscope.models.cv.face_emotion.emotion_model": [
-            "sys",
+            "os",
             "torch",
-            "os"
+            "sys"
         ],
         "modelscope.models.cv.face_emotion.face_alignment.face": [
+            "os",
             "tensorflow",
-            "numpy",
             "cv2",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.face_emotion.face_alignment.face_align": [
-            "numpy",
+            "sys",
             "os",
             "PIL",
             "cv2",
-            "sys"
+            "numpy"
         ],
         "modelscope.models.cv.face_generation.op.conv2d_gradfix": [
-            "contextlib",
+            "warnings",
             "torch",
-            "warnings"
+            "contextlib"
         ],
         "modelscope.models.cv.face_generation.op.fused_act": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.face_generation.op.upfirdn2d": [
+            "os",
             "torch",
-            "collections",
-            "os"
+            "collections"
         ],
         "modelscope.models.cv.face_generation.stylegan2": [
             "functools",
+            "operator",
             "math",
-            "random",
             "torch",
-            "operator"
+            "random"
         ],
         "modelscope.models.cv.face_human_hand_detection.det_infer": [
-            "numpy",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_human_hand_detection.ghost_pan": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.face_human_hand_detection.nanodet_plus_head": [
-            "numpy",
             "math",
-            "torchvision",
             "torch",
-            "cv2"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.face_human_hand_detection.one_stage_detector": [
             "torch"
         ],
         "modelscope.models.cv.face_human_hand_detection.shufflenetv2": [
             "torch"
         ],
         "modelscope.models.cv.face_human_hand_detection.utils": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.align_face": [
-            "numpy",
             "skimage",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.arcface_backbone": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.common": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.facemask_backbone": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.model_irse": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.backbone.model_resnet": [
             "torch"
         ],
         "modelscope.models.cv.face_recognition.torchkit.rts_backbone": [
-            "os",
-            "torch",
             "collections",
+            "torch",
+            "os",
             "math"
         ],
         "modelscope.models.cv.face_reconstruction.models.bfm": [
-            "numpy",
-            "torch",
             "os",
-            "scipy"
+            "torch",
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.de_retouching_module": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facelandmark.large_base_lmks_infer": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.facelandmark.nets.large_base_lmks_net": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facelandmark.nets.large_eyeball_net": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.facerecon_model": [
-            "numpy",
-            "torch",
             "collections",
             "os",
-            "cv2"
+            "torch",
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.losses": [
-            "kornia",
             "numpy",
-            "torch"
+            "torch",
+            "kornia"
         ],
         "modelscope.models.cv.face_reconstruction.models.networks": [
-            "kornia",
-            "typing",
+            "os",
             "torch",
-            "os"
+            "kornia",
+            "typing"
         ],
         "modelscope.models.cv.face_reconstruction.models.nv_diffrast": [
-            "numpy",
             "warnings",
-            "nvdiffrast",
+            "typing",
             "torch",
-            "typing"
+            "nvdiffrast",
+            "numpy"
         ],
         "modelscope.models.cv.face_reconstruction.models.opt": [],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.networks": [
             "functools",
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.pix2pix_model": [
             "torch"
         ],
         "modelscope.models.cv.face_reconstruction.models.pix2pix.pix2pix_options": [],
         "modelscope.models.cv.face_reconstruction.models.renderer": [
-            "skimage",
-            "numpy",
+            "imageio",
             "torch",
-            "imageio"
+            "numpy",
+            "skimage"
         ],
         "modelscope.models.cv.face_reconstruction.models.unet": [
-            "torch",
-            "warnings"
+            "warnings",
+            "torch"
         ],
         "modelscope.models.cv.face_reconstruction.utils": [
-            "numpy",
+            "os",
+            "scipy",
             "array",
             "math",
-            "torch",
-            "os",
-            "cv2",
             "argparse",
-            "PIL",
+            "torch",
             "numba",
-            "scipy"
+            "PIL",
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.facial_expression_recognition": [
-            "numpy",
-            "torch",
             "os",
+            "torch",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.transforms": [
-            "numpy",
             "torch",
-            "PIL",
             "types",
+            "PIL",
+            "numpy",
             "numbers"
         ],
         "modelscope.models.cv.facial_expression_recognition.fer.vgg": [
             "torch"
         ],
         "modelscope.models.cv.facial_landmark_confidence.flc.facial_landmark_confidence": [
-            "numpy",
-            "torch",
             "os",
+            "torch",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.facial_landmark_confidence.flc.manual_landmark_net": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.hand_static.hand_model": [
             "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "cv2",
+            "torch",
             "PIL",
+            "cv2",
+            "torchvision",
             "sys"
         ],
         "modelscope.models.cv.hand_static.networks": [
             "os",
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.human_reconstruction.Reconstruction": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
-            "PIL",
             "os",
             "typing",
-            "skimage"
+            "skimage",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.human_reconstruction.models.Embedding": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.PixToMesh": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.Res_backbone": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.human_reconstruction.models.Surface_head": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.detectors": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.human_reconstruction.models.geometry": [
             "torch"
         ],
         "modelscope.models.cv.human_reconstruction.models.human_segmenter": [
             "tensorflow",
             "numpy",
             "cv2"
         ],
         "modelscope.models.cv.human_reconstruction.models.networks": [
             "functools",
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.human_reconstruction.utils": [
-            "numpy",
-            "torch",
             "os",
-            "mcubes"
+            "mcubes",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_binary_quant_classification.binary_quant_model": [
-            "torch",
             "collections",
+            "torch",
             "os"
         ],
         "modelscope.models.cv.image_binary_quant_classification.bnext": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.image_body_reshaping": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.model": [
             "torch"
         ],
         "modelscope.models.cv.image_body_reshaping.person_info": [
             "numpy",
             "copy",
             "cv2",
             "torch"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.body": [
-            "numpy",
+            "scipy",
             "math",
             "torch",
             "cv2",
-            "scipy"
+            "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.model": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.image_body_reshaping.pose_estimator.util": [
             "numpy"
         ],
         "modelscope.models.cv.image_body_reshaping.slim_utils": [
-            "numpy",
             "torch",
+            "numba",
+            "random",
             "os",
             "cv2",
-            "random",
-            "numba",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.image_classification.backbones.beit_v2": [
+            "collections",
+            "functools",
+            "einops",
             "mmcv",
+            "mmcls",
+            "os",
             "warnings",
-            "functools",
             "math",
-            "itertools",
+            "typing",
             "torch",
-            "collections",
-            "os",
-            "einops",
-            "mmcls",
-            "typing"
+            "itertools"
         ],
         "modelscope.models.cv.image_classification.backbones.nextvit": [
+            "collections",
+            "functools",
+            "einops",
             "mmcv",
+            "mmcls",
+            "os",
             "warnings",
-            "functools",
             "math",
-            "itertools",
+            "typing",
             "torch",
-            "collections",
-            "os",
-            "einops",
-            "mmcls",
-            "typing"
+            "itertools"
         ],
         "modelscope.models.cv.image_classification.mmcls_model": [
             "os"
         ],
         "modelscope.models.cv.image_classification.resnet50_cc": [
-            "torchvision",
+            "collections",
+            "os",
             "math",
             "torch",
-            "collections",
-            "os"
+            "torchvision"
         ],
         "modelscope.models.cv.image_classification.utils": [
-            "numpy",
-            "itertools",
-            "torch",
             "collections",
-            "os",
+            "torch",
             "mmcls",
+            "os",
+            "itertools",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.image_color_enhance.adaint.adaint": [
-            "torchvision",
-            "torch",
             "os",
             "typing",
+            "torch",
+            "torchvision",
             "numbers"
         ],
         "modelscope.models.cv.image_color_enhance.csrnet": [
             "functools",
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_color_enhance.deeplpf.deeplpf_image_color_enhance": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_color_enhance.deeplpf.deeplpfnet": [
             "torch",
-            "math",
-            "matplotlib"
+            "matplotlib",
+            "math"
         ],
         "modelscope.models.cv.image_color_enhance.image_color_enhance": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.ddcolor": [
             "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.ddcolor_for_image_colorization": [
-            "numpy",
-            "torch",
-            "copy",
             "os",
-            "typing"
+            "copy",
+            "typing",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.loss": [
             "torch"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.convnext": [
             "torch",
             "timm"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.position_encoding": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.transformer_utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.unet": [
-            "torch",
             "collections",
+            "torch",
             "enum"
         ],
         "modelscope.models.cv.image_colorization.ddcolor.utils.vgg": [
-            "torchvision",
+            "os",
             "torch",
-            "collections",
-            "os"
+            "torchvision",
+            "collections"
         ],
         "modelscope.models.cv.image_colorization.unet.unet": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_colorization.unet.utils": [
             "functools",
             "torch",
             "enum"
         ],
         "modelscope.models.cv.image_debanding.rrdb.rrdb_image_debanding": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_deblur.nafnet_for_image_deblur": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.defrcn_for_fewshot": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.coco_evaluation": [
-            "numpy",
-            "fvcore",
+            "collections",
             "tabulate",
-            "detectron2",
-            "itertools",
-            "copy",
+            "pycocotools",
+            "contextlib",
             "logging",
             "os",
+            "detectron2",
+            "copy",
+            "fvcore",
             "torch",
-            "collections",
-            "json",
-            "pycocotools",
             "io",
-            "contextlib"
+            "itertools",
+            "numpy",
+            "json"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.evaluator": [
-            "time",
-            "detectron2",
             "datetime",
-            "torch",
-            "logging"
+            "logging",
+            "detectron2",
+            "time",
+            "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.evaluation.pascal_voc_evaluation": [
-            "numpy",
             "collections",
+            "detectron2",
             "os",
             "tempfile",
-            "detectron2"
+            "numpy"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.calibration_layer": [
-            "cv2",
             "detectron2",
             "sklearn",
-            "torch"
+            "torch",
+            "cv2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.defrcn": [
-            "typing",
-            "detectron2",
             "os",
-            "torch"
+            "typing",
+            "torch",
+            "detectron2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.fast_rcnn": [
-            "numpy",
             "detectron2",
             "torch",
+            "numpy",
             "fvcore"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.gdl": [
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.resnet": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.models.roi_heads": [
             "detectron2",
             "torch"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.coco_register": [
-            "fvcore",
+            "io",
+            "contextlib",
             "os",
             "pycocotools",
             "detectron2",
-            "io",
-            "contextlib"
+            "fvcore"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.configuration_mapper": [
             "detectron2"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.model_surgery_op": [
+            "argparse",
             "torch",
-            "os",
-            "argparse"
+            "os"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.register_data": [],
         "modelscope.models.cv.image_defrcn_fewshot.utils.requirements_check": [
-            "packaging",
             "collections",
             "importlib_metadata",
-            "sys",
-            "importlib"
+            "importlib",
+            "packaging",
+            "sys"
         ],
         "modelscope.models.cv.image_defrcn_fewshot.utils.voc_register": [
-            "numpy",
-            "fvcore",
-            "os",
+            "xml",
             "detectron2",
-            "xml"
+            "os",
+            "fvcore",
+            "numpy"
         ],
         "modelscope.models.cv.image_denoise.nafnet.NAFNet_arch": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_denoise.nafnet.arch_util": [
             "torch"
         ],
         "modelscope.models.cv.image_denoise.nafnet_for_image_denoise": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_depth": [
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_layers": [
-            "numpy",
             "torch",
+            "numpy",
             "timm"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.newcrf_utils": [
-            "pkgutil",
-            "torch",
             "collections",
+            "importlib",
+            "torch",
+            "pkgutil",
             "os",
             "warnings",
-            "importlib",
             "torchvision"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.swin_transformer": [
-            "numpy",
             "torch",
+            "numpy",
             "timm"
         ],
         "modelscope.models.cv.image_depth_estimation.networks.uper_crf_head": [
-            "mmcv",
-            "torch"
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.image_depth_estimation.newcrfs_model": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.depth_estimation_bts_model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.bts_model": [
             "torch"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.decoder": [
             "torch"
         ],
@@ -11939,260 +12277,260 @@
             "torchvision"
         ],
         "modelscope.models.cv.image_depth_estimation_bts.networks.utils": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_driving_perception.image_driving_percetion_model": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.cv.image_driving_perception.preprocessor": [
-            "typing",
-            "numpy",
             "torch",
-            "cv2"
+            "numpy",
+            "cv2",
+            "typing"
         ],
         "modelscope.models.cv.image_driving_perception.utils": [
             "time",
             "torch",
             "torchvision",
             "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.gan_wrap": [
-            "numpy",
-            "torchvision",
+            "os",
             "torch",
-            "cv2",
             "PIL",
-            "os"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.model": [
+            "random",
             "torch",
-            "math",
-            "random"
+            "math"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.conv2d_gradfix": [
-            "contextlib",
+            "warnings",
             "torch",
-            "warnings"
+            "contextlib"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.fused_act": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.facegan.op.upfirdn2d": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.image_face_fusion.facelib.align_trans": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.facelib.matlab_cp2tform": [
             "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.image_face_fusion": [
-            "numpy",
-            "torchvision",
-            "torch",
             "collections",
-            "cv2",
-            "PIL",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.network.aad_layer": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.aei_flow_net": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.bfm": [
-            "numpy",
-            "torch",
             "os",
-            "scipy"
+            "torch",
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.image_face_fusion.network.dense_motion": [
             "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.facerecon_model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_face_fusion.network.model_irse": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.image_face_fusion.network.ops": [
             "torch"
         ],
         "modelscope.models.cv.image_human_parsing.backbone.deeplab_resnet": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.image_human_parsing.m2fp.m2fp_decoder": [
             "torch"
         ],
         "modelscope.models.cv.image_human_parsing.m2fp.m2fp_encoder": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.image_human_parsing.m2fp_net": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_human_parsing.parsing_utils": [
-            "numpy",
-            "copy",
             "PIL",
+            "copy",
+            "numpy",
             "torch"
         ],
         "modelscope.models.cv.image_inpainting.base": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.default": [
-            "bisect",
-            "torch"
+            "torch",
+            "bisect"
         ],
         "modelscope.models.cv.image_inpainting.model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.modules.ade20k.base": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.image_inpainting.modules.ade20k.resnet": [
-            "math",
+            "os",
             "torch",
-            "os"
+            "math"
         ],
         "modelscope.models.cv.image_inpainting.modules.adversarial": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.modules.feature_matching": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_inpainting.modules.ffc": [
-            "kornia",
             "numpy",
-            "torch"
+            "torch",
+            "kornia"
         ],
         "modelscope.models.cv.image_inpainting.modules.inception": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.image_inpainting.modules.perceptual": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.image_inpainting.modules.pix2pixhd": [
-            "numpy",
-            "torch",
             "collections",
+            "functools",
+            "torch",
             "logging",
-            "functools"
+            "numpy"
         ],
         "modelscope.models.cv.image_inpainting.refinement": [
             "numpy",
-            "kornia",
+            "tqdm",
             "torch",
             "cv2",
-            "tqdm"
+            "kornia"
         ],
         "modelscope.models.cv.image_instance_segmentation.backbones.resnet": [
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.backbones.swin_transformer": [
-            "numpy",
             "torch",
+            "numpy",
             "timm"
         ],
         "modelscope.models.cv.image_instance_segmentation.cascade_mask_rcnn_swin": [
+            "os",
             "torch",
-            "collections",
-            "os"
+            "collections"
         ],
         "modelscope.models.cv.image_instance_segmentation.datasets.transforms": [
-            "numpy",
-            "os"
+            "os",
+            "numpy"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst.fastinst_decoder": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst.fastinst_encoder": [
-            "typing",
+            "logging",
             "torch",
-            "logging"
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.fastinst_model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.dino_decoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.maskdino_decoder": [
             "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.maskdino_encoder": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.ms_deform_attn": [
-            "mmcv",
             "torch",
-            "warnings",
+            "mmcv",
             "__future__",
+            "warnings",
             "math"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.position_encoding": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino.utils": [
             "copy",
-            "math",
-            "torch"
+            "torch",
+            "math"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino_model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.maskdino_swin": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.image_instance_segmentation.model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_instance_segmentation.postprocess_utils": [
-            "numpy",
-            "itertools",
-            "torch",
             "pycocotools",
-            "cv2"
+            "torch",
+            "itertools",
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.image_matching.config.default": [
             "yacs"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.backbone.resnet_fpn": [
             "torch"
         ],
@@ -12208,398 +12546,398 @@
             "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.quadtree_attention": [
             "torch",
             "timm"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.loftr_module.transformer": [
-            "math",
-            "timm",
-            "torch",
+            "einops",
             "copy",
-            "einops"
+            "timm",
+            "math",
+            "torch"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.coarse_matching": [
             "torch",
             "einops"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.fine_matching": [
-            "kornia",
             "torch",
+            "kornia",
             "math"
         ],
         "modelscope.models.cv.image_matching.loftr_quadtree.utils.position_encoding": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_matching.quadtree_attention_model": [
-            "numpy",
-            "torch",
             "os",
+            "pathlib",
+            "torch",
             "cv2",
-            "pathlib"
+            "numpy"
         ],
         "modelscope.models.cv.image_matching.utils.misc": [
             "yacs"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.cas_mvsnet": [
             "torch"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.casmvs_model": [
-            "numpy",
-            "torch",
             "os",
+            "easydict",
+            "torch",
             "cv2",
-            "easydict"
+            "numpy"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.colmap2mvsnet": [
-            "numpy",
-            "struct",
-            "functools",
-            "multiprocessing",
-            "shutil",
             "collections",
+            "functools",
             "os",
+            "__future__",
+            "struct",
+            "shutil",
             "cv2",
-            "__future__"
+            "numpy",
+            "multiprocessing"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.depth_filter": [
-            "numpy",
-            "plyfile",
             "os",
+            "plyfile",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.general_eval_dataset": [
             "numpy",
-            "re",
             "torch",
-            "cv2",
-            "os",
             "PIL",
+            "re",
+            "os",
+            "cv2",
             "sys"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.module": [
             "torch"
         ],
         "modelscope.models.cv.image_mvs_depth_estimation.utils": [
-            "numpy",
-            "torch",
+            "random",
             "torchvision",
-            "random"
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.image_paintbyexample.model": [
-            "torch",
+            "omegaconf",
             "os",
             "typing",
-            "paint_ldm",
-            "omegaconf"
+            "torch",
+            "paint_ldm"
         ],
         "modelscope.models.cv.image_panoptic_segmentation.panseg_model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.align_faces": [
-            "numpy",
             "skimage",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.eqface.fqa": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.eqface.model_resnet": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.gpen": [
             "functools",
+            "operator",
             "math",
-            "random",
-            "itertools",
             "torch",
-            "operator"
+            "itertools",
+            "random"
         ],
         "modelscope.models.cv.image_portrait_enhancement.image_portrait_enhancement": [
-            "typing",
             "os",
             "torch",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.helpers": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.losses": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.losses.model_irse": [
             "torch"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.detection": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.models.net": [
             "time",
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.models.retinaface": [
-            "torch",
             "collections",
+            "torch",
             "torchvision"
         ],
         "modelscope.models.cv.image_portrait_enhancement.retinaface.utils": [
-            "numpy",
             "itertools",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.image_probing_model.backbone": [
-            "numpy",
+            "collections",
+            "sys",
             "functools",
+            "operator",
             "math",
-            "torchvision",
             "torch",
-            "collections",
             "PIL",
-            "sys",
-            "operator"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.image_probing_model.model": [
-            "typing",
-            "torch",
             "os",
-            "json"
+            "torch",
+            "json",
+            "typing"
         ],
         "modelscope.models.cv.image_probing_model.utils": [
-            "re",
-            "torch"
+            "torch",
+            "re"
         ],
         "modelscope.models.cv.image_quality_assessment_degradation.degradation_model": [
-            "numpy",
-            "torch",
             "collections",
-            "cv2",
             "time",
+            "torch",
+            "cv2",
             "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.image_quality_assessment_degradation.image_quality_assessment_degradation": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_quality_assessment_man.image_quality_assessment_man": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_quality_assessment_man.maniqa": [
+            "timm",
             "torch",
-            "einops",
-            "timm"
+            "einops"
         ],
         "modelscope.models.cv.image_quality_assessment_man.swin": [
-            "itertools",
-            "torch",
             "collections",
+            "itertools",
             "einops",
+            "torch",
             "warnings",
             "math"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.backbones.resnet": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.censeo_ivqa_model": [
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.heads.simple_head": [
             "torch"
         ],
         "modelscope.models.cv.image_quality_assessment_mos.image_quality_assessment_mos": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.image_reid_person.pass_model": [
+            "os",
             "enum",
-            "torch",
-            "os"
+            "torch"
         ],
         "modelscope.models.cv.image_reid_person.transreid_model": [
+            "collections",
             "functools",
-            "itertools",
             "torch",
-            "collections"
+            "itertools"
         ],
         "modelscope.models.cv.image_restoration.demoire_models.nets": [
             "torch"
         ],
         "modelscope.models.cv.image_restoration.image_restoration_model": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.data_util": [],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.feature_extractors": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.pixel_classifier": [
-            "numpy",
-            "torch",
             "collections",
             "os",
-            "PIL"
+            "torch",
+            "PIL",
+            "numpy"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_seg.utils": [
-            "numpy",
-            "torch",
             "PIL",
-            "random"
+            "random",
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.image_semantic_segmentation.ddpm_segmentation_model": [
-            "ddpm_guided_diffusion",
-            "typing",
+            "os",
             "torch",
-            "os"
+            "ddpm_guided_diffusion",
+            "typing"
         ],
         "modelscope.models.cv.image_semantic_segmentation.pan_merge.base_panoptic_fusion_head": [
+            "mmdet",
             "mmcv",
-            "abc",
-            "mmdet"
+            "abc"
         ],
         "modelscope.models.cv.image_semantic_segmentation.pan_merge.maskformer_semantic_head": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.image_semantic_segmentation.semantic_seg_model": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.adapter_modules": [
+            "functools",
             "torch",
             "logging",
             "mmdet",
-            "functools",
             "timm"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.base.beit": [
-            "mmcv",
+            "functools",
             "torch",
+            "mmcv",
             "mmdet",
-            "functools",
-            "math",
-            "timm"
+            "timm",
+            "math"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.backbone.beit_adapter": [
-            "mmdet",
-            "math",
+            "logging",
             "timm",
+            "math",
             "torch",
-            "logging"
+            "mmdet"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.base_decode_head": [
-            "mmcv",
-            "abc",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv",
+            "abc"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.decode_heads.mask2former_head_from_mmseg": [
-            "mmcv",
+            "mmdet",
             "copy",
-            "torch",
-            "mmdet"
+            "mmcv",
+            "torch"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.base_segmentor": [
+            "collections",
+            "torch",
             "mmcv",
+            "warnings",
             "numpy",
-            "abc",
-            "torch",
-            "collections",
-            "warnings"
+            "abc"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.models.segmentors.encoder_decoder_mask2former": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.builder": [
             "mmcv"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.data_process_func": [
-            "mmcv",
-            "mmdet"
+            "mmdet",
+            "mmcv"
         ],
         "modelscope.models.cv.image_semantic_segmentation.vit_adapter.utils.seg_func": [
-            "torch",
-            "warnings"
+            "warnings",
+            "torch"
         ],
         "modelscope.models.cv.image_skychange.preprocessor": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "pdb",
             "typing",
+            "torch",
+            "cv2",
+            "torchvision",
+            "numpy",
             "numbers",
             "json"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.BlockModules": [
             "torch"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.hrnet_backnone": [
-            "numpy",
-            "torch",
             "logging",
+            "torch",
+            "numpy",
             "os"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.hrnet_super_and_ocr": [
-            "numpy",
+            "__future__",
             "torch",
-            "__future__"
+            "numpy"
         ],
         "modelscope.models.cv.image_skychange.ptsemseg.unet": [
             "torch"
         ],
         "modelscope.models.cv.image_skychange.skychange": [
-            "numpy",
-            "torchvision",
-            "torch",
             "collections",
-            "cv2",
-            "os",
             "pdb",
+            "os",
+            "torch",
             "PIL",
+            "cv2",
+            "torchvision",
+            "numpy",
             "numbers",
             "json"
         ],
         "modelscope.models.cv.image_skychange.skychange_model": [
-            "time",
-            "math",
-            "torch",
             "collections",
-            "os",
-            "cv2",
             "pdb",
+            "os",
+            "math",
+            "time",
             "typing",
+            "torch",
+            "cv2",
             "json"
         ],
         "modelscope.models.cv.image_to_image_generation.data.transforms": [
-            "PIL",
+            "random",
             "torchvision",
-            "math",
-            "random"
+            "PIL",
+            "math"
         ],
         "modelscope.models.cv.image_to_image_generation.model": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_generation.models.autoencoder": [
             "torch",
@@ -12614,674 +12952,894 @@
             "math"
         ],
         "modelscope.models.cv.image_to_image_generation.ops.losses": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.data.transforms": [
-            "PIL",
+            "random",
             "torchvision",
-            "math",
-            "random"
+            "PIL",
+            "math"
         ],
         "modelscope.models.cv.image_to_image_translation.model_translation": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.models.autoencoder": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.models.clip": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.apps": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
+            "artist",
+            "torch",
             "PIL",
-            "artist"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.degradation": [
-            "numpy",
             "torch",
+            "random",
             "os",
             "cv2",
-            "random",
-            "math",
-            "scipy"
+            "scipy",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.diffusion": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.losses": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.metrics": [
-            "numpy",
             "torch",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.random_color": [
-            "colorsys",
-            "random"
+            "random",
+            "colorsys"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.random_mask": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.svd": [
             "torch"
         ],
         "modelscope.models.cv.image_to_image_translation.ops.utils": [
-            "numpy",
-            "zipfile",
-            "base64",
             "hashlib",
-            "math",
-            "multiprocessing",
-            "torch",
+            "zipfile",
             "os",
             "cv2",
+            "math",
+            "base64",
+            "torch",
+            "io",
             "PIL",
             "binascii",
-            "io",
+            "numpy",
+            "multiprocessing",
             "json"
         ],
+        "modelscope.models.cv.image_try_on.generator": [
+            "os",
+            "functools",
+            "torch",
+            "torchvision"
+        ],
+        "modelscope.models.cv.image_try_on.landmark": [
+            "logging",
+            "torch",
+            "os"
+        ],
+        "modelscope.models.cv.image_try_on.try_on_infer": [
+            "os",
+            "yaml",
+            "argparse",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy"
+        ],
+        "modelscope.models.cv.image_try_on.warping": [
+            "collections",
+            "torch",
+            "cv2",
+            "numpy",
+            "math"
+        ],
         "modelscope.models.cv.indoor_layout_estimation.networks.backbone.resnet_DA": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.backbone.vit_horizon_pry_image": [
+            "timm",
             "numpy",
-            "torch",
-            "timm"
+            "torch"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.fourier": [
+            "scipy",
             "numpy",
-            "PIL",
-            "scipy"
+            "PIL"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.panostretch": [
             "functools",
-            "numpy",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.misc.post_proc": [
-            "numpy",
             "sklearn",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.modality.layout": [
-            "numpy",
+            "scipy",
             "shapely",
             "math",
             "torch",
-            "scipy"
+            "numpy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.panovit": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.networks.utils": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.indoor_layout_estimation.panovit": [
-            "yacs",
+            "os",
             "numpy",
             "torch",
-            "os"
+            "yacs"
         ],
         "modelscope.models.cv.language_guided_video_summarization.summarizer": [
-            "numpy",
-            "videofeatures_clipit",
-            "torch",
             "os",
-            "argparse",
             "typing",
+            "argparse",
+            "videofeatures_clipit",
+            "torch",
+            "numpy",
             "bmt_clipit"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.layers": [
             "torch"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.models": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.modules": [
             "torch"
         ],
         "modelscope.models.cv.language_guided_video_summarization.transformer.sub_layers": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.motion_generation.model": [],
         "modelscope.models.cv.motion_generation.modules.cfg_sampler": [
-            "torch",
-            "copy"
+            "copy",
+            "torch"
         ],
         "modelscope.models.cv.motion_generation.modules.gaussian_diffusion": [
-            "numpy",
             "enum",
             "torch",
             "copy",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.motion_generation.modules.mdm": [
             "clip",
             "numpy",
             "torch"
         ],
         "modelscope.models.cv.motion_generation.modules.respace": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.motion_generation.modules.rotation2xyz": [
             "torch"
         ],
         "modelscope.models.cv.motion_generation.modules.smpl": [
-            "numpy",
             "torch",
+            "contextlib",
             "os",
             "smplx",
-            "contextlib"
+            "numpy"
         ],
         "modelscope.models.cv.movie_scene_segmentation.get_model": [],
         "modelscope.models.cv.movie_scene_segmentation.model": [
-            "numpy",
-            "math",
-            "torchvision",
-            "torch",
             "einops",
             "os",
-            "PIL",
-            "shotdetect_scenedetect_lgss",
+            "tqdm",
+            "math",
             "typing",
-            "tqdm"
+            "shotdetect_scenedetect_lgss",
+            "torch",
+            "PIL",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.head": [
             "torch"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.save_op": [
-            "numpy",
-            "subprocess",
-            "cv2",
             "os",
+            "cv2",
+            "subprocess",
+            "numpy",
             "tqdm"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.shot_encoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.movie_scene_segmentation.utils.trn": [
+            "transformers",
+            "torch"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.dataloader.load_blender": [
             "torch",
-            "transformers"
+            "os",
+            "cv2",
+            "numpy",
+            "imageio",
+            "json"
         ],
-        "modelscope.models.cv.nerf_recon_acc.dataloader.nerf_dataset": [
+        "modelscope.models.cv.nerf_recon_4k.dataloader.load_data": [
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.dataloader.load_llff": [
+            "torch",
+            "os",
+            "scipy",
             "numpy",
+            "imageio"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.dataloader.load_tankstemple": [
+            "os",
+            "glob",
+            "numpy",
+            "imageio"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.dataloader.read_write_model": [
+            "collections",
+            "argparse",
+            "struct",
+            "os",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.nerf_preprocess": [
+            "os",
+            "typing",
+            "tensorflow",
+            "glob",
+            "cv2",
+            "subprocess",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.nerf_recon_4k": [
+            "mmcv",
+            "os",
+            "tqdm",
+            "time",
+            "argparse",
+            "torch",
+            "imageio",
+            "random",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.network.dvgo": [
+            "functools",
+            "os",
+            "copy",
             "math",
-            "torchvision",
+            "time",
             "torch",
+            "torch_scatter",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_4k.network.utils": [
+            "mcubes",
+            "collections",
+            "torch",
+            "gc",
+            "tinycudann",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_acc.dataloader.nerf_dataset": [
             "os",
+            "math",
+            "torch",
             "PIL",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.nerf_recon_acc.dataloader.read_write_model": [
-            "numpy",
             "collections",
-            "os",
             "argparse",
-            "struct"
+            "struct",
+            "os",
+            "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.nerf_preprocess": [
-            "numpy",
-            "subprocess",
-            "glob",
+            "os",
+            "typing",
             "tensorflow",
+            "glob",
             "cv2",
-            "os",
-            "typing"
+            "subprocess",
+            "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.nerf_recon_acc": [
-            "numpy",
+            "os",
+            "tqdm",
             "time",
-            "glob",
             "torch",
+            "glob",
             "cv2",
-            "os",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.nerf": [
-            "numpy",
             "nerfacc",
             "tinycudann",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.segmenter": [
             "tensorflow",
             "numpy"
         ],
         "modelscope.models.cv.nerf_recon_acc.network.utils": [
-            "numpy",
-            "gc",
-            "torch",
+            "mcubes",
             "collections",
+            "torch",
+            "gc",
             "tinycudann",
-            "mcubes"
+            "numpy"
         ],
-        "modelscope.models.cv.object_detection.mmdet_model": [
+        "modelscope.models.cv.nerf_recon_vq_compression.dataloader.blender": [
+            "os",
+            "tqdm",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy",
+            "json"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.dataloader.llff": [
+            "os",
+            "torch",
+            "PIL",
+            "glob",
+            "torchvision",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.dataloader.nsvf": [
+            "os",
+            "tqdm",
+            "torch",
+            "PIL",
+            "torchvision"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.dataloader.ray_utils": [
+            "kornia",
+            "torch",
             "numpy",
+            "re"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.dataloader.tankstemple": [
+            "os",
+            "tqdm",
             "torch",
-            "os"
+            "PIL",
+            "torchvision"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.nerf_recon_vq_compression": [
+            "functools",
+            "os",
+            "tqdm",
+            "time",
+            "torch",
+            "glob",
+            "cv2",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.network.tensoRF": [],
+        "modelscope.models.cv.nerf_recon_vq_compression.network.tensoRF_VQ": [
+            "os",
+            "tqdm",
+            "typing",
+            "torch",
+            "random"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.network.tensorBase": [
+            "time",
+            "torch",
+            "numpy"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.network.weighted_vq": [
+            "contextlib",
+            "torch",
+            "einops"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.renderer": [
+            "numpy",
+            "os",
+            "tqdm",
+            "torch",
+            "imageio",
+            "sys"
+        ],
+        "modelscope.models.cv.nerf_recon_vq_compression.utils": [
+            "scipy",
+            "skimage",
+            "plyfile",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy"
+        ],
+        "modelscope.models.cv.object_detection.mmdet_model": [
+            "os",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.backbones.vit": [
-            "mmdet",
             "functools",
-            "math",
             "timm",
-            "torch"
+            "math",
+            "torch",
+            "mmdet"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.anchor_head": [
             "mmdet"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.dense_heads.rpn_head": [
-            "mmcv",
+            "mmdet",
             "copy",
-            "torch",
-            "mmdet"
+            "mmcv",
+            "torch"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.necks.fpn": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.bbox_heads.convfc_bbox_head": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.roi_heads.mask_heads.fcn_mask_head": [
             "mmcv",
-            "numpy",
             "warnings",
+            "torch",
             "mmdet",
-            "torch"
+            "numpy"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.utils.checkpoint": [
+            "collections",
             "mmcv",
+            "pkgutil",
+            "os",
             "warnings",
             "time",
-            "torchvision",
-            "pkgutil",
+            "importlib",
             "torch",
-            "collections",
-            "os",
+            "io",
             "tempfile",
-            "importlib",
-            "io"
+            "torchvision"
         ],
         "modelscope.models.cv.object_detection.mmdet_ms.utils.convModule_norm": [
             "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.depe_detect": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.assigners.hungarian_assigner_3d": [
-            "torch",
             "mmdet",
+            "torch",
             "scipy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.coders.nms_free_coder": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.match_costs.match_cost": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.core.bbox.util": [
-            "numpy",
             "torch",
-            "mmdet3d"
+            "mmdet3d",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.nuscenes_dataset": [
-            "numpy",
+            "mmdet",
             "mmdet3d",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.loading": [
+            "mmdet",
             "mmcv",
-            "numpy",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.datasets.pipelines.transform_3d": [
-            "mmcv",
-            "numpy",
-            "copy",
             "torch",
+            "mmcv",
             "PIL",
+            "mmdet",
+            "copy",
             "mmdet3d",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.backbones.vovnet": [
-            "mmcv",
-            "torch",
             "collections",
-            "mmdet"
+            "mmdet",
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.depth_net": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.dense_heads.petrv2_dednhead": [
             "mmcv",
-            "numpy",
-            "mmdet3d",
-            "mmdet",
-            "math",
             "copy",
-            "torch"
+            "math",
+            "torch",
+            "mmdet",
+            "mmdet3d",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.detectors.petr3d": [
             "mmcv",
-            "numpy",
-            "mmdet3d",
+            "torch",
             "mmdet",
-            "torch"
+            "mmdet3d",
+            "numpy"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.necks.cp_fpn": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.petr_transformer": [
-            "mmcv",
-            "copy",
             "torch",
+            "mmcv",
             "warnings",
+            "mmdet",
+            "copy",
             "math",
-            "typing",
-            "mmdet"
+            "typing"
         ],
         "modelscope.models.cv.object_detection_3d.depe.mmdet3d_plugin.models.utils.positional_encoding": [
-            "mmcv",
             "torch",
+            "mmcv",
             "math"
         ],
         "modelscope.models.cv.object_detection_3d.depe.result_vis": [
-            "numpy",
-            "pickle",
-            "mmdet3d",
-            "cv2",
             "os",
             "argparse",
+            "pickle",
             "pyquaternion",
+            "cv2",
+            "mmdet3d",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.ocr_detection.model": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.ocr_detection.modules.dbnet": [
-            "math",
-            "torch",
             "collections",
             "os",
+            "math",
+            "torch",
             "sys"
         ],
         "modelscope.models.cv.ocr_detection.modules.layers": [
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy"
         ],
         "modelscope.models.cv.ocr_detection.modules.mix_ops": [
-            "numpy",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.ocr_detection.modules.proxyless": [
             "numpy",
+            "torch",
             "sys",
-            "re",
-            "torch"
+            "re"
         ],
         "modelscope.models.cv.ocr_detection.modules.seg_detector_loss": [
-            "sys",
-            "torch"
+            "torch",
+            "sys"
         ],
         "modelscope.models.cv.ocr_detection.preprocessor": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.ocr_detection.utils": [
-            "pyclipper",
-            "numpy",
+            "shapely",
             "cv2",
-            "shapely"
+            "numpy",
+            "pyclipper"
         ],
         "modelscope.models.cv.ocr_recognition.model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.CRNN.main_model": [
             "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.convnext": [
             "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.main_model": [
             "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.timm_tinyc": [
-            "itertools",
-            "copy",
-            "torch",
             "collections",
-            "logging",
             "functools",
+            "torch",
+            "logging",
+            "itertools",
+            "copy",
             "math"
         ],
         "modelscope.models.cv.ocr_recognition.modules.ConvNextViT.vitstr": [
             "functools",
-            "copy",
             "logging",
-            "torch",
-            "__future__"
+            "__future__",
+            "copy",
+            "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.main_model": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.layers": [
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy"
         ],
         "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.mix_ops": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.ocr_recognition.modules.LightweightEdge.nas_block.proxyless": [
-            "numpy",
-            "re",
-            "queue",
+            "sys",
             "torch",
-            "sys"
+            "queue",
+            "re",
+            "numpy"
         ],
         "modelscope.models.cv.ocr_recognition.preprocessor": [
-            "numpy",
-            "torch",
             "os",
+            "torch",
             "PIL",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.open_vocabulary_detection_vild.vild": [
-            "numpy",
+            "os",
             "clip",
+            "scipy",
+            "typing",
             "tensorflow",
             "torch",
-            "os",
-            "typing",
-            "scipy"
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.equi": [
-            "numpy",
-            "torch",
             "collections",
-            "__future__"
+            "__future__",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.layers": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.mobilenet": [
             "torch"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.resnet": [
             "torch"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.unifuse": [
-            "numpy",
-            "torch",
             "collections",
-            "__future__"
+            "__future__",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.networks.util": [
-            "numpy",
             "cv2",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.panorama_depth_estimation.unifuse_model": [
-            "numpy",
             "os",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.pedestrian_attribute_recognition.model": [
-            "numpy",
             "os",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.common": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.pointnet2_utils": [
-            "typing",
             "torch",
-            "pointnet2_cuda"
+            "pointnet2_cuda",
+            "typing"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.rcp_model": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.models.cv.pointcloud_sceneflow_estimation.sf_rcp": [
             "torch"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_detection": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_embedding": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.models.cv.product_retrieval_embedding.item_model": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.product_segmentation.net": [
             "torch"
         ],
         "modelscope.models.cv.product_segmentation.seg_infer": [
             "numpy",
-            "cv2",
             "torch",
+            "cv2",
             "PIL"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.backbone": [
             "torch",
-            "einops",
-            "torchvision"
+            "torchvision",
+            "einops"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.criterion": [
             "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.matcher": [
             "torch",
             "scipy"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.misc": [
-            "typing",
-            "torch",
+            "pickle",
             "torchvision",
-            "pickle"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.mttr": [
             "torch",
             "einops"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.multimodal_transformer": [
-            "transformers",
-            "copy",
             "einops",
             "os",
-            "torch",
-            "typing"
+            "transformers",
+            "copy",
+            "typing",
+            "torch"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.position_encoding_2d": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.referring_video_object_segmentation.utils.postprocessing": [
+            "pycocotools",
+            "torch",
             "numpy",
+            "einops"
+        ],
+        "modelscope.models.cv.referring_video_object_segmentation.utils.segmentation": [
             "torch",
+            "typing"
+        ],
+        "modelscope.models.cv.referring_video_object_segmentation.utils.swin_transformer": [
+            "functools",
+            "operator",
             "einops",
-            "pycocotools"
+            "torch",
+            "timm",
+            "numpy"
         ],
-        "modelscope.models.cv.referring_video_object_segmentation.utils.segmentation": [
-            "typing",
+        "modelscope.models.cv.robust_image_classification.easyrobust_model": [
+            "os",
             "torch"
         ],
-        "modelscope.models.cv.referring_video_object_segmentation.utils.swin_transformer": [
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.config": [
+            "os",
+            "yaml",
+            "yacs"
+        ],
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.decoder": [
+            "torch",
             "numpy",
+            "einops"
+        ],
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.model": [
             "torch",
-            "einops",
-            "operator",
-            "functools",
+            "numpy"
+        ],
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.resnet": [
+            "torch"
+        ],
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.swin_transformer": [
+            "torch",
+            "numpy",
             "timm"
         ],
-        "modelscope.models.cv.robust_image_classification.easyrobust_model": [
+        "modelscope.models.cv.s2net_panorama_depth_estimation.networks.util_helper": [
+            "pkgutil",
+            "os",
+            "warnings",
+            "importlib",
             "torch",
-            "os"
+            "healpy",
+            "apex",
+            "torchvision",
+            "numpy"
+        ],
+        "modelscope.models.cv.s2net_panorama_depth_estimation.s2net_model": [
+            "os",
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.salient_detection.models.backbone.Res2Net_v1b": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.salient_detection.models.modules": [
             "torch"
@@ -13292,146 +13850,146 @@
         "modelscope.models.cv.salient_detection.models.u2net": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.models.utils": [
             "torch"
         ],
         "modelscope.models.cv.salient_detection.salient_model": [
-            "torchvision",
-            "torch",
             "os",
+            "torch",
+            "PIL",
             "cv2",
-            "PIL"
+            "torchvision"
         ],
         "modelscope.models.cv.shop_segmentation.common": [
-            "torch",
-            "warnings"
+            "warnings",
+            "torch"
         ],
         "modelscope.models.cv.shop_segmentation.head_fpn": [
-            "mmcv",
-            "torch",
             "timm",
-            "numpy"
+            "mmcv",
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.shop_segmentation.models": [
-            "torch",
             "collections",
-            "math",
-            "timm"
+            "torch",
+            "timm",
+            "math"
         ],
         "modelscope.models.cv.shop_segmentation.neck_fpn": [
-            "mmcv",
             "torch",
+            "mmcv",
             "timm"
         ],
         "modelscope.models.cv.shop_segmentation.shop_seg_base": [
             "torch"
         ],
         "modelscope.models.cv.shop_segmentation.shop_seg_model": [
-            "numpy",
-            "torch",
-            "PIL",
             "os",
             "typing",
+            "torch",
+            "PIL",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.shop_segmentation.utils": [
-            "ftfy",
-            "html",
             "functools",
+            "ftfy",
+            "os",
             "regex",
+            "typing",
             "torch",
             "gzip",
-            "os",
-            "typing"
+            "html"
         ],
         "modelscope.models.cv.skin_retouching.detection_model.detection_module": [
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.detection_model.detection_unet_in": [
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.inpainting_model.gconv": [
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.inpainting_model.inpainting_unet": [
             "torch"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.box_utils": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.net": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.network": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.predict_single": [
-            "numpy",
-            "torchvision",
-            "torch",
             "albumentations",
-            "typing"
+            "typing",
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.prior_box": [
             "itertools",
             "torch",
             "math"
         ],
         "modelscope.models.cv.skin_retouching.retinaface.utils": [
-            "numpy",
-            "re",
+            "pathlib",
             "torch",
+            "re",
             "cv2",
-            "typing",
-            "pathlib"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.unet_deploy": [
-            "torch",
-            "warnings"
+            "warnings",
+            "torch"
         ],
         "modelscope.models.cv.skin_retouching.utils": [
-            "numpy",
-            "torch",
+            "time",
             "einops",
+            "torch",
             "cv2",
-            "typing",
-            "time"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.skin_retouching.weights_init": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.data.data_augment": [
             "numpy",
             "cv2",
-            "math",
-            "random"
+            "random",
+            "math"
         ],
         "modelscope.models.cv.stream_yolo.exp.base_exp": [
-            "abc",
-            "torch"
+            "torch",
+            "abc"
         ],
         "modelscope.models.cv.stream_yolo.exp.build": [
-            "sys",
-            "os"
+            "os",
+            "sys"
         ],
         "modelscope.models.cv.stream_yolo.exp.default.streamyolo": [
-            "sys",
+            "os",
             "torch",
-            "os"
+            "sys"
         ],
         "modelscope.models.cv.stream_yolo.exp.yolox_base": [
-            "torch",
             "os",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.models.cv.stream_yolo.models.darknet": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.models.dfp_pafpn": [
             "torch"
         ],
@@ -13441,183 +13999,206 @@
         "modelscope.models.cv.stream_yolo.models.streamyolo": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.models.tal_head": [
             "torch"
         ],
         "modelscope.models.cv.stream_yolo.realtime_video_detector": [
-            "numpy",
-            "time",
-            "torch",
             "logging",
-            "cv2",
             "os",
+            "tqdm",
+            "time",
             "argparse",
-            "json",
-            "tqdm"
+            "torch",
+            "cv2",
+            "numpy",
+            "json"
         ],
         "modelscope.models.cv.stream_yolo.utils.boxes": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.stream_yolo.utils.format": [
             "math"
         ],
         "modelscope.models.cv.super_resolution.arch_util": [
+            "collections",
             "itertools",
             "torch",
-            "collections",
             "warnings",
-            "math",
-            "torchvision"
+            "torchvision",
+            "math"
         ],
         "modelscope.models.cv.super_resolution.ecb": [
             "torch"
         ],
         "modelscope.models.cv.super_resolution.ecbsr_model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.super_resolution.rrdbnet_arch": [
             "torch"
         ],
         "modelscope.models.cv.table_recognition.lineless_table_process": [
-            "numpy",
-            "torch",
             "cv2",
-            "shapely"
+            "numpy",
+            "shapely",
+            "torch"
         ],
         "modelscope.models.cv.table_recognition.model_lore": [
-            "numpy",
-            "math",
+            "os",
             "copy",
+            "typing",
+            "math",
             "torch",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.cv.table_recognition.modules.lore_detector": [
-            "numpy",
-            "copy",
             "torch",
             "os",
+            "copy",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.table_recognition.modules.lore_processor": [
-            "numpy",
-            "copy",
             "torch",
             "os",
+            "copy",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.text_driven_segmentation.clip": [
             "urllib",
-            "tqdm",
-            "warnings",
             "hashlib",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
+            "warnings",
+            "tqdm",
             "typing",
-            "pkg_resources"
+            "pkg_resources",
+            "torch",
+            "PIL",
+            "torchvision"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_base": [
             "torch"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_blocks": [
             "torch"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_model": [
-            "numpy",
-            "torch",
-            "PIL",
             "os",
             "typing",
+            "torch",
+            "PIL",
+            "numpy",
             "json"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_net": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.text_driven_segmentation.lseg_vit": [
+            "timm",
             "types",
             "torch",
-            "math",
-            "timm"
+            "math"
         ],
         "modelscope.models.cv.text_driven_segmentation.model": [
-            "typing",
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.text_driven_segmentation.simple_tokenizer": [
+            "functools",
             "ftfy",
             "gzip",
             "os",
-            "html",
-            "functools",
-            "regex"
+            "regex",
+            "html"
+        ],
+        "modelscope.models.cv.text_to_360panorama_image.pipeline_base": [
+            "transformers",
+            "warnings",
+            "typing",
+            "torch",
+            "diffusers",
+            "re",
+            "packaging",
+            "inspect"
+        ],
+        "modelscope.models.cv.text_to_360panorama_image.pipeline_sr": [
+            "numpy",
+            "os",
+            "warnings",
+            "transformers",
+            "copy",
+            "typing",
+            "torch",
+            "PIL",
+            "re",
+            "diffusers",
+            "inspect"
         ],
         "modelscope.models.cv.tinynas_classfication.basic_blocks": [
-            "uuid",
+            "torch",
             "numpy",
-            "torch"
+            "uuid"
         ],
         "modelscope.models.cv.tinynas_classfication.global_utils": [],
         "modelscope.models.cv.tinynas_classfication.master_net": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_classfication.model_zoo": [],
         "modelscope.models.cv.tinynas_classfication.plain_net_utils": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_classfication.super_blocks": [
-            "uuid",
-            "torch"
+            "torch",
+            "uuid"
         ],
         "modelscope.models.cv.tinynas_classfication.super_res_idwexkx": [
-            "uuid",
-            "torch"
+            "torch",
+            "uuid"
         ],
         "modelscope.models.cv.tinynas_classfication.super_res_k1kxk1": [
-            "uuid",
-            "torch"
+            "torch",
+            "uuid"
         ],
         "modelscope.models.cv.tinynas_classfication.super_res_kxkx": [
-            "uuid",
-            "torch"
+            "torch",
+            "uuid"
         ],
         "modelscope.models.cv.tinynas_detection.damo.apis.detector_evaluater": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.apis.detector_inference": [
-            "torch",
             "os",
+            "torch",
             "tqdm"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.box_level_augs": [
-            "numpy",
-            "random"
+            "random",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.color_augs": [
-            "torch",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.gaussian_maps": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.box_level_augs.geometric_augs": [
             "copy",
             "torchvision",
-            "torch",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.augmentations.scale_aware_aug": [
             "copy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.backbones.darknet": [
             "torch"
         ],
@@ -13628,41 +14209,41 @@
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.base_ops": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.neck_ops": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.ops": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.ota_assigner": [
-            "torch",
-            "warnings"
+            "warnings",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.repvgg_block": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.utils": [
             "functools",
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.core.weight_init": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.heads.gfocal_v2_tiny": [
             "functools",
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.heads.zero_head": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.losses.distill_loss": [
             "torch"
         ],
@@ -13671,411 +14252,411 @@
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_config": [
             "collections",
             "networkx"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_fpn": [
-            "numpy",
+            "collections",
             "functools",
-            "math",
             "timm",
+            "typing",
+            "math",
             "torch",
-            "collections",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.base_models.necks.giraffe_fpn_btn": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.detectors.detector": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.bounding_box": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.boxlist_ops": [
             "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.structures.image_list": [
-            "torch",
-            "__future__"
+            "__future__",
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.boxes": [
-            "numpy",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.model_utils": [
+            "time",
             "thop",
             "torch",
             "copy",
-            "time",
             "math"
         ],
         "modelscope.models.cv.tinynas_detection.damo.utils.scheduler": [
             "math"
         ],
         "modelscope.models.cv.tinynas_detection.detector": [
             "os",
-            "torch",
+            "pickle",
             "torchvision",
-            "pickle"
+            "torch"
         ],
         "modelscope.models.cv.tinynas_detection.tinynas_damoyolo": [],
         "modelscope.models.cv.tinynas_detection.tinynas_detector": [],
         "modelscope.models.cv.tinynas_detection.utils": [
-            "shutil",
-            "os",
-            "tempfile",
-            "importlib",
             "sys",
-            "easydict"
+            "importlib",
+            "easydict",
+            "os",
+            "shutil",
+            "tempfile"
         ],
         "modelscope.models.cv.video_deinterlace.UNet_for_video_deinterlace": [
-            "typing",
-            "torch",
+            "os",
             "copy",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_deinterlace.deinterlace_arch": [
             "torch"
         ],
         "modelscope.models.cv.video_deinterlace.models.archs": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_deinterlace.models.deep_fourier_upsampling": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_deinterlace.models.enh": [
             "torch"
         ],
         "modelscope.models.cv.video_deinterlace.models.fre": [
             "torch"
         ],
         "modelscope.models.cv.video_deinterlace.models.utils": [
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.configs.default_config": [
-            "yacs",
-            "os"
+            "os",
+            "yacs"
         ],
         "modelscope.models.cv.video_depth_estimation.dro_model": [
-            "numpy",
-            "glob",
-            "torch",
             "os",
+            "tqdm",
+            "torch",
+            "glob",
             "cv2",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.camera": [
             "functools",
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.camera_utils": [
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.pose": [
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.geometry.pose_utils": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.models.model_checkpoint": [
-            "numpy",
-            "re",
             "os",
-            "torch"
+            "torch",
+            "numpy",
+            "re"
         ],
         "modelscope.models.cv.video_depth_estimation.models.model_utils": [],
         "modelscope.models.cv.video_depth_estimation.models.model_wrapper": [
-            "numpy",
-            "random",
-            "torch",
             "collections",
-            "importlib"
+            "importlib",
+            "torch",
+            "random",
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.models.sfm_model_mf": [
-            "torch",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.models.sup_model_mf": [],
         "modelscope.models.cv.video_depth_estimation.networks.depth_pose.depth_pose_net": [
             "functools",
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.depth_decoder": [
-            "numpy",
-            "torch",
             "collections",
-            "__future__"
+            "__future__",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.layers": [
-            "torch",
-            "__future__"
+            "__future__",
+            "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.pose_decoder": [
-            "torch",
             "collections",
-            "__future__"
+            "__future__",
+            "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.layers.resnet.resnet_encoder": [
-            "numpy",
-            "torch",
             "__future__",
-            "torchvision"
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.optim.extractor": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.video_depth_estimation.networks.optim.update": [
             "torch"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.augmentations": [
-            "numpy",
-            "torchvision",
             "random",
+            "PIL",
             "cv2",
-            "PIL"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.config": [
-            "yacs",
-            "torch",
             "os",
+            "torch",
+            "yacs",
             "datetime"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.depth": [
-            "numpy",
             "torch",
             "torchvision",
+            "numpy",
             "matplotlib"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.horovod": [
             "horovod"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.image": [
-            "numpy",
             "functools",
-            "torch",
             "os",
+            "torch",
+            "PIL",
             "cv2",
-            "PIL"
+            "numpy"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.image_gt": [
             "functools",
-            "cv2",
             "torch",
+            "cv2",
             "PIL"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.load": [
-            "warnings",
-            "inspect",
-            "torch",
+            "collections",
             "logging",
+            "warnings",
             "os",
-            "collections",
-            "importlib"
+            "importlib",
+            "torch",
+            "inspect"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.misc": [
             "termcolor"
         ],
         "modelscope.models.cv.video_depth_estimation.utils.types": [
-            "yacs",
             "numpy",
-            "torch"
+            "torch",
+            "yacs"
         ],
         "modelscope.models.cv.video_frame_interpolation.VFINet_arch": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.VFINet_for_video_frame_interpolation": [
-            "typing",
-            "torch",
+            "os",
             "copy",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.corr": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.extractor": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.raft": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_frame_interpolation.flow_model.update": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.IFNet_swin": [
-            "numpy",
             "torch",
+            "numpy",
             "timm"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.UNet": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.flow_reversal": [
             "torch"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.refinenet_arch": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_frame_interpolation.interp_model.transformer_layers": [
-            "torch",
             "functools",
+            "torch",
+            "timm",
             "sys",
-            "math",
-            "timm"
+            "math"
         ],
         "modelscope.models.cv.video_frame_interpolation.utils.scene_change_detection": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_frame_interpolation.utils.utils": [
-            "numpy",
             "torch",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.video_human_matting.model": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.video_human_matting.models.decoder": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_human_matting.models.deep_guided_filter": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.effv2": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.lraspp": [
             "torch"
         ],
         "modelscope.models.cv.video_human_matting.models.matting": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.video_inpainting.inpainting": [
-            "numpy",
+            "time",
             "torch",
-            "cv2",
-            "os",
             "PIL",
-            "time",
-            "torchvision"
+            "os",
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.video_inpainting.inpainting_model": [
-            "math",
-            "numpy",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_frame_iter_head": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_head": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_iter_head": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_update_head": [
-            "mmcv",
-            "torch",
             "mmdet",
+            "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.head.kernel_updator": [
-            "mmcv",
-            "torch"
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.video_instance_segmentation.neck.msdeformattn_decoder": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.video_instance_segmentation.track.kernel_update_head": [
-            "mmcv",
-            "torch",
             "mmdet",
+            "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.track.mask_hungarian_assigner": [
-            "numpy",
+            "mmdet",
             "torch",
             "scipy",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.utils": [
-            "numpy",
+            "mmdet",
             "torch",
-            "mmdet"
+            "numpy"
         ],
         "modelscope.models.cv.video_instance_segmentation.video_knet": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.common": [
             "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.decode": [
             "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.model": [
             "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.models.yolo": [
-            "torch",
             "copy",
+            "torch",
             "math"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.basetrack": [
-            "numpy",
-            "collections"
+            "collections",
+            "numpy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.matching": [
-            "numpy",
             "lap",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.tracker.multitracker": [
-            "numpy",
+            "collections",
             "torch",
-            "collections"
+            "numpy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.image": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.kalman_filter": [
-            "numpy",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.utils": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.models.cv.video_multi_object_tracking.utils.visualization": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.video_object_segmentation.aggregate": [
             "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.cbam": [
             "torch"
         ],
@@ -14086,110 +14667,110 @@
             "torch"
         ],
         "modelscope.models.cv.video_object_segmentation.inference_memory_bank": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.video_object_segmentation.mod_resnet": [
-            "torch",
             "collections",
+            "torch",
             "math"
         ],
         "modelscope.models.cv.video_object_segmentation.model": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.video_object_segmentation.modules": [
             "torch",
             "torchvision"
         ],
         "modelscope.models.cv.video_object_segmentation.network": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.backbone.swin_checkpoint": [
-            "pkgutil",
-            "torch",
             "collections",
-            "os",
             "importlib",
+            "torch",
+            "pkgutil",
+            "os",
             "torchvision"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.backbone.swin_transformer": [
-            "numpy",
-            "torch",
+            "mmdet",
             "timm",
-            "mmdet"
+            "numpy",
+            "torch"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_head": [
-            "mmcv",
-            "torch"
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_iter_head": [
-            "torch",
-            "mmdet"
+            "mmdet",
+            "torch"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_update_head": [
-            "mmcv",
-            "torch",
             "mmdet",
+            "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.kernel_updator": [
-            "mmcv",
-            "torch"
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.mask": [
-            "numpy",
             "torch",
             "pycocotools",
+            "__future__",
             "cv2",
-            "__future__"
+            "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.semantic_fpn_wrapper": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.head.track_heads": [
-            "mmcv",
             "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.neck.fpn": [
-            "mmcv",
-            "torch"
+            "torch",
+            "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.track.quasi_dense_embed_tracker": [
-            "mmcv",
+            "mmdet",
             "torch",
-            "mmdet"
+            "mmcv"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.video_k_net": [
-            "mmcv",
-            "torch",
             "mmdet",
+            "torch",
+            "mmcv",
             "numpy"
         ],
         "modelscope.models.cv.video_panoptic_segmentation.visualizer": [
-            "numpy",
             "hashlib",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.video_single_object_tracking.config.ostrack": [
             "easydict"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.attn": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.attn_blocks": [
             "torch",
-            "math",
-            "timm"
+            "timm",
+            "math"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.head": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.layers.patch_embed": [
             "torch",
             "timm"
@@ -14202,408 +14783,408 @@
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.ostrack.utils": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.ostrack.vit_ce": [
             "functools",
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.procontext.procontext": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.procontext.utils": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.models.procontext.vit_ce": [
             "functools",
-            "torch",
-            "timm"
+            "timm",
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.tracker.ostrack": [
             "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.tracker.procontext": [
-            "torch",
-            "copy"
+            "copy",
+            "torch"
         ],
         "modelscope.models.cv.video_single_object_tracking.utils.utils": [
-            "numpy",
             "torch",
             "cv2",
-            "typing",
-            "math"
+            "numpy",
+            "math",
+            "typing"
         ],
         "modelscope.models.cv.video_stabilization.DUT.DUT_raft": [
             "numpy",
-            "sys",
             "torch",
+            "sys",
             "cv2"
         ],
         "modelscope.models.cv.video_stabilization.DUT.MotionPro": [
-            "numpy",
+            "os",
             "math",
             "torch",
-            "os",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.corr": [
             "alt_cuda_corr",
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.extractor": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.raft": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.DUT.RAFT.update": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.Smoother": [
-            "numpy",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.video_stabilization.DUT.config": [
             "__future__",
             "easydict"
         ],
         "modelscope.models.cv.video_stabilization.DUT.rf_det_module": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUT.rf_det_so": [
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.DUTRAFTStabilizer": [
             "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "cv2",
-            "os",
             "tempfile",
-            "typing",
+            "cv2",
             "sys"
         ],
         "modelscope.models.cv.video_stabilization.utils.IterativeSmooth": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.cv.video_stabilization.utils.MedianFilter": [
+            "torch",
             "numpy",
             "cv2",
-            "torch",
             "math"
         ],
         "modelscope.models.cv.video_stabilization.utils.ProjectionUtils": [
+            "torch",
             "numpy",
             "cv2",
-            "torch",
             "math"
         ],
         "modelscope.models.cv.video_stabilization.utils.RAFTUtils": [
-            "numpy",
             "torch",
-            "scipy"
+            "scipy",
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.utils.WarpUtils": [
-            "numpy",
+            "tqdm",
             "torch",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.models.cv.video_stabilization.utils.image_utils": [
             "skimage",
             "torch"
         ],
         "modelscope.models.cv.video_stabilization.utils.math_utils": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.exp.longshortnet_base": [],
         "modelscope.models.cv.video_streaming_perception.longshortnet.longshortnet": [
-            "numpy",
-            "time",
-            "torch",
             "logging",
-            "cv2",
             "os",
+            "tqdm",
+            "time",
             "argparse",
-            "json",
-            "tqdm"
+            "torch",
+            "cv2",
+            "numpy",
+            "json"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.dfp_pafpn_long": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.dfp_pafpn_short": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.longshort": [
             "torch"
         ],
         "modelscope.models.cv.video_streaming_perception.longshortnet.models.longshort_backbone_neck": [
             "torch"
         ],
         "modelscope.models.cv.video_summarization.base_model": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.models.cv.video_summarization.kts.cpd_auto": [
             "numpy"
         ],
         "modelscope.models.cv.video_summarization.kts.cpd_nonlin": [
             "numpy"
         ],
         "modelscope.models.cv.video_summarization.pgl_sum": [
             "torch",
             "math"
         ],
         "modelscope.models.cv.video_summarization.summarizer": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.cv.video_super_resolution.basicvsr_net": [
             "torch"
         ],
         "modelscope.models.cv.video_super_resolution.common": [
             "torch"
         ],
         "modelscope.models.cv.video_super_resolution.msrresnet_lite_model": [
+            "os",
             "functools",
-            "typing",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.video_super_resolution.real_basicvsr_for_video_super_resolution": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.cv.video_super_resolution.real_basicvsr_net": [
             "torch"
         ],
         "modelscope.models.cv.vidt.backbone": [
-            "numpy",
             "torch",
             "os",
-            "math",
-            "timm"
+            "timm",
+            "numpy",
+            "math"
         ],
         "modelscope.models.cv.vidt.deformable_transformer": [
-            "copy",
             "torch",
+            "timm",
             "warnings",
-            "math",
-            "timm"
+            "copy",
+            "math"
         ],
         "modelscope.models.cv.vidt.fpn_fusion": [
             "torch"
         ],
         "modelscope.models.cv.vidt.head": [
             "copy",
-            "math",
-            "torch"
+            "torch",
+            "math"
         ],
         "modelscope.models.cv.vidt.model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.virual_tryon.sdafnet": [
+            "random",
             "numpy",
-            "torch",
-            "random"
+            "torch"
         ],
         "modelscope.models.cv.vision_efficient_tuning.backbone": [
             "functools",
             "torch"
         ],
         "modelscope.models.cv.vision_efficient_tuning.head": [
             "torch"
         ],
         "modelscope.models.cv.vision_efficient_tuning.model": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.cv.vision_efficient_tuning.petl": [
             "collections",
             "torch",
             "torchvision",
             "math"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_helpers": [
-            "typing",
             "itertools",
             "torch",
+            "typing",
             "math"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_vision_transformer": [
+            "collections",
             "functools",
+            "logging",
             "math",
-            "itertools",
             "torch",
-            "collections",
-            "logging"
+            "itertools"
         ],
         "modelscope.models.cv.vision_efficient_tuning.timm_weight_init": [
+            "warnings",
             "torch",
-            "math",
-            "warnings"
+            "math"
         ],
         "modelscope.models.cv.vision_efficient_tuning.vision_efficient_tuning": [
+            "os",
             "torch",
-            "collections",
-            "os"
+            "collections"
         ],
         "modelscope.models.cv.vision_middleware.backbone": [
-            "numpy",
-            "math",
-            "torch",
             "collections",
             "os",
-            "typing"
+            "typing",
+            "math",
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.vision_middleware.head": [
-            "mmcv",
-            "abc",
             "torch",
-            "numpy"
+            "mmcv",
+            "numpy",
+            "abc"
         ],
         "modelscope.models.cv.vision_middleware.model": [
-            "typing",
-            "torch",
             "os",
-            "json"
+            "torch",
+            "json",
+            "typing"
         ],
         "modelscope.models.cv.vision_middleware.vim": [
             "torch",
-            "einops",
-            "math"
+            "math",
+            "einops"
         ],
         "modelscope.models.cv.vop_retrieval.backbone": [
+            "collections",
             "urllib",
-            "numpy",
-            "warnings",
             "hashlib",
-            "torch",
-            "collections",
             "os",
+            "warnings",
+            "tqdm",
             "typing",
-            "tqdm"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.cv.vop_retrieval.basic_utils": [
-            "numpy",
+            "collections",
             "zipfile",
-            "pickle",
             "ujson",
-            "random",
-            "torchvision",
-            "shutil",
-            "torch",
-            "collections",
             "os",
             "cv2",
-            "PIL"
+            "pickle",
+            "torch",
+            "PIL",
+            "shutil",
+            "random",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.cv.vop_retrieval.model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.vop_retrieval.model_se": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.cv.vop_retrieval.tokenization_clip": [
+            "functools",
             "ftfy",
             "torch",
             "gzip",
             "os",
-            "html",
-            "functools",
-            "regex"
+            "regex",
+            "html"
         ],
         "modelscope.models.multi_modal.clip.bert_tokenizer": [
-            "re",
             "collections",
-            "os",
-            "six",
             "unicodedata",
-            "__future__"
+            "re",
+            "os",
+            "__future__",
+            "six"
         ],
         "modelscope.models.multi_modal.clip.configuration_bert": [
-            "__future__",
-            "logging"
+            "logging",
+            "__future__"
         ],
         "modelscope.models.multi_modal.clip.model": [
-            "numpy",
-            "torch",
             "collections",
             "os",
             "typing",
+            "torch",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.clip.modeling_bert": [
-            "math",
-            "torch",
             "logging",
             "os",
-            "sys",
             "__future__",
+            "math",
+            "torch",
             "io",
+            "sys",
             "json"
         ],
         "modelscope.models.multi_modal.clip_interrogator.model": [
-            "safetensors",
             "hashlib",
-            "math",
-            "torchvision",
-            "torch",
-            "os",
-            "typing",
+            "safetensors",
             "open_clip",
             "tqdm",
-            "numpy",
+            "math",
+            "time",
+            "torch",
+            "PIL",
             "dataclasses",
+            "torchvision",
+            "numpy",
+            "os",
             "requests",
-            "time",
             "transformers",
-            "PIL"
+            "typing"
         ],
         "modelscope.models.multi_modal.diffusion.diffusion": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.diffusion.model": [
-            "numpy",
-            "torch",
             "os",
             "typing",
+            "torch",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.diffusion.structbert": [
-            "numpy",
-            "copy",
             "torch",
             "six",
+            "json",
             "__future__",
-            "math",
-            "json"
+            "copy",
+            "numpy",
+            "math"
         ],
         "modelscope.models.multi_modal.diffusion.tokenizer": [
-            "unicodedata",
-            "six",
             "collections",
-            "__future__"
+            "__future__",
+            "six",
+            "unicodedata"
         ],
         "modelscope.models.multi_modal.diffusion.unet_generator": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.diffusion.unet_upsampler_1024": [
             "torch",
@@ -14616,3526 +15197,3603 @@
         ],
         "modelscope.models.multi_modal.dpm_solver_pytorch": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.efficient_diffusion_tuning.efficient_stable_diffusion": [
             "functools",
-            "diffusers",
+            "os",
             "transformers",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "diffusers"
         ],
         "modelscope.models.multi_modal.gemm.gemm_base": [
-            "numpy",
-            "torch",
             "collections",
             "os",
             "typing",
+            "torch",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.gemm.gemm_model": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
             "typing",
+            "torch",
+            "PIL",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.gemm.tokenizer": [
+            "functools",
             "ftfy",
             "torch",
             "gzip",
             "os",
-            "html",
-            "functools",
-            "regex"
+            "regex",
+            "html"
         ],
         "modelscope.models.multi_modal.guided_diffusion.gaussian_diffusion": [
-            "math",
+            "enum",
             "numpy",
             "torch",
-            "enum"
+            "math"
         ],
         "modelscope.models.multi_modal.guided_diffusion.respace": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.multi_modal.guided_diffusion.script": [],
         "modelscope.models.multi_modal.guided_diffusion.unet": [
+            "torch",
+            "transformers",
             "numpy",
             "abc",
-            "torch",
-            "math",
-            "transformers"
+            "math"
         ],
         "modelscope.models.multi_modal.mgeo.backbone": [
-            "dataclasses",
+            "os",
             "warnings",
-            "math",
-            "random",
             "transformers",
+            "dataclasses",
+            "math",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "random"
         ],
         "modelscope.models.multi_modal.mgeo.text_classification": [
             "torch"
         ],
         "modelscope.models.multi_modal.mgeo.text_ranking": [
             "torch"
         ],
         "modelscope.models.multi_modal.mgeo.token_classification": [
             "torch"
         ],
         "modelscope.models.multi_modal.mmr.dataloaders.rawvideo_util": [
-            "numpy",
-            "torchvision",
             "torch",
+            "PIL",
             "cv2",
-            "PIL"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.multi_modal.mmr.models.clip_for_mm_video_embedding": [
-            "uuid",
-            "numpy",
             "urllib",
-            "random",
-            "torch",
             "os",
-            "PIL",
-            "tempfile",
             "typing",
             "decord",
+            "torch",
+            "uuid",
+            "PIL",
+            "tempfile",
+            "random",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.mmr.models.dynamic_inverted_softmax": [
             "numpy"
         ],
         "modelscope.models.multi_modal.mmr.models.modeling": [
-            "torch",
             "collections",
             "os",
-            "platform",
-            "types"
+            "torch",
+            "types",
+            "platform"
         ],
         "modelscope.models.multi_modal.mmr.models.module_clip": [
+            "collections",
             "urllib",
-            "warnings",
             "hashlib",
-            "torch",
-            "collections",
             "os",
+            "warnings",
+            "tqdm",
             "typing",
-            "tqdm"
+            "torch"
         ],
         "modelscope.models.multi_modal.mmr.models.module_cross": [
-            "torch",
             "collections",
             "logging",
             "__future__",
+            "torch",
             "json"
         ],
         "modelscope.models.multi_modal.mmr.models.tokenization_clip": [
+            "functools",
             "ftfy",
             "gzip",
             "os",
-            "html",
-            "functools",
-            "regex"
+            "regex",
+            "html"
         ],
         "modelscope.models.multi_modal.mmr.models.until_module": [
-            "numpy",
-            "torch",
             "logging",
+            "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.multi_modal.mplug.clip.clip": [
-            "typing",
+            "collections",
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.models.multi_modal.mplug.configuration_mplug": [
-            "typing",
             "os",
             "yaml",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.multi_modal.mplug.modeling_mplug": [
-            "math",
-            "transformers",
-            "torch",
             "os",
-            "typing"
+            "transformers",
+            "math",
+            "typing",
+            "torch"
         ],
         "modelscope.models.multi_modal.mplug.mvit": [
-            "numpy",
-            "torch",
             "collections",
             "functools",
+            "torch",
             "fairscale",
-            "timm"
+            "timm",
+            "numpy"
         ],
         "modelscope.models.multi_modal.mplug.predictor": [
-            "torch",
-            "__future__"
+            "__future__",
+            "torch"
         ],
         "modelscope.models.multi_modal.mplug_for_all_tasks": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.multi_modal.mplug_owl.configuration_mplug_owl": [
-            "typing",
-            "copy",
             "os",
-            "transformers"
+            "copy",
+            "transformers",
+            "typing"
         ],
         "modelscope.models.multi_modal.mplug_owl.modeling_mplug_owl": [
-            "dataclasses",
-            "math",
-            "random",
-            "transformers",
-            "copy",
             "logging",
             "os",
-            "torch",
+            "transformers",
+            "copy",
+            "dataclasses",
+            "math",
             "typing",
-            "io"
+            "torch",
+            "io",
+            "random"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.clip": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.decoder": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.gaussian_diffusion": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.model": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
             "PIL",
-            "typing",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.prior": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.tokenizer": [
+            "functools",
             "ftfy",
             "torch",
             "gzip",
-            "html",
-            "functools",
+            "transformers",
             "regex",
-            "transformers"
+            "html"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.upsampler": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.multi_stage_diffusion.xglm": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.ofa.configuration_mmspeech": [
-            "warnings",
-            "transformers"
+            "transformers",
+            "warnings"
         ],
         "modelscope.models.multi_modal.ofa.configuration_ofa": [
-            "warnings",
-            "transformers"
+            "transformers",
+            "warnings"
         ],
         "modelscope.models.multi_modal.ofa.generate.incremental_decoding_utils": [
+            "torch",
             "uuid",
-            "typing",
-            "torch"
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.multihead_attention": [
+            "fairseq",
             "typing",
             "torch",
-            "math",
-            "fairseq"
+            "math"
         ],
         "modelscope.models.multi_modal.ofa.generate.ngram_repeat_block": [
-            "torch",
             "fairseq",
-            "typing",
+            "torch",
+            "warnings",
             "math",
-            "warnings"
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.search": [
-            "typing",
             "torch",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.sequence_generator": [
-            "typing",
-            "sys",
             "torch",
-            "math"
+            "sys",
+            "math",
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.token_generation_constraints": [
-            "typing",
+            "collections",
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.generate.utils": [
-            "itertools",
-            "torch",
             "collections",
+            "amp_C",
+            "torch",
             "torch_xla",
-            "amp_C"
+            "itertools"
         ],
         "modelscope.models.multi_modal.ofa.modeling_mmspeech": [
-            "numpy",
-            "dataclasses",
-            "fairseq",
-            "math",
             "transformers",
-            "packaging",
-            "torch",
             "typing",
-            "apex"
+            "math",
+            "fairseq",
+            "torch",
+            "apex",
+            "packaging",
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.models.multi_modal.ofa.modeling_ofa": [
-            "dataclasses",
-            "math",
             "random",
             "transformers",
-            "packaging",
-            "torch",
             "typing",
-            "apex"
+            "math",
+            "torch",
+            "apex",
+            "packaging",
+            "dataclasses"
         ],
         "modelscope.models.multi_modal.ofa.resnet": [
             "torch"
         ],
         "modelscope.models.multi_modal.ofa.tokenization_ofa": [
-            "typing",
             "collections",
+            "transformers",
             "os",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.tokenization_ofa_fast": [
             "tokenizers",
-            "typing",
+            "transformers",
             "json",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.utils.constant": [],
         "modelscope.models.multi_modal.ofa.utils.utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.multi_modal.ofa.vit": [
-            "torch",
             "collections",
-            "fairseq"
+            "fairseq",
+            "torch"
         ],
         "modelscope.models.multi_modal.ofa_for_all_tasks": [
-            "re",
             "functools",
             "string",
-            "math",
-            "torch",
             "os",
             "typing",
+            "math",
+            "torch",
+            "re",
             "json"
         ],
         "modelscope.models.multi_modal.ofa_for_text_to_image_synthesis_model": [
-            "numpy",
+            "taming",
+            "os",
+            "typing",
             "pkg_resources",
-            "torchvision",
             "torch",
-            "os",
             "PIL",
-            "typing",
-            "taming",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.models.multi_modal.rleg.model": [
-            "torch",
             "os",
+            "torch",
             "json"
         ],
         "modelscope.models.multi_modal.rleg.rleg": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.models.multi_modal.soonet.blocks": [
             "torch",
             "math"
         ],
         "modelscope.models.multi_modal.soonet.clip": [
-            "numpy",
-            "torch",
             "collections",
+            "torch",
             "warnings",
+            "numpy",
             "typing"
         ],
         "modelscope.models.multi_modal.soonet.model": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.multi_modal.soonet.swin_transformer": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.multi_modal.soonet.tokenizer": [
+            "functools",
             "ftfy",
             "torch",
             "gzip",
-            "html",
-            "functools",
-            "regex"
+            "regex",
+            "html"
         ],
         "modelscope.models.multi_modal.soonet.utils": [
-            "numpy",
-            "copy",
+            "tqdm",
             "decord",
-            "tqdm"
+            "copy",
+            "numpy"
         ],
         "modelscope.models.multi_modal.stable_diffusion.stable_diffusion": [
             "functools",
-            "diffusers",
+            "os",
             "transformers",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "diffusers",
+            "packaging"
         ],
         "modelscope.models.multi_modal.team.team_model": [
-            "numpy",
-            "torchvision",
+            "tokenizers",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "tokenizers",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.multi_modal.team.utils": [
-            "numpy",
-            "torch",
             "collections",
-            "typing",
-            "transformers"
+            "torch",
+            "transformers",
+            "numpy",
+            "typing"
         ],
         "modelscope.models.multi_modal.video_synthesis.autoencoder": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.multi_modal.video_synthesis.diffusion": [
             "torch"
         ],
         "modelscope.models.multi_modal.video_synthesis.text_to_video_synthesis_model": [
-            "torch",
             "einops",
             "os",
             "open_clip",
-            "typing"
+            "typing",
+            "torch"
         ],
         "modelscope.models.multi_modal.video_synthesis.unet_sd": [
             "torch",
-            "einops",
-            "math"
+            "math",
+            "einops"
         ],
         "modelscope.models.multi_modal.vldoc.conv_fpn_trans": [
-            "random",
+            "collections",
             "timm",
             "torch",
-            "collections",
-            "apex"
+            "apex",
+            "random"
         ],
         "modelscope.models.multi_modal.vldoc.convnext": [
-            "torch",
             "os",
+            "torch",
             "timm"
         ],
         "modelscope.models.multi_modal.vldoc.model": [
-            "re",
-            "math",
-            "torchvision",
-            "copy",
             "logging",
             "os",
+            "copy",
+            "math",
             "torch",
+            "re",
+            "torchvision",
             "sys",
             "json"
         ],
         "modelscope.models.multi_modal.vldoc.modeling_layout_roberta": [
             "packaging",
             "torch",
+            "transformers",
             "os",
-            "math",
-            "transformers"
+            "math"
         ],
         "modelscope.models.multi_modal.vldoc.processing": [
-            "numpy",
-            "torchvision",
+            "collections",
             "timm",
+            "typing",
             "torch",
-            "collections",
             "PIL",
             "cv2",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.models.multi_modal.vldoc.tokenization": [
             "os",
             "transformers"
         ],
         "modelscope.models.multi_modal.vldoc.transformer_local": [
             "copy",
             "torch"
         ],
         "modelscope.models.nlp.T5.backbone": [
+            "os",
             "warnings",
-            "math",
             "transformers",
             "copy",
-            "torch",
-            "os",
-            "typing"
+            "math",
+            "typing",
+            "torch"
         ],
         "modelscope.models.nlp.T5.configuration": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.T5.text2text_generation": [
-            "warnings",
             "transformers",
+            "warnings",
             "copy",
-            "torch",
-            "typing"
+            "typing",
+            "torch"
         ],
         "modelscope.models.nlp.bart.text_error_correction": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.nlp.bert.backbone": [
+            "transformers",
             "packaging",
             "torch",
-            "math",
-            "transformers"
+            "math"
         ],
         "modelscope.models.nlp.bert.configuration": [
-            "typing",
             "collections",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.bert.document_segmentation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.bert.fill_mask": [],
         "modelscope.models.nlp.bert.sentence_embedding": [
             "torch"
         ],
         "modelscope.models.nlp.bert.siamese_uie": [
-            "torch",
-            "copy"
+            "copy",
+            "torch"
         ],
         "modelscope.models.nlp.bert.text_classification": [],
         "modelscope.models.nlp.bert.text_ranking": [],
         "modelscope.models.nlp.bert.token_classification": [],
         "modelscope.models.nlp.bert.word_alignment": [
             "torch"
         ],
         "modelscope.models.nlp.bloom.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.canmt.canmt_model": [
-            "numpy",
-            "torch",
             "fairseq",
-            "typing",
-            "math"
+            "torch",
+            "numpy",
+            "math",
+            "typing"
         ],
         "modelscope.models.nlp.canmt.canmt_translation": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.nlp.canmt.sequence_generator": [
+            "fairseq",
             "numpy",
             "torch",
-            "fairseq",
-            "typing",
             "sys",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.models.nlp.chatglm.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.chatglm.quantization": [
-            "torch",
             "bz2",
-            "cpm_kernels",
+            "ctypes",
             "typing",
             "base64",
-            "ctypes",
-            "transformers"
+            "torch",
+            "cpm_kernels"
         ],
         "modelscope.models.nlp.chatglm.text_generation": [
-            "re",
+            "os",
             "warnings",
-            "math",
             "transformers",
             "copy",
-            "torch",
-            "os",
+            "math",
             "typing",
+            "torch",
+            "re",
             "sys"
         ],
         "modelscope.models.nlp.chatglm.tokenization": [
-            "numpy",
             "os",
-            "typing",
+            "transformers",
             "sentencepiece",
-            "transformers"
+            "typing",
+            "numpy"
         ],
         "modelscope.models.nlp.chatglm2.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.chatglm2.quantization": [
             "bz2",
-            "functools",
-            "base64",
             "ctypes",
-            "transformers",
+            "typing",
+            "base64",
             "torch",
-            "cpm_kernels",
-            "typing"
+            "cpm_kernels"
         ],
         "modelscope.models.nlp.chatglm2.text_generation": [
-            "re",
-            "warnings",
-            "math",
             "transformers",
+            "warnings",
             "copy",
-            "torch",
             "typing",
+            "math",
+            "torch",
             "sys"
         ],
         "modelscope.models.nlp.chatglm2.tokenization": [
-            "typing",
-            "transformers",
             "os",
-            "sentencepiece"
+            "sentencepiece",
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.codegeex.codegeex": [
             "torch",
             "math"
         ],
         "modelscope.models.nlp.codegeex.codegeex_for_code_generation": [
-            "typing",
             "copy",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.codegeex.codegeex_for_code_translation": [
-            "typing",
             "copy",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.codegeex.inference": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.codegeex.tokenizer": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.csanmt.translation": [
-            "tensorflow",
-            "typing",
             "collections",
-            "math"
+            "tensorflow",
+            "math",
+            "typing"
         ],
         "modelscope.models.nlp.deberta_v2.backbone": [
-            "typing",
-            "torch",
             "collections",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.deberta_v2.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.deberta_v2.fill_mask": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.deberta_v2.tokenization": [
-            "os",
-            "typing",
+            "transformers",
             "unicodedata",
+            "os",
             "sentencepiece",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.deberta_v2.tokenization_fast": [
-            "shutil",
-            "typing",
             "os",
-            "transformers"
+            "shutil",
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.dgds.backbone": [
-            "torch",
-            "__future__",
             "os",
+            "__future__",
+            "torch",
             "transformers"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_generate": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_rerank": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.nlp.dgds.document_grounded_dialog_retrieval": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.models.nlp.fid_T5.text_generation": [
-            "torch",
             "os",
-            "io",
-            "transformers"
+            "torch",
+            "transformers",
+            "io"
         ],
         "modelscope.models.nlp.fid_plug.backbone": [
-            "numpy",
-            "dataclasses",
-            "math",
+            "os",
             "transformers",
             "copy",
+            "typing",
+            "math",
             "torch",
-            "os",
-            "typing"
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.models.nlp.fid_plug.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.fid_plug.text_generation": [
-            "torch",
             "os",
-            "io",
-            "transformers"
+            "torch",
+            "transformers",
+            "io"
         ],
         "modelscope.models.nlp.glm_130b.generation.strategies": [
-            "numpy",
             "SwissArmyTransformer",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.nlp.glm_130b.initialize": [
+            "argparse",
             "time",
             "SwissArmyTransformer",
-            "torch",
-            "argparse"
+            "torch"
         ],
         "modelscope.models.nlp.glm_130b.quantization.functional": [
             "torch"
         ],
         "modelscope.models.nlp.glm_130b.quantization.layers": [
             "SwissArmyTransformer",
             "torch"
         ],
         "modelscope.models.nlp.glm_130b.text_generation": [
-            "re",
             "functools",
-            "time",
-            "SwissArmyTransformer",
-            "random",
+            "os",
             "copy",
+            "typing",
+            "time",
             "torch",
             "stat",
-            "os",
-            "typing",
+            "re",
+            "SwissArmyTransformer",
+            "random",
             "sys"
         ],
         "modelscope.models.nlp.gpt2.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.gpt3.backbone": [
-            "math",
-            "transformers",
-            "torch",
+            "addict",
             "os",
+            "transformers",
+            "math",
             "typing",
-            "addict"
+            "torch"
         ],
         "modelscope.models.nlp.gpt3.configuration": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.gpt3.distributed_gpt3": [
-            "math",
-            "transformers",
-            "torch",
             "collections",
+            "megatron_util",
             "os",
+            "transformers",
             "typing",
-            "megatron_util"
+            "math",
+            "torch"
         ],
         "modelscope.models.nlp.gpt3.text_generation": [
-            "typing",
-            "torch",
             "collections",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.gpt3.tokenizer": [
             "tokenizers",
             "typing"
         ],
         "modelscope.models.nlp.gpt_moe.backbone": [
-            "math",
-            "transformers",
-            "torch",
+            "addict",
             "os",
+            "transformers",
+            "math",
             "typing",
-            "addict"
+            "torch"
         ],
         "modelscope.models.nlp.gpt_moe.checkpointing": [
-            "megatron_util",
             "os",
-            "torch"
+            "torch",
+            "megatron_util"
         ],
         "modelscope.models.nlp.gpt_moe.configuration": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.gpt_moe.distributed_gpt_moe": [
             "megatron_util",
             "torch",
-            "math",
-            "transformers"
+            "transformers",
+            "math"
         ],
         "modelscope.models.nlp.gpt_moe.moe.experts": [
             "copy",
             "torch"
         ],
         "modelscope.models.nlp.gpt_moe.moe.layer": [
-            "typing",
             "megatron_util",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.gpt_moe.moe.mappings": [
             "megatron_util",
             "torch"
         ],
         "modelscope.models.nlp.gpt_moe.moe.sharded_moe": [
-            "math",
-            "torch",
-            "apex",
-            "typing",
             "megatron_util",
+            "scipy",
+            "typing",
+            "math",
             "tutel",
-            "scipy"
+            "torch",
+            "apex"
         ],
         "modelscope.models.nlp.gpt_moe.moe.utils": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.gpt_moe.text_generation": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.gpt_moe.tokenizer": [
             "tokenizers"
         ],
         "modelscope.models.nlp.gpt_neo.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.heads.crf_head": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.heads.fill_mask_head": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.heads.infromation_extraction_head": [
             "torch"
         ],
         "modelscope.models.nlp.heads.text_classification_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.text_generation_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.text_ranking_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.token_classification_head": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.heads.torch_pretrain_head": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.hf_transformers.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.llama.backbone": [
-            "typing",
+            "transformers",
             "torch",
             "math",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.llama.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.llama.convert_llama_weights_to_hf": [
-            "math",
-            "shutil",
-            "gc",
-            "torch",
             "os",
+            "math",
             "argparse",
+            "torch",
+            "gc",
+            "shutil",
             "json"
         ],
         "modelscope.models.nlp.llama.text_generation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.llama.tokenization": [
-            "transformers",
-            "shutil",
             "os",
+            "transformers",
+            "sentencepiece",
             "typing",
-            "sentencepiece"
+            "shutil"
         ],
         "modelscope.models.nlp.llama.tokenization_fast": [
+            "os",
             "shutil",
+            "transformers",
+            "typing"
+        ],
+        "modelscope.models.nlp.llama2.backbone": [
+            "transformers",
+            "torch",
+            "math",
+            "typing"
+        ],
+        "modelscope.models.nlp.llama2.configuration": [
+            "transformers"
+        ],
+        "modelscope.models.nlp.llama2.text_generation": [
+            "transformers",
+            "torch",
+            "typing"
+        ],
+        "modelscope.models.nlp.llama2.tokenization": [
+            "os",
+            "transformers",
+            "sentencepiece",
             "typing",
+            "shutil"
+        ],
+        "modelscope.models.nlp.llama2.tokenization_fast": [
+            "tokenizers",
+            "transformers",
             "os",
-            "transformers"
+            "typing",
+            "shutil"
         ],
         "modelscope.models.nlp.lstm.backbone": [
             "torch"
         ],
         "modelscope.models.nlp.lstm.token_classification": [],
         "modelscope.models.nlp.megatron_bert.backbone": [
+            "transformers",
             "torch",
-            "math",
-            "transformers"
+            "math"
         ],
         "modelscope.models.nlp.megatron_bert.configuration": [
-            "typing",
             "collections",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.megatron_bert.fill_mask": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.mglm.arguments": [
-            "torch",
+            "deepspeed",
             "os",
             "argparse",
-            "deepspeed",
+            "torch",
             "json"
         ],
         "modelscope.models.nlp.mglm.blocklm_utils": [
-            "numpy",
-            "copy",
+            "megatron_util",
             "torch",
             "random",
-            "megatron_util",
-            "math",
-            "scipy"
+            "copy",
+            "scipy",
+            "numpy",
+            "math"
         ],
         "modelscope.models.nlp.mglm.configure_data": [
-            "numpy",
-            "bisect",
-            "random",
-            "itertools",
+            "megatron_util",
+            "os",
             "copy",
             "torch",
-            "os",
-            "megatron_util"
+            "bisect",
+            "itertools",
+            "random",
+            "numpy"
         ],
         "modelscope.models.nlp.mglm.data_utils.corpora": [
-            "random",
-            "multiprocessing",
-            "queue",
-            "torch",
             "collections",
             "os",
-            "json",
-            "tqdm"
+            "tqdm",
+            "torch",
+            "queue",
+            "random",
+            "multiprocessing",
+            "json"
         ],
         "modelscope.models.nlp.mglm.data_utils.datasets": [
-            "math",
-            "itertools",
-            "torch",
-            "os",
-            "pandas",
             "operator",
             "tqdm",
-            "json",
-            "numpy",
+            "nltk",
+            "math",
             "time",
+            "torch",
             "bisect",
+            "itertools",
+            "pandas",
+            "numpy",
+            "csv",
+            "os",
             "random",
-            "nltk",
-            "csv"
+            "json"
         ],
         "modelscope.models.nlp.mglm.data_utils.extraction": [
-            "json",
-            "nltk",
             "os",
-            "glob"
+            "glob",
+            "nltk",
+            "json"
         ],
         "modelscope.models.nlp.mglm.data_utils.file_utils": [
             "functools",
             "hashlib",
-            "shutil",
             "logging",
-            "os",
-            "sys",
-            "__future__",
-            "io",
             "tqdm",
-            "json",
-            "urllib",
-            "botocore",
-            "requests",
             "boto3",
+            "io",
+            "botocore",
             "tempfile",
-            "pathlib"
+            "shutil",
+            "urllib",
+            "os",
+            "requests",
+            "__future__",
+            "pathlib",
+            "sys",
+            "json"
         ],
         "modelscope.models.nlp.mglm.data_utils.lazy_loader": [
-            "numpy",
-            "itertools",
-            "torch",
+            "time",
             "pickle",
+            "torch",
+            "mmap",
             "os",
-            "time",
-            "mmap"
+            "itertools",
+            "numpy"
         ],
         "modelscope.models.nlp.mglm.data_utils.samplers": [
             "numpy",
             "torch",
             "os",
             "sys",
             "math"
         ],
         "modelscope.models.nlp.mglm.data_utils.sp_tokenizer": [
             "os"
         ],
         "modelscope.models.nlp.mglm.data_utils.tokenization": [
-            "random",
-            "regex",
-            "nltk",
-            "itertools",
-            "torch",
             "collections",
-            "os",
             "csv",
-            "sentencepiece"
+            "os",
+            "sentencepiece",
+            "nltk",
+            "regex",
+            "torch",
+            "itertools",
+            "random"
         ],
         "modelscope.models.nlp.mglm.data_utils.tokenization_gpt2": [
             "functools",
-            "regex",
             "logging",
             "os",
-            "sys",
             "__future__",
+            "regex",
             "io",
+            "sys",
             "json"
         ],
         "modelscope.models.nlp.mglm.data_utils.wordpiece": [
-            "unicodedata",
-            "logging",
             "collections",
+            "logging",
             "os",
             "__future__",
+            "unicodedata",
             "io"
         ],
         "modelscope.models.nlp.mglm.generation_utils": [
-            "typing",
-            "abc",
+            "collections",
             "torch",
-            "collections"
+            "abc",
+            "typing"
         ],
         "modelscope.models.nlp.mglm.mglm_for_text_summarization": [
-            "numpy",
-            "random",
-            "torch",
+            "megatron_util",
             "os",
             "typing",
-            "megatron_util"
+            "torch",
+            "random",
+            "numpy"
         ],
         "modelscope.models.nlp.mglm.model.distributed": [
             "megatron_util",
             "torch"
         ],
         "modelscope.models.nlp.mglm.model.downstream": [
             "torch"
         ],
         "modelscope.models.nlp.mglm.model.modeling_bert": [
-            "math",
+            "megatron_util",
             "tarfile",
-            "shutil",
-            "copy",
             "logging",
             "os",
-            "torch",
-            "tempfile",
-            "data_utils",
-            "megatron_util",
             "__future__",
+            "copy",
+            "tempfile",
+            "math",
+            "torch",
             "apex",
+            "data_utils",
+            "shutil",
             "json"
         ],
         "modelscope.models.nlp.mglm.model.modeling_glm": [
             "megatron_util",
             "torch"
         ],
         "modelscope.models.nlp.mglm.model.prompt": [
-            "torch",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.models.nlp.mglm.model.transformer": [
+            "megatron_util",
             "torch",
             "apex",
-            "megatron_util",
             "deepspeed",
             "math"
         ],
         "modelscope.models.nlp.mglm.process_grid": [
-            "statistics",
             "os",
-            "json",
+            "glob",
+            "statistics",
             "sys",
-            "glob"
+            "json"
         ],
         "modelscope.models.nlp.mglm.run_test": [
-            "sys",
-            "test"
+            "test",
+            "sys"
         ],
         "modelscope.models.nlp.mglm.tasks.data_utils": [
-            "numpy",
-            "re",
-            "pickle",
+            "megatron_util",
             "copy",
-            "torch",
             "typing",
-            "megatron_util",
+            "pickle",
+            "torch",
+            "re",
+            "numpy",
             "json"
         ],
         "modelscope.models.nlp.mglm.tasks.eval_utils": [
-            "time",
+            "collections",
+            "megatron_util",
             "tasks",
-            "finetune_glm",
-            "random",
-            "sklearn",
             "datetime",
-            "torch",
-            "collections",
             "os",
-            "utils",
+            "sklearn",
             "typing",
-            "megatron_util"
+            "time",
+            "utils",
+            "torch",
+            "random",
+            "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.dataset": [
-            "numpy",
             "tasks",
-            "bisect",
             "math",
-            "itertools",
-            "torch",
             "utils",
+            "torch",
+            "bisect",
+            "itertools",
+            "numpy",
             "json"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.detokenizer": [
             "re"
         ],
         "modelscope.models.nlp.mglm.tasks.language_model.finetune": [
-            "torch",
             "megatron_util",
             "functools",
             "tasks",
-            "finetune_glm",
+            "torch",
             "pretrain_glm",
+            "finetune_glm",
             "math"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.dataset": [
-            "numpy",
-            "tqdm",
             "tasks",
-            "random",
-            "torch",
-            "utils",
             "os",
+            "tqdm",
+            "utils",
+            "torch",
             "data_utils",
+            "random",
+            "numpy",
             "json"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.evaluate": [
-            "generation_utils",
+            "megatron_util",
             "torch",
-            "rouge_score",
             "string",
-            "megatron_util",
+            "rouge_score",
+            "datetime",
             "random",
-            "datetime"
+            "generation_utils"
         ],
         "modelscope.models.nlp.mglm.tasks.seq2seq.finetune": [
-            "torch",
             "collections",
-            "megatron_util",
             "functools",
+            "megatron_util",
             "tasks",
-            "finetune_glm",
-            "pretrain_glm"
+            "torch",
+            "pretrain_glm",
+            "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.dataset": [
-            "abc",
-            "copy",
+            "collections",
+            "tqdm",
+            "utils",
             "torch",
-            "os",
-            "pandas",
-            "typing",
             "data_utils",
-            "tqdm",
-            "json",
-            "numpy",
             "re",
-            "random",
+            "pandas",
+            "numpy",
+            "csv",
+            "os",
+            "copy",
+            "abc",
+            "typing",
             "glob",
-            "collections",
-            "utils",
-            "csv"
+            "random",
+            "json"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.evaluate": [
-            "re",
             "collections",
             "functools",
+            "tasks",
             "string",
+            "re",
             "__future__",
-            "typing",
-            "tasks"
+            "typing"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.finetune": [
+            "collections",
             "tasks",
-            "finetune_glm",
-            "collections"
+            "finetune_glm"
         ],
         "modelscope.models.nlp.mglm.tasks.superglue.pvp": [
-            "numpy",
-            "string",
+            "collections",
             "tasks",
-            "math",
-            "random",
-            "abc",
+            "string",
             "copy",
-            "collections",
+            "abc",
+            "math",
+            "typing",
             "utils",
-            "typing"
+            "random",
+            "numpy"
         ],
         "modelscope.models.nlp.mglm.test.test_block": [
-            "numpy",
+            "argparse",
             "random",
-            "blocklm_utils",
-            "argparse"
+            "numpy",
+            "blocklm_utils"
         ],
         "modelscope.models.nlp.mglm.test.test_rel_shift": [
-            "numpy",
-            "torch",
             "learning_rates",
+            "torch",
+            "numpy",
             "matplotlib"
         ],
         "modelscope.models.nlp.mglm.train_utils": [
             "megatron_util",
             "torch",
-            "deepspeed",
-            "apex"
+            "apex",
+            "deepspeed"
         ],
         "modelscope.models.nlp.mglm.utils": [
-            "numpy",
-            "subprocess",
+            "megatron_util",
+            "os",
             "time",
-            "random",
             "torch",
-            "os",
-            "megatron_util",
+            "random",
+            "subprocess",
+            "numpy",
             "json"
         ],
         "modelscope.models.nlp.palm_v2.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.palm_v2.dureader_eval": [
+            "collections",
             "numpy",
             "zipfile",
-            "re",
+            "copy",
             "rouge",
             "math",
-            "copy",
-            "collections",
             "argparse",
+            "re",
             "sys",
             "json"
         ],
         "modelscope.models.nlp.palm_v2.text_generation": [
-            "numpy",
-            "dataclasses",
-            "subprocess",
-            "codecs",
-            "math",
+            "os",
             "transformers",
             "copy",
-            "torch",
-            "os",
+            "math",
             "typing",
+            "codecs",
+            "torch",
+            "dataclasses",
+            "subprocess",
+            "numpy",
             "json"
         ],
         "modelscope.models.nlp.peer.backbone": [
-            "dataclasses",
-            "math",
             "transformers",
+            "math",
+            "typing",
             "torch",
-            "typing"
+            "dataclasses"
         ],
         "modelscope.models.nlp.peer.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.peer.sas_utils": [
-            "numpy",
-            "torch",
+            "nltk",
             "random",
-            "nltk"
+            "numpy",
+            "torch"
         ],
         "modelscope.models.nlp.peer.text_classification": [
             "copy",
             "torch"
         ],
         "modelscope.models.nlp.plug.AnnealingLR": [
             "torch",
             "math"
         ],
         "modelscope.models.nlp.plug.backbone": [
-            "math",
-            "torch",
-            "logging",
             "megatron_util",
-            "__future__"
+            "logging",
+            "__future__",
+            "math",
+            "torch"
         ],
         "modelscope.models.nlp.plug.configuration": [
-            "json",
+            "transformers",
             "copy",
-            "transformers"
+            "json"
         ],
         "modelscope.models.nlp.plug.distributed_plug": [
             "megatron_util",
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.plug.generator": [
             "torch"
         ],
         "modelscope.models.nlp.plug_mental.adv_utils": [
             "torch"
         ],
         "modelscope.models.nlp.plug_mental.backbone": [
-            "dataclasses",
-            "math",
             "transformers",
-            "packaging",
+            "math",
+            "typing",
             "torch",
-            "typing"
+            "packaging",
+            "dataclasses"
         ],
         "modelscope.models.nlp.plug_mental.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.plug_mental.text_classification": [
             "torch"
         ],
+        "modelscope.models.nlp.polylm.text_generation": [
+            "collections",
+            "torch",
+            "transformers",
+            "typing"
+        ],
         "modelscope.models.nlp.ponet.backbone": [
-            "math",
+            "distutils",
             "transformers",
-            "packaging",
+            "math",
             "torch",
-            "distutils"
+            "packaging"
         ],
         "modelscope.models.nlp.ponet.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.ponet.document_segmentation": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.ponet.fill_mask": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.ponet.tokenization": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.nlp.space.configuration": [],
         "modelscope.models.nlp.space.dialog_intent_prediction": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.nlp.space.dialog_modeling": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.models.nlp.space.dialog_state_tracking": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.models.nlp.space.model.gen_unified_transformer": [
             "torch"
         ],
         "modelscope.models.nlp.space.model.generator": [
-            "numpy",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.models.nlp.space.model.intent_unified_transformer": [
             "torch"
         ],
         "modelscope.models.nlp.space.model.model_base": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.models.nlp.space.model.tokenization_space": [
             "transformers"
         ],
         "modelscope.models.nlp.space.model.unified_transformer": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.nlp.space.modules.embedder": [
             "torch"
         ],
         "modelscope.models.nlp.space.modules.feedforward": [
             "torch"
         ],
         "modelscope.models.nlp.space.modules.functions": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.models.nlp.space.modules.multihead_attention": [
             "torch"
         ],
         "modelscope.models.nlp.space.modules.transformer_block": [
             "torch"
         ],
         "modelscope.models.nlp.space_T_cn.backbone": [
-            "numpy",
-            "math",
             "tarfile",
-            "shutil",
-            "copy",
-            "torch",
             "os",
+            "__future__",
+            "copy",
             "tempfile",
-            "__future__"
+            "math",
+            "torch",
+            "shutil",
+            "numpy"
         ],
         "modelscope.models.nlp.space_T_cn.configuration": [
-            "copy",
             "logging",
             "__future__",
+            "copy",
             "json"
         ],
         "modelscope.models.nlp.space_T_cn.table_question_answering": [
-            "numpy",
+            "os",
             "transformers",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.nlp.space_T_en.text_to_sql": [
-            "typing",
+            "os",
             "torch",
             "text2sql_lgesql",
-            "os"
+            "typing"
         ],
         "modelscope.models.nlp.structbert.adv_utils": [
             "torch"
         ],
         "modelscope.models.nlp.structbert.backbone": [
-            "dataclasses",
-            "math",
             "transformers",
-            "packaging",
+            "math",
+            "typing",
             "torch",
-            "typing"
+            "packaging",
+            "dataclasses"
         ],
         "modelscope.models.nlp.structbert.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.structbert.faq_question_answering": [
-            "math",
-            "torch",
             "collections",
             "os",
-            "typing"
+            "math",
+            "typing",
+            "torch"
         ],
         "modelscope.models.nlp.structbert.fill_mask": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.structbert.text_classification": [
             "torch"
         ],
         "modelscope.models.nlp.structbert.token_classification": [
             "torch"
         ],
         "modelscope.models.nlp.task_models.feature_extraction": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.fill_mask": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.information_extraction": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.task_model": [
-            "re",
-            "abc",
-            "torch",
             "collections",
             "os",
-            "typing"
+            "abc",
+            "typing",
+            "torch",
+            "re"
         ],
         "modelscope.models.nlp.task_models.text_classification": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.text_generation": [
-            "typing",
-            "numpy",
+            "transformers",
             "torch",
-            "transformers"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.text_ranking": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.nlp.task_models.token_classification": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.nlp.unite.configuration": [
             "enum"
         ],
         "modelscope.models.nlp.unite.translation_evaluation": [
-            "numpy",
-            "dataclasses",
+            "transformers",
             "warnings",
             "math",
-            "transformers",
-            "packaging",
+            "typing",
             "torch",
-            "typing"
+            "packaging",
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.models.nlp.use.transformer": [
             "torch",
             "math"
         ],
         "modelscope.models.nlp.use.user_satisfaction_estimation": [
-            "numpy",
+            "os",
             "transformers",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.models.nlp.veco.backbone": [
             "transformers"
         ],
         "modelscope.models.nlp.veco.configuration": [
             "transformers"
         ],
         "modelscope.models.nlp.veco.fill_mask": [
             "transformers"
         ],
         "modelscope.models.nlp.veco.text_classification": [
             "transformers"
         ],
         "modelscope.models.nlp.veco.token_classification": [
-            "torch",
-            "transformers"
+            "transformers",
+            "torch"
         ],
         "modelscope.models.nlp.xlm_roberta.backbone": [
+            "transformers",
             "packaging",
             "torch",
-            "math",
-            "transformers"
+            "math"
         ],
         "modelscope.models.nlp.xlm_roberta.configuration": [
-            "typing",
             "collections",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.models.science.unifold.config": [
             "ml_collections",
-            "typing",
-            "copy"
+            "copy",
+            "typing"
         ],
         "modelscope.models.science.unifold.data.data_ops": [
-            "numpy",
-            "unicore",
             "functools",
-            "itertools",
-            "torch",
+            "operator",
             "typing",
-            "operator"
+            "torch",
+            "itertools",
+            "unicore",
+            "numpy"
         ],
         "modelscope.models.science.unifold.data.msa_pairing": [
-            "numpy",
             "collections",
-            "pandas",
+            "scipy",
             "typing",
-            "scipy"
+            "pandas",
+            "numpy"
         ],
         "modelscope.models.science.unifold.data.process": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.science.unifold.data.process_multimer": [
-            "typing",
+            "collections",
             "numpy",
-            "collections"
+            "typing"
         ],
         "modelscope.models.science.unifold.data.protein": [
-            "numpy",
-            "dataclasses",
-            "Bio",
             "typing",
-            "io"
+            "Bio",
+            "io",
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.models.science.unifold.data.residue_constants": [
-            "numpy",
-            "unicore",
             "collections",
-            "os",
             "functools",
+            "os",
+            "unicore",
+            "numpy",
             "typing"
         ],
         "modelscope.models.science.unifold.data.utils": [
-            "numpy",
-            "pickle",
             "functools",
             "copy",
-            "gzip",
             "scipy",
             "typing",
+            "pickle",
+            "gzip",
+            "numpy",
             "json"
         ],
         "modelscope.models.science.unifold.dataset": [
-            "numpy",
-            "unicore",
             "ml_collections",
-            "copy",
             "logging",
             "os",
-            "torch",
+            "copy",
             "typing",
+            "torch",
+            "unicore",
+            "numpy",
             "json"
         ],
         "modelscope.models.science.unifold.model": [
-            "typing",
-            "torch",
             "os",
-            "argparse"
+            "torch",
+            "argparse",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.alphafold": [
-            "unicore",
-            "torch"
+            "torch",
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.attentions": [
             "functools",
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.auxillary_heads": [
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.common": [
             "functools",
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.confidence": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.embedders": [
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.evoformer": [
             "functools",
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.featurization": [
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.frame": [
-            "typing",
-            "numpy",
+            "__future__",
             "torch",
-            "__future__"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.structure_module": [
-            "typing",
-            "unicore",
             "torch",
-            "math"
+            "unicore",
+            "math",
+            "typing"
         ],
         "modelscope.models.science.unifold.modules.template": [
-            "unicore",
             "functools",
             "math",
+            "typing",
             "torch",
-            "typing"
+            "unicore"
         ],
         "modelscope.models.science.unifold.modules.triangle_multiplication": [
             "functools",
-            "typing",
+            "torch",
             "unicore",
-            "torch"
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.mmcif": [
-            "dataclasses",
-            "absl",
             "collections",
-            "Bio",
             "functools",
-            "typing",
-            "io"
+            "Bio",
+            "absl",
+            "io",
+            "dataclasses",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.msa_identifiers": [
-            "typing",
+            "re",
             "dataclasses",
-            "re"
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.parsers": [
-            "dataclasses",
+            "collections",
+            "string",
             "re",
             "itertools",
-            "collections",
-            "typing",
-            "string"
+            "dataclasses",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.pipeline": [
-            "typing",
-            "numpy",
+            "os",
             "absl",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.templates": [
-            "numpy",
-            "dataclasses",
-            "re",
             "functools",
-            "glob",
             "datetime",
-            "abc",
-            "absl",
             "os",
-            "typing"
+            "abc",
+            "typing",
+            "re",
+            "glob",
+            "dataclasses",
+            "numpy",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.hhblits": [
-            "subprocess",
-            "glob",
-            "absl",
             "os",
-            "typing"
+            "typing",
+            "glob",
+            "subprocess",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.hhsearch": [
-            "subprocess",
-            "glob",
-            "absl",
             "os",
-            "typing"
+            "typing",
+            "glob",
+            "subprocess",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.hmmbuild": [
             "os",
             "absl",
-            "re",
-            "subprocess"
+            "subprocess",
+            "re"
         ],
         "modelscope.models.science.unifold.msa.tools.hmmsearch": [
-            "typing",
-            "absl",
             "os",
-            "subprocess"
+            "absl",
+            "subprocess",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.tools.jackhmmer": [
             "urllib",
-            "subprocess",
-            "glob",
-            "absl",
             "os",
+            "concurrent",
             "typing",
-            "concurrent"
+            "glob",
+            "subprocess",
+            "absl"
         ],
         "modelscope.models.science.unifold.msa.tools.kalign": [
-            "typing",
-            "absl",
             "os",
-            "subprocess"
+            "absl",
+            "subprocess",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.tools.utils": [
-            "shutil",
+            "time",
             "absl",
+            "contextlib",
             "tempfile",
-            "typing",
-            "time",
-            "contextlib"
+            "shutil",
+            "typing"
         ],
         "modelscope.models.science.unifold.msa.utils": [
+            "os",
             "typing",
             "absl",
-            "os",
             "json"
         ],
         "modelscope.msdatasets.audio.asr_dataset": [],
         "modelscope.msdatasets.auth.auth_config": [
-            "typing",
-            "http"
+            "http",
+            "typing"
         ],
         "modelscope.msdatasets.context.dataset_context_config": [
             "typing"
         ],
         "modelscope.msdatasets.data_files.data_files_manager": [
-            "typing",
             "os",
-            "datasets"
+            "datasets",
+            "typing"
         ],
         "modelscope.msdatasets.data_loader.data_loader": [
-            "typing",
-            "abc",
             "os",
-            "datasets"
+            "datasets",
+            "abc",
+            "typing"
         ],
         "modelscope.msdatasets.data_loader.data_loader_manager": [
-            "enum",
-            "abc",
             "os",
-            "datasets"
+            "enum",
+            "datasets",
+            "abc"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.asr_dataset": [
             "os"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_farfield_dataset": [
-            "numpy",
+            "os",
             "math",
-            "queue",
             "torch",
-            "os",
-            "threading"
+            "threading",
+            "queue",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_dataset": [
-            "torch",
-            "random"
+            "random",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.audio.kws_nearfield_processor": [
-            "kaldiio",
-            "numpy",
             "random",
+            "kaldiio",
             "torch",
             "torchaudio",
+            "numpy",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.bad_image_detecting.bad_image_detecting_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.builder": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.build": [
-            "bisect",
             "copy",
-            "math",
-            "torch"
+            "bisect",
+            "torch",
+            "math"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.collate_batch": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.datasets.coco": [
-            "numpy",
-            "cv2",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy",
+            "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.datasets.mosaic_wrapper": [
-            "numpy",
-            "math",
             "random",
+            "math",
             "torch",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.evaluation.coco.coco_eval": [
-            "torch",
             "collections",
-            "os",
-            "tempfile"
+            "tempfile",
+            "torch",
+            "os"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.distributed": [
             "torch",
             "math"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.grouped_batch_sampler": [
             "itertools",
             "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.samplers.iteration_based_batch_sampler": [
             "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.transforms.build": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.damoyolo.transforms.transforms": [
-            "numpy",
             "torch",
-            "cv2",
             "random",
-            "torchvision"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.easycv_base": [
             "os"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.gopro_image_deblurring_dataset": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_colorization.image_colorization_dataset": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.aug": [
             "imgaug",
             "albumentations"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_inpainting.image_inpainting_dataset": [
-            "numpy",
-            "glob",
-            "albumentations",
+            "enum",
             "os",
+            "albumentations",
+            "glob",
             "cv2",
-            "enum"
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_instance_segmentation_coco_dataset": [
-            "numpy",
             "os",
-            "pycocotools"
+            "pycocotools",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_portrait_enhancement.data_utils": [
-            "torch",
-            "cv2"
+            "cv2",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_portrait_enhancement.image_portrait_enhancement_dataset": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assessment_degradation.image_quality_assessment_degradation_dataset": [
             "torchvision"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.image_quality_assmessment_mos.image_quality_assessment_mos_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.language_guided_video_summarization_dataset": [
-            "numpy",
+            "os",
             "h5py",
             "torch",
-            "os",
+            "numpy",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.mgeo_ranking_dataset": [
-            "typing",
             "torch",
             "random",
-            "json"
+            "json",
+            "typing"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.movie_scene_segmentation_dataset": [
-            "torchvision",
-            "random",
+            "os",
             "copy",
             "torch",
-            "os",
+            "random",
+            "torchvision",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.movie_scene_segmentation.sampler": [
-            "numpy",
-            "random"
+            "random",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.augmenter": [
             "imgaug"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.data_loader": [
-            "numpy",
-            "bisect",
-            "math",
             "imgaug",
-            "torch"
+            "math",
+            "torch",
+            "bisect",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.image_dataset": [
-            "numpy",
             "functools",
-            "bisect",
-            "math",
-            "glob",
-            "torch",
             "logging",
             "os",
-            "cv2"
+            "math",
+            "torch",
+            "bisect",
+            "glob",
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.measures.iou_evaluator": [
-            "numpy",
             "collections",
+            "numpy",
             "shapely"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.measures.quad_measurer": [
             "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.augment_data": [
-            "numpy",
-            "cv2",
             "imgaug",
+            "cv2",
+            "numpy",
             "math"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.data_process": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_border_map": [
             "pyclipper",
-            "numpy",
             "cv2",
+            "numpy",
             "shapely"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_icdar_data": [
-            "numpy",
-            "torch",
             "collections",
+            "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.make_seg_detection_data": [
             "pyclipper",
-            "numpy",
             "cv2",
+            "numpy",
             "shapely"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.normalize_image": [
-            "numpy",
-            "torch"
+            "torch",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_detection.processes.random_crop_data": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.ocr_recognition_dataset": [
-            "numpy",
             "six",
+            "os",
             "lmdb",
             "torch",
-            "cv2",
-            "os",
             "PIL",
+            "cv2",
+            "numpy",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.reds_image_deblurring_dataset": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.referring_video_object_segmentation_dataset": [
-            "numpy",
-            "tqdm",
             "torchvision",
-            "glob",
+            "os",
+            "tqdm",
             "h5py",
             "torch",
-            "pandas",
-            "os",
             "pycocotools",
+            "glob",
+            "pandas",
+            "numpy",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.referring_video_object_segmentation.transformers": [
             "torch",
-            "PIL",
             "torchvision",
-            "random"
+            "random",
+            "PIL"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.data_utils": [
-            "torch",
-            "cv2"
+            "cv2",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.sidd_image_denoising_dataset": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.sidd_image_denoising.transforms": [
             "random"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.text_ranking_dataset": [
-            "typing",
+            "random",
             "torch",
-            "random"
+            "typing"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.torch_custom_dataset": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.veco_dataset": [
-            "typing",
+            "numpy",
             "datasets",
-            "numpy"
+            "typing"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.data_utils": [
-            "torch",
-            "cv2"
+            "cv2",
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_frame_interpolation.video_frame_interpolation_dataset": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_stabilization.video_stabilization_dataset": [],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_summarization_dataset": [
-            "numpy",
+            "os",
             "h5py",
             "torch",
-            "os",
+            "numpy",
             "json"
         ],
         "modelscope.msdatasets.dataset_cls.custom_datasets.video_super_resolution.video_super_resolution_dataset": [
-            "numpy",
-            "torch",
             "collections",
+            "torch",
+            "numpy",
             "cv2"
         ],
         "modelscope.msdatasets.dataset_cls.dataset": [
-            "copy",
-            "datasets",
             "os",
+            "tqdm",
+            "copy",
             "pandas",
-            "tqdm"
+            "datasets"
         ],
         "modelscope.msdatasets.download.dataset_builder": [
             "pyarrow",
             "os",
-            "pandas",
             "typing",
+            "pandas",
             "datasets"
         ],
         "modelscope.msdatasets.download.download_config": [
-            "typing",
-            "datasets"
+            "datasets",
+            "typing"
         ],
         "modelscope.msdatasets.download.download_manager": [
             "datasets"
         ],
         "modelscope.msdatasets.meta.data_meta_config": [],
         "modelscope.msdatasets.meta.data_meta_manager": [
-            "shutil",
             "collections",
             "os",
-            "json",
-            "datasets"
+            "shutil",
+            "datasets",
+            "json"
         ],
         "modelscope.msdatasets.ms_dataset": [
             "numpy",
-            "warnings",
             "os",
+            "warnings",
             "typing",
             "datasets"
         ],
         "modelscope.msdatasets.task_datasets.gopro_image_deblurring_dataset": [],
         "modelscope.msdatasets.task_datasets.reds_image_deblurring_dataset": [],
         "modelscope.msdatasets.task_datasets.sidd_image_denoising": [],
         "modelscope.msdatasets.task_datasets.torch_base_dataset": [],
         "modelscope.msdatasets.task_datasets.video_summarization_dataset": [],
         "modelscope.msdatasets.utils.dataset_utils": [
-            "typing",
-            "os",
             "collections",
-            "pandas"
+            "pandas",
+            "os",
+            "typing"
         ],
         "modelscope.msdatasets.utils.delete_utils": [],
         "modelscope.msdatasets.utils.maxcompute_utils": [
-            "math",
-            "pandas"
+            "pandas",
+            "math"
         ],
         "modelscope.msdatasets.utils.oss_utils": [
-            "multiprocessing",
             "os",
-            "oss2",
             "__future__",
-            "datasets"
+            "oss2",
+            "datasets",
+            "multiprocessing"
         ],
         "modelscope.msdatasets.utils.upload_utils": [
             "os",
             "multiprocessing",
             "tqdm"
         ],
         "modelscope.pipelines.audio.ans_dfsmn_pipeline": [
-            "numpy",
-            "librosa",
-            "torch",
             "collections",
-            "os",
+            "librosa",
+            "numpy",
             "soundfile",
+            "os",
             "typing",
-            "sys",
-            "io"
+            "torch",
+            "io",
+            "sys"
         ],
         "modelscope.pipelines.audio.ans_pipeline": [
-            "numpy",
             "librosa",
-            "torch",
             "soundfile",
             "typing",
-            "io"
+            "torch",
+            "io",
+            "numpy"
         ],
         "modelscope.pipelines.audio.asr_inference_pipeline": [
-            "typing",
             "os",
             "yaml",
-            "json"
+            "json",
+            "typing"
         ],
         "modelscope.pipelines.audio.asr_wenet_inference_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.audio.inverse_text_processing_pipeline": [
-            "shutil",
-            "typing",
             "os",
-            "yaml"
+            "yaml",
+            "shutil",
+            "typing"
         ],
         "modelscope.pipelines.audio.kws_farfield_pipeline": [
-            "numpy",
             "wave",
             "soundfile",
             "typing",
-            "io"
+            "io",
+            "numpy"
         ],
         "modelscope.pipelines.audio.kws_kwsbp_pipeline": [
-            "typing",
             "os",
-            "json"
+            "json",
+            "typing"
         ],
-        "modelscope.pipelines.audio.linear_aec_pipeline": [
-            "numpy",
+        "modelscope.pipelines.audio.language_recognition_pipeline": [
+            "soundfile",
+            "os",
+            "typing",
             "torch",
+            "io",
+            "torchaudio",
+            "numpy"
+        ],
+        "modelscope.pipelines.audio.linear_aec_pipeline": [
             "os",
+            "scipy",
+            "typing",
             "yaml",
             "importlib",
-            "typing",
-            "scipy"
+            "torch",
+            "numpy"
         ],
         "modelscope.pipelines.audio.lm_infer_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.audio.punctuation_processing_pipeline": [
-            "shutil",
-            "typing",
             "os",
-            "yaml"
+            "yaml",
+            "shutil",
+            "typing"
         ],
         "modelscope.pipelines.audio.segmentation_clustering_pipeline": [
-            "numpy",
-            "torch",
             "soundfile",
             "typing",
+            "torch",
+            "io",
             "torchaudio",
-            "io"
+            "numpy"
         ],
         "modelscope.pipelines.audio.separation_pipeline": [
-            "numpy",
-            "torch",
             "soundfile",
             "typing",
-            "io"
+            "torch",
+            "io",
+            "numpy"
         ],
         "modelscope.pipelines.audio.speaker_change_locating_pipeline": [
-            "numpy",
-            "torch",
             "soundfile",
             "typing",
+            "torch",
+            "io",
             "torchaudio",
-            "io"
+            "numpy"
         ],
-        "modelscope.pipelines.audio.speaker_diarization_pipeline": [
+        "modelscope.pipelines.audio.speaker_diarization_dialogue_detection_pipeline": [
             "numpy",
-            "shutil",
+            "typing"
+        ],
+        "modelscope.pipelines.audio.speaker_diarization_pipeline": [
             "os",
-            "yaml",
             "typing",
+            "yaml",
+            "shutil",
+            "numpy",
             "json"
         ],
+        "modelscope.pipelines.audio.speaker_diarization_semantic_speaker_turn_detection_pipeline": [
+            "torch",
+            "numpy",
+            "typing"
+        ],
         "modelscope.pipelines.audio.speaker_verification_eres2net_pipeline": [
             "soundfile",
-            "typing",
+            "io",
             "torch",
-            "io"
+            "typing"
         ],
         "modelscope.pipelines.audio.speaker_verification_light_pipeline": [
-            "numpy",
-            "torch",
-            "os",
             "soundfile",
+            "os",
             "typing",
+            "torch",
+            "io",
             "torchaudio",
-            "io"
+            "numpy"
         ],
         "modelscope.pipelines.audio.speaker_verification_pipeline": [
-            "shutil",
-            "typing",
             "os",
-            "yaml"
+            "yaml",
+            "shutil",
+            "typing"
         ],
         "modelscope.pipelines.audio.speaker_verification_rdino_pipeline": [
             "soundfile",
-            "typing",
+            "io",
             "torch",
-            "io"
+            "typing"
         ],
         "modelscope.pipelines.audio.text_to_speech_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.audio.timestamp_pipeline": [
-            "funasr",
             "os",
-            "yaml",
+            "funasr",
             "typing",
+            "yaml",
             "json"
         ],
         "modelscope.pipelines.audio.voice_activity_detection_pipeline": [
-            "funasr",
             "os",
-            "yaml",
+            "funasr",
             "typing",
+            "yaml",
             "json"
         ],
         "modelscope.pipelines.base": [
-            "numpy",
             "functools",
-            "random",
-            "multiprocessing",
-            "packaging",
-            "abc",
-            "torch",
             "os",
+            "abc",
             "typing",
-            "threading"
+            "torch",
+            "threading",
+            "packaging",
+            "random",
+            "numpy",
+            "multiprocessing"
         ],
         "modelscope.pipelines.builder": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.cv.action_detection_pipeline": [
+            "os",
             "math",
-            "typing",
-            "os"
+            "typing"
         ],
         "modelscope.pipelines.cv.action_recognition_pipeline": [
-            "typing",
             "os",
             "torch",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.pipelines.cv.animal_recognition_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.arc_face_recognition_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.bad_image_detecting_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.body_2d_keypoints_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
-            "PIL",
             "typing",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.cv.body_3d_keypoints_pipeline": [
-            "numpy",
-            "matplotlib",
             "datetime",
-            "torch",
-            "cv2",
             "os",
-            "tempfile",
+            "mpl_toolkits",
+            "matplotlib",
             "typing",
-            "mpl_toolkits"
+            "torch",
+            "tempfile",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.card_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.cmdssl_video_embedding_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
             "typing",
-            "decord"
+            "decord",
+            "torch",
+            "PIL",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.content_check_pipeline": [
-            "numpy",
-            "torchvision",
+            "os",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "os",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.controllable_image_generation_pipeline": [
-            "numpy",
-            "subprocess",
+            "os",
+            "tempfile",
             "math",
-            "glob",
+            "typing",
             "torch",
-            "os",
+            "glob",
             "cv2",
-            "tempfile",
-            "typing"
+            "subprocess",
+            "numpy"
         ],
         "modelscope.pipelines.cv.crowd_counting_pipeline": [
-            "numpy",
             "math",
-            "torchvision",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.ddcolor_image_colorization_pipeline": [
-            "numpy",
-            "torchvision",
+            "typing",
             "torch",
             "cv2",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.ddpm_semantic_segmentation_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.face_attribute_recognition_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_detection_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_emotion_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.face_human_hand_detection_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.face_image_generation_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_liveness_ir_pipeline": [
-            "onnxruntime",
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "PIL",
+            "onnxruntime",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_liveness_xc_pipeline": [
-            "onnxruntime",
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "PIL",
+            "onnxruntime",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_processing_base_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_quality_assessment_pipeline": [
-            "onnxruntime",
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "PIL",
+            "onnxruntime",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_recognition_onnx_fm_pipeline": [
-            "onnxruntime",
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "PIL",
+            "onnxruntime",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_recognition_onnx_ir_pipeline": [
-            "onnxruntime",
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "PIL",
+            "onnxruntime",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_recognition_ood_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_recognition_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.face_reconstruction_pipeline": [
-            "numpy",
-            "io",
-            "shutil",
-            "tensorflow",
-            "torch",
-            "cv2",
             "os",
-            "PIL",
+            "scipy",
             "typing",
             "face_alignment",
-            "scipy"
+            "tensorflow",
+            "torch",
+            "io",
+            "PIL",
+            "shutil",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.facial_expression_recognition_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.facial_landmark_confidence_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.fast_instance_segmentation_pipeline": [
-            "typing",
-            "numpy",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.general_recognition_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.hand_static_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.hicossl_video_embedding_pipeline": [
-            "typing",
             "os",
             "torch",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.pipelines.cv.human_reconstruction_pipeline": [
-            "numpy",
-            "shutil",
             "trimesh",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "shutil",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_body_reshaping_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_bts_depth_estimation_pipeline": [
-            "numpy",
-            "torch",
             "albumentations",
+            "typing",
+            "torch",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_cartoon_pipeline": [
-            "numpy",
-            "tensorflow",
             "os",
+            "typing",
+            "tensorflow",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_classification_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_color_enhance_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_colorization_pipeline": [
-            "numpy",
-            "torchvision",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_debanding_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_deblur_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_defrcn_fewshot_pipeline": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_denoise_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_depth_estimation_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_detection_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_driving_perception_pipeline": [
-            "typing",
-            "numpy",
             "os",
-            "cv2"
+            "cv2",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_face_fusion_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_human_parsing_pipeline": [
-            "typing",
-            "numpy",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_inpainting_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_inpainting_sdv2_pipeline": [
             "numpy",
-            "diffusers",
+            "os",
             "math",
+            "typing",
             "torch",
-            "cv2",
-            "os",
+            "diffusers",
             "tempfile",
-            "typing",
+            "cv2",
             "sys"
         ],
         "modelscope.pipelines.cv.image_instance_segmentation_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_matching_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_matting_pipeline": [
-            "numpy",
-            "tensorflow",
             "os",
+            "typing",
+            "tensorflow",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_mvs_depth_estimation_pipeline": [
-            "shutil",
-            "typing",
             "os",
-            "tempfile"
+            "tempfile",
+            "shutil",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_open_vocabulary_detection_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_paintbyexample_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "einops",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_panoptic_segmentation_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_portrait_enhancement_pipeline": [
-            "numpy",
+            "scipy",
             "math",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing",
-            "scipy"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_degradation_pipeline": [
-            "numpy",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "cv2",
             "tempfile",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_man_pipeline": [
-            "numpy",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "cv2",
             "tempfile",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_quality_assessment_mos_pipeline": [
-            "numpy",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "cv2",
             "tempfile",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_reid_person_pipeline": [
+            "os",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "os",
             "PIL",
-            "typing"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.image_restoration_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_salient_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.image_semantic_segmentation_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_skychange_pipeline": [
-            "numpy",
+            "pdb",
+            "typing",
             "time",
-            "cv2",
             "PIL",
-            "pdb",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_structured_model_probing_pipeline": [
-            "numpy",
             "mmcv",
-            "torchvision",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_style_transfer_pipeline": [
-            "typing",
-            "numpy",
             "os",
-            "cv2"
+            "cv2",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.image_super_resolution_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_to_image_generate_pipeline": [
-            "numpy",
-            "torchvision",
+            "os",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "os",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.image_to_image_translation_pipeline": [
             "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
-            "PIL",
             "typing",
-            "sys",
-            "io"
+            "torch",
+            "io",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "sys"
+        ],
+        "modelscope.pipelines.cv.image_try_on_pipeline": [
+            "torch",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.indoor_layout_estimation_pipeline": [
-            "typing",
             "cv2",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.language_guided_video_summarization_pipeline": [
-            "numpy",
-            "clip",
-            "random",
-            "shutil",
-            "torch",
             "os",
-            "cv2",
+            "clip",
             "tempfile",
+            "cv2",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "shutil",
+            "random",
+            "numpy"
         ],
         "modelscope.pipelines.cv.license_plate_detection_pipeline": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.lineless_table_recognition_pipeline": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.live_category_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
             "typing",
-            "decord"
+            "decord",
+            "torch",
+            "PIL",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.mask_face_recognition_pipeline": [
-            "numpy",
-            "torch",
             "collections",
+            "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.maskdino_instance_segmentation_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.mobile_image_super_resolution_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "typing",
-            "skimage"
+            "torch",
+            "skimage",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.mog_face_detection_pipeline": [
-            "typing",
             "os",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.motion_generation_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "tempfile",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.movie_scene_segmentation_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.cv.mtcnn_face_detection_pipeline": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
+        ],
+        "modelscope.pipelines.cv.nerf_recon_4k_pipeline": [
+            "typing"
         ],
         "modelscope.pipelines.cv.nerf_recon_acc_pipeline": [
             "typing"
         ],
+        "modelscope.pipelines.cv.nerf_recon_vq_compression_pipeline": [
+            "typing"
+        ],
         "modelscope.pipelines.cv.object_detection_3d_pipeline": [
-            "numpy",
-            "tempfile",
+            "os",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "os",
-            "typing"
+            "tempfile",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.ocr_detection_pipeline": [
-            "numpy",
+            "os",
+            "typing",
             "math",
             "tensorflow",
             "torch",
-            "os",
+            "tf_slim",
             "cv2",
-            "typing",
-            "tf_slim"
+            "numpy"
         ],
         "modelscope.pipelines.cv.ocr_recognition_pipeline": [],
         "modelscope.pipelines.cv.ocr_utils.model_convnext_transformer": [
             "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_dla34": [
-            "numpy",
             "os",
             "torch",
+            "numpy",
             "math"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_resnet18_half": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_resnet_mutex_v4_linewithchar": [
             "tensorflow",
             "tf_slim"
         ],
         "modelscope.pipelines.cv.ocr_utils.model_vlpt": [
             "os",
+            "torch",
             "sys",
-            "math",
-            "torch"
+            "math"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.convnext": [
             "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.timm_tinyc": [
-            "itertools",
-            "copy",
-            "torch",
             "collections",
-            "logging",
             "functools",
+            "torch",
+            "logging",
+            "itertools",
+            "copy",
             "math"
         ],
         "modelscope.pipelines.cv.ocr_utils.ocr_modules.vitstr": [
             "functools",
-            "copy",
             "logging",
-            "torch",
-            "__future__"
+            "__future__",
+            "copy",
+            "torch"
         ],
         "modelscope.pipelines.cv.ocr_utils.ops": [
-            "uuid",
             "numpy",
+            "os",
             "math",
-            "shutil",
             "tensorflow",
-            "absl",
-            "os",
+            "uuid",
+            "shutil",
             "cv2",
-            "sys"
+            "sys",
+            "absl"
         ],
         "modelscope.pipelines.cv.ocr_utils.resnet18_v1": [
             "tensorflow",
             "tf_slim"
         ],
         "modelscope.pipelines.cv.ocr_utils.resnet_utils": [
-            "tensorflow",
             "collections",
+            "tensorflow",
             "tf_slim"
         ],
         "modelscope.pipelines.cv.ocr_utils.table_process": [
-            "numpy",
-            "copy",
             "torch",
-            "cv2",
             "random",
+            "copy",
+            "numpy",
+            "cv2",
             "math"
         ],
         "modelscope.pipelines.cv.ocr_utils.utils": [
-            "pyclipper",
-            "numpy",
+            "shapely",
             "cv2",
-            "shapely"
+            "numpy",
+            "pyclipper"
         ],
         "modelscope.pipelines.cv.panorama_depth_estimation_pipeline": [
-            "numpy",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
-        "modelscope.pipelines.cv.pedestrian_attribute_recognition_pipeline": [
-            "numpy",
-            "torchvision",
+        "modelscope.pipelines.cv.panorama_depth_estimation_s2net_pipeline": [
+            "typing",
             "torch",
+            "PIL",
             "cv2",
+            "numpy"
+        ],
+        "modelscope.pipelines.cv.pedestrian_attribute_recognition_pipeline": [
             "os",
-            "PIL",
             "typing",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.cv.pointcloud_sceneflow_estimation_pipeline": [
-            "typing",
-            "numpy",
             "plyfile",
-            "torch"
-        ],
-        "modelscope.pipelines.cv.product_retrieval_embedding_pipeline": [
             "numpy",
-            "torchvision",
             "torch",
-            "cv2",
-            "os",
-            "PIL",
             "typing"
         ],
-        "modelscope.pipelines.cv.product_segmentation_pipeline": [
+        "modelscope.pipelines.cv.product_retrieval_embedding_pipeline": [
+            "os",
             "typing",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
             "numpy"
         ],
-        "modelscope.pipelines.cv.realtime_video_object_detection_pipeline": [
+        "modelscope.pipelines.cv.product_segmentation_pipeline": [
             "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
+            "typing"
+        ],
+        "modelscope.pipelines.cv.realtime_video_object_detection_pipeline": [
             "os",
-            "PIL",
             "typing",
+            "torch",
+            "PIL",
+            "cv2",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.cv.referring_video_object_segmentation_pipeline": [
-            "numpy",
+            "einops",
+            "tqdm",
             "moviepy",
-            "torchvision",
+            "typing",
             "torch",
-            "einops",
             "PIL",
             "tempfile",
-            "typing",
-            "tqdm"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.retina_face_detection_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.shop_segmentation_pipleline": [
             "typing"
         ],
         "modelscope.pipelines.cv.skin_retouching_pipeline": [
-            "numpy",
-            "torchvision",
+            "os",
+            "typing",
             "tensorflow",
             "torch",
-            "cv2",
             "PIL",
-            "os",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.table_recognition_pipeline": [
-            "numpy",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.tbs_detection_pipeline": [
-            "numpy",
-            "colorsys",
-            "torch",
-            "cv2",
             "os",
+            "typing",
+            "torch",
+            "colorsys",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.tbs_detection_utils.utils": [
-            "numpy",
-            "colorsys",
-            "torchvision",
+            "os",
+            "__future__",
             "matplotlib",
             "torch",
-            "pandas",
-            "os",
+            "colorsys",
             "PIL",
-            "__future__"
+            "pandas",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.text_driven_segmentation_pipleline": [
             "typing"
         ],
+        "modelscope.pipelines.cv.text_to_360panorama_image_pipeline": [
+            "basicsr",
+            "realesrgan",
+            "typing",
+            "torch",
+            "diffusers",
+            "PIL",
+            "random",
+            "numpy"
+        ],
         "modelscope.pipelines.cv.tinynas_classification_pipeline": [
+            "os",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "torchvision"
         ],
         "modelscope.pipelines.cv.tinynas_detection_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.ulfd_face_detection_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_category_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
             "typing",
             "decord",
+            "torch",
+            "PIL",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.cv.video_colorization_pipeline": [
-            "numpy",
-            "subprocess",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
-            "tempfile",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "tempfile",
+            "cv2",
+            "subprocess",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.video_deinterlace_pipeline": [
-            "numpy",
-            "subprocess",
+            "os",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "tempfile",
-            "typing"
+            "cv2",
+            "subprocess",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.video_depth_estimation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.video_frame_interpolation_pipeline": [
-            "numpy",
-            "subprocess",
+            "os",
+            "tempfile",
             "math",
-            "torchvision",
-            "glob",
+            "typing",
             "torch",
-            "os",
+            "glob",
             "cv2",
-            "tempfile",
-            "typing"
+            "subprocess",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.video_human_matting_pipeline": [
-            "numpy",
+            "os",
             "moviepy",
+            "typing",
             "torch",
-            "os",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_inpainting_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.cv.video_instance_segmentation_pipeline": [
             "mmcv",
-            "numpy",
-            "torch",
-            "cv2",
             "os",
+            "tqdm",
             "typing",
-            "tqdm"
+            "torch",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_multi_object_tracking_pipeline": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.pipelines.cv.video_object_segmentation_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_panoptic_segmentation_pipeline": [
             "mmcv",
-            "numpy",
-            "torch",
-            "cv2",
             "os",
+            "tqdm",
             "typing",
-            "tqdm"
+            "torch",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_single_object_tracking_pipeline": [
-            "typing",
             "os",
-            "cv2"
+            "cv2",
+            "typing"
         ],
         "modelscope.pipelines.cv.video_stabilization_pipeline": [
-            "numpy",
-            "subprocess",
+            "os",
+            "tempfile",
             "math",
-            "glob",
+            "typing",
             "torch",
-            "os",
+            "glob",
             "cv2",
-            "tempfile",
-            "typing"
+            "subprocess",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_summarization_pipeline": [
-            "numpy",
-            "torch",
             "os",
-            "cv2",
+            "tqdm",
             "typing",
-            "tqdm"
+            "torch",
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.cv.video_super_resolution_pipeline": [
-            "numpy",
-            "subprocess",
+            "os",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "tempfile",
-            "typing"
+            "cv2",
+            "subprocess",
+            "numpy",
+            "torchvision"
         ],
         "modelscope.pipelines.cv.vidt_pipeline": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.pipelines.cv.virtual_try_on_pipeline": [
-            "numpy",
-            "torch",
             "os",
+            "typing",
+            "torch",
             "PIL",
             "cv2",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.cv.vision_efficient_tuning_pipeline": [
-            "typing",
-            "numpy",
             "torch",
-            "torchvision"
+            "torchvision",
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.cv.vision_middleware_pipeline": [
-            "numpy",
             "mmcv",
-            "torchvision",
+            "os",
             "math",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.cv.vop_retrieval_pipeline": [
-            "numpy",
-            "pickle",
+            "collections",
+            "os",
+            "tqdm",
             "math",
-            "random",
+            "typing",
+            "pickle",
             "torch",
             "gzip",
-            "os",
-            "collections",
-            "typing",
-            "tqdm"
+            "random",
+            "numpy"
         ],
         "modelscope.pipelines.cv.vop_retrieval_se_pipeline": [
-            "numpy",
+            "os",
+            "typing",
             "torch",
             "gzip",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.asr_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.diffusers_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.chinese_stable_diffusion_pipeline": [
-            "numpy",
-            "diffusers",
             "transformers",
+            "typing",
             "torch",
-            "cv2",
+            "diffusers",
             "PIL",
-            "typing"
+            "cv2",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.diffusers_wrapped.stable_diffusion.stable_diffusion_pipeline": [
-            "numpy",
-            "diffusers",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
+            "typing",
+            "torch",
+            "diffusers",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.disco_guided_diffusion": [
-            "numpy",
+            "os",
             "clip",
             "math",
-            "torchvision",
-            "gc",
+            "importlib",
             "torch",
-            "os",
-            "cv2",
+            "gc",
             "PIL",
-            "importlib",
+            "cv2",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.multi_modal.disco_guided_diffusion_pipeline.utils": [
-            "numpy",
             "torch",
             "warnings",
-            "math",
-            "fractions"
+            "numpy",
+            "fractions",
+            "math"
         ],
         "modelscope.pipelines.multi_modal.document_vl_embedding_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.efficient_diffusion_tuning_pipeline": [
-            "numpy",
-            "torchvision",
+            "typing",
             "torch",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.generative_multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.gridvlp_pipeline": [
-            "numpy",
-            "time",
-            "traceback",
+            "os",
             "transformers",
+            "typing",
+            "time",
             "torch",
-            "os",
+            "traceback",
             "PIL",
-            "typing",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.multi_modal.image_captioning_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.image_text_retrieval_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.mgeo_ranking_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.multimodal_dialogue_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.ocr_recognition_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.soonet_video_temporal_grounding_pipeline": [
-            "numpy",
-            "torchvision",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.pipelines.multi_modal.sudoku_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.team_multi_modal_similarity_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.text2sql_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.text_to_image_synthesis_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.text_to_video_synthesis_pipeline": [
-            "torch",
             "einops",
             "os",
-            "cv2",
+            "typing",
+            "torch",
             "tempfile",
-            "typing"
+            "cv2"
         ],
         "modelscope.pipelines.multi_modal.video_captioning_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.video_multi_modal_embedding_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.multi_modal.video_question_answering_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_entailment_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_grounding_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.multi_modal.visual_question_answering_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.automatic_post_editing_pipeline": [
-            "numpy",
-            "jieba",
-            "html",
             "sacremoses",
-            "tensorflow",
+            "jieba",
             "os",
+            "sentencepiece",
             "typing",
-            "sentencepiece"
+            "tensorflow",
+            "numpy",
+            "html"
         ],
         "modelscope.pipelines.nlp.canmt_translation_pipeline": [
-            "typing",
-            "torch",
+            "os",
             "sacremoses",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.codegeex_code_generation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.codegeex_code_translation_pipeline": [
             "typing"
         ],
@@ -18150,505 +18808,514 @@
         "modelscope.pipelines.nlp.dialog_modeling_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.dialog_state_tracking_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.distributed_gpt3_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.distributed_gpt_moe_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.distributed_plug_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_generate_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_rerank_pipeline": [
+            "collections",
             "numpy",
-            "re",
-            "time",
-            "ujson",
-            "random",
-            "transformers",
-            "torch",
             "pprint",
+            "ujson",
             "os",
-            "collections",
+            "transformers",
             "typing",
+            "time",
+            "torch",
+            "re",
+            "random",
             "sys"
         ],
         "modelscope.pipelines.nlp.document_grounded_dialog_retrieval_pipeline": [
-            "numpy",
-            "faiss",
             "os",
             "typing",
+            "faiss",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.nlp.document_segmentation_pipeline": [
             "numpy",
-            "re",
-            "torch",
             "typing",
+            "torch",
+            "re",
             "datasets"
         ],
         "modelscope.pipelines.nlp.extractive_summarization_pipeline": [
             "numpy",
-            "re",
-            "torch",
             "typing",
+            "torch",
+            "re",
             "datasets"
         ],
         "modelscope.pipelines.nlp.faq_question_answering_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.fasttext_text_classification_pipeline": [
-            "numpy",
             "fasttext",
             "os",
+            "sentencepiece",
             "typing",
-            "sentencepiece"
+            "numpy"
         ],
         "modelscope.pipelines.nlp.feature_extraction_pipeline": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.pipelines.nlp.fid_dialogue_pipeline": [
-            "typing",
             "re",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.fill_mask_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.glm130b_text_generation_pipeline": [
             "typing"
         ],
         "modelscope.pipelines.nlp.information_extraction_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.interactive_translation_pipeline": [
-            "numpy",
-            "jieba",
             "sacremoses",
+            "jieba",
+            "os",
+            "typing",
             "subword_nmt",
             "tensorflow",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.nlp.language_identification_pipline": [
-            "numpy",
-            "re",
-            "tensorflow",
             "os",
+            "typing",
+            "tensorflow",
+            "re",
+            "numpy"
+        ],
+        "modelscope.pipelines.nlp.llama2_text_generation_pipeline": [
+            "torch",
             "typing"
         ],
         "modelscope.pipelines.nlp.mglm_text_summarization_pipeline": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.pipelines.nlp.named_entity_recognition_pipeline": [
             "typing"
         ],
+        "modelscope.pipelines.nlp.polylm_text_generation_pipeline": [
+            "os",
+            "torch",
+            "typing"
+        ],
         "modelscope.pipelines.nlp.sentence_embedding_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.siamese_uie_pipeline": [
-            "tqdm",
-            "time",
-            "math",
-            "torch",
             "logging",
             "os",
+            "tqdm",
             "copy",
             "scipy",
+            "math",
+            "time",
             "typing",
             "pathlib",
+            "torch",
             "json"
         ],
         "modelscope.pipelines.nlp.summarization_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.table_question_answering_pipeline": [
-            "transformers",
-            "torch",
             "os",
+            "transformers",
             "typing",
+            "torch",
             "json"
         ],
         "modelscope.pipelines.nlp.text_classification_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.text_error_correction_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.text_generation_pipeline": [
-            "typing",
+            "os",
             "torch",
-            "os"
+            "typing"
         ],
         "modelscope.pipelines.nlp.text_ranking_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.token_classification_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.translation_evaluation_pipeline": [
-            "numpy",
-            "torch",
+            "enum",
             "os",
             "typing",
-            "enum"
+            "torch",
+            "numpy"
         ],
         "modelscope.pipelines.nlp.translation_pipeline": [
-            "numpy",
-            "jieba",
             "sacremoses",
+            "jieba",
+            "os",
+            "typing",
             "subword_nmt",
             "tensorflow",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.pipelines.nlp.translation_quality_estimation_pipeline": [
-            "transformers",
-            "torch",
             "os",
+            "transformers",
             "typing",
+            "torch",
             "io"
         ],
         "modelscope.pipelines.nlp.user_satisfaction_estimation_pipeline": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.word_alignment_pipeline": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.nlp.word_segmentation_pipeline": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.pipelines.nlp.zero_shot_classification_pipeline": [
-            "typing",
             "torch",
-            "scipy"
+            "scipy",
+            "typing"
         ],
         "modelscope.pipelines.pipeline_template": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.pipelines.science.protein_structure_pipeline": [
-            "numpy",
-            "unicore",
-            "time",
-            "torch",
             "os",
             "typing",
+            "time",
+            "torch",
+            "unicore",
+            "numpy",
             "json"
         ],
         "modelscope.pipelines.util": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.asr": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.audio": [
-            "numpy",
-            "torch",
             "os",
+            "scipy",
             "typing",
+            "torch",
             "io",
-            "scipy"
+            "numpy"
         ],
         "modelscope.preprocessors.base": [
-            "typing",
+            "os",
             "abc",
-            "os"
+            "typing"
         ],
         "modelscope.preprocessors.builder": [],
         "modelscope.preprocessors.common": [
-            "numpy",
+            "collections",
+            "typing",
             "time",
             "torch",
-            "collections",
-            "typing"
+            "numpy"
         ],
         "modelscope.preprocessors.cv.action_detection_mapper": [
-            "numpy",
-            "copy",
-            "torch",
-            "detectron2",
             "decord",
+            "torch",
             "random",
-            "scipy"
+            "detectron2",
+            "copy",
+            "scipy",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.bad_image_detecting_preprocessor": [
-            "numpy",
-            "torchvision",
             "math",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.controllable_image_generation": [
-            "numpy",
+            "os",
             "math",
-            "torchvision",
+            "typing",
             "torch",
-            "os",
-            "cv2",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.cv2_transforms": [
-            "numpy",
-            "torch",
             "collections",
-            "cv2",
+            "torch",
             "random",
+            "cv2",
+            "numpy",
             "numbers",
             "math"
         ],
         "modelscope.preprocessors.cv.image_classification_preprocessor": [
-            "numpy",
-            "torchvision",
-            "torch",
-            "cv2",
             "os",
+            "typing",
+            "torch",
             "PIL",
-            "typing"
+            "cv2",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.image_quality_assessment_man": [
-            "numpy",
-            "torchvision",
             "math",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.image_quality_assessment_mos": [
-            "numpy",
             "math",
-            "torchvision",
+            "typing",
             "cv2",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.image_restoration_preprocessor": [
-            "numpy",
-            "torchvision",
             "math",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.cv.mmcls_preprocessor": [
-            "typing",
             "os",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.cv.timer": [
             "time"
         ],
         "modelscope.preprocessors.cv.util": [
+            "collections",
             "shutil",
             "sys",
-            "collections",
             "os"
         ],
         "modelscope.preprocessors.cv.video_stabilization": [
+            "cv2",
             "numpy",
-            "torch",
-            "cv2"
+            "torch"
         ],
         "modelscope.preprocessors.cv.video_super_resolution": [
             "os",
-            "collections",
-            "cv2"
+            "cv2",
+            "collections"
         ],
         "modelscope.preprocessors.image": [
-            "numpy",
-            "cv2",
-            "PIL",
             "typing",
-            "io"
+            "io",
+            "PIL",
+            "cv2",
+            "numpy"
         ],
         "modelscope.preprocessors.kws": [
-            "typing",
             "os",
-            "yaml"
+            "yaml",
+            "typing"
         ],
         "modelscope.preprocessors.movie_scene_segmentation.transforms": [
-            "numpy",
-            "random",
-            "torchvision",
-            "torch",
             "os",
-            "PIL",
             "typing",
+            "torch",
+            "PIL",
+            "random",
+            "torchvision",
+            "numpy",
             "numbers"
         ],
         "modelscope.preprocessors.multi_modal": [
-            "numpy",
-            "re",
-            "torchvision",
-            "timm",
-            "torch",
             "os",
-            "PIL",
+            "timm",
             "typing",
             "decord",
+            "torch",
             "io",
+            "PIL",
+            "re",
+            "torchvision",
+            "numpy",
             "json"
         ],
         "modelscope.preprocessors.nlp.bert_seq_cls_tokenizer": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.canmt_translation": [
-            "jieba",
             "sacremoses",
-            "subword_nmt",
-            "torch",
+            "jieba",
             "os",
-            "typing"
+            "typing",
+            "subword_nmt",
+            "torch"
         ],
         "modelscope.preprocessors.nlp.dialog_classification_use_preprocessor": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_generate_preprocessor": [
-            "typing",
-            "torch",
             "os",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_rerank_preprocessor": [
+            "os",
             "transformers",
             "copy",
-            "torch",
-            "os",
-            "typing"
+            "typing",
+            "torch"
         ],
         "modelscope.preprocessors.nlp.document_grounded_dialog_retrieval_preprocessor": [
-            "typing",
-            "torch",
             "os",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.document_segmentation_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.faq_question_answering_preprocessor": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.feature_extraction_preprocessor": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.fill_mask_preprocessor": [
-            "numpy",
-            "re",
+            "os",
             "abc",
+            "typing",
             "torch",
-            "os",
-            "typing"
+            "re",
+            "numpy"
         ],
         "modelscope.preprocessors.nlp.mgeo_ranking_preprocessor": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.preprocessors.nlp.mglm_summarization_preprocessor": [
-            "typing",
+            "os",
             "re",
-            "os"
+            "typing"
         ],
         "modelscope.preprocessors.nlp.relation_extraction_preprocessor": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.sentence_embedding_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.siamese_uie_preprocessor": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.space.args": [
             "argparse",
             "json"
         ],
         "modelscope.preprocessors.nlp.space.batch": [],
         "modelscope.preprocessors.nlp.space.data_loader": [
-            "math",
+            "os",
             "numpy",
-            "os"
+            "math"
         ],
         "modelscope.preprocessors.nlp.space.dialog_intent_prediction_preprocessor": [
-            "typing",
             "os",
-            "json"
+            "json",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.space.dialog_modeling_preprocessor": [
-            "typing",
-            "os"
+            "os",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.space.dialog_state_tracking_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.space.dst_processors": [
-            "numpy",
+            "json",
             "re",
             "logging",
-            "json",
             "six",
+            "numpy",
             "tqdm"
         ],
         "modelscope.preprocessors.nlp.space.fields.gen_field": [
-            "numpy",
-            "random",
-            "asyncio",
-            "itertools",
             "collections",
+            "random",
             "os",
+            "itertools",
+            "asyncio",
+            "numpy",
             "json"
         ],
         "modelscope.preprocessors.nlp.space.fields.intent_field": [
-            "numpy",
+            "collections",
+            "os",
             "tqdm",
-            "re",
             "time",
+            "re",
+            "itertools",
+            "glob",
             "random",
+            "numpy",
             "multiprocessing",
-            "glob",
-            "itertools",
-            "collections",
-            "os",
             "json"
         ],
         "modelscope.preprocessors.nlp.space.lazy_dataset": [
             "json"
         ],
         "modelscope.preprocessors.nlp.space.preprocess": [
             "os",
@@ -18657,882 +19324,902 @@
         "modelscope.preprocessors.nlp.space.sampler": [
             "numpy"
         ],
         "modelscope.preprocessors.nlp.space.tensorlistdataset": [
             "torch"
         ],
         "modelscope.preprocessors.nlp.space.tokenizer": [
-            "functools",
-            "unicodedata",
-            "regex",
             "collections",
-            "os",
+            "functools",
             "logging",
-            "sys",
+            "os",
             "__future__",
+            "regex",
+            "unicodedata",
+            "sys",
             "json"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.database": [
-            "json",
+            "tqdm",
             "sqlite3",
-            "tqdm"
+            "json"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.schema_link": [
             "re"
         ],
         "modelscope.preprocessors.nlp.space_T_cn.fields.struct": [],
         "modelscope.preprocessors.nlp.space_T_cn.table_question_answering_preprocessor": [
-            "typing",
-            "torch",
             "os",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.space_T_en.conversational_text_to_sql_preprocessor": [
-            "text2sql_lgesql",
-            "torch",
+            "json",
             "os",
             "typing",
-            "json"
+            "torch",
+            "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.common_utils": [
-            "numpy",
-            "sqlite3",
-            "text2sql_lgesql",
+            "os",
             "nltk",
+            "sqlite3",
             "itertools",
-            "os"
+            "numpy",
+            "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.parse": [],
         "modelscope.preprocessors.nlp.space_T_en.fields.preprocess_dataset": [
             "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.space_T_en.fields.process_dataset": [
-            "sys",
-            "text2sql_lgesql",
             "os",
-            "pickle"
+            "pickle",
+            "sys",
+            "text2sql_lgesql"
         ],
         "modelscope.preprocessors.nlp.text_classification_preprocessor": [
-            "typing",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.text_clean": [
             "codecs",
-            "re",
-            "sys"
+            "sys",
+            "re"
         ],
         "modelscope.preprocessors.nlp.text_error_correction": [
-            "typing",
-            "torch",
             "os",
-            "transformers"
+            "torch",
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.text_generation_preprocessor": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.text_ranking_preprocessor": [
-            "typing",
-            "transformers"
+            "transformers",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.token_classification_preprocessor": [
-            "typing",
+            "torch",
             "numpy",
-            "torch"
+            "typing"
         ],
         "modelscope.preprocessors.nlp.token_classification_thai_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.nlp.token_classification_viet_preprocessor": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.nlp.transformers_tokenizer": [
-            "json",
             "collections",
+            "transformers",
             "os",
-            "transformers"
+            "json"
         ],
         "modelscope.preprocessors.nlp.translation_evaluation_preprocessor": [
-            "typing",
+            "transformers",
             "torch",
-            "transformers"
+            "typing"
         ],
         "modelscope.preprocessors.nlp.utils": [
-            "numpy",
-            "transformers",
             "collections",
+            "transformers",
             "os",
             "typing",
+            "numpy",
             "json"
         ],
         "modelscope.preprocessors.nlp.word_alignment_preprocessor": [
-            "numpy",
-            "itertools",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "itertools",
+            "numpy"
         ],
         "modelscope.preprocessors.nlp.zero_shot_classification_preprocessor": [
             "typing"
         ],
         "modelscope.preprocessors.ofa.asr": [
-            "fairseq",
             "librosa",
-            "random",
-            "torch",
-            "os",
             "soundfile",
+            "os",
             "typing",
-            "pathlib"
+            "fairseq",
+            "pathlib",
+            "torch",
+            "random"
         ],
         "modelscope.preprocessors.ofa.base": [
-            "numpy",
-            "re",
             "string",
-            "torch",
             "os",
+            "torch",
+            "io",
             "PIL",
+            "re",
             "torchaudio",
-            "io",
+            "numpy",
             "json"
         ],
         "modelscope.preprocessors.ofa.image_captioning": [
-            "typing",
             "torch",
-            "torchvision"
+            "torchvision",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.image_classification": [
             "functools",
-            "torchvision",
             "timm",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision"
         ],
         "modelscope.preprocessors.ofa.ocr_recognition": [
-            "torchvision",
+            "zhconv",
+            "typing",
             "torch",
             "unicodedata2",
-            "typing",
-            "zhconv"
+            "torchvision"
         ],
         "modelscope.preprocessors.ofa.sudoku": [
-            "typing",
+            "torch",
             "numpy",
-            "torch"
+            "typing"
         ],
         "modelscope.preprocessors.ofa.summarization": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.text2sql": [
-            "re",
-            "random",
-            "torch",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "re",
+            "random"
         ],
         "modelscope.preprocessors.ofa.text_classification": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.text_to_image_synthesis": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.utils.audio_helper": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.utils.bridge_content_encoder": [
+            "difflib",
+            "functools",
             "sqlite3",
             "rapidfuzz",
-            "functools",
-            "typing",
-            "difflib"
+            "typing"
         ],
         "modelscope.preprocessors.ofa.utils.collate": [
-            "typing",
             "torch",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.preprocessors.ofa.utils.constant": [],
         "modelscope.preprocessors.ofa.utils.get_tables": [
-            "sys",
             "sqlite3",
+            "sys",
             "traceback"
         ],
         "modelscope.preprocessors.ofa.utils.random_help": [
-            "torch",
-            "torch_xla"
+            "torch_xla",
+            "torch"
         ],
         "modelscope.preprocessors.ofa.utils.text2phone": [],
         "modelscope.preprocessors.ofa.utils.transforms": [
-            "numpy",
             "torch",
             "PIL",
             "random",
-            "torchvision"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.ofa.utils.vision_helper": [
-            "numpy",
-            "cv2"
+            "cv2",
+            "numpy"
         ],
         "modelscope.preprocessors.ofa.visual_entailment": [
-            "typing",
             "torch",
+            "torchvision",
             "PIL",
-            "torchvision"
+            "typing"
         ],
         "modelscope.preprocessors.ofa.visual_grounding": [
-            "numpy",
-            "torchvision",
+            "typing",
             "torch",
             "PIL",
-            "typing"
+            "torchvision",
+            "numpy"
         ],
         "modelscope.preprocessors.ofa.visual_question_answering": [
-            "typing",
             "torch",
+            "torchvision",
             "PIL",
-            "torchvision"
+            "typing"
         ],
         "modelscope.preprocessors.science.uni_fold": [
-            "pickle",
-            "hashlib",
             "tarfile",
-            "torch",
-            "gzip",
-            "os",
+            "hashlib",
             "logging",
-            "typing",
-            "json",
             "tqdm",
-            "numpy",
+            "time",
+            "pickle",
+            "torch",
+            "gzip",
             "re",
+            "numpy",
+            "ipdb",
+            "os",
             "requests",
-            "time",
+            "typing",
+            "pathlib",
             "random",
             "unittest",
-            "ipdb",
-            "pathlib"
+            "json"
+        ],
+        "modelscope.preprocessors.speaker": [
+            "torch",
+            "typing"
         ],
         "modelscope.preprocessors.tts": [
-            "typing",
+            "os",
             "kantts",
-            "os"
+            "typing"
         ],
         "modelscope.preprocessors.video": [
-            "uuid",
-            "numpy",
             "urllib",
+            "os",
             "math",
-            "random",
-            "torchvision",
+            "decord",
             "torch",
-            "os",
+            "uuid",
             "tempfile",
-            "decord"
+            "random",
+            "torchvision",
+            "numpy"
         ],
         "modelscope.trainers.audio.ans_trainer": [],
         "modelscope.trainers.audio.asr_trainer": [
-            "shutil",
-            "funasr",
             "os",
-            "tempfile",
+            "funasr",
+            "shutil",
             "typing",
+            "tempfile",
             "json"
         ],
         "modelscope.trainers.audio.kws_farfield_trainer": [
-            "numpy",
-            "pickle",
-            "math",
-            "glob",
             "datetime",
-            "torch",
             "os",
-            "typing"
+            "math",
+            "typing",
+            "pickle",
+            "torch",
+            "glob",
+            "numpy"
         ],
         "modelscope.trainers.audio.kws_nearfield_trainer": [
-            "re",
             "datetime",
-            "copy",
-            "torch",
             "os",
-            "yaml",
+            "copy",
             "typing",
+            "yaml",
+            "torch",
+            "re",
             "tensorboardX"
         ],
         "modelscope.trainers.audio.kws_utils.batch_utils": [
-            "numpy",
-            "math",
-            "datetime",
-            "torch",
             "collections",
+            "sys",
+            "datetime",
             "os",
+            "math",
             "typing",
-            "sys"
+            "torch",
+            "numpy"
         ],
         "modelscope.trainers.audio.kws_utils.det_utils": [
+            "os",
             "kaldiio",
-            "numpy",
             "matplotlib",
-            "glob",
             "torch",
-            "os",
-            "json",
-            "threading"
+            "threading",
+            "glob",
+            "numpy",
+            "json"
         ],
         "modelscope.trainers.audio.kws_utils.file_utils": [
             "re"
         ],
         "modelscope.trainers.audio.kws_utils.model_utils": [
-            "numpy",
-            "re",
-            "glob",
+            "os",
             "shutil",
+            "yaml",
             "torch",
-            "os",
-            "yaml"
+            "re",
+            "glob",
+            "numpy"
         ],
         "modelscope.trainers.audio.kws_utils.runtime_utils": [
-            "re",
-            "codecs",
-            "shutil",
             "collections",
-            "stat",
             "os",
+            "codecs",
+            "stat",
+            "re",
+            "shutil",
             "sys",
             "json"
         ],
         "modelscope.trainers.audio.separation_trainer": [
-            "numpy",
-            "speechbrain",
-            "torch",
-            "os",
             "csv",
+            "os",
+            "tqdm",
             "typing",
+            "speechbrain",
+            "torch",
             "torchaudio",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.trainers.audio.tts_trainer": [
             "zipfile",
-            "shutil",
             "os",
-            "tempfile",
+            "shutil",
             "typing",
+            "tempfile",
             "json"
         ],
         "modelscope.trainers.base": [
-            "typing",
+            "os",
             "time",
             "abc",
-            "os"
+            "typing"
         ],
         "modelscope.trainers.builder": [],
         "modelscope.trainers.cli_argument_parser": [
-            "typing",
+            "argparse",
             "dataclasses",
-            "argparse"
+            "typing"
         ],
         "modelscope.trainers.cv.action_detection_trainer": [
-            "fvcore",
-            "detectron2",
-            "torch",
             "os",
-            "typing"
+            "detectron2",
+            "fvcore",
+            "typing",
+            "torch"
         ],
         "modelscope.trainers.cv.card_detection_scrfd_trainer": [],
         "modelscope.trainers.cv.cartoon_translation_trainer": [
-            "numpy",
-            "tensorflow",
-            "packaging",
             "os",
+            "tqdm",
             "typing",
-            "tqdm"
+            "tensorflow",
+            "packaging",
+            "numpy"
         ],
         "modelscope.trainers.cv.face_detection_scrfd_trainer": [
-            "typing",
+            "os",
             "time",
             "copy",
-            "os"
+            "typing"
         ],
         "modelscope.trainers.cv.image_classifition_trainer": [
-            "numpy",
-            "time",
+            "os",
             "copy",
+            "typing",
+            "time",
             "torch",
-            "os",
-            "typing"
+            "numpy"
         ],
         "modelscope.trainers.cv.image_defrcn_fewshot_detection_trainer": [
-            "detectron2",
-            "torch",
             "collections",
             "os",
-            "typing"
+            "detectron2",
+            "typing",
+            "torch"
         ],
         "modelscope.trainers.cv.image_detection_damoyolo_trainer": [
-            "time",
-            "math",
             "datetime",
-            "torch",
             "os",
+            "math",
+            "time",
             "typing",
+            "torch",
             "easydict"
         ],
         "modelscope.trainers.cv.image_inpainting_trainer": [
             "time",
             "torch",
             "collections"
         ],
         "modelscope.trainers.cv.image_instance_segmentation_trainer": [],
         "modelscope.trainers.cv.image_portrait_enhancement_trainer": [
-            "torch",
-            "collections"
+            "collections",
+            "torch"
         ],
         "modelscope.trainers.cv.movie_scene_segmentation_trainer": [],
         "modelscope.trainers.cv.nerf_recon_acc_trainer": [
-            "numpy",
-            "time",
-            "random",
-            "glob",
             "datetime",
-            "torch",
-            "cv2",
             "os",
+            "tqdm",
+            "cv2",
             "typing",
-            "tqdm"
+            "time",
+            "torch",
+            "glob",
+            "random",
+            "numpy"
         ],
         "modelscope.trainers.cv.ocr_detection_db_trainer": [
-            "numpy",
-            "time",
-            "math",
             "datetime",
-            "copy",
-            "torch",
             "os",
+            "tqdm",
+            "copy",
+            "math",
+            "time",
             "typing",
+            "torch",
             "easydict",
-            "tqdm"
+            "numpy"
         ],
         "modelscope.trainers.cv.ocr_recognition_trainer": [
             "time",
             "torch",
             "collections"
         ],
         "modelscope.trainers.cv.referring_video_object_segmentation_trainer": [
-            "torch",
-            "os"
+            "os",
+            "torch"
         ],
         "modelscope.trainers.cv.vision_efficient_tuning_trainer": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.default_config": [
             "typing"
         ],
         "modelscope.trainers.hooks.builder": [],
         "modelscope.trainers.hooks.checkpoint.checkpoint_hook": [
-            "numpy",
-            "random",
-            "shutil",
-            "torch",
             "os",
             "typing",
+            "torch",
+            "shutil",
+            "random",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.hooks.checkpoint.checkpoint_processor": [
+            "os",
             "shutil",
-            "re",
-            "os"
+            "re"
         ],
         "modelscope.trainers.hooks.checkpoint.load_checkpoint_hook": [
-            "numpy",
-            "random",
-            "packaging",
+            "typing",
             "torch",
-            "typing"
+            "packaging",
+            "random",
+            "numpy"
         ],
         "modelscope.trainers.hooks.clip_clamp_logit_scale_hook": [
             "torch"
         ],
         "modelscope.trainers.hooks.compression.sparsity_hook": [
             "os"
         ],
         "modelscope.trainers.hooks.compression.utils": [
             "torch"
         ],
         "modelscope.trainers.hooks.distributed.ddp_hook": [],
         "modelscope.trainers.hooks.distributed.deepspeed_hook": [
+            "megatron_util",
             "functools",
-            "math",
+            "deepspeed",
+            "os",
             "transformers",
-            "shutil",
+            "math",
             "torch",
-            "os",
-            "megatron_util",
-            "deepspeed"
+            "shutil"
         ],
         "modelscope.trainers.hooks.distributed.megatron_hook": [
-            "shutil",
             "megatron_util",
+            "shutil",
             "torch",
             "os"
         ],
         "modelscope.trainers.hooks.early_stop_hook": [
             "numpy"
         ],
         "modelscope.trainers.hooks.evaluation_hook": [
-            "typing",
-            "collections"
+            "collections",
+            "typing"
         ],
         "modelscope.trainers.hooks.hook": [
             "functools"
         ],
         "modelscope.trainers.hooks.iter_timer_hook": [
             "time"
         ],
         "modelscope.trainers.hooks.logger.base": [
+            "torch",
             "numpy",
             "abc",
-            "torch",
             "numbers"
         ],
         "modelscope.trainers.hooks.logger.tensorboard_hook": [
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy"
         ],
         "modelscope.trainers.hooks.logger.text_logger_hook": [
-            "datetime",
-            "torch",
             "collections",
+            "datetime",
             "os",
+            "torch",
             "json"
         ],
         "modelscope.trainers.hooks.lr_scheduler_hook": [],
         "modelscope.trainers.hooks.optimizer.apex_optimizer_hook": [
+            "logging",
             "packaging",
-            "torch",
-            "logging"
+            "torch"
         ],
         "modelscope.trainers.hooks.optimizer.base": [
-            "torch",
-            "logging"
+            "logging",
+            "torch"
         ],
         "modelscope.trainers.hooks.optimizer.torch_optimizer_hook": [
             "logging"
         ],
         "modelscope.trainers.hooks.priority": [
-            "typing",
-            "enum"
+            "enum",
+            "typing"
         ],
         "modelscope.trainers.lrscheduler.builder": [
-            "inspect",
             "packaging",
-            "torch"
+            "torch",
+            "inspect"
         ],
         "modelscope.trainers.lrscheduler.warmup.base": [
             "torch"
         ],
         "modelscope.trainers.lrscheduler.warmup.warmup": [],
         "modelscope.trainers.multi_modal.clip.clip_trainer": [
-            "typing",
             "os",
             "torch",
-            "math"
+            "math",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.clip.clip_trainer_utils": [
             "functools",
-            "inspect",
+            "os",
             "math",
             "torch",
-            "os"
+            "inspect"
         ],
-        "modelscope.trainers.multi_modal.dreambooth_diffusion.dreambooth_diffusion_trainer": [
-            "warnings",
+        "modelscope.trainers.multi_modal.custom_diffusion.custom_diffusion_trainer": [
             "hashlib",
+            "os",
+            "warnings",
+            "tqdm",
+            "typing",
+            "pathlib",
+            "torch",
             "diffusers",
-            "torchvision",
-            "shutil",
+            "PIL",
             "itertools",
-            "torch",
+            "random",
+            "torchvision",
+            "numpy",
+            "json"
+        ],
+        "modelscope.trainers.multi_modal.dreambooth_diffusion.dreambooth_diffusion_trainer": [
             "collections",
-            "PIL",
+            "hashlib",
+            "tqdm",
+            "warnings",
             "typing",
             "pathlib",
-            "tqdm"
+            "torch",
+            "diffusers",
+            "PIL",
+            "itertools",
+            "shutil",
+            "torchvision"
         ],
         "modelscope.trainers.multi_modal.efficient_diffusion_tuning.efficient_diffusion_tuning_trainer": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.lora_diffusion.lora_diffusion_trainer": [
-            "typing",
             "torch",
-            "diffusers"
+            "diffusers",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.mgeo_ranking_trainer": [
-            "typing",
             "dataclasses",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.mplug.mplug_trainer": [
-            "typing",
+            "collections",
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.trainers.multi_modal.ofa.ofa_trainer": [
             "functools",
-            "math",
+            "os",
             "shutil",
+            "typing",
+            "math",
             "torch",
-            "os",
             "tempfile",
-            "typing",
             "json"
         ],
         "modelscope.trainers.multi_modal.ofa.ofa_trainer_utils": [
-            "shutil",
-            "numpy",
             "torch",
+            "transformers",
             "os",
-            "math",
-            "transformers"
+            "shutil",
+            "numpy",
+            "math"
         ],
         "modelscope.trainers.multi_modal.stable_diffusion.stable_diffusion_trainer": [
-            "typing",
-            "torch"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.multi_modal.team.team_trainer": [
-            "numpy",
-            "sklearn",
-            "torch",
             "collections",
+            "sklearn",
             "os",
-            "typing"
+            "typing",
+            "torch",
+            "numpy"
         ],
         "modelscope.trainers.multi_modal.team.team_trainer_utils": [
             "torch",
             "torchvision",
             "PIL"
         ],
         "modelscope.trainers.nlp.csanmt_translation_trainer": [
-            "tensorflow",
-            "time",
             "os",
+            "time",
+            "tensorflow",
             "typing"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_generate_trainer": [
-            "tqdm",
-            "re",
-            "rouge",
+            "collections",
+            "sacrebleu",
             "string",
+            "os",
+            "tqdm",
             "transformers",
+            "rouge",
             "torch",
-            "collections",
-            "os",
-            "sacrebleu",
+            "re",
             "json"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_rerank_trainer": [
-            "numpy",
-            "time",
-            "random",
+            "os",
             "transformers",
+            "typing",
+            "time",
             "torch",
-            "os",
-            "typing"
+            "random",
+            "numpy"
         ],
         "modelscope.trainers.nlp.document_grounded_dialog_retrieval_trainer": [
-            "numpy",
+            "os",
             "tqdm",
-            "faiss",
             "transformers",
             "torch",
-            "os",
+            "faiss",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.faq_question_answering_trainer": [
-            "numpy",
-            "dataclasses",
-            "functools",
-            "torch",
             "collections",
+            "functools",
             "distutils",
+            "contextlib",
             "typing",
-            "contextlib"
+            "torch",
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.trainers.nlp.gpt3_trainer": [
-            "typing",
-            "torch",
+            "os",
             "copy",
-            "os"
+            "torch",
+            "typing"
         ],
         "modelscope.trainers.nlp.gpt_moe_trainer": [
-            "torch",
+            "megatron_util",
             "collections",
             "os",
             "typing",
-            "megatron_util"
+            "torch"
         ],
         "modelscope.trainers.nlp.plug_trainer": [
-            "torch",
+            "megatron_util",
+            "deepspeed",
             "os",
             "typing",
-            "megatron_util",
-            "deepspeed"
+            "torch"
         ],
         "modelscope.trainers.nlp.sentence_embedding_trainer": [
-            "numpy",
-            "dataclasses",
-            "time",
+            "tqdm",
             "transformers",
-            "torch",
             "typing",
-            "tqdm"
+            "time",
+            "torch",
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.trainers.nlp.sequence_classification_trainer": [
-            "typing",
             "time",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.trainers.nlp.siamese_uie_trainer": [
-            "numpy",
-            "time",
-            "math",
-            "random",
-            "torch",
             "collections",
             "os",
             "typing",
+            "time",
+            "math",
+            "torch",
+            "random",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.space.dialog_intent_trainer": [
-            "typing",
             "os",
-            "numpy"
+            "numpy",
+            "typing"
         ],
         "modelscope.trainers.nlp.space.dialog_modeling_trainer": [
-            "typing",
-            "numpy",
             "os",
-            "time"
+            "time",
+            "numpy",
+            "typing"
         ],
         "modelscope.trainers.nlp.space.eval": [
-            "numpy",
+            "collections",
             "sklearn",
-            "math",
             "nltk",
-            "collections",
+            "math",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.space.metrics.metrics_tracker": [
             "collections",
             "math"
         ],
         "modelscope.trainers.nlp.space.trainer.gen_trainer": [
-            "numpy",
+            "collections",
+            "os",
             "tqdm",
-            "time",
             "transformers",
+            "time",
             "torch",
-            "collections",
-            "os",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.space.trainer.intent_trainer": [
-            "numpy",
+            "collections",
+            "os",
             "tqdm",
-            "time",
             "transformers",
+            "time",
             "torch",
-            "collections",
-            "os",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.table_question_answering_trainer": [
-            "numpy",
+            "os",
             "tqdm",
+            "typing",
             "time",
             "torch",
-            "os",
-            "typing",
+            "numpy",
             "json"
         ],
         "modelscope.trainers.nlp.text_generation_trainer": [
             "torch",
-            "collections"
+            "typing"
         ],
         "modelscope.trainers.nlp.text_ranking_trainer": [
-            "numpy",
-            "dataclasses",
+            "tqdm",
+            "typing",
             "time",
             "torch",
-            "typing",
-            "tqdm"
+            "dataclasses",
+            "numpy"
         ],
         "modelscope.trainers.nlp.translation_evaluation_trainer": [
-            "math",
-            "random",
-            "transformers",
-            "torch",
             "os",
-            "pandas",
+            "tqdm",
+            "transformers",
             "typing",
-            "tqdm"
+            "math",
+            "torch",
+            "random",
+            "pandas"
         ],
         "modelscope.trainers.nlp_trainer": [
-            "typing",
-            "numpy",
+            "os",
             "torch",
-            "os"
+            "numpy",
+            "typing"
         ],
         "modelscope.trainers.optimizer.builder": [
-            "typing",
             "torch",
-            "inspect"
+            "inspect",
+            "typing"
         ],
         "modelscope.trainers.parallel.builder": [
             "torch"
         ],
         "modelscope.trainers.parallel.utils": [],
         "modelscope.trainers.trainer": [
-            "functools",
-            "inspect",
-            "torch",
             "collections",
+            "functools",
+            "distutils",
             "os",
             "copy",
-            "distutils",
             "typing",
+            "torch",
+            "inspect",
             "json"
         ],
         "modelscope.trainers.training_args": [
-            "dataclasses",
-            "re",
+            "addict",
             "copy",
             "typing",
-            "addict",
+            "re",
+            "dataclasses",
             "json"
         ],
         "modelscope.trainers.utils.inference": [
-            "pickle",
-            "shutil",
-            "torch",
+            "collections",
             "logging",
             "os",
-            "collections",
-            "tqdm"
+            "tqdm",
+            "pickle",
+            "torch",
+            "shutil"
         ],
         "modelscope.trainers.utils.log_buffer": [
-            "numpy",
-            "collections"
+            "collections",
+            "numpy"
         ]
     },
-    "version": "1.7.1"
+    "version": "1.8.0rc0"
 }
```

### Comparing `modelscope-1.7.1/modelscope/utils/ast_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/ast_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/audio/audio_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/audio/audio_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/audio/tts_exceptions.py` & `modelscope-1.8.0rc0/modelscope/utils/audio/tts_exceptions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/checkpoint.py` & `modelscope-1.8.0rc0/modelscope/utils/checkpoint.py`

 * *Files 0% similar despite different names*

```diff
@@ -607,32 +607,30 @@
             f'Provided path ({target_folder}) should be a directory, not a file'
         )
 
     if save_checkpoint_name is None:
         raise Exception(
             'At least pass in one checkpoint name for saving method')
 
-    # Clean the folder from a previous save
-    if os.path.exists(target_folder):
-        rmtree(target_folder)
-
     # Single ckpt path, sharded ckpt logic will be added later
     output_ckpt_path = os.path.join(target_folder, save_checkpoint_name)
 
     # Save the files to be copied to the save directory, ignore the original ckpts and configuration
     origin_file_to_be_ignored = [save_checkpoint_name]
     ignore_file_set = set(origin_file_to_be_ignored)
     ignore_file_set.add(ModelFile.CONFIGURATION)
+    ignore_file_set.add('*.safetensors')
     ignore_file_set.add('.*')
     if hasattr(model,
                'model_dir') and model.model_dir is not None and is_master():
         copytree(
             model.model_dir,
             target_folder,
-            ignore=ignore_patterns(*ignore_file_set))
+            ignore=ignore_patterns(*ignore_file_set),
+            dirs_exist_ok=True)
 
     # Save the ckpt to the save directory
     try:
         save_function(model, output_ckpt_path, **kwargs)
     except Exception as e:
         raise Exception(
             f'During saving checkpoints, the error of "{type(e).__name__} '
```

### Comparing `modelscope-1.7.1/modelscope/utils/chinese_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/chinese_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/config.py` & `modelscope-1.8.0rc0/modelscope/utils/config.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/config_ds.py` & `modelscope-1.8.0rc0/modelscope/utils/config_ds.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/constant.py` & `modelscope-1.8.0rc0/modelscope/utils/constant.py`

 * *Files 2% similar despite different names*

```diff
@@ -92,14 +92,16 @@
     image_style_transfer = 'image-style-transfer'
     image_portrait_stylization = 'image-portrait-stylization'
     image_body_reshaping = 'image-body-reshaping'
     image_embedding = 'image-embedding'
     image_face_fusion = 'image-face-fusion'
     product_retrieval_embedding = 'product-retrieval-embedding'
     controllable_image_generation = 'controllable-image-generation'
+    text_to_360panorama_image = 'text-to-360panorama-image'
+    image_try_on = 'image-try-on'
 
     # video recognition
     live_category = 'live-category'
     action_recognition = 'action-recognition'
     action_detection = 'action-detection'
     video_category = 'video-category'
     video_embedding = 'video-embedding'
@@ -148,14 +150,16 @@
 
     # image quality assessment mos
     image_quality_assessment_mos = 'image-quality-assessment-mos'
     # motion generation
     motion_generation = 'motion-generation'
     # 3d reconstruction
     nerf_recon_acc = 'nerf-recon-acc'
+    nerf_recon_4k = 'nerf-recon-4k'
+    nerf_recon_vq_compression = 'nerf-recon-vq-compression'
 
     # vision efficient tuning
     vision_efficient_tuning = 'vision-efficient-tuning'
 
     # bad image detecting
     bad_image_detecting = 'bad-image-detecting'
 
@@ -219,18 +223,21 @@
     speech_separation = 'speech-separation'
     acoustic_echo_cancellation = 'acoustic-echo-cancellation'
     acoustic_noise_suppression = 'acoustic-noise-suppression'
     keyword_spotting = 'keyword-spotting'
     inverse_text_processing = 'inverse-text-processing'
     punctuation = 'punctuation'
     speaker_verification = 'speaker-verification'
+    speech_language_recognition = 'speech-language-recognition'
     speaker_diarization = 'speaker-diarization'
     voice_activity_detection = 'voice-activity-detection'
     language_score_prediction = 'language-score-prediction'
     speech_timestamp = 'speech-timestamp'
+    speaker_diarization_dialogue_detection = 'speaker-diarization-dialogue-detection'
+    speaker_diarization_semantic_speaker_turn_detection = 'speaker-diarization-semantic-speaker-turn-detection'
 
 
 class MultiModalTasks(object):
     # multi-modal tasks
     image_captioning = 'image-captioning'
     visual_grounding = 'visual-grounding'
     text_to_image_synthesis = 'text-to-image-synthesis'
```

### Comparing `modelscope-1.7.1/modelscope/utils/cv/image_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/cv/image_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/cv/motion_utils/motion_process.py` & `modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/motion_process.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/cv/motion_utils/plot_script.py` & `modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/plot_script.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/cv/motion_utils/rotation_conversions.py` & `modelscope-1.8.0rc0/modelscope/utils/cv/motion_utils/rotation_conversions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/data_collators.py` & `modelscope-1.8.0rc0/modelscope/utils/data_collators.py`

 * *Files 8% similar despite different names*

```diff
@@ -3,15 +3,15 @@
 
 from collections import OrderedDict
 from collections.abc import Mapping
 from typing import Any, List, Optional, Tuple
 
 from .logger import get_logger
 
-logger = get_logger(__name__)
+logger = get_logger()
 
 
 class RemoveColumnsCollator:
     """Remove specified columns from the input mini-batch, and convert them to attributes.
 
     For example: if columns_to_remove = ['id'], then user should call batch.id instead of batch['id'].
```

### Comparing `modelscope-1.7.1/modelscope/utils/data_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/data_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/device.py` & `modelscope-1.8.0rc0/modelscope/utils/device.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/error.py` & `modelscope-1.8.0rc0/modelscope/utils/error.py`

 * *Files 1% similar despite different names*

```diff
@@ -164,7 +164,13 @@
 """
 
 # docstyle-ignore
 TAMING_IMPORT_ERROR = """
 {0} requires the timm library but it was not found in your environment. You can install it with pip:
 `pip install taming-transformers-rom1504`
 """
+
+# docstyle-ignore
+XFORMERS_IMPORT_ERROR = """
+{0} requires the timm library but it was not found in your environment. You can install it with pip:
+`pip install xformers>=0.0.17`
+"""
```

### Comparing `modelscope-1.7.1/modelscope/utils/file_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/file_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/hub.py` & `modelscope-1.8.0rc0/modelscope/utils/hub.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/import_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/import_utils.py`

 * *Files 0% similar despite different names*

```diff
@@ -302,14 +302,15 @@
     ('megatron_util', (is_package_available('megatron_util'),
                        MEGATRON_UTIL_IMPORT_ERROR)),
     ('text2sql_lgesql', (is_package_available('text2sql_lgesql'),
                          TEXT2SQL_LGESQL_IMPORT_ERROR)),
     ('mpi4py', (is_package_available('mpi4py'), MPI4PY_IMPORT_ERROR)),
     ('open_clip', (is_package_available('open_clip'), OPENCLIP_IMPORT_ERROR)),
     ('taming', (is_package_available('taming'), TAMING_IMPORT_ERROR)),
+    ('xformers', (is_package_available('xformers'), XFORMERS_IMPORT_ERROR)),
 ])
 
 SYSTEM_PACKAGE = set(['os', 'sys', 'typing'])
 
 
 def requires(obj, requirements):
     if not isinstance(requirements, (list, tuple)):
```

### Comparing `modelscope-1.7.1/modelscope/utils/input_output.py` & `modelscope-1.8.0rc0/modelscope/utils/input_output.py`

 * *Files 2% similar despite different names*

```diff
@@ -615,18 +615,24 @@
     service_input = body['input']
     if 'parameters' in body:
         parameters = body['parameters']
     else:
         parameters = {}
     pipeline_input = {}
 
+    if isinstance(service_input, (str, int, float)):
+        return service_input, parameters
     task_input_info = TASK_INPUTS[task_name]
     if isinstance(task_input_info, str):  # no input key default
-        return base64_decoder_map[task_input_info](list(
-            service_input.values())[0]), parameters
+        if isinstance(service_input, dict):
+            return base64_decoder_map[task_input_info](list(
+                service_input.values())[0]), parameters
+        else:
+            return base64_decoder_map[task_input_info](
+                service_input), parameters
     elif isinstance(task_input_info, tuple):
         pipeline_input = tuple(service_input)
         return pipeline_input, parameters
     elif isinstance(task_input_info, dict):
         for key, value in service_input.items(
         ):  # task input has no nesting field.
             # get input filed type
@@ -649,16 +655,15 @@
                     input_type = item[key]
                     if input_type not in INPUT_TYPE:
                         raise ValueError('Invalid input field: %s'
                                          % input_type)
                     pipeline_input[key] = base64_decoder_map[input_type](value)
                 return pipeline_input, parameters
     else:
-        raise IndexError('Task %s input invalid: %s' %
-                         (task_name, task_input_info))
+        return service_input, parameters
 
 
 def encode_numpy_image_to_base64(image):
     from PIL import Image
     with BytesIO() as output_bytes:
         pil_image = Image.fromarray(image.astype(np.uint8))
         pil_image.save(output_bytes, 'PNG')
@@ -738,15 +743,16 @@
             if isinstance(value, list):
                 items = []
                 if key == OutputKeys.OUTPUT_IMGS:
                     output_item_type = OutputKeys.OUTPUT_IMG
                 else:
                     output_item_type = OutputKeys.OUTPUT_PCM
                 for item in value:
-                    items.append(base64_encoder_map[output_item_type](item))
+                    items.append(base64_encoder_map[
+                        OutputTypes[output_item_type]](item))
                 json_serializable_output[key] = items
             else:
                 json_serializable_output[key] = base64_encoder_map[
                     OutputTypes[key]](
                         value)
         elif OutputTypes[key] in [np.ndarray]:
             json_serializable_output[key] = value.tolist()
```

### Comparing `modelscope-1.7.1/modelscope/utils/logger.py` & `modelscope-1.8.0rc0/modelscope/utils/logger.py`

 * *Files 1% similar despite different names*

```diff
@@ -21,15 +21,15 @@
         log_level: Logging level.
         file_mode: Specifies the mode to open the file, if filename is
             specified (if filemode is unspecified, it defaults to 'w').
     """
 
     logger_name = __name__.split('.')[0]
     logger = logging.getLogger(logger_name)
-
+    logger.propagate = False
     if logger_name in init_loggers:
         add_file_handler_if_needed(logger, log_file, file_mode, log_level)
         return logger
 
     # handle duplicate logs to the console
     # Starting in 1.8.0, PyTorch DDP attaches a StreamHandler <stderr> (NOTSET)
     # to the root logger. As logger.propagate is True by default, this root
```

### Comparing `modelscope-1.7.1/modelscope/utils/megatron_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/megatron_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/metric.py` & `modelscope-1.8.0rc0/modelscope/utils/metric.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/model_tag.py` & `modelscope-1.8.0rc0/modelscope/utils/model_tag.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/distributed.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/distributed.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/load_checkpoint.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/load_checkpoint.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/args.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/args.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/clean_dataset.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/clean_dataset.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/criterions.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/criterions.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/db_ops.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/db_ops.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/ontology.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/ontology.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/utils.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space/utils_dst.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space/utils_dst.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/space_T_en/utils.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/space_T_en/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/nlp/utils.py` & `modelscope-1.8.0rc0/modelscope/utils/nlp/utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/plugins.py` & `modelscope-1.8.0rc0/modelscope/utils/plugins.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Copyright (c) Alibaba, Inc. and its affiliates.
 # This file is adapted from the AllenNLP library at https://github.com/allenai/allennlp
 # Part of the implementation is borrowed from wimglenn/johnnydep
 
 import copy
+import filecmp
 import importlib
 import os
 import pkgutil
 import shutil
 import sys
 import venv
 from contextlib import contextmanager
@@ -24,14 +25,17 @@
 from modelscope.utils.hub import read_config, snapshot_download
 from modelscope.utils.logger import get_logger
 
 logger = get_logger()
 storage = LocalStorage()
 
 MODELSCOPE_FILE_DIR = get_default_cache_dir()
+MODELSCOPE_DYNAMIC_MODULE = 'modelscope_modules'
+BASE_MODULE_DIR = os.path.join(MODELSCOPE_FILE_DIR, MODELSCOPE_DYNAMIC_MODULE)
+
 PLUGINS_FILENAME = '.modelscope_plugins'
 OFFICIAL_PLUGINS = [
     {
         'name': 'adaseq',
         'desc':
         'Provide hundreds of additions NERs algorithms, check: https://github.com/modelscope/AdaSeq',
         'version': '',
@@ -318,14 +322,49 @@
     """
     spec = importlib.util.spec_from_file_location(module_name, file_path)
     module = importlib.util.module_from_spec(spec)
     spec.loader.exec_module(module)
     return module
 
 
+def create_module_from_files(file_list, file_prefix, module_name):
+    """
+    Create a python module from a list of files by copying them to the destination directory.
+
+    Args:
+        file_list (List[str]): List of relative file paths to be copied.
+        file_prefix (str): Path prefix for each file in file_list.
+        module_name (str): Name of the module.
+
+    Returns:
+        None
+    """
+
+    def create_empty_file(file_path):
+        with open(file_path, 'w') as _:
+            pass
+
+    dest_dir = os.path.join(BASE_MODULE_DIR, module_name)
+    for file_path in file_list:
+        file_dir = os.path.dirname(file_path)
+        target_dir = os.path.join(dest_dir, file_dir)
+        os.makedirs(target_dir, exist_ok=True)
+        init_file = os.path.join(target_dir, '__init__.py')
+        if not os.path.exists(init_file):
+            create_empty_file(init_file)
+
+        target_file = os.path.join(target_dir, os.path.basename(file_path))
+        src_file = os.path.join(file_prefix, file_path)
+        if not os.path.exists(target_file) or not filecmp.cmp(
+                src_file, target_file):
+            shutil.copyfile(src_file, target_file)
+
+    importlib.invalidate_caches()
+
+
 def import_module_from_model_dir(model_dir):
     """ import all the necessary module from a model dir
 
     Args:
         model_dir: model file location
 
      No returns, raise error if failed
@@ -336,20 +375,34 @@
     file_scanner.traversal_files(model_dir)
     file_dirs = file_scanner.file_dirs
     requirements = file_scanner.requirement_dirs
 
     # install the requirements firstly
     install_requirements_by_files(requirements)
 
-    # then import the modules
-    import sys
-    sys.path.insert(0, model_dir)
-    for file in file_dirs:
-        module_name = Path(file).stem
-        import_module_from_file(module_name, file)
+    if BASE_MODULE_DIR not in sys.path:
+        sys.path.append(BASE_MODULE_DIR)
+
+    module_name = Path(model_dir).stem
+
+    # in order to keep forward compatibility, we add module path to
+    # sys.path so that submodule can be imported directly as before
+    MODULE_PATH = os.path.join(BASE_MODULE_DIR, module_name)
+    if MODULE_PATH not in sys.path:
+        sys.path.append(MODULE_PATH)
+
+    relative_file_dirs = [
+        file.replace(model_dir.rstrip(os.sep) + os.sep, '')
+        for file in file_dirs
+    ]
+    create_module_from_files(relative_file_dirs, model_dir, module_name)
+    for file in relative_file_dirs:
+        submodule = module_name + '.' + file.replace(os.sep, '.').replace(
+            '.py', '')
+        importlib.import_module(submodule)
 
 
 def install_requirements_by_names(plugins: List[str]):
     """ install the requirements by names
 
     Args:
         plugins: name of plugins (pai-easyscv, transformers)
```

### Comparing `modelscope-1.7.1/modelscope/utils/pre_compile.py` & `modelscope-1.8.0rc0/modelscope/utils/pre_compile.py`

 * *Files 24% similar despite different names*

```diff
@@ -15,13 +15,14 @@
     os.environ['MASTER_PORT'] = '39501'
     init_megatron_util(dummy_megatron_cfg)
 
 
 def pre_compile_all():
     if torch.cuda.is_available():  # extension require cuda.
         pre_compile_megatron_util()
-
-    # extension for all platform.
+        # pre compile pai-easycv
+        from easycv.thirdparty.deformable_attention.functions import ms_deform_attn_func
+        # extension for all platform.
 
 
 if __name__ == '__main__':
     pre_compile_all()
```

### Comparing `modelscope-1.7.1/modelscope/utils/registry.py` & `modelscope-1.8.0rc0/modelscope/utils/registry.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/regress_test_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/regress_test_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/service_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/service_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/task_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/task_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/tensor_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/tensor_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/test_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/test_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/timer.py` & `modelscope-1.8.0rc0/modelscope/utils/timer.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/torch_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/torch_utils.py`

 * *Files 4% similar despite different names*

```diff
@@ -350,7 +350,12 @@
 
     data_list = []
     for size, tensor in zip(size_list, tensor_list):
         buffer = tensor.cpu().numpy().tobytes()[:size]
         data_list.append(pickle.loads(buffer))
 
     return data_list
+
+
+def is_on_same_device(model: torch.nn.Module) -> bool:
+    device_set = set(str(p.device) for p in model.parameters()) - {'cpu'}
+    return len(device_set) <= 1
```

### Comparing `modelscope-1.7.1/modelscope/utils/trie.py` & `modelscope-1.8.0rc0/modelscope/utils/trie.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/type_assert.py` & `modelscope-1.8.0rc0/modelscope/utils/type_assert.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope/utils/url_utils.py` & `modelscope-1.8.0rc0/modelscope/utils/url_utils.py`

 * *Files identical despite different names*

### Comparing `modelscope-1.7.1/modelscope.egg-info/PKG-INFO` & `modelscope-1.8.0rc0/modelscope.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: modelscope
-Version: 1.7.1
+Version: 1.8.0rc0
 Summary: ModelScope: bring the notion of Model-as-a-Service to life.
 Home-page: https://github.com/modelscope/modelscope
 Author: ModelScope team
 Author-email: contact@modelscope.cn
 License: Apache License 2.0
 Description: 
         <p align="center">
@@ -25,15 +25,16 @@
         
         <!-- [![GitHub contributors](https://img.shields.io/github/contributors/modelscope/modelscope.svg)](https://GitHub.com/modelscope/modelscope/graphs/contributors/) -->
         <!-- [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) -->
         
         <h4 align="center">
             <p>
                 <b>English</b> |
-                <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a>
+                <a href="https://github.com/modelscope/modelscope/blob/master/README_zh.md"></a> |
+                <a href="https://github.com/modelscope/modelscope/blob/master/README_ja.md"></a>
             <p>
         </h4>
         
         
         </div>
         
         # Introduction
```

#### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: modelscope Version: 1.7.1 Summary: ModelScope:
+Metadata-Version: 2.1 Name: modelscope Version: 1.8.0rc0 Summary: ModelScope:
 bring the notion of Model-as-a-Service to life. Home-page: https://github.com/
 modelscope/modelscope Author: ModelScope team Author-email:
 contact@modelscope.cn License: Apache License 2.0 Description:
 
        [https://modelscope.oss-cn-beijing.aliyuncs.com/modelscope.gif]
  [![PyPI](https://img.shields.io/pypi/v/modelscope)](https://pypi.org/project/
   modelscope/)  [![license](https://img.shields.io/github/license/modelscope/
@@ -12,15 +12,15 @@
       pull-requests](https://img.shields.io/github/issues-pr/modelscope/
   modelscope.svg)](https://GitHub.com/modelscope/modelscope/pull/) [![GitHub
  latest commit](https://badgen.net/github/last-commit/modelscope/modelscope)]
   (https://GitHub.com/modelscope/modelscope/commit/) [![Leaderboard](https://
  img.shields.io/badge/ModelScope-Check%20Your%20Contribution-orange)](https://
                opensource.alibaba.com/contribution_leaderboard/
                       details?projectValue=modelscope)
-                           *** English |  ***
+                     *** English |  |  ***
 # Introduction [ModelScope]( https://www.modelscope.cn) is built upon the
 notion of Model-as-a-Service (MaaS). It seeks to bring together most
 advanced machine learning models from the AI community, and streamlines the
 process of leveraging AI models in real-world applications. The core ModelScope
 library open-sourced in this repository provides the interfaces and
 implementations that allow developers to perform model inference, training and
 evaluation. In particular, with rich layers of API-abstraction, the ModelScope
```

### Comparing `modelscope-1.7.1/modelscope.egg-info/SOURCES.txt` & `modelscope-1.8.0rc0/modelscope.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -156,17 +156,20 @@
 modelscope/models/audio/sv/ERes2Net.py
 modelscope/models/audio/sv/ERes2Net_aug.py
 modelscope/models/audio/sv/__init__.py
 modelscope/models/audio/sv/cluster_backend.py
 modelscope/models/audio/sv/ecapa_tdnn.py
 modelscope/models/audio/sv/fusion.py
 modelscope/models/audio/sv/generic_speaker_verification.py
+modelscope/models/audio/sv/lanuage_recognition_model.py
 modelscope/models/audio/sv/pooling_layers.py
 modelscope/models/audio/sv/rdino.py
 modelscope/models/audio/sv/speaker_change_locator.py
+modelscope/models/audio/sv/speaker_diarization_dialogue_detection.py
+modelscope/models/audio/sv/speaker_diarization_semantic_speaker_turn_detection.py
 modelscope/models/audio/tts/__init__.py
 modelscope/models/audio/tts/sambert_hifi.py
 modelscope/models/audio/tts/voice.py
 modelscope/models/base/__init__.py
 modelscope/models/base/base_head.py
 modelscope/models/base/base_model.py
 modelscope/models/base/base_torch_head.py
@@ -691,14 +694,19 @@
 modelscope/models/cv/image_to_image_translation/ops/diffusion.py
 modelscope/models/cv/image_to_image_translation/ops/losses.py
 modelscope/models/cv/image_to_image_translation/ops/metrics.py
 modelscope/models/cv/image_to_image_translation/ops/random_color.py
 modelscope/models/cv/image_to_image_translation/ops/random_mask.py
 modelscope/models/cv/image_to_image_translation/ops/svd.py
 modelscope/models/cv/image_to_image_translation/ops/utils.py
+modelscope/models/cv/image_try_on/__init__.py
+modelscope/models/cv/image_try_on/generator.py
+modelscope/models/cv/image_try_on/landmark.py
+modelscope/models/cv/image_try_on/try_on_infer.py
+modelscope/models/cv/image_try_on/warping.py
 modelscope/models/cv/indoor_layout_estimation/__init__.py
 modelscope/models/cv/indoor_layout_estimation/panovit.py
 modelscope/models/cv/indoor_layout_estimation/networks/__init__.py
 modelscope/models/cv/indoor_layout_estimation/networks/panovit.py
 modelscope/models/cv/indoor_layout_estimation/networks/utils.py
 modelscope/models/cv/indoor_layout_estimation/networks/backbone/__init__.py
 modelscope/models/cv/indoor_layout_estimation/networks/backbone/resnet_DA.py
@@ -729,24 +737,51 @@
 modelscope/models/cv/movie_scene_segmentation/get_model.py
 modelscope/models/cv/movie_scene_segmentation/model.py
 modelscope/models/cv/movie_scene_segmentation/utils/__init__.py
 modelscope/models/cv/movie_scene_segmentation/utils/head.py
 modelscope/models/cv/movie_scene_segmentation/utils/save_op.py
 modelscope/models/cv/movie_scene_segmentation/utils/shot_encoder.py
 modelscope/models/cv/movie_scene_segmentation/utils/trn.py
+modelscope/models/cv/nerf_recon_4k/__init__.py
+modelscope/models/cv/nerf_recon_4k/nerf_preprocess.py
+modelscope/models/cv/nerf_recon_4k/nerf_recon_4k.py
+modelscope/models/cv/nerf_recon_4k/dataloader/__init__.py
+modelscope/models/cv/nerf_recon_4k/dataloader/load_blender.py
+modelscope/models/cv/nerf_recon_4k/dataloader/load_data.py
+modelscope/models/cv/nerf_recon_4k/dataloader/load_llff.py
+modelscope/models/cv/nerf_recon_4k/dataloader/load_tankstemple.py
+modelscope/models/cv/nerf_recon_4k/dataloader/read_write_model.py
+modelscope/models/cv/nerf_recon_4k/network/__init__.py
+modelscope/models/cv/nerf_recon_4k/network/dvgo.py
+modelscope/models/cv/nerf_recon_4k/network/utils.py
 modelscope/models/cv/nerf_recon_acc/__init__.py
 modelscope/models/cv/nerf_recon_acc/nerf_preprocess.py
 modelscope/models/cv/nerf_recon_acc/nerf_recon_acc.py
 modelscope/models/cv/nerf_recon_acc/dataloader/__init__.py
 modelscope/models/cv/nerf_recon_acc/dataloader/nerf_dataset.py
 modelscope/models/cv/nerf_recon_acc/dataloader/read_write_model.py
 modelscope/models/cv/nerf_recon_acc/network/__init__.py
 modelscope/models/cv/nerf_recon_acc/network/nerf.py
 modelscope/models/cv/nerf_recon_acc/network/segmenter.py
 modelscope/models/cv/nerf_recon_acc/network/utils.py
+modelscope/models/cv/nerf_recon_vq_compression/__init__.py
+modelscope/models/cv/nerf_recon_vq_compression/nerf_recon_vq_compression.py
+modelscope/models/cv/nerf_recon_vq_compression/renderer.py
+modelscope/models/cv/nerf_recon_vq_compression/utils.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/__init__.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/blender.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/llff.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/nsvf.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/ray_utils.py
+modelscope/models/cv/nerf_recon_vq_compression/dataloader/tankstemple.py
+modelscope/models/cv/nerf_recon_vq_compression/network/__init__.py
+modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF.py
+modelscope/models/cv/nerf_recon_vq_compression/network/tensoRF_VQ.py
+modelscope/models/cv/nerf_recon_vq_compression/network/tensorBase.py
+modelscope/models/cv/nerf_recon_vq_compression/network/weighted_vq.py
 modelscope/models/cv/object_detection/__init__.py
 modelscope/models/cv/object_detection/mmdet_model.py
 modelscope/models/cv/object_detection/mmdet_ms/__init__.py
 modelscope/models/cv/object_detection/mmdet_ms/backbones/__init__.py
 modelscope/models/cv/object_detection/mmdet_ms/backbones/vit.py
 modelscope/models/cv/object_detection/mmdet_ms/dense_heads/__init__.py
 modelscope/models/cv/object_detection/mmdet_ms/dense_heads/anchor_head.py
@@ -856,14 +891,23 @@
 modelscope/models/cv/referring_video_object_segmentation/utils/multimodal_transformer.py
 modelscope/models/cv/referring_video_object_segmentation/utils/position_encoding_2d.py
 modelscope/models/cv/referring_video_object_segmentation/utils/postprocessing.py
 modelscope/models/cv/referring_video_object_segmentation/utils/segmentation.py
 modelscope/models/cv/referring_video_object_segmentation/utils/swin_transformer.py
 modelscope/models/cv/robust_image_classification/__init__.py
 modelscope/models/cv/robust_image_classification/easyrobust_model.py
+modelscope/models/cv/s2net_panorama_depth_estimation/__init__.py
+modelscope/models/cv/s2net_panorama_depth_estimation/s2net_model.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/__init__.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/config.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/decoder.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/model.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/resnet.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/swin_transformer.py
+modelscope/models/cv/s2net_panorama_depth_estimation/networks/util_helper.py
 modelscope/models/cv/salient_detection/__init__.py
 modelscope/models/cv/salient_detection/salient_model.py
 modelscope/models/cv/salient_detection/models/__init__.py
 modelscope/models/cv/salient_detection/models/modules.py
 modelscope/models/cv/salient_detection/models/senet.py
 modelscope/models/cv/salient_detection/models/u2net.py
 modelscope/models/cv/salient_detection/models/utils.py
@@ -929,14 +973,17 @@
 modelscope/models/cv/text_driven_segmentation/lseg_base.py
 modelscope/models/cv/text_driven_segmentation/lseg_blocks.py
 modelscope/models/cv/text_driven_segmentation/lseg_model.py
 modelscope/models/cv/text_driven_segmentation/lseg_net.py
 modelscope/models/cv/text_driven_segmentation/lseg_vit.py
 modelscope/models/cv/text_driven_segmentation/model.py
 modelscope/models/cv/text_driven_segmentation/simple_tokenizer.py
+modelscope/models/cv/text_to_360panorama_image/__init__.py
+modelscope/models/cv/text_to_360panorama_image/pipeline_base.py
+modelscope/models/cv/text_to_360panorama_image/pipeline_sr.py
 modelscope/models/cv/tinynas_classfication/__init__.py
 modelscope/models/cv/tinynas_classfication/basic_blocks.py
 modelscope/models/cv/tinynas_classfication/global_utils.py
 modelscope/models/cv/tinynas_classfication/master_net.py
 modelscope/models/cv/tinynas_classfication/model_zoo.py
 modelscope/models/cv/tinynas_classfication/plain_net_utils.py
 modelscope/models/cv/tinynas_classfication/super_blocks.py
@@ -1439,14 +1486,20 @@
 modelscope/models/nlp/llama/__init__.py
 modelscope/models/nlp/llama/backbone.py
 modelscope/models/nlp/llama/configuration.py
 modelscope/models/nlp/llama/convert_llama_weights_to_hf.py
 modelscope/models/nlp/llama/text_generation.py
 modelscope/models/nlp/llama/tokenization.py
 modelscope/models/nlp/llama/tokenization_fast.py
+modelscope/models/nlp/llama2/__init__.py
+modelscope/models/nlp/llama2/backbone.py
+modelscope/models/nlp/llama2/configuration.py
+modelscope/models/nlp/llama2/text_generation.py
+modelscope/models/nlp/llama2/tokenization.py
+modelscope/models/nlp/llama2/tokenization_fast.py
 modelscope/models/nlp/lstm/__init__.py
 modelscope/models/nlp/lstm/backbone.py
 modelscope/models/nlp/lstm/token_classification.py
 modelscope/models/nlp/megatron_bert/__init__.py
 modelscope/models/nlp/megatron_bert/backbone.py
 modelscope/models/nlp/megatron_bert/configuration.py
 modelscope/models/nlp/megatron_bert/fill_mask.py
@@ -1497,14 +1550,16 @@
 modelscope/models/nlp/plug/distributed_plug.py
 modelscope/models/nlp/plug/generator.py
 modelscope/models/nlp/plug_mental/__init__.py
 modelscope/models/nlp/plug_mental/adv_utils.py
 modelscope/models/nlp/plug_mental/backbone.py
 modelscope/models/nlp/plug_mental/configuration.py
 modelscope/models/nlp/plug_mental/text_classification.py
+modelscope/models/nlp/polylm/__init__.py
+modelscope/models/nlp/polylm/text_generation.py
 modelscope/models/nlp/ponet/__init__.py
 modelscope/models/nlp/ponet/backbone.py
 modelscope/models/nlp/ponet/configuration.py
 modelscope/models/nlp/ponet/document_segmentation.py
 modelscope/models/nlp/ponet/fill_mask.py
 modelscope/models/nlp/ponet/tokenization.py
 modelscope/models/nlp/space/__init__.py
@@ -1715,14 +1770,15 @@
 modelscope/msdatasets/utils/__init__.py
 modelscope/msdatasets/utils/dataset_utils.py
 modelscope/msdatasets/utils/delete_utils.py
 modelscope/msdatasets/utils/maxcompute_utils.py
 modelscope/msdatasets/utils/oss_utils.py
 modelscope/msdatasets/utils/upload_utils.py
 modelscope/ops/__init__.py
+modelscope/ops/4knerf/__init__.py
 modelscope/ops/ailut/__init__.py
 modelscope/ops/ailut/pyinterfaces.py
 modelscope/ops/ailut/Ailut/__init__.py
 modelscope/ops/ailut/Ailut/csrc/__init__.py
 modelscope/ops/quadtree_attention/__init__.py
 modelscope/ops/quadtree_attention/functions/__init__.py
 modelscope/ops/quadtree_attention/functions/quadtree_attention.py
@@ -1742,21 +1798,24 @@
 modelscope/pipelines/audio/ans_dfsmn_pipeline.py
 modelscope/pipelines/audio/ans_pipeline.py
 modelscope/pipelines/audio/asr_inference_pipeline.py
 modelscope/pipelines/audio/asr_wenet_inference_pipeline.py
 modelscope/pipelines/audio/inverse_text_processing_pipeline.py
 modelscope/pipelines/audio/kws_farfield_pipeline.py
 modelscope/pipelines/audio/kws_kwsbp_pipeline.py
+modelscope/pipelines/audio/language_recognition_pipeline.py
 modelscope/pipelines/audio/linear_aec_pipeline.py
 modelscope/pipelines/audio/lm_infer_pipeline.py
 modelscope/pipelines/audio/punctuation_processing_pipeline.py
 modelscope/pipelines/audio/segmentation_clustering_pipeline.py
 modelscope/pipelines/audio/separation_pipeline.py
 modelscope/pipelines/audio/speaker_change_locating_pipeline.py
+modelscope/pipelines/audio/speaker_diarization_dialogue_detection_pipeline.py
 modelscope/pipelines/audio/speaker_diarization_pipeline.py
+modelscope/pipelines/audio/speaker_diarization_semantic_speaker_turn_detection_pipeline.py
 modelscope/pipelines/audio/speaker_verification_eres2net_pipeline.py
 modelscope/pipelines/audio/speaker_verification_light_pipeline.py
 modelscope/pipelines/audio/speaker_verification_pipeline.py
 modelscope/pipelines/audio/speaker_verification_rdino_pipeline.py
 modelscope/pipelines/audio/text_to_speech_pipeline.py
 modelscope/pipelines/audio/timestamp_pipeline.py
 modelscope/pipelines/audio/voice_activity_detection_pipeline.py
@@ -1830,43 +1889,48 @@
 modelscope/pipelines/cv/image_semantic_segmentation_pipeline.py
 modelscope/pipelines/cv/image_skychange_pipeline.py
 modelscope/pipelines/cv/image_structured_model_probing_pipeline.py
 modelscope/pipelines/cv/image_style_transfer_pipeline.py
 modelscope/pipelines/cv/image_super_resolution_pipeline.py
 modelscope/pipelines/cv/image_to_image_generate_pipeline.py
 modelscope/pipelines/cv/image_to_image_translation_pipeline.py
+modelscope/pipelines/cv/image_try_on_pipeline.py
 modelscope/pipelines/cv/indoor_layout_estimation_pipeline.py
 modelscope/pipelines/cv/language_guided_video_summarization_pipeline.py
 modelscope/pipelines/cv/license_plate_detection_pipeline.py
 modelscope/pipelines/cv/lineless_table_recognition_pipeline.py
 modelscope/pipelines/cv/live_category_pipeline.py
 modelscope/pipelines/cv/mask_face_recognition_pipeline.py
 modelscope/pipelines/cv/maskdino_instance_segmentation_pipeline.py
 modelscope/pipelines/cv/mobile_image_super_resolution_pipeline.py
 modelscope/pipelines/cv/mog_face_detection_pipeline.py
 modelscope/pipelines/cv/motion_generation_pipeline.py
 modelscope/pipelines/cv/movie_scene_segmentation_pipeline.py
 modelscope/pipelines/cv/mtcnn_face_detection_pipeline.py
+modelscope/pipelines/cv/nerf_recon_4k_pipeline.py
 modelscope/pipelines/cv/nerf_recon_acc_pipeline.py
+modelscope/pipelines/cv/nerf_recon_vq_compression_pipeline.py
 modelscope/pipelines/cv/object_detection_3d_pipeline.py
 modelscope/pipelines/cv/ocr_detection_pipeline.py
 modelscope/pipelines/cv/ocr_recognition_pipeline.py
 modelscope/pipelines/cv/panorama_depth_estimation_pipeline.py
+modelscope/pipelines/cv/panorama_depth_estimation_s2net_pipeline.py
 modelscope/pipelines/cv/pedestrian_attribute_recognition_pipeline.py
 modelscope/pipelines/cv/pointcloud_sceneflow_estimation_pipeline.py
 modelscope/pipelines/cv/product_retrieval_embedding_pipeline.py
 modelscope/pipelines/cv/product_segmentation_pipeline.py
 modelscope/pipelines/cv/realtime_video_object_detection_pipeline.py
 modelscope/pipelines/cv/referring_video_object_segmentation_pipeline.py
 modelscope/pipelines/cv/retina_face_detection_pipeline.py
 modelscope/pipelines/cv/shop_segmentation_pipleline.py
 modelscope/pipelines/cv/skin_retouching_pipeline.py
 modelscope/pipelines/cv/table_recognition_pipeline.py
 modelscope/pipelines/cv/tbs_detection_pipeline.py
 modelscope/pipelines/cv/text_driven_segmentation_pipleline.py
+modelscope/pipelines/cv/text_to_360panorama_image_pipeline.py
 modelscope/pipelines/cv/tinynas_classification_pipeline.py
 modelscope/pipelines/cv/tinynas_detection_pipeline.py
 modelscope/pipelines/cv/ulfd_face_detection_pipeline.py
 modelscope/pipelines/cv/video_category_pipeline.py
 modelscope/pipelines/cv/video_colorization_pipeline.py
 modelscope/pipelines/cv/video_deinterlace_pipeline.py
 modelscope/pipelines/cv/video_depth_estimation_pipeline.py
@@ -1958,16 +2022,18 @@
 modelscope/pipelines/nlp/feature_extraction_pipeline.py
 modelscope/pipelines/nlp/fid_dialogue_pipeline.py
 modelscope/pipelines/nlp/fill_mask_pipeline.py
 modelscope/pipelines/nlp/glm130b_text_generation_pipeline.py
 modelscope/pipelines/nlp/information_extraction_pipeline.py
 modelscope/pipelines/nlp/interactive_translation_pipeline.py
 modelscope/pipelines/nlp/language_identification_pipline.py
+modelscope/pipelines/nlp/llama2_text_generation_pipeline.py
 modelscope/pipelines/nlp/mglm_text_summarization_pipeline.py
 modelscope/pipelines/nlp/named_entity_recognition_pipeline.py
+modelscope/pipelines/nlp/polylm_text_generation_pipeline.py
 modelscope/pipelines/nlp/sentence_embedding_pipeline.py
 modelscope/pipelines/nlp/siamese_uie_pipeline.py
 modelscope/pipelines/nlp/summarization_pipeline.py
 modelscope/pipelines/nlp/table_question_answering_pipeline.py
 modelscope/pipelines/nlp/text_classification_pipeline.py
 modelscope/pipelines/nlp/text_error_correction_pipeline.py
 modelscope/pipelines/nlp/text_generation_pipeline.py
@@ -1987,14 +2053,15 @@
 modelscope/preprocessors/audio.py
 modelscope/preprocessors/base.py
 modelscope/preprocessors/builder.py
 modelscope/preprocessors/common.py
 modelscope/preprocessors/image.py
 modelscope/preprocessors/kws.py
 modelscope/preprocessors/multi_modal.py
+modelscope/preprocessors/speaker.py
 modelscope/preprocessors/tts.py
 modelscope/preprocessors/video.py
 modelscope/preprocessors/cv/__init__.py
 modelscope/preprocessors/cv/action_detection_mapper.py
 modelscope/preprocessors/cv/bad_image_detecting_preprocessor.py
 modelscope/preprocessors/cv/controllable_image_generation.py
 modelscope/preprocessors/cv/cv2_transforms.py
@@ -2178,14 +2245,16 @@
 modelscope/trainers/lrscheduler/warmup/base.py
 modelscope/trainers/lrscheduler/warmup/warmup.py
 modelscope/trainers/multi_modal/__init__.py
 modelscope/trainers/multi_modal/mgeo_ranking_trainer.py
 modelscope/trainers/multi_modal/clip/__init__.py
 modelscope/trainers/multi_modal/clip/clip_trainer.py
 modelscope/trainers/multi_modal/clip/clip_trainer_utils.py
+modelscope/trainers/multi_modal/custom_diffusion/__init__.py
+modelscope/trainers/multi_modal/custom_diffusion/custom_diffusion_trainer.py
 modelscope/trainers/multi_modal/dreambooth_diffusion/__init__.py
 modelscope/trainers/multi_modal/dreambooth_diffusion/dreambooth_diffusion_trainer.py
 modelscope/trainers/multi_modal/efficient_diffusion_tuning/__init__.py
 modelscope/trainers/multi_modal/efficient_diffusion_tuning/efficient_diffusion_tuning_trainer.py
 modelscope/trainers/multi_modal/lora_diffusion/__init__.py
 modelscope/trainers/multi_modal/lora_diffusion/lora_diffusion_trainer.py
 modelscope/trainers/multi_modal/mplug/__init__.py
@@ -2240,14 +2309,15 @@
 modelscope/utils/config_ds.py
 modelscope/utils/constant.py
 modelscope/utils/data_collators.py
 modelscope/utils/data_utils.py
 modelscope/utils/device.py
 modelscope/utils/error.py
 modelscope/utils/file_utils.py
+modelscope/utils/hf_util.py
 modelscope/utils/hub.py
 modelscope/utils/import_utils.py
 modelscope/utils/input_output.py
 modelscope/utils/input_output_typing.py
 modelscope/utils/json_utils.py
 modelscope/utils/logger.py
 modelscope/utils/megatron_utils.py
```

### Comparing `modelscope-1.7.1/modelscope.egg-info/requires.txt` & `modelscope-1.8.0rc0/modelscope.egg-info/requires.txt`

 * *Files 6% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 addict
 attrs
-datasets
+datasets<=2.13.0,>=2.8.0
 einops
 filelock>=3.3.0
 gast>=0.2.2
 numpy<=1.22.0
 oss2
 pandas<1.4.0
 Pillow>=6.2.0
@@ -25,25 +25,26 @@
 albumentations>=1.0.3
 av>=9.2.0
 bmt_clipit>=1.0
 chumpy
 clip>=1.0
 control_ldm
 ddpm_guided_diffusion
-diffusers<=0.15.0,>=0.13.1
+diffusers==0.18.0
 easydict
 easyrobust
 edit_distance
 face_alignment>=1.3.5
 fairscale>=0.4.1
 fastai>=1.0.51
 ffmpeg>=1.4
 ffmpeg-python>=0.2.0
 ftfy
 fvcore
+healpy
 imageio>=2.9.0
 imageio-ffmpeg>=0.4.2
 imgaug>=0.4.0
 kornia>=0.5.0
 lap
 lmdb
 lpips
@@ -66,36 +67,40 @@
 pandas
 panopticapi
 plyfile>=0.7.4
 psutil
 pyclipper
 PyMCubes
 pytorch-lightning
+realesrgan==0.3.0
 regex
 scikit-image<0.20.0,>=0.19.3
 scikit-learn>=0.20.1
 shapely
 shotdetect_scenedetect_lgss>=0.0.4
 smplx
 tensorflow-estimator>=1.15.1
 tf_slim
 thop
 timm>=0.4.9
-torchmetrics>=0.6.2
+torch-scatter
+torchmetrics<=0.11.4,>=0.6.2
 torchsummary>=1.5.1
 torchvision
+tqdm
 transformers>=4.26.0
 trimesh
 ujson
 utils
 videofeatures_clipit>=1.0
+yacs
 accelerate
 cloudpickle
 decord>=0.6.0
-diffusers==0.15.0
+diffusers==0.18.0
 fairseq
 ftfy>=6.0.3
 librosa==0.9.2
 opencv-python
 pycocoevalcap>=1.2
 pycocotools>=2.0.4
 pydot
@@ -132,15 +137,15 @@
 sentencepiece
 seqeval
 spacy>=2.3.5
 stanza
 subword_nmt>=0.3.8
 termcolor
 tokenizers
-transformers>=4.12.0
+transformers<=4.30.2,>=4.12.0
 zhconv
 biopython
 iopath
 ipdb
 lmdb
 ml_collections
 scipy
@@ -152,24 +157,26 @@
 kaldiio
 kwsbp>=0.0.6
 matplotlib
 py_sound_connect>=0.1
 scipy
 SoundFile>0.10
 tensorboardX
+hdbscan
 hyperpyyaml
 librosa==0.9.2
 MinDAEC
 mir_eval>=0.7
 rotary_embedding_torch>=0.1.5
 scipy
 SoundFile>0.10
 speechbrain>=0.5.12
 torchaudio
 tqdm
+umap-learn
 bitstring
 greenlet>=1.1.2
 inflect
 jedi>=0.18.1
 kantts
 librosa==0.9.2
 lxml
@@ -179,15 +186,15 @@
 pexpect>=4.8.0
 pickleshare>=0.7.5
 prompt-toolkit>=3.0.30
 protobuf
 ptflops
 ptyprocess>=0.7.0
 pygments>=2.12.0
-pysptk<0.2.0,>=0.1.15
+pysptk<0.1.19,>=0.1.15
 pytorch_wavelets
 PyWavelets>=1.0.0
 scikit-learn
 sox
 tensorboardx
 tqdm
 traitlets>=5.3.0
@@ -204,24 +211,26 @@
 matplotlib
 py_sound_connect>=0.1
 scipy
 SoundFile>0.10
 tensorboardX
 
 [audio_signal]
+hdbscan
 hyperpyyaml
 librosa==0.9.2
 MinDAEC
 mir_eval>=0.7
 rotary_embedding_torch>=0.1.5
 scipy
 SoundFile>0.10
 speechbrain>=0.5.12
 torchaudio
 tqdm
+umap-learn
 
 [audio_tts]
 bitstring
 greenlet>=1.1.2
 inflect
 jedi>=0.18.1
 kantts
@@ -233,15 +242,15 @@
 pexpect>=4.8.0
 pickleshare>=0.7.5
 prompt-toolkit>=3.0.30
 protobuf
 ptflops
 ptyprocess>=0.7.0
 pygments>=2.12.0
-pysptk<0.2.0,>=0.1.15
+pysptk<0.1.19,>=0.1.15
 pytorch_wavelets
 PyWavelets>=1.0.0
 scikit-learn
 sox
 tensorboardx
 tqdm
 traitlets>=5.3.0
@@ -254,25 +263,26 @@
 albumentations>=1.0.3
 av>=9.2.0
 bmt_clipit>=1.0
 chumpy
 clip>=1.0
 control_ldm
 ddpm_guided_diffusion
-diffusers<=0.15.0,>=0.13.1
+diffusers==0.18.0
 easydict
 easyrobust
 edit_distance
 face_alignment>=1.3.5
 fairscale>=0.4.1
 fastai>=1.0.51
 ffmpeg>=1.4
 ffmpeg-python>=0.2.0
 ftfy
 fvcore
+healpy
 imageio>=2.9.0
 imageio-ffmpeg>=0.4.2
 imgaug>=0.4.0
 kornia>=0.5.0
 lap
 lmdb
 lpips
@@ -295,38 +305,42 @@
 pandas
 panopticapi
 plyfile>=0.7.4
 psutil
 pyclipper
 PyMCubes
 pytorch-lightning
+realesrgan==0.3.0
 regex
 scikit-image<0.20.0,>=0.19.3
 scikit-learn>=0.20.1
 shapely
 shotdetect_scenedetect_lgss>=0.0.4
 smplx
 tensorflow-estimator>=1.15.1
 tf_slim
 thop
 timm>=0.4.9
-torchmetrics>=0.6.2
+torch-scatter
+torchmetrics<=0.11.4,>=0.6.2
 torchsummary>=1.5.1
 torchvision
+tqdm
 transformers>=4.26.0
 trimesh
 ujson
 utils
 videofeatures_clipit>=1.0
+yacs
 
 [multi-modal]
 accelerate
 cloudpickle
 decord>=0.6.0
-diffusers==0.15.0
+diffusers==0.18.0
 fairseq
 ftfy>=6.0.3
 librosa==0.9.2
 opencv-python
 pycocoevalcap>=1.2
 pycocotools>=2.0.4
 pydot
@@ -365,15 +379,15 @@
 sentencepiece
 seqeval
 spacy>=2.3.5
 stanza
 subword_nmt>=0.3.8
 termcolor
 tokenizers
-transformers>=4.12.0
+transformers<=4.30.2,>=4.12.0
 zhconv
 
 [science]
 biopython
 iopath
 ipdb
 lmdb
```

