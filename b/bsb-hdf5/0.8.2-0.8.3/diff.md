# Comparing `tmp/bsb_hdf5-0.8.2-py3-none-any.whl.zip` & `tmp/bsb_hdf5-0.8.3-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,20 @@
-Zip file size: 36681 bytes, number of entries: 18
--rwxrwxrwx  2.0 unx     5923 b- defN 23-Jul-31 08:27 bsb_hdf5/__init__.py
--rwxrwxrwx  2.0 unx    12094 b- defN 23-Feb-27 09:41 bsb_hdf5/chunks.py
--rwxrwxrwx  2.0 unx    21597 b- defN 23-Jul-18 10:37 bsb_hdf5/connectivity_set.py
+Zip file size: 36653 bytes, number of entries: 18
+-rwxrwxrwx  2.0 unx     5923 b- defN 23-Jul-31 10:57 bsb_hdf5/__init__.py
+-rwxrwxrwx  2.0 unx    12127 b- defN 23-Jul-31 10:49 bsb_hdf5/chunks.py
+-rwxrwxrwx  2.0 unx    21305 b- defN 23-Jul-31 10:54 bsb_hdf5/connectivity_set.py
 -rwxrwxrwx  2.0 unx     4952 b- defN 23-Jun-09 08:38 bsb_hdf5/file_store.py
 -rwxrwxrwx  2.0 unx     7673 b- defN 23-Jul-31 08:27 bsb_hdf5/morphology_repository.py
 -rwxrwxrwx  2.0 unx    17464 b- defN 23-Jul-31 08:29 bsb_hdf5/placement_set.py
--rwxrwxrwx  2.0 unx     4994 b- defN 23-Jul-18 10:37 bsb_hdf5/resource.py
+-rwxrwxrwx  2.0 unx     4979 b- defN 23-Jul-31 10:48 bsb_hdf5/resource.py
 -rwxrwxrwx  2.0 unx        0 b- defN 22-Jul-03 16:33 test/__init__.py
 -rwxrwxrwx  2.0 unx     1281 b- defN 22-Nov-08 13:27 test/test_cs.py
 -rwxrwxrwx  2.0 unx      652 b- defN 23-Jul-31 08:27 test/test_interface.py
 -rwxrwxrwx  2.0 unx     6319 b- defN 23-Jul-18 10:37 test/test_mr.py
 -rwxrwxrwx  2.0 unx      567 b- defN 22-Nov-08 13:21 test/test_setup/__init__.py
--rwxrwxrwx  2.0 unx    35149 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/LICENSE
--rwxrwxrwx  2.0 unx     1110 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/METADATA
--rwxrwxrwx  2.0 unx       92 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/WHEEL
--rwxrwxrwx  2.0 unx       39 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/entry_points.txt
--rwxrwxrwx  2.0 unx       14 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     1431 b- defN 23-Jul-31 08:32 bsb_hdf5-0.8.2.dist-info/RECORD
-18 files, 121351 bytes uncompressed, 34359 bytes compressed:  71.7%
+-rwxrwxrwx  2.0 unx    35149 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/LICENSE
+-rwxrwxrwx  2.0 unx     1110 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/METADATA
+-rwxrwxrwx  2.0 unx       92 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/WHEEL
+-rwxrwxrwx  2.0 unx       39 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/entry_points.txt
+-rwxrwxrwx  2.0 unx       14 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     1431 b- defN 23-Jul-31 11:08 bsb_hdf5-0.8.3.dist-info/RECORD
+18 files, 121077 bytes uncompressed, 34331 bytes compressed:  71.6%
```

## zipnote {}

```diff
@@ -30,26 +30,26 @@
 
 Filename: test/test_mr.py
 Comment: 
 
 Filename: test/test_setup/__init__.py
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/LICENSE
+Filename: bsb_hdf5-0.8.3.dist-info/LICENSE
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/METADATA
+Filename: bsb_hdf5-0.8.3.dist-info/METADATA
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/WHEEL
+Filename: bsb_hdf5-0.8.3.dist-info/WHEEL
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/entry_points.txt
+Filename: bsb_hdf5-0.8.3.dist-info/entry_points.txt
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/top_level.txt
+Filename: bsb_hdf5-0.8.3.dist-info/top_level.txt
 Comment: 
 
-Filename: bsb_hdf5-0.8.2.dist-info/RECORD
+Filename: bsb_hdf5-0.8.3.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bsb_hdf5/__init__.py

```diff
@@ -8,15 +8,15 @@
 from datetime import datetime
 import json
 import h5py
 import os
 import shutil
 import shortuuid
 
-__version__ = "0.8.2"
+__version__ = "0.8.3"
 __all__ = [
     "PlacementSet",
     "ConnectivitySet",
     "FileStore",
     "MorphologyRepository",
     "HDF5Engine",
     "StorageNode",
```

## bsb_hdf5/chunks.py

```diff
@@ -163,15 +163,15 @@
         if shape is not None:
             maxshape = list(shape)
             maxshape[0] = None
             self.maxshape = tuple(maxshape)
         else:
             self.maxshape = None
 
-    @handles_handles("r", lambda self: self.loader._engine)
+    @handles_handles("r", lambda args: args[0].loader._engine)
     def load(self, raw=False, key=None, pad_by=None, handle=HANDLED):
         chunks = self.loader.get_loaded_chunks()
         reader = self.get_chunk_reader(handle, raw, key, pad_by=pad_by)
         # Read and collect all non empty chunks
         chunked_data = tuple(data for c in chunks if (data := reader(c)).size)
         # No data? Return empty
         if not chunked_data:
@@ -209,15 +209,15 @@
             if not (raw or self.extract is None):
                 data = self.extract(data, chunk_group)
             return data
 
         # Return the created function
         return read_chunk
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def append(self, chunk, data, key=None, handle=HANDLED):
         """
         Append data to a property chunk. Will create it if it doesn't exist.
 
         :param data: Data to append to the chunked property.
         :param chunk: Chunk
         :type chunk: :class:`bsb.storage.Chunk`
@@ -245,15 +245,15 @@
             )
         else:
             dset = chunk_group[key]
             start_pos = dset.shape[0]
             dset.resize(start_pos + len(data), axis=0)
             dset[start_pos:] = data
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def clear(self, chunk, key=None, handle=HANDLED):
         key = key or self.name
         chunk_group = handle[self._chunk_path(chunk)]
         if key not in chunk_group:
             chunk_group.create_dataset(
                 key,
                 self.shape,
@@ -261,15 +261,15 @@
                 maxshape=self.maxshape,
                 dtype=self.dtype,
             )
         else:
             dset = chunk_group[key]
             dset.resize(0, axis=0)
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def overwrite(self, chunk, data, key=None, handle=HANDLED):
         self.clear(chunk, key, handle)
         self.append(chunk, data, key, handle)
 
     def _chunk_path(self, chunk, key=None):
         return self.loader.get_chunk_path(chunk, self.collection, key)
 
@@ -281,46 +281,46 @@
     created per chunk, inside of which a group exists per collection. Arbitrarily named
     datasets can be stored inside of this collection.
     """
 
     def __init__(self, loader, collection, shape, dtype, insert=None, extract=None):
         super().__init__(loader, None, shape, dtype, insert, extract, collection)
 
-    @handles_handles("r", lambda self: self.loader._engine)
+    @handles_handles("r", lambda args: args[0].loader._engine)
     def keys(self, handle=HANDLED):
         try:
             return list(handle[self.loader._path].attrs[f"{self.collection}_keys"])
         except KeyError:
             return []
 
-    @handles_handles("r", lambda self: self.loader._engine)
+    @handles_handles("r", lambda args: args[0].loader._engine)
     def load(self, key, handle=HANDLED, **kwargs):
         return super().load(key=key, handle=handle, **kwargs)
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def append(self, chunk, key, data, handle=HANDLED, **kwargs):
         self._add_key(key, handle=handle)
         return super().append(chunk, data, key=key, handle=handle, **kwargs)
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def overwrite(self, chunk, data, key, handle=HANDLED, **kwargs):
         self._add_key(key, handle=handle)
         return super().overwrite(chunk, data, key=key, handle=handle, **kwargs)
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def clear(self, chunk, handle=HANDLED):
         del handle[self._chunk_path(chunk)]
         handle.create_group(self._chunk_path(chunk))
 
-    @handles_handles("a", lambda self: self.loader._engine)
+    @handles_handles("a", lambda args: args[0].loader._engine)
     def _add_key(self, key, handle=HANDLED):
         keys = set(self.keys(handle=handle))
         keys.add(key)
         handle[self.loader._path].attrs[f"{self.collection}_keys"] = list(keys)
 
-    @handles_handles("r", lambda self: self.loader._engine)
+    @handles_handles("r", lambda args: args[0].loader._engine)
     def load_all(self, handle=HANDLED, **kwargs):
         print("?", self)
         return {
             key: super(type(self), self).load(key=key, handle=handle, **kwargs)
             for key in self.keys()
         }
```

## bsb_hdf5/connectivity_set.py

```diff
@@ -19,90 +19,80 @@
 
     .. note::
 
         Use :meth:`Scaffold.get_connectivity_set <bsb.core.Scaffold.get_connectivity_set>`
         to correctly obtain a :class:`~bsb.storage.interfaces.ConnectivitySet`.
     """
 
-    def __init__(self, engine, tag):
+    @handles_handles("r", handler=lambda args: args[1])
+    def __init__(self, engine, tag, handle=HANDLED):
         self.tag = tag
         self.pre_type = None
         self.post_type = None
         super().__init__(engine, _root + tag)
-        with engine._read():
-            with engine._handle("r") as h:
-                if not self.exists(engine, tag, handle=h):
-                    raise DatasetNotFoundError(
-                        f"ConnectivitySet '{tag}' does not exist. Choose from: "
-                        + errr.quotejoin(self.get_tags(self._engine))
-                    )
-                self._pre_name = h[self._path].attrs["pre"]
-                self._post_name = h[self._path].attrs["post"]
+        if not self.exists(engine, tag, handle=handle):
+            raise DatasetNotFoundError(
+                f"ConnectivitySet '{tag}' does not exist. Choose from: "
+                + errr.quotejoin(self.get_tags(self._engine))
+            )
+        self.pre_type_name = handle[self._path].attrs["pre"]
+        self.post_type_name = handle[self._path].attrs["post"]
 
     def __len__(self):
         return sum(len(data[0]) for _, _, _, data in self.flat_iter_connections("inc"))
 
     @classmethod
-    def get_tags(cls, engine):
+    @handles_handles("r", handler=lambda args: args[1])
+    def get_tags(cls, engine, handle=HANDLED):
         """
         Returns all the connectivity tags in the network.
         """
-        with engine._read():
-            with engine._handle("r") as h:
-                return list(h[_root].keys())
+        return list(handle[_root].keys())
 
     @classmethod
-    def create(cls, engine, pre_type, post_type, tag=None):
+    @handles_handles("a", handler=lambda args: args[1])
+    def create(cls, engine, pre_type, post_type, tag=None, handle=HANDLED):
         """
         Create the structure for this connectivity set in the HDF5 file. Connectivity sets
         are stored under ``/connectivity/<tag>``.
         """
         if tag is None:
             tag = f"{pre_type.name}_to_{post_type.name}"
         path = _root + tag
-        with engine._write():
-            with engine._handle("a") as h:
-                g = h.create_group(path)
-                g.attrs["pre"] = pre_type.name
-                g.attrs["post"] = post_type.name
-                g.require_group(f"{path}/inc")
-                g.require_group(f"{path}/out")
-        cs = cls(engine, tag)
+        g = handle.create_group(path)
+        g.attrs["pre"] = pre_type.name
+        g.attrs["post"] = post_type.name
+        g.require_group(f"{path}/inc")
+        g.require_group(f"{path}/out")
+        cs = cls(engine, tag, handle=handle)
         cs.pre_type = pre_type
         cs.post_type = post_type
         return cs
 
     @staticmethod
-    def exists(engine, tag, handle=None):
+    @handles_handles("r", handler=lambda args: args[0])
+    def exists(engine, tag, handle=HANDLED):
         """
         Checks whether a :class:`~.connectivity_set.ConnectivitySet` with the given tag
         exists.
 
         :param engine: Engine to use for the lookup.
         :type engine: :class:`.HDF5Engine`
         :param tag: Tag of the set to look for.
         :type tag: str
         :param handle: An open handle to use instead of opening one.
         :type handle: :class:`h5py.File`
         :returns: Whether the tag exists.
         :rtype: bool
         """
-
-        def check(h):
-            return _root + tag in h
-
-        if handle is not None:
-            return check(handle)
-        else:
-            with engine._read():
-                with engine._handle("r") as h:
-                    return check(h)
+        return _root + tag in handle
 
     @classmethod
-    def require(cls, engine, pre_type, post_type, tag=None):
+    @handles_handles("a", handler=lambda args: args[1])
+    def require(cls, engine, pre_type, post_type, tag=None, handle=HANDLED):
         """
         Get or create a :class:`~.connectivity_set.ConnectivitySet`.
 
         :param engine: Engine to fetch/write the data.
         :type engine: :class:`.HDF5Engine`
         :param pre_type: Presynaptic cell type.
         :type pre_type: :class:`~bsb.cell_types.CellType`
@@ -113,32 +103,30 @@
         :type tag: str
         :returns: Existing or new connectivity set.
         :rtype: :class:`~.connectivity_set.ConnectivitySet`
         """
         if tag is None:
             tag = f"{pre_type.name}_to_{post_type.name}"
         path = _root + tag
-        with engine._write():
-            with engine._handle("a") as h:
-                g = h.require_group(path)
-                if g.attrs.setdefault("pre", pre_type.name) != pre_type.name:
-                    raise ValueError(
-                        "Given and stored type mismatch:"
-                        + f" {pre_type.name} vs {g.attrs['pre']}"
-                    )
-                if g.attrs.setdefault("post", post_type.name) != post_type.name:
-                    raise ValueError(
-                        "Given and stored type mismatch:"
-                        + f" {post_type.name} vs {g.attrs['post']}"
-                    )
-                g.require_group(path + "/inc")
-                g.require_group(path + "/out")
-        cs = cls(engine, tag)
-        cs.pre_type = pre_type
-        cs.post_type = post_type
+        g = handle.require_group(path)
+        if g.attrs.setdefault("pre", pre_type.name) != pre_type.name:
+            raise ValueError(
+                "Given and stored type mismatch:"
+                + f" {pre_type.name} vs {g.attrs['pre']}"
+            )
+        if g.attrs.setdefault("post", post_type.name) != post_type.name:
+            raise ValueError(
+                "Given and stored type mismatch:"
+                + f" {post_type.name} vs {g.attrs['post']}"
+            )
+        g.require_group(path + "/inc")
+        g.require_group(path + "/out")
+        cs = cls(engine, tag, handle=handle)
+        cs.pre_type_name = pre_type.name
+        cs.post_type_name = post_type.name
         return cs
 
     def clear(self):
         raise NotImplementedError("Will do once I have some sample data :)")
 
     @handles_handles("a")
     def connect(self, pre_set, post_set, src_locs, dest_locs, handle=HANDLED):
```

## bsb_hdf5/resource.py

```diff
@@ -9,35 +9,35 @@
     from . import HDF5Engine
 
 # Semantic marker for things that get injected
 HANDLED = None
 
 
 # Decorator to inject handles
-def handles_handles(handle_type, handler=lambda self: self._engine):
+def handles_handles(handle_type, handler=lambda args: args[0]._engine):
     lock_f = {"r": lambda eng: eng._read, "a": lambda eng: eng._write}.get(handle_type)
 
     def decorator(f):
         sig = inspect.signature(f)
         if "handle" not in sig.parameters:
             raise ValueError(
                 f"`{f.__module__}.{f.__name__}` needs handle to be handled by "
                 f"handles_handles. Clearly."
             )
 
         @functools.wraps(f)
-        def handle_indirection(self, *args, handle=None, **kwargs):
-            engine = handler(self)
+        def handle_indirection(*args, handle=None, **kwargs):
+            engine = handler(args)
             lock = lock_f(engine)
             try:
-                bound = sig.bind(self, *args, **kwargs)
+                bound = sig.bind(*args, **kwargs)
             except TypeError:
                 # Re-call the actual function, for better TypeError
                 try:
-                    f(self, *args, **kwargs)
+                    f(*args, **kwargs)
                 except TypeError as e:
                     # Re-raise the exception from None for better stack trace
                     raise e from None
             if bound.arguments.get("handle", None) is None:
                 with lock():
                     with engine._handle(handle_type) as handle:
                         bound.arguments["handle"] = handle
```

## Comparing `bsb_hdf5-0.8.2.dist-info/LICENSE` & `bsb_hdf5-0.8.3.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `bsb_hdf5-0.8.2.dist-info/METADATA` & `bsb_hdf5-0.8.3.dist-info/METADATA`

 * *Files 18% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: bsb-hdf5
-Version: 0.8.2
+Version: 0.8.3
 Summary: The HDF5 storage engine of the BSB
 Home-page: https://github.com/dbbs-lab/bsb-hdf5
 Author: Robin De Schepper, Egidio D'Angelo, Claudia Casellato
 Author-email: robingilbert.deschepper@unipv.it
 License: GPLv3
 Project-URL: Bug Tracker, https://github.com/dbbs-lab/bsb-hdf5/issues/
 Project-URL: Documentation, https://bsb-hdf5.readthedocs.io/
@@ -14,15 +14,15 @@
 Classifier: Programming Language :: Python :: 3 :: Only
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Operating System :: OS Independent
 Requires-Python: ~=3.8
 Description-Content-Type: text/markdown
 License-File: LICENSE
-Requires-Dist: bsb (~=4.0.0a54)
+Requires-Dist: bsb (~=4.0.0a56)
 Requires-Dist: shortuuid
 Provides-Extra: dev
 Requires-Dist: sphinx ; extra == 'dev'
 Requires-Dist: sphinxemoji ; extra == 'dev'
 Requires-Dist: furo ; extra == 'dev'
 Requires-Dist: sphinx-design ; extra == 'dev'
```

## Comparing `bsb_hdf5-0.8.2.dist-info/RECORD` & `bsb_hdf5-0.8.3.dist-info/RECORD`

 * *Files 19% similar despite different names*

```diff
@@ -1,18 +1,18 @@
-bsb_hdf5/__init__.py,sha256=DUMwpFtpZiv7TxNTABKHSoaSRgbW1AB99UcrVzPAfBQ,5923
-bsb_hdf5/chunks.py,sha256=uJ9OkKU6C7p1nc0sNsRmhbdNqyrN9kMU91og7GW5xg4,12094
-bsb_hdf5/connectivity_set.py,sha256=-CfwzlBsHQqpbL7uc2BJMk5O75RpXfb6u7qDxiu0Nu4,21597
+bsb_hdf5/__init__.py,sha256=HYlqNVyiU0v7HTZhsAskM-9-uX9u_7yuaNSUXjj7Evw,5923
+bsb_hdf5/chunks.py,sha256=CEkN-T47i9dSHxwKbBR0WkzinNDHs6Ek2J9FOnGsX0w,12127
+bsb_hdf5/connectivity_set.py,sha256=JeR3_CqfecoSgFBxLdJ9dZiQpV5TRLYvXvRL2rDyEuU,21305
 bsb_hdf5/file_store.py,sha256=wWsjXMim6ebS3YucsiQIQwPRIoHV7V5NuE2aG5EwaE8,4952
 bsb_hdf5/morphology_repository.py,sha256=yf7RiCvOGuXZCtiXHFA6BZXZ7soqknSZrTCBDBDSsQg,7673
 bsb_hdf5/placement_set.py,sha256=XHhkoDI_iSbOg3jpFqy6WPHcnJ2QzZsLJ8_iJqCPPwg,17464
-bsb_hdf5/resource.py,sha256=JkCSKQjde0M0HWVbi_jt0jcu3dEXChyUSlydo0IXeSw,4994
+bsb_hdf5/resource.py,sha256=Ps7oAyVWgBQZFTWZzf-kWgEsSy_NyHYoXAddb1a5U1A,4979
 test/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 test/test_cs.py,sha256=Yvn_TQXeo3wgx8_TCbMqYmDU2aaB7EJuEgYZAuSb07c,1281
 test/test_interface.py,sha256=kugwWaoBpoR-j4w4V852sB3W4liXlXZgRUEbzUYLZAA,652
 test/test_mr.py,sha256=t4R1AmnmI1BWTUnqZztL5-PuBm3DSbCnsaYakHgZnQI,6319
 test/test_setup/__init__.py,sha256=tUNXjGeU1UR3P8F0Sqi1ZZ6eqQqTihgPQgFLBtMARDk,567
-bsb_hdf5-0.8.2.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-bsb_hdf5-0.8.2.dist-info/METADATA,sha256=f6SjaATAsjp89_aNiLNG6dmAUxco0-g4tHEUp0rlqwU,1110
-bsb_hdf5-0.8.2.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-bsb_hdf5-0.8.2.dist-info/entry_points.txt,sha256=pFmqnRpHXdr1v0OOA28puW34cZgPGGWddSg3rg7lDXs,39
-bsb_hdf5-0.8.2.dist-info/top_level.txt,sha256=NHvOdI6Unokyufz7Fzz7XUmcVIiIFPDwPnN1lLuqtDo,14
-bsb_hdf5-0.8.2.dist-info/RECORD,,
+bsb_hdf5-0.8.3.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+bsb_hdf5-0.8.3.dist-info/METADATA,sha256=vFm6Q0YW82a9pqDbE1Bi7r2H4ZVBlaILVGQNN53EsoE,1110
+bsb_hdf5-0.8.3.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+bsb_hdf5-0.8.3.dist-info/entry_points.txt,sha256=pFmqnRpHXdr1v0OOA28puW34cZgPGGWddSg3rg7lDXs,39
+bsb_hdf5-0.8.3.dist-info/top_level.txt,sha256=NHvOdI6Unokyufz7Fzz7XUmcVIiIFPDwPnN1lLuqtDo,14
+bsb_hdf5-0.8.3.dist-info/RECORD,,
```

