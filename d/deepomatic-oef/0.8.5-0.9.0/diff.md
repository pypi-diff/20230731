# Comparing `tmp/deepomatic_oef-0.8.5-py3-none-any.whl.zip` & `tmp/deepomatic_oef-0.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,86 +1,86 @@
-Zip file size: 150550 bytes, number of entries: 84
--rw-r--r--  2.0 unx      559 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5-nspkg.pth
--rw-r--r--  2.0 unx       18 b- defN 21-Mar-29 12:34 deepomatic/oef/__init__.py
--rw-r--r--  2.0 unx     5868 b- defN 21-Mar-29 12:34 deepomatic/oef/dataset_dump.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/api/__init__.py
--rw-r--r--  2.0 unx     2152 b- defN 20-Dec-22 18:06 deepomatic/oef/api/backbone.py
--rw-r--r--  2.0 unx     1483 b- defN 20-Dec-22 18:06 deepomatic/oef/api/experiment.py
--rw-r--r--  2.0 unx     4624 b- defN 21-Jan-19 09:46 deepomatic/oef/api/model.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/__init__.py
--rw-r--r--  2.0 unx     6431 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/config_utils.py
--rw-r--r--  2.0 unx     1115 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/model_args.py
--rw-r--r--  2.0 unx   690816 b- defN 21-Mar-29 13:07 deepomatic/oef/configs/model_list.py
--rw-r--r--  2.0 unx     6578 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/model_list_generator.py
--rw-r--r--  2.0 unx     3532 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/utils.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/__init__.py
--rw-r--r--  2.0 unx     7936 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/backbones.py
--rw-r--r--  2.0 unx      455 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/utils.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/classification/__init__.py
--rw-r--r--  2.0 unx     8586 b- defN 21-Jan-19 09:46 deepomatic/oef/configs/image/classification/configs.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/detection/__init__.py
--rw-r--r--  2.0 unx     5950 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/detection/efficientdet.py
--rw-r--r--  2.0 unx     7352 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/detection/rcnn.py
--rw-r--r--  2.0 unx    10261 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/detection/ssd.py
--rw-r--r--  2.0 unx     1489 b- defN 21-Mar-29 12:34 deepomatic/oef/configs/image/detection/yolo.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/configs/image/ocr/__init__.py
--rw-r--r--  2.0 unx      742 b- defN 21-Mar-29 12:34 deepomatic/oef/configs/image/ocr/attention.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/__init__.py
--rw-r--r--  2.0 unx     1050 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/api.py
--rw-r--r--  2.0 unx     5426 b- defN 21-Mar-29 12:34 deepomatic/oef/platform/config.py
--rw-r--r--  2.0 unx     6137 b- defN 21-Mar-29 12:34 deepomatic/oef/platform/experiment_to_display_name.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/__init__.py
--rw-r--r--  2.0 unx    30040 b- defN 21-Mar-29 12:34 deepomatic/oef/platform/helpers/backends.json
--rw-r--r--  2.0 unx     2742 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/common.py
--rw-r--r--  2.0 unx    22480 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/controls.py
--rw-r--r--  2.0 unx     6788 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/form.py
--rw-r--r--  2.0 unx     4034 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/section.py
--rw-r--r--  2.0 unx     1023 b- defN 20-Dec-22 18:06 deepomatic/oef/platform/helpers/tags.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/protos/__init__.py
--rw-r--r--  2.0 unx     4904 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/dataoperation_pb2.py
--rw-r--r--  2.0 unx    41041 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/dataset_dump_pb2.py
--rw-r--r--  2.0 unx     3211 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/dataset_pb2.py
--rw-r--r--  2.0 unx     3968 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/experiment_pb2.py
--rw-r--r--  2.0 unx    37858 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/losses_pb2.py
--rw-r--r--  2.0 unx    25067 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/optimizer_pb2.py
--rw-r--r--  2.0 unx   105075 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/preprocessor_pb2.py
--rw-r--r--  2.0 unx    14928 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/trainer_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/protos/models/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/protos/models/image/__init__.py
--rw-r--r--  2.0 unx    32791 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/backbones_pb2.py
--rw-r--r--  2.0 unx     4400 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/classification_pb2.py
--rw-r--r--  2.0 unx    75029 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection_pb2.py
--rw-r--r--  2.0 unx     6377 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/ocr_pb2.py
--rw-r--r--  2.0 unx   121125 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/preprocessing_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/protos/models/image/detection/__init__.py
--rw-r--r--  2.0 unx     7702 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/anchor_generator_pb2.py
--rw-r--r--  2.0 unx     4581 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/argmax_matcher_pb2.py
--rw-r--r--  2.0 unx     2327 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/bipartite_matcher_pb2.py
--rw-r--r--  2.0 unx     7093 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/box_coder_pb2.py
--rw-r--r--  2.0 unx    37528 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/box_predictor_pb2.py
--rw-r--r--  2.0 unx    26035 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/calibration_pb2.py
--rw-r--r--  2.0 unx     6580 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/example_miner_pb2.py
--rw-r--r--  2.0 unx     3639 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/faster_rcnn_box_coder_pb2.py
--rw-r--r--  2.0 unx     6428 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/flexible_grid_anchor_generator_pb2.py
--rw-r--r--  2.0 unx     5332 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/grid_anchor_generator_pb2.py
--rw-r--r--  2.0 unx     4018 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/keypoint_box_coder_pb2.py
--rw-r--r--  2.0 unx     4416 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/matcher_pb2.py
--rw-r--r--  2.0 unx     2336 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/mean_stddev_box_coder_pb2.py
--rw-r--r--  2.0 unx     4660 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/multiscale_anchor_generator_pb2.py
--rw-r--r--  2.0 unx     8733 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/post_processing_pb2.py
--rw-r--r--  2.0 unx    10063 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/region_similarity_calculator_pb2.py
--rw-r--r--  2.0 unx     3124 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/square_box_coder_pb2.py
--rw-r--r--  2.0 unx     7598 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/detection/ssd_anchor_generator_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/protos/models/image/utils/__init__.py
--rw-r--r--  2.0 unx    28139 b- defN 21-Mar-29 13:07 deepomatic/oef/protos/models/image/utils/hyperparameters_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 20-Dec-22 18:06 deepomatic/oef/utils/__init__.py
--rw-r--r--  2.0 unx     4270 b- defN 21-Mar-29 12:34 deepomatic/oef/utils/class_helpers.py
--rw-r--r--  2.0 unx     1059 b- defN 20-Dec-22 18:06 deepomatic/oef/utils/common.py
--rw-r--r--  2.0 unx     6368 b- defN 21-Mar-29 12:34 deepomatic/oef/utils/experiment_builder.py
--rw-r--r--  2.0 unx    17951 b- defN 21-Mar-29 12:34 deepomatic/oef/utils/serializer.py
--rw-r--r--  2.0 unx     1105 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/LICENSE
--rw-r--r--  2.0 unx     2984 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/namespace_packages.txt
--rw-r--r--  2.0 unx       11 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     8658 b- defN 21-Mar-29 13:07 deepomatic_oef-0.8.5.dist-info/RECORD
-84 files, 1544282 bytes uncompressed, 136230 bytes compressed:  91.2%
+Zip file size: 150125 bytes, number of entries: 84
+-rw-r--r--  2.0 unx      559 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0-nspkg.pth
+-rw-r--r--  2.0 unx       18 b- defN 21-Apr-28 12:31 deepomatic/oef/__init__.py
+-rw-r--r--  2.0 unx     1309 b- defN 21-Mar-22 15:28 deepomatic/oef/hyperparameter_dump.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/api/__init__.py
+-rw-r--r--  2.0 unx     2152 b- defN 21-Jan-13 15:59 deepomatic/oef/api/backbone.py
+-rw-r--r--  2.0 unx     1631 b- defN 21-Apr-28 12:16 deepomatic/oef/api/experiment.py
+-rw-r--r--  2.0 unx     4624 b- defN 21-Jan-21 15:50 deepomatic/oef/api/model.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/__init__.py
+-rw-r--r--  2.0 unx     6431 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/config_utils.py
+-rw-r--r--  2.0 unx     1115 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/model_args.py
+-rw-r--r--  2.0 unx   693811 b- defN 21-Apr-28 12:41 deepomatic/oef/configs/model_list.py
+-rw-r--r--  2.0 unx     6578 b- defN 21-Apr-23 12:34 deepomatic/oef/configs/model_list_generator.py
+-rw-r--r--  2.0 unx     3532 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/__init__.py
+-rw-r--r--  2.0 unx     7936 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/backbones.py
+-rw-r--r--  2.0 unx      455 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/utils.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/classification/__init__.py
+-rw-r--r--  2.0 unx     8586 b- defN 21-Feb-24 10:47 deepomatic/oef/configs/image/classification/configs.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/detection/__init__.py
+-rw-r--r--  2.0 unx     5950 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/detection/efficientdet.py
+-rw-r--r--  2.0 unx     7352 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/detection/rcnn.py
+-rw-r--r--  2.0 unx    10261 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/detection/ssd.py
+-rw-r--r--  2.0 unx     2171 b- defN 21-Mar-22 15:28 deepomatic/oef/configs/image/detection/yolo.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/configs/image/ocr/__init__.py
+-rw-r--r--  2.0 unx     1110 b- defN 21-Apr-28 12:16 deepomatic/oef/configs/image/ocr/attention.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/platform/__init__.py
+-rw-r--r--  2.0 unx     1050 b- defN 21-Jan-13 15:59 deepomatic/oef/platform/api.py
+-rw-r--r--  2.0 unx     5458 b- defN 21-Mar-22 15:28 deepomatic/oef/platform/config.py
+-rw-r--r--  2.0 unx     6190 b- defN 21-Apr-23 12:34 deepomatic/oef/platform/experiment_to_display_name.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/platform/helpers/__init__.py
+-rw-r--r--  2.0 unx    30350 b- defN 21-Apr-28 12:25 deepomatic/oef/platform/helpers/backends.json
+-rw-r--r--  2.0 unx     2742 b- defN 21-Jan-13 15:59 deepomatic/oef/platform/helpers/common.py
+-rw-r--r--  2.0 unx    22480 b- defN 20-Jul-09 13:01 deepomatic/oef/platform/helpers/controls.py
+-rw-r--r--  2.0 unx     6788 b- defN 21-Jan-13 15:59 deepomatic/oef/platform/helpers/form.py
+-rw-r--r--  2.0 unx     4034 b- defN 20-Jul-09 13:01 deepomatic/oef/platform/helpers/section.py
+-rw-r--r--  2.0 unx     1023 b- defN 20-Jul-09 13:01 deepomatic/oef/platform/helpers/tags.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/protos/__init__.py
+-rw-r--r--  2.0 unx     4904 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/dataoperation_pb2.py
+-rw-r--r--  2.0 unx    41041 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/dataset_dump_pb2.py
+-rw-r--r--  2.0 unx     3211 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/dataset_pb2.py
+-rw-r--r--  2.0 unx     7390 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/experiment_pb2.py
+-rw-r--r--  2.0 unx    16464 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/hyperparameter_pb2.py
+-rw-r--r--  2.0 unx    37858 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/losses_pb2.py
+-rw-r--r--  2.0 unx    28605 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/optimizer_pb2.py
+-rw-r--r--  2.0 unx   105075 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/preprocessor_pb2.py
+-rw-r--r--  2.0 unx    15991 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/trainer_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/protos/models/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/protos/models/image/__init__.py
+-rw-r--r--  2.0 unx    32791 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/backbones_pb2.py
+-rw-r--r--  2.0 unx     4400 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/classification_pb2.py
+-rw-r--r--  2.0 unx    75815 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection_pb2.py
+-rw-r--r--  2.0 unx     7282 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/ocr_pb2.py
+-rw-r--r--  2.0 unx   121125 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/preprocessing_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/protos/models/image/detection/__init__.py
+-rw-r--r--  2.0 unx     7702 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/anchor_generator_pb2.py
+-rw-r--r--  2.0 unx     4581 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/argmax_matcher_pb2.py
+-rw-r--r--  2.0 unx     2327 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/bipartite_matcher_pb2.py
+-rw-r--r--  2.0 unx     7093 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/box_coder_pb2.py
+-rw-r--r--  2.0 unx    37528 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/box_predictor_pb2.py
+-rw-r--r--  2.0 unx    26035 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/calibration_pb2.py
+-rw-r--r--  2.0 unx     6580 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/example_miner_pb2.py
+-rw-r--r--  2.0 unx     3639 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/faster_rcnn_box_coder_pb2.py
+-rw-r--r--  2.0 unx     6428 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/flexible_grid_anchor_generator_pb2.py
+-rw-r--r--  2.0 unx     5332 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/grid_anchor_generator_pb2.py
+-rw-r--r--  2.0 unx     4018 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/keypoint_box_coder_pb2.py
+-rw-r--r--  2.0 unx     4416 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/matcher_pb2.py
+-rw-r--r--  2.0 unx     2336 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/mean_stddev_box_coder_pb2.py
+-rw-r--r--  2.0 unx     4660 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/multiscale_anchor_generator_pb2.py
+-rw-r--r--  2.0 unx     8733 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/post_processing_pb2.py
+-rw-r--r--  2.0 unx    10063 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/region_similarity_calculator_pb2.py
+-rw-r--r--  2.0 unx     3124 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/square_box_coder_pb2.py
+-rw-r--r--  2.0 unx     7598 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/detection/ssd_anchor_generator_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/protos/models/image/utils/__init__.py
+-rw-r--r--  2.0 unx    28139 b- defN 21-Apr-28 12:41 deepomatic/oef/protos/models/image/utils/hyperparameters_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 20-Jul-09 13:01 deepomatic/oef/utils/__init__.py
+-rw-r--r--  2.0 unx     2306 b- defN 21-Mar-22 15:28 deepomatic/oef/utils/class_helpers.py
+-rw-r--r--  2.0 unx     1059 b- defN 20-Jul-09 13:01 deepomatic/oef/utils/common.py
+-rw-r--r--  2.0 unx    12717 b- defN 21-Apr-28 12:16 deepomatic/oef/utils/experiment_builder.py
+-rw-r--r--  2.0 unx     1105 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3011 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/namespace_packages.txt
+-rw-r--r--  2.0 unx       11 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     8676 b- defN 21-Apr-28 12:41 deepomatic_oef-0.9.0.dist-info/RECORD
+84 files, 1556968 bytes uncompressed, 135773 bytes compressed:  91.3%
```

## zipnote {}

```diff
@@ -1,14 +1,14 @@
-Filename: deepomatic_oef-0.8.5-nspkg.pth
+Filename: deepomatic_oef-0.9.0-nspkg.pth
 Comment: 
 
 Filename: deepomatic/oef/__init__.py
 Comment: 
 
-Filename: deepomatic/oef/dataset_dump.py
+Filename: deepomatic/oef/hyperparameter_dump.py
 Comment: 
 
 Filename: deepomatic/oef/api/__init__.py
 Comment: 
 
 Filename: deepomatic/oef/api/backbone.py
 Comment: 
@@ -117,14 +117,17 @@
 
 Filename: deepomatic/oef/protos/dataset_pb2.py
 Comment: 
 
 Filename: deepomatic/oef/protos/experiment_pb2.py
 Comment: 
 
+Filename: deepomatic/oef/protos/hyperparameter_pb2.py
+Comment: 
+
 Filename: deepomatic/oef/protos/losses_pb2.py
 Comment: 
 
 Filename: deepomatic/oef/protos/optimizer_pb2.py
 Comment: 
 
 Filename: deepomatic/oef/protos/preprocessor_pb2.py
@@ -225,29 +228,26 @@
 
 Filename: deepomatic/oef/utils/common.py
 Comment: 
 
 Filename: deepomatic/oef/utils/experiment_builder.py
 Comment: 
 
-Filename: deepomatic/oef/utils/serializer.py
-Comment: 
-
-Filename: deepomatic_oef-0.8.5.dist-info/LICENSE
+Filename: deepomatic_oef-0.9.0.dist-info/LICENSE
 Comment: 
 
-Filename: deepomatic_oef-0.8.5.dist-info/METADATA
+Filename: deepomatic_oef-0.9.0.dist-info/METADATA
 Comment: 
 
-Filename: deepomatic_oef-0.8.5.dist-info/WHEEL
+Filename: deepomatic_oef-0.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: deepomatic_oef-0.8.5.dist-info/namespace_packages.txt
+Filename: deepomatic_oef-0.9.0.dist-info/namespace_packages.txt
 Comment: 
 
-Filename: deepomatic_oef-0.8.5.dist-info/top_level.txt
+Filename: deepomatic_oef-0.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: deepomatic_oef-0.8.5.dist-info/RECORD
+Filename: deepomatic_oef-0.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## deepomatic/oef/__init__.py

```diff
@@ -1 +1 @@
-VERSION = '0.8.5'
+VERSION = '0.9.0'
```

## deepomatic/oef/api/experiment.py

```diff
@@ -1,13 +1,13 @@
 import os
 import requests
 from google.protobuf.json_format import MessageToDict
 
 
-def launch_experiment(xp, dataset_slug, model_name, url_prefix=None, api_key=None):
+def launch_experiment(xp, organisation, dataset_slug, view_slug, model_name, url_prefix=None, api_key=None):
     if url_prefix is None:
         url_prefix = os.getenv('DEEPOMATIC_STUDIO_API_PREFIX', 'https://studio.deepomatic.com/api')
     if api_key is None:
         api_key = os.getenv('DEEPOMATIC_API_KEY')
         if api_key is None:
             raise Exception("Could not find API key, please set environment variable 'DEEPOMATIC_API_KEY'.")
 
@@ -21,20 +21,21 @@
         else:
             r = requests.post(url, json=body, headers=headers)
         if r.status_code == 200:
             return r.json()
         else:
             raise Exception('Invalid status code {} for url {}, response: {}'.format(r.status_code, url, r.text))
 
-    # Get the commit ID
-    url = 'datasets/{}/commits/'.format(dataset_slug)
-    commits = make_request(url_prefix, url, api_key)
-    assert commits['count'] == 1
-    commit_id = commits['results'][0]['uuid']
+    # Get the view UUID
+    url = 'orgs/{}/datasets/{}/views/'.format(organisation, dataset_slug)
+    views = make_request(url_prefix, url, api_key)
+    view = [v for v in views['results'] if v['name'] == view_slug]
+    assert len(view) == 1, 'view {} not found'.format(view_slug)
+    view_uuid = view[0]['uuid']
 
     # Trigger the training
-    url = 'datasets/{}/commits/{}/models/train/'.format(dataset_slug, commit_id)
+    url = 'orgs/{}/datasets/{}/views/{}/models/train/'.format(organisation, dataset_slug, view_uuid)
     body = {
         'model_name': model_name,
         'experiment': MessageToDict(xp),
     }
     return make_request(url_prefix, url, api_key, body)
```

## deepomatic/oef/configs/model_list.py

```diff
@@ -244,16 +244,17 @@
     "image_detection.pretraining_natural_rgb.ssd.resnet_152_v1": ModelArguments("SSD - ResNet 152 v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'resnet': {'depth': 152, 'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/resnet_152_v1-classification-imagenet2012-2016_08_28.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd.resnet_152_v2": ModelArguments("SSD - ResNet 152 v2", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'resnet': {'depth': 152, 'version': 2}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/resnet_152_v2-classification-imagenet2012-2017_04_14.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd.resnet_50_v1": ModelArguments("SSD - ResNet 50 v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'resnet': {'depth': 50, 'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/resnet_50_v1-classification-imagenet2012-2016_08_28.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd.resnet_50_v2": ModelArguments("SSD - ResNet 50 v2", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'resnet': {'depth': 50, 'version': 2}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/resnet_50_v2-classification-imagenet2012-2017_04_14.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd.vgg_16": ModelArguments("SSD - VGG 16", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'vgg': {'depth': 16}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/vgg_16-classification-imagenet2012-2016_08_28.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd.vgg_19": ModelArguments("SSD - VGG 19", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'vgg': {'depth': 19}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': False, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': False, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 0, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/vgg_19-classification-imagenet2012-2016_08_28.ckpt'}}),
     "image_detection.pretraining_natural_rgb.ssd_lite.mobilenet_v2": ModelArguments("SSD Lite - MobileNet v2", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'mobilenet': {'version': 2}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/mobilenet_v2-ssd_lite-coco-2018_05_09.tar.gz'}}),
-    "image_detection.pretraining_natural_rgb.yolo_v2.darknet_19": ModelArguments("YOLO v2 - Darknet 19", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 19}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v2': {'parameters': {'classification_loss': {'weighted_softmax': {'logit_scale': 1.0}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'darknet/natural_rgb/darknet19-yolo-voc2007.weights'}}),
+    "image_detection.pretraining_natural_rgb.yolo_v2.darknet_19": ModelArguments("YOLO v2 - Darknet 19", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 19}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v2': {'parameters': {'classification_loss': {'weighted_softmax': {'logit_scale': 1.0}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'darknet/natural_rgb/darknet19-yolo-voc2007.weights'}}),
     "image_detection.pretraining_natural_rgb.yolo_v3.darknet_53": ModelArguments("YOLO v3 - Darknet 53", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 53}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v3': {'parameters': {'classification_loss': {'weighted_sigmoid': {}}, 'subdivisions': 32}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'darknet/natural_rgb/darknet53-yolo-imagenet2012.weights'}}),
+    "image_detection.pretraining_natural_rgb.yolo_v3_spp.darknet_53": ModelArguments("YOLO v3 SPP - Darknet 53", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 53}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 608, 'resize_method': 'BILINEAR', 'width': 608}}}}, 'yolo_v3_spp': {'parameters': {'classification_loss': {'weighted_sigmoid': {}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.001, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'darknet/natural_rgb/darknet53-yolo_v3_spp_608-coco.weights'}}),
 
     # IMAGE_DETECTION - PRETRAINING_NONE
     "image_detection.pretraining_none.efficientdet_d0.efficientnet_b0": ModelArguments("EfficientDet D0 - EfficientNet B0", {'trainer': {'batch_size': 16, 'image_detection': {'backbone': {'efficientnet': {'survival_prob': 0.0, 'version': 0}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'height': 512, 'resize_method': 'BICUBIC', 'width': 512}}}, 'width_multiplier': 1.0}, 'efficientdet': {'aspect_ratios': [{'height_ratio': 1.0, 'width_ratio': 1.0}, {'height_ratio': 1.4, 'width_ratio': 0.7}, {'height_ratio': 0.7, 'width_ratio': 1.4}], 'box_class_repeats': 3, 'fpn_cell_repeats': 3, 'fpn_num_filters': 64}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.efficientdet_d1.efficientnet_b1": ModelArguments("EfficientDet D1 - EfficientNet B1", {'trainer': {'batch_size': 8, 'image_detection': {'backbone': {'efficientnet': {'version': 1}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'height': 640, 'resize_method': 'BICUBIC', 'width': 640}}}, 'width_multiplier': 1.0}, 'efficientdet': {'aspect_ratios': [{'height_ratio': 1.0, 'width_ratio': 1.0}, {'height_ratio': 1.4, 'width_ratio': 0.7}, {'height_ratio': 0.7, 'width_ratio': 1.4}], 'box_class_repeats': 3, 'fpn_cell_repeats': 4, 'fpn_num_filters': 88}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.efficientdet_d2.efficientnet_b2": ModelArguments("EfficientDet D2 - EfficientNet B2", {'trainer': {'batch_size': 4, 'image_detection': {'backbone': {'efficientnet': {'version': 2}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'height': 768, 'resize_method': 'BICUBIC', 'width': 768}}}, 'width_multiplier': 1.1}, 'efficientdet': {'aspect_ratios': [{'height_ratio': 1.0, 'width_ratio': 1.0}, {'height_ratio': 1.4, 'width_ratio': 0.7}, {'height_ratio': 0.7, 'width_ratio': 1.4}], 'box_class_repeats': 3, 'fpn_cell_repeats': 5, 'fpn_num_filters': 112}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.efficientdet_d3.efficientnet_b3": ModelArguments("EfficientDet D3 - EfficientNet B3", {'trainer': {'batch_size': 2, 'image_detection': {'backbone': {'efficientnet': {'version': 3}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'height': 896, 'resize_method': 'BICUBIC', 'width': 896}}}, 'width_multiplier': 1.2}, 'efficientdet': {'aspect_ratios': [{'height_ratio': 1.0, 'width_ratio': 1.0}, {'height_ratio': 1.4, 'width_ratio': 0.7}, {'height_ratio': 0.7, 'width_ratio': 1.4}], 'box_class_repeats': 4, 'fpn_cell_repeats': 6, 'fpn_num_filters': 160}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.efficientdet_d4.efficientnet_b4": ModelArguments("EfficientDet D4 - EfficientNet B4", {'trainer': {'batch_size': 1, 'image_detection': {'backbone': {'efficientnet': {'version': 4}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'height': 1024, 'resize_method': 'BICUBIC', 'width': 1024}}}, 'width_multiplier': 1.4}, 'efficientdet': {'aspect_ratios': [{'height_ratio': 1.0, 'width_ratio': 1.0}, {'height_ratio': 1.4, 'width_ratio': 0.7}, {'height_ratio': 0.7, 'width_ratio': 1.4}], 'box_class_repeats': 4, 'fpn_cell_repeats': 7, 'fpn_num_filters': 224}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
@@ -371,17 +372,20 @@
     "image_detection.pretraining_none.ssd_lite.inception_v2": ModelArguments("SSD Lite - Inception v2", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'inception': {'version': 2}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.inception_v3": ModelArguments("SSD Lite - Inception v3", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'inception': {'version': 3}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.mobilenet_v1": ModelArguments("SSD Lite - MobileNet v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'mobilenet': {'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.mobilenet_v2": ModelArguments("SSD Lite - MobileNet v2", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'min_width': 16, 'mobilenet': {'version': 2}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.resnet_101_v1": ModelArguments("SSD Lite - ResNet 101 v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'resnet': {'depth': 101, 'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.resnet_152_v1": ModelArguments("SSD Lite - ResNet 152 v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'resnet': {'depth': 152, 'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.ssd_lite.resnet_50_v1": ModelArguments("SSD Lite - ResNet 50 v1", {'trainer': {'batch_size': 24, 'image_detection': {'backbone': {'hyperparameters': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'input': {'data_augmentation_options': [{'random_horizontal_flip': {'keypoint_flip_permutation': []}}], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 300, 'resize_method': 'BILINEAR', 'width': 300}}}, 'resnet': {'depth': 50, 'version': 1}}, 'ssd': {'anchor_generator': {'ssd_anchor_generator': {'aspect_ratios': [1.0, 2.0, 0.5, 3.0, 0.3333], 'base_anchor_height': 1.0, 'base_anchor_width': 1.0, 'height_offset': [], 'height_stride': [], 'interpolated_scale_aspect_ratio': 1.0, 'max_scale': 0.95, 'min_scale': 0.2, 'num_layers': 6, 'reduce_boxes_in_lowest_layer': True, 'scales': [], 'width_offset': [], 'width_stride': []}}, 'box_coder': {'faster_rcnn_box_coder': {'height_scale': 5.0, 'width_scale': 5.0, 'x_scale': 10.0, 'y_scale': 10.0}}, 'box_predictor': {'convolutional_box_predictor': {'apply_sigmoid_to_scores': False, 'box_code_size': 4, 'class_prediction_bias_init': 0.0, 'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'dropout_keep_probability': 0.8, 'kernel_size': 3, 'max_depth': 0, 'min_depth': 0, 'num_layers_before_predictor': 0, 'use_depthwise': True, 'use_dropout': False}}, 'feature_extractor': {'conv_hyperparams': {'activation': 'RELU_6', 'batch_norm': {'center': True, 'decay': 0.9997, 'epsilon': 0.001, 'scale': True, 'train': True}, 'initializer': {'truncated_normal_initializer': {'mean': 0.0, 'stddev': 0.03}}, 'op': 'CONV', 'regularize_depthwise': False, 'regularizer': {'l2_regularizer': {'weight': 4e-05}}}, 'pad_to_multiple': 1, 'use_depthwise': True, 'use_explicit_padding': False}, 'losses': {'classification_loss': {'weighted_sigmoid': {}}, 'classification_weight': 1.0, 'hard_example_miner': {'iou_threshold': 0.99, 'loss_type': 'CLASSIFICATION', 'max_negatives_per_positive': 3, 'min_negatives_per_image': 3, 'num_hard_examples': 3000}, 'localization_loss': {'weighted_smooth_l1': {'anchorwise_output': False, 'delta': 1.0}}, 'localization_weight': 1.0}, 'matcher': {'argmax_matcher': {'force_match_for_each_row': True, 'ignore_thresholds': False, 'matched_threshold': 0.5, 'negatives_lower_than_unmatched': True, 'unmatched_threshold': 0.5, 'use_matmul_gather': False}}, 'post_processing': {'batch_non_max_suppression': {'iou_threshold': 0.6, 'max_detections_per_class': 100, 'max_total_detections': 100, 'score_threshold': 1e-08}, 'logit_scale': 1.0, 'score_converter': 'SIGMOID'}, 'similarity_calculator': {'iou_similarity': {}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
-    "image_detection.pretraining_none.yolo_v2.darknet_19": ModelArguments("YOLO v2 - Darknet 19", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 19}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v2': {'parameters': {'classification_loss': {'weighted_softmax': {'logit_scale': 1.0}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
+    "image_detection.pretraining_none.yolo_v2.darknet_19": ModelArguments("YOLO v2 - Darknet 19", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 19}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v2': {'parameters': {'classification_loss': {'weighted_softmax': {'logit_scale': 1.0}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.002, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
     "image_detection.pretraining_none.yolo_v3.darknet_53": ModelArguments("YOLO v3 - Darknet 53", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 53}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 416, 'resize_method': 'BILINEAR', 'width': 416}}}}, 'yolo_v3': {'parameters': {'classification_loss': {'weighted_sigmoid': {}}, 'subdivisions': 32}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
+    "image_detection.pretraining_none.yolo_v3_spp.darknet_53": ModelArguments("YOLO v3 SPP - Darknet 53", {'trainer': {'batch_size': 64, 'image_detection': {'backbone': {'darknet': {'depth': 53}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 608, 'resize_method': 'BILINEAR', 'width': 608}}}}, 'yolo_v3_spp': {'parameters': {'classification_loss': {'weighted_sigmoid': {}}, 'subdivisions': 16}}}, 'initial_learning_rate': 0.001, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
 
     # IMAGE_OCR - PRETRAINING_NATURAL_RGB
-    "image_ocr.pretraining_natural_rgb.attention.inception_v3": ModelArguments("Attention OCR - Inception v3", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'inception': {'version': 3}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/inception_v3-classification-imagenet2012-2016_08_28.ckpt'}}),
+    "image_ocr.pretraining_natural_rgb.attention.efficientnet_b0": ModelArguments("Attention OCR - EfficientNet B0", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'efficientnet': {'survival_prob': 0.0, 'version': 0}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}, 'width_multiplier': 1.0}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/efficientdet-d0.tar.gz'}}),
+    "image_ocr.pretraining_natural_rgb.attention.inception_v3": ModelArguments("Attention OCR - Inception v3", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'inception': {'version': 3}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}, 'pretrained_parameters': 'tensorflow/natural_rgb/inception_v3-classification-imagenet2012-2016_08_28.ckpt'}}),
 
     # IMAGE_OCR - PRETRAINING_NONE
-    "image_ocr.pretraining_none.attention.inception_v3": ModelArguments("Attention OCR - Inception v3", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'inception': {'version': 3}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}}}, 'initial_learning_rate': 0.004, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
+    "image_ocr.pretraining_none.attention.efficientnet_b0": ModelArguments("Attention OCR - EfficientNet B0", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'efficientnet': {'survival_prob': 0.0, 'version': 0}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}, 'width_multiplier': 1.0}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
+    "image_ocr.pretraining_none.attention.inception_v3": ModelArguments("Attention OCR - Inception v3", {'trainer': {'batch_size': 32, 'image_ocr': {'attention': {}, 'backbone': {'inception': {'version': 3}, 'input': {'data_augmentation_options': [], 'image_resizer': {'fixed_shape_resizer': {'convert_to_grayscale': False, 'height': 32, 'resize_method': 'BILINEAR', 'width': 102}}}}}, 'initial_learning_rate': 0.01, 'learning_rate_policy': {'manual_step_learning_rate': {'schedule': [{'learning_rate_factor': 0.1, 'step_pct': 0.33}, {'learning_rate_factor': 0.01, 'step_pct': 0.66}]}}, 'optimizer': {'momentum_optimizer': {}}}}),
 
 }
```

## deepomatic/oef/configs/image/detection/yolo.py

```diff
@@ -17,15 +17,15 @@
         '@meta_arch.parameters': {
             'subdivisions': 16,
             'classification_loss': {'weighted_softmax': {'logit_scale': 1.0}}
         },
 
     },
 )
-yolo_v2.add_backbone(bb.DARKNET_19, args={'trainer': {'initial_learning_rate': 0.01}}, pretrained_parameters={
+yolo_v2.add_backbone(bb.DARKNET_19, args={'trainer': {'initial_learning_rate': 0.002}}, pretrained_parameters={
     DataType.NATURAL_RGB: 'darknet/natural_rgb/darknet19-yolo-voc2007.weights',
 })
 
 yolo_v3 = ModelConfig(
     display_name='YOLO v3',
     meta_arch='yolo_v3',
     args={
@@ -42,8 +42,30 @@
         },
     },
 )
 yolo_v3.add_backbone(bb.DARKNET_53, args={'trainer': {'initial_learning_rate': 0.01}}, pretrained_parameters={
     DataType.NATURAL_RGB: 'darknet/natural_rgb/darknet53-yolo-imagenet2012.weights',
 })
 
-configs = [yolo_v2, yolo_v3]
+yolo_v3_spp = ModelConfig(
+    display_name='YOLO v3 SPP',
+    meta_arch='yolo_v3_spp',
+    args={
+        'trainer': {
+            'batch_size': 64,
+        },
+        '@model.backbone.input': {
+            'image_resizer': fixed_shape_resizer(608, 608),
+            'data_augmentation_options': [],
+        },
+        '@meta_arch.parameters': {
+            'subdivisions': 16,
+            'classification_loss': {'weighted_sigmoid': {}}
+        },
+    },
+)
+yolo_v3_spp.add_backbone(bb.DARKNET_53, args={'trainer': {'initial_learning_rate': 0.001}}, pretrained_parameters={
+    DataType.NATURAL_RGB: 'darknet/natural_rgb/darknet53-yolo_v3_spp_608-coco.weights',
+})
+
+
+configs = [yolo_v2, yolo_v3, yolo_v3_spp]
```

## deepomatic/oef/configs/image/ocr/attention.py

```diff
@@ -4,21 +4,41 @@
 from ..backbones import Backbones as bb
 
 attention = ModelConfig(
     display_name='Attention OCR',
     alias='attention',
     meta_arch='attention',
     args={
-        'trainer': {
-            'batch_size': 32,
-        },
         '@model.backbone.input': {
             'image_resizer': fixed_shape_resizer(102, 32),
             'data_augmentation_options': [],
         },
     }
 )
-attention.add_backbone(bb.INCEPTION_V3, args={'trainer': {'initial_learning_rate': 0.004}}, pretrained_parameters={
-    DataType.NATURAL_RGB: 'tensorflow/natural_rgb/inception_v3-classification-imagenet2012-2016_08_28.ckpt'
-})
+attention.add_backbone(
+    bb.INCEPTION_V3,
+    args={
+        'trainer': {
+            'batch_size': 32,
+            'initial_learning_rate': 0.01
+        }
+    },
+    pretrained_parameters={
+        DataType.NATURAL_RGB: 'tensorflow/natural_rgb/inception_v3-classification-imagenet2012-2016_08_28.ckpt'
+    }
+)
+
+attention.add_backbone(
+    bb.EFFICIENTNET_B0,
+    args={
+        'trainer': {
+            'batch_size': 32,
+            'initial_learning_rate': 0.01
+        },
+        '@model.backbone.efficientnet.survival_prob': 0.,
+    },
+    pretrained_parameters={
+        DataType.NATURAL_RGB: 'tensorflow/natural_rgb/efficientdet-d0.tar.gz'
+    }
+)
 
 configs = [attention]
```

## deepomatic/oef/platform/config.py

```diff
@@ -40,15 +40,16 @@
     'faster_rcnn.resnet_101_v1',
     'faster_rcnn.resnet_50_v1',
     'ssd.inception_v2',
     'ssd.mobilenet_v1',
     'ssd.mobilenet_v2',
     'ssd_lite.mobilenet_v2',
     'yolo_v2.darknet_19',
-    'yolo_v3.darknet_53'
+    'yolo_v3.darknet_53',
+    'yolo_v3_spp.darknet_53',
 ]
 
 
 ###############################################################################
 
 form_parameters = {
     ViewType.CLASSIFICATION: (
@@ -68,14 +69,15 @@
 }
 
 
 ###############################################################################
 
 form = Form(form_parameters)
 
+
 def num_train_steps_default_value(model_key, model, backend):
     """
     Yolo models have a large batch size (64) versus Tensorflow models (24 for SSD).
     To make training times comparable, we use a lower default number of iteration for
     Yolo.
     TODO: normalize batch sizes (64 in Yolo, 24 in TF detection) to make this comparable
     Args:
```

## deepomatic/oef/platform/experiment_to_display_name.py

```diff
@@ -2,14 +2,15 @@
 import re
 
 import deepomatic.oef.protos.models.image.backbones_pb2 as backbones_pb2
 
 NOT_RE = re.compile(r'not\((.*)\)')
 CONCAT_BEFORE_RE = re.compile(r'concat_before\((.*)\)')
 
+
 class CustomFormatter(string.Formatter):
 
     def get_field(self, field_name, args, kwargs):
         value = getattr(args[0], field_name)
         if isinstance(value, float):
             value = round(value, 7)  # otherwise we would for example get 0.800000011920929 for 0.8
         return value, field_name
@@ -50,26 +51,28 @@
                     int_to_key = {v: k for k, v in enum_class.items()}
                     value = int_to_key[value]
                 else:
                     value = super(CustomFormatter, self).format_field(value, format_spec)
 
         return super(CustomFormatter, self).format_field(value, '')
 
+
 def switch_and_format(options, obj, oneof_name):
     which_oneof = obj.WhichOneof(oneof_name)
     if which_oneof not in options:
         raise Exception("Unexpected one-of value: '{}'".format(which_oneof))
 
     format_value = options[which_oneof]
     if callable(format_value):
         return format_value(obj)
     else:
         fmt = CustomFormatter()
         return fmt.format(format_value, getattr(obj, which_oneof))
 
+
 def backbone_to_name(backbone):
     width_multiplier_str = ''
     if backbone.width_multiplier != 1:
         width_multiplier_str = ' {:.0%}'.format(backbone.width_multiplier)
 
     options = {
         'vgg':              'VGG {depth}',
@@ -79,21 +82,23 @@
         'mobilenet':        'MobileNet v{version}' + width_multiplier_str,
         'nasnet':           '{version:backbones_pb2.NasNetBackbone.Version} {depth:backbones_pb2.NasNetBackbone.Depth,title}',
         'darknet':          'Darknet {depth}',
         'efficientnet':     'EfficientNet {version:backbones_pb2.EfficientNetBackbone.Version}',
     }
     return switch_and_format(options, backbone, 'backbone_type')
 
+
 def ssd_version(model):
     if model.ssd.box_predictor.WhichOneof('box_predictor_oneof') == 'convolutional_box_predictor' and \
        model.ssd.box_predictor.convolutional_box_predictor.use_depthwise and \
        model.ssd.feature_extractor.use_depthwise:
         return 'SSD Lite'
     return 'SSD'
 
+
 def efficientdet_version(model):
     efficientdet_arch = {
         64: 'D0',
         88: 'D1',
         112: 'D2',
         160: 'D3',
         224: 'D4',
@@ -106,14 +111,15 @@
         if model.backbone.input.image_resizer.WhichOneof('image_resizer_oneof') == 'fixed_shape_resizer':
             if model.backbone.input.image_resizer.fixed_shape_resizer.width == 1280:
                 return 'EfficientDet D6'
             elif model.backbone.input.image_resizer.fixed_shape_resizer.width == 1536:
                 return 'EfficientDet D7'
     return 'EfficientDet'
 
+
 def experiment_to_display_name(experiment):
     model_type = experiment.trainer.WhichOneof('model_type')
     model = getattr(experiment.trainer, model_type)
 
     backbone_name = None  # if left like this, we will use the default backbone accessor, see below
     if model_type == 'image_classification':
         meta_arch_name = switch_and_format({
@@ -126,14 +132,15 @@
     elif model_type == 'image_detection':
         meta_arch_name = switch_and_format({
             'faster_rcnn':  'Faster RCNN',
             'rfcn':         'RFCN',
             'ssd':          ssd_version,
             'yolo_v2':      'YOLO v2',
             'yolo_v3':      'YOLO v3',
+            'yolo_v3_spp':      'YOLO v3 SPP',
             'efficientdet': efficientdet_version
         }, model, 'meta_architecture_type')
     elif model_type == 'image_ocr':
         meta_arch_name = switch_and_format({
             'attention':  'Attention OCR',
         }, model, 'meta_architecture_type')
     else:
```

## deepomatic/oef/platform/helpers/backends.json

### Pretty-printed

 * *Similarity: 0.9893048128342246%*

 * *Differences: {"'image_detection.pretraining_natural_rgb.yolo_v3_spp.darknet_53'": "'darknet'",*

 * * "'image_detection.pretraining_none.yolo_v3_spp.darknet_53'": "'darknet'",*

 * * "'image_ocr.pretraining_natural_rgb.attention.efficientnet_b0'": "'tensorflow'",*

 * * "'image_ocr.pretraining_none.attention.efficientnet_b0'": "'tensorflow'"}*

```diff
@@ -238,14 +238,15 @@
     "image_detection.pretraining_natural_rgb.ssd.resnet_50_v1": "tensorflow",
     "image_detection.pretraining_natural_rgb.ssd.resnet_50_v2": "tensorflow",
     "image_detection.pretraining_natural_rgb.ssd.vgg_16": "tensorflow",
     "image_detection.pretraining_natural_rgb.ssd.vgg_19": "tensorflow",
     "image_detection.pretraining_natural_rgb.ssd_lite.mobilenet_v2": "tensorflow",
     "image_detection.pretraining_natural_rgb.yolo_v2.darknet_19": "darknet",
     "image_detection.pretraining_natural_rgb.yolo_v3.darknet_53": "darknet",
+    "image_detection.pretraining_natural_rgb.yolo_v3_spp.darknet_53": "darknet",
     "image_detection.pretraining_none.efficientdet_d0.efficientnet_b0": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d1.efficientnet_b1": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d2.efficientnet_b2": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d3.efficientnet_b3": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d4.efficientnet_b4": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d5.efficientnet_b5": "tensorflow",
     "image_detection.pretraining_none.efficientdet_d6.efficientnet_b6": "tensorflow",
@@ -363,10 +364,13 @@
     "image_detection.pretraining_none.ssd_lite.mobilenet_v1": "tensorflow",
     "image_detection.pretraining_none.ssd_lite.mobilenet_v2": "tensorflow",
     "image_detection.pretraining_none.ssd_lite.resnet_101_v1": "tensorflow",
     "image_detection.pretraining_none.ssd_lite.resnet_152_v1": "tensorflow",
     "image_detection.pretraining_none.ssd_lite.resnet_50_v1": "tensorflow",
     "image_detection.pretraining_none.yolo_v2.darknet_19": "darknet",
     "image_detection.pretraining_none.yolo_v3.darknet_53": "darknet",
+    "image_detection.pretraining_none.yolo_v3_spp.darknet_53": "darknet",
+    "image_ocr.pretraining_natural_rgb.attention.efficientnet_b0": "tensorflow",
     "image_ocr.pretraining_natural_rgb.attention.inception_v3": "tensorflow",
+    "image_ocr.pretraining_none.attention.efficientnet_b0": "tensorflow",
     "image_ocr.pretraining_none.attention.inception_v3": "tensorflow"
 }
```

## deepomatic/oef/protos/experiment_pb2.py

```diff
@@ -11,27 +11,65 @@
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
 from deepomatic.oef.protos import dataset_pb2 as deepomatic_dot_oef_dot_protos_dot_dataset__pb2
 from deepomatic.oef.protos import trainer_pb2 as deepomatic_dot_oef_dot_protos_dot_trainer__pb2
+from deepomatic.oef.protos import hyperparameter_pb2 as deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='deepomatic/oef/protos/experiment.proto',
   package='deepomatic.oef.experiment',
   syntax='proto2',
-  serialized_pb=_b('\n&deepomatic/oef/protos/experiment.proto\x12\x19\x64\x65\x65pomatic.oef.experiment\x1a#deepomatic/oef/protos/dataset.proto\x1a#deepomatic/oef/protos/trainer.proto\"\xa2\x01\n\nExperiment\x12\x0f\n\x04seed\x18\x01 \x01(\x05:\x01\x30\x12\x30\n\x07\x64\x61taset\x18\x02 \x02(\x0b\x32\x1f.deepomatic.oef.dataset.Dataset\x12\x30\n\x07trainer\x18\x03 \x02(\x0b\x32\x1f.deepomatic.oef.trainer.Trainer\x12\x1f\n\x10\x65xclusive_labels\x18\xff\x01 \x01(\x08:\x04true')
+  serialized_pb=_b('\n&deepomatic/oef/protos/experiment.proto\x12\x19\x64\x65\x65pomatic.oef.experiment\x1a#deepomatic/oef/protos/dataset.proto\x1a#deepomatic/oef/protos/trainer.proto\x1a*deepomatic/oef/protos/hyperparameter.proto\"\xf6\x02\n\nExperiment\x12\x0f\n\x04seed\x18\x01 \x01(\x05:\x01\x30\x12\x30\n\x07\x64\x61taset\x18\x02 \x02(\x0b\x32\x1f.deepomatic.oef.dataset.Dataset\x12\x30\n\x07trainer\x18\x03 \x02(\x0b\x32\x1f.deepomatic.oef.trainer.Trainer\x12S\n\x0fhyperparameters\x18\x04 \x03(\x0b\x32:.deepomatic.oef.experiment.Experiment.HyperparametersEntry\x12\x16\n\x0bmax_hp_runs\x18\x05 \x01(\x05:\x01\x31\x12\x1f\n\x10\x65xclusive_labels\x18\xff\x01 \x01(\x08:\x04true\x1a\x65\n\x14HyperparametersEntry\x12\x0b\n\x03key\x18\x01 \x01(\t\x12<\n\x05value\x18\x02 \x01(\x0b\x32-.deepomatic.oef.hyperparameter.HyperParameter:\x02\x38\x01')
   ,
-  dependencies=[deepomatic_dot_oef_dot_protos_dot_dataset__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_trainer__pb2.DESCRIPTOR,])
+  dependencies=[deepomatic_dot_oef_dot_protos_dot_dataset__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_trainer__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2.DESCRIPTOR,])
 
 
 
 
+_EXPERIMENT_HYPERPARAMETERSENTRY = _descriptor.Descriptor(
+  name='HyperparametersEntry',
+  full_name='deepomatic.oef.experiment.Experiment.HyperparametersEntry',
+  filename=None,
+  file=DESCRIPTOR,
+  containing_type=None,
+  fields=[
+    _descriptor.FieldDescriptor(
+      name='key', full_name='deepomatic.oef.experiment.Experiment.HyperparametersEntry.key', index=0,
+      number=1, type=9, cpp_type=9, label=1,
+      has_default_value=False, default_value=_b("").decode('utf-8'),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='value', full_name='deepomatic.oef.experiment.Experiment.HyperparametersEntry.value', index=1,
+      number=2, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+  ],
+  extensions=[
+  ],
+  nested_types=[],
+  enum_types=[
+  ],
+  options=_descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001')),
+  is_extendable=False,
+  syntax='proto2',
+  extension_ranges=[],
+  oneofs=[
+  ],
+  serialized_start=461,
+  serialized_end=562,
+)
+
 _EXPERIMENT = _descriptor.Descriptor(
   name='Experiment',
   full_name='deepomatic.oef.experiment.Experiment',
   filename=None,
   file=DESCRIPTOR,
   containing_type=None,
   fields=[
@@ -53,43 +91,70 @@
       name='trainer', full_name='deepomatic.oef.experiment.Experiment.trainer', index=2,
       number=3, type=11, cpp_type=10, label=2,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
     _descriptor.FieldDescriptor(
-      name='exclusive_labels', full_name='deepomatic.oef.experiment.Experiment.exclusive_labels', index=3,
+      name='hyperparameters', full_name='deepomatic.oef.experiment.Experiment.hyperparameters', index=3,
+      number=4, type=11, cpp_type=10, label=3,
+      has_default_value=False, default_value=[],
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='max_hp_runs', full_name='deepomatic.oef.experiment.Experiment.max_hp_runs', index=4,
+      number=5, type=5, cpp_type=1, label=1,
+      has_default_value=True, default_value=1,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='exclusive_labels', full_name='deepomatic.oef.experiment.Experiment.exclusive_labels', index=5,
       number=255, type=8, cpp_type=7, label=1,
       has_default_value=True, default_value=True,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
   ],
   extensions=[
   ],
-  nested_types=[],
+  nested_types=[_EXPERIMENT_HYPERPARAMETERSENTRY, ],
   enum_types=[
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=144,
-  serialized_end=306,
+  serialized_start=188,
+  serialized_end=562,
 )
 
+_EXPERIMENT_HYPERPARAMETERSENTRY.fields_by_name['value'].message_type = deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2._HYPERPARAMETER
+_EXPERIMENT_HYPERPARAMETERSENTRY.containing_type = _EXPERIMENT
 _EXPERIMENT.fields_by_name['dataset'].message_type = deepomatic_dot_oef_dot_protos_dot_dataset__pb2._DATASET
 _EXPERIMENT.fields_by_name['trainer'].message_type = deepomatic_dot_oef_dot_protos_dot_trainer__pb2._TRAINER
+_EXPERIMENT.fields_by_name['hyperparameters'].message_type = _EXPERIMENT_HYPERPARAMETERSENTRY
 DESCRIPTOR.message_types_by_name['Experiment'] = _EXPERIMENT
 _sym_db.RegisterFileDescriptor(DESCRIPTOR)
 
 Experiment = _reflection.GeneratedProtocolMessageType('Experiment', (_message.Message,), dict(
+
+  HyperparametersEntry = _reflection.GeneratedProtocolMessageType('HyperparametersEntry', (_message.Message,), dict(
+    DESCRIPTOR = _EXPERIMENT_HYPERPARAMETERSENTRY,
+    __module__ = 'deepomatic.oef.protos.experiment_pb2'
+    # @@protoc_insertion_point(class_scope:deepomatic.oef.experiment.Experiment.HyperparametersEntry)
+    ))
+  ,
   DESCRIPTOR = _EXPERIMENT,
   __module__ = 'deepomatic.oef.protos.experiment_pb2'
   # @@protoc_insertion_point(class_scope:deepomatic.oef.experiment.Experiment)
   ))
 _sym_db.RegisterMessage(Experiment)
+_sym_db.RegisterMessage(Experiment.HyperparametersEntry)
 
 
+_EXPERIMENT_HYPERPARAMETERSENTRY.has_options = True
+_EXPERIMENT_HYPERPARAMETERSENTRY._options = _descriptor._ParseOptions(descriptor_pb2.MessageOptions(), _b('8\001'))
 # @@protoc_insertion_point(module_scope)
```

## deepomatic/oef/protos/optimizer_pb2.py

```diff
@@ -9,22 +9,24 @@
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf import descriptor_pb2
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
+from deepomatic.oef.protos import hyperparameter_pb2 as deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='deepomatic/oef/protos/optimizer.proto',
   package='deepomatic.oef.optimizer',
   syntax='proto2',
-  serialized_pb=_b('\n%deepomatic/oef/protos/optimizer.proto\x12\x18\x64\x65\x65pomatic.oef.optimizer\"\xb9\x02\n\tOptimizer\x12H\n\x12rms_prop_optimizer\x18\x01 \x01(\x0b\x32*.deepomatic.oef.optimizer.RMSPropOptimizerH\x00\x12I\n\x12momentum_optimizer\x18\x02 \x01(\x0b\x32+.deepomatic.oef.optimizer.MomentumOptimizerH\x00\x12\x41\n\x0e\x61\x64\x61m_optimizer\x18\x03 \x01(\x0b\x32\'.deepomatic.oef.optimizer.AdamOptimizerH\x00\x12!\n\x12use_moving_average\x18\x04 \x01(\x08:\x05\x66\x61lse\x12$\n\x14moving_average_decay\x18\x05 \x01(\x02:\x06\x30.9999B\x0b\n\toptimizer\"a\n\x10RMSPropOptimizer\x12%\n\x18momentum_optimizer_value\x18\x02 \x01(\x02:\x03\x30.9\x12\x12\n\x05\x64\x65\x63\x61y\x18\x03 \x01(\x02:\x03\x30.9\x12\x12\n\x07\x65psilon\x18\x04 \x01(\x02:\x01\x31\":\n\x11MomentumOptimizer\x12%\n\x18momentum_optimizer_value\x18\x02 \x01(\x02:\x03\x30.9\"\x0f\n\rAdamOptimizer\"\x91\x03\n\x12LearningRatePolicy\x12P\n\x16\x63onstant_learning_rate\x18\x01 \x01(\x0b\x32..deepomatic.oef.optimizer.ConstantLearningRateH\x00\x12\x61\n\x1f\x65xponential_decay_learning_rate\x18\x02 \x01(\x0b\x32\x36.deepomatic.oef.optimizer.ExponentialDecayLearningRateH\x00\x12U\n\x19manual_step_learning_rate\x18\x03 \x01(\x0b\x32\x30.deepomatic.oef.optimizer.ManualStepLearningRateH\x00\x12W\n\x1a\x63osine_decay_learning_rate\x18\x04 \x01(\x0b\x32\x31.deepomatic.oef.optimizer.CosineDecayLearningRateH\x00\x42\x16\n\x14learning_rate_policy\"\x16\n\x14\x43onstantLearningRate\"\xcf\x01\n\x1c\x45xponentialDecayLearningRate\x12\x1e\n\x0f\x64\x65\x63\x61y_steps_pct\x18\x02 \x01(\x02:\x05\x30.006\x12\x1a\n\x0c\x64\x65\x63\x61y_factor\x18\x03 \x01(\x02:\x04\x30.95\x12\x17\n\tstaircase\x18\x04 \x01(\x08:\x04true\x12\x1f\n\x14\x62urnin_learning_rate\x18\x05 \x01(\x02:\x01\x30\x12\x1b\n\x10\x62urnin_steps_pct\x18\x06 \x01(\x02:\x01\x30\x12\x1c\n\x11min_learning_rate\x18\x07 \x01(\x02:\x01\x30\"\xd5\x01\n\x16ManualStepLearningRate\x12W\n\x08schedule\x18\x02 \x03(\x0b\x32\x45.deepomatic.oef.optimizer.ManualStepLearningRate.LearningRateSchedule\x12\x15\n\x06warmup\x18\x03 \x01(\x08:\x05\x66\x61lse\x1aK\n\x14LearningRateSchedule\x12\x10\n\x08step_pct\x18\x01 \x01(\x02\x12!\n\x14learning_rate_factor\x18\x02 \x01(\x02:\x03\x30.1\"\xa5\x01\n\x17\x43osineDecayLearningRate\x12\x1d\n\x0ftotal_steps_pct\x18\x02 \x01(\x02:\x04\x31.07\x12$\n\x14warmup_learning_rate\x18\x03 \x01(\x02:\x06\x30.0002\x12 \n\x10warmup_steps_pct\x18\x04 \x01(\x02:\x06\x30.0025\x12#\n\x18hold_base_rate_steps_pct\x18\x05 \x01(\x02:\x01\x30')
-)
+  serialized_pb=_b('\n%deepomatic/oef/protos/optimizer.proto\x12\x18\x64\x65\x65pomatic.oef.optimizer\x1a*deepomatic/oef/protos/hyperparameter.proto\"\x96\x03\n\tOptimizer\x12H\n\x12rms_prop_optimizer\x18\x01 \x01(\x0b\x32*.deepomatic.oef.optimizer.RMSPropOptimizerH\x00\x12I\n\x12momentum_optimizer\x18\x02 \x01(\x0b\x32+.deepomatic.oef.optimizer.MomentumOptimizerH\x00\x12\x41\n\x0e\x61\x64\x61m_optimizer\x18\x03 \x01(\x0b\x32\'.deepomatic.oef.optimizer.AdamOptimizerH\x00\x12\x35\n\x12use_moving_average\x18\x04 \x01(\x08:\x05\x66\x61lseB\x12\xc2>\x06\n\x04\n\x02\x18\x00\xc2>\x06\n\x04\n\x02\x18\x01\x12:\n\x14moving_average_decay\x18\x05 \x01(\x02:\x06\x30.9999B\x14\xc2>\x07\x12\x05\rfff?\xc2>\x07\x12\x05\x15\x00\x00\x80?B>\n\toptimizer\x12\x31\xc2>.\n,\n\x14\"\x12momentum_optimizer\n\x14\"\x12rms_prop_optimizer\"\x8d\x01\n\x10RMSPropOptimizer\x12;\n\x18momentum_optimizer_value\x18\x02 \x01(\x02:\x03\x30.9B\x14\xc2>\x07\x12\x05\r\x00\x00\x00\x00\xc2>\x07\x12\x05\x15\x00\x00\x80?\x12(\n\x05\x64\x65\x63\x61y\x18\x03 \x01(\x02:\x03\x30.9B\x14\xc2>\x07\x12\x05\r\x00\x00\x00\x00\xc2>\x07\x12\x05\x15\x00\x00\x80?\x12\x12\n\x07\x65psilon\x18\x04 \x01(\x02:\x01\x31\"P\n\x11MomentumOptimizer\x12;\n\x18momentum_optimizer_value\x18\x02 \x01(\x02:\x03\x30.9B\x14\xc2>\x07\x12\x05\r\x00\x00\x00\x00\xc2>\x07\x12\x05\x15\x00\x00\x80?\"\x0f\n\rAdamOptimizer\"\xcf\x03\n\x12LearningRatePolicy\x12P\n\x16\x63onstant_learning_rate\x18\x01 \x01(\x0b\x32..deepomatic.oef.optimizer.ConstantLearningRateH\x00\x12\x61\n\x1f\x65xponential_decay_learning_rate\x18\x02 \x01(\x0b\x32\x36.deepomatic.oef.optimizer.ExponentialDecayLearningRateH\x00\x12U\n\x19manual_step_learning_rate\x18\x03 \x01(\x0b\x32\x30.deepomatic.oef.optimizer.ManualStepLearningRateH\x00\x12W\n\x1a\x63osine_decay_learning_rate\x18\x04 \x01(\x0b\x32\x31.deepomatic.oef.optimizer.CosineDecayLearningRateH\x00\x42T\n\x14learning_rate_policy\x12<\xc2>9\n7\n\x1b\"\x19manual_step_learning_rate\n\x18\"\x16\x63onstant_learning_rate\"\x16\n\x14\x43onstantLearningRate\"\xcf\x01\n\x1c\x45xponentialDecayLearningRate\x12\x1e\n\x0f\x64\x65\x63\x61y_steps_pct\x18\x02 \x01(\x02:\x05\x30.006\x12\x1a\n\x0c\x64\x65\x63\x61y_factor\x18\x03 \x01(\x02:\x04\x30.95\x12\x17\n\tstaircase\x18\x04 \x01(\x08:\x04true\x12\x1f\n\x14\x62urnin_learning_rate\x18\x05 \x01(\x02:\x01\x30\x12\x1b\n\x10\x62urnin_steps_pct\x18\x06 \x01(\x02:\x01\x30\x12\x1c\n\x11min_learning_rate\x18\x07 \x01(\x02:\x01\x30\"\xd5\x01\n\x16ManualStepLearningRate\x12W\n\x08schedule\x18\x02 \x03(\x0b\x32\x45.deepomatic.oef.optimizer.ManualStepLearningRate.LearningRateSchedule\x12\x15\n\x06warmup\x18\x03 \x01(\x08:\x05\x66\x61lse\x1aK\n\x14LearningRateSchedule\x12\x10\n\x08step_pct\x18\x01 \x01(\x02\x12!\n\x14learning_rate_factor\x18\x02 \x01(\x02:\x03\x30.1\"\xa5\x01\n\x17\x43osineDecayLearningRate\x12\x1d\n\x0ftotal_steps_pct\x18\x02 \x01(\x02:\x04\x31.07\x12$\n\x14warmup_learning_rate\x18\x03 \x01(\x02:\x06\x30.0002\x12 \n\x10warmup_steps_pct\x18\x04 \x01(\x02:\x06\x30.0025\x12#\n\x18hold_base_rate_steps_pct\x18\x05 \x01(\x02:\x01\x30')
+  ,
+  dependencies=[deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2.DESCRIPTOR,])
 
 
 
 
 _OPTIMIZER = _descriptor.Descriptor(
   name='Optimizer',
   full_name='deepomatic.oef.optimizer.Optimizer',
@@ -55,39 +57,39 @@
       options=None),
     _descriptor.FieldDescriptor(
       name='use_moving_average', full_name='deepomatic.oef.optimizer.Optimizer.use_moving_average', index=3,
       number=4, type=8, cpp_type=7, label=1,
       has_default_value=True, default_value=False,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\006\n\004\n\002\030\000\302>\006\n\004\n\002\030\001'))),
     _descriptor.FieldDescriptor(
       name='moving_average_decay', full_name='deepomatic.oef.optimizer.Optimizer.moving_average_decay', index=4,
       number=5, type=2, cpp_type=6, label=1,
       has_default_value=True, default_value=float(0.9999),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\rfff?\302>\007\022\005\025\000\000\200?'))),
   ],
   extensions=[
   ],
   nested_types=[],
   enum_types=[
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='optimizer', full_name='deepomatic.oef.optimizer.Optimizer.optimizer',
-      index=0, containing_type=None, fields=[]),
+      index=0, containing_type=None, fields=[], options=_descriptor._ParseOptions(descriptor_pb2.OneofOptions(), _b('\302>.\n,\n\024\"\022momentum_optimizer\n\024\"\022rms_prop_optimizer'))),
   ],
-  serialized_start=68,
-  serialized_end=381,
+  serialized_start=112,
+  serialized_end=518,
 )
 
 
 _RMSPROPOPTIMIZER = _descriptor.Descriptor(
   name='RMSPropOptimizer',
   full_name='deepomatic.oef.optimizer.RMSPropOptimizer',
   filename=None,
@@ -96,22 +98,22 @@
   fields=[
     _descriptor.FieldDescriptor(
       name='momentum_optimizer_value', full_name='deepomatic.oef.optimizer.RMSPropOptimizer.momentum_optimizer_value', index=0,
       number=2, type=2, cpp_type=6, label=1,
       has_default_value=True, default_value=float(0.9),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))),
     _descriptor.FieldDescriptor(
       name='decay', full_name='deepomatic.oef.optimizer.RMSPropOptimizer.decay', index=1,
       number=3, type=2, cpp_type=6, label=1,
       has_default_value=True, default_value=float(0.9),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))),
     _descriptor.FieldDescriptor(
       name='epsilon', full_name='deepomatic.oef.optimizer.RMSPropOptimizer.epsilon', index=2,
       number=4, type=2, cpp_type=6, label=1,
       has_default_value=True, default_value=float(1),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
@@ -123,16 +125,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=383,
-  serialized_end=480,
+  serialized_start=521,
+  serialized_end=662,
 )
 
 
 _MOMENTUMOPTIMIZER = _descriptor.Descriptor(
   name='MomentumOptimizer',
   full_name='deepomatic.oef.optimizer.MomentumOptimizer',
   filename=None,
@@ -141,29 +143,29 @@
   fields=[
     _descriptor.FieldDescriptor(
       name='momentum_optimizer_value', full_name='deepomatic.oef.optimizer.MomentumOptimizer.momentum_optimizer_value', index=0,
       number=2, type=2, cpp_type=6, label=1,
       has_default_value=True, default_value=float(0.9),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))),
   ],
   extensions=[
   ],
   nested_types=[],
   enum_types=[
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=482,
-  serialized_end=540,
+  serialized_start=664,
+  serialized_end=744,
 )
 
 
 _ADAMOPTIMIZER = _descriptor.Descriptor(
   name='AdamOptimizer',
   full_name='deepomatic.oef.optimizer.AdamOptimizer',
   filename=None,
@@ -178,16 +180,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=542,
-  serialized_end=557,
+  serialized_start=746,
+  serialized_end=761,
 )
 
 
 _LEARNINGRATEPOLICY = _descriptor.Descriptor(
   name='LearningRatePolicy',
   full_name='deepomatic.oef.optimizer.LearningRatePolicy',
   filename=None,
@@ -231,18 +233,18 @@
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='learning_rate_policy', full_name='deepomatic.oef.optimizer.LearningRatePolicy.learning_rate_policy',
-      index=0, containing_type=None, fields=[]),
+      index=0, containing_type=None, fields=[], options=_descriptor._ParseOptions(descriptor_pb2.OneofOptions(), _b('\302>9\n7\n\033\"\031manual_step_learning_rate\n\030\"\026constant_learning_rate'))),
   ],
-  serialized_start=560,
-  serialized_end=961,
+  serialized_start=764,
+  serialized_end=1227,
 )
 
 
 _CONSTANTLEARNINGRATE = _descriptor.Descriptor(
   name='ConstantLearningRate',
   full_name='deepomatic.oef.optimizer.ConstantLearningRate',
   filename=None,
@@ -257,16 +259,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=963,
-  serialized_end=985,
+  serialized_start=1229,
+  serialized_end=1251,
 )
 
 
 _EXPONENTIALDECAYLEARNINGRATE = _descriptor.Descriptor(
   name='ExponentialDecayLearningRate',
   full_name='deepomatic.oef.optimizer.ExponentialDecayLearningRate',
   filename=None,
@@ -323,16 +325,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=988,
-  serialized_end=1195,
+  serialized_start=1254,
+  serialized_end=1461,
 )
 
 
 _MANUALSTEPLEARNINGRATE_LEARNINGRATESCHEDULE = _descriptor.Descriptor(
   name='LearningRateSchedule',
   full_name='deepomatic.oef.optimizer.ManualStepLearningRate.LearningRateSchedule',
   filename=None,
@@ -361,16 +363,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=1336,
-  serialized_end=1411,
+  serialized_start=1602,
+  serialized_end=1677,
 )
 
 _MANUALSTEPLEARNINGRATE = _descriptor.Descriptor(
   name='ManualStepLearningRate',
   full_name='deepomatic.oef.optimizer.ManualStepLearningRate',
   filename=None,
   file=DESCRIPTOR,
@@ -398,16 +400,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=1198,
-  serialized_end=1411,
+  serialized_start=1464,
+  serialized_end=1677,
 )
 
 
 _COSINEDECAYLEARNINGRATE = _descriptor.Descriptor(
   name='CosineDecayLearningRate',
   full_name='deepomatic.oef.optimizer.CosineDecayLearningRate',
   filename=None,
@@ -450,16 +452,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=1414,
-  serialized_end=1579,
+  serialized_start=1680,
+  serialized_end=1845,
 )
 
 _OPTIMIZER.fields_by_name['rms_prop_optimizer'].message_type = _RMSPROPOPTIMIZER
 _OPTIMIZER.fields_by_name['momentum_optimizer'].message_type = _MOMENTUMOPTIMIZER
 _OPTIMIZER.fields_by_name['adam_optimizer'].message_type = _ADAMOPTIMIZER
 _OPTIMIZER.oneofs_by_name['optimizer'].fields.append(
   _OPTIMIZER.fields_by_name['rms_prop_optimizer'])
@@ -567,8 +569,22 @@
   DESCRIPTOR = _COSINEDECAYLEARNINGRATE,
   __module__ = 'deepomatic.oef.protos.optimizer_pb2'
   # @@protoc_insertion_point(class_scope:deepomatic.oef.optimizer.CosineDecayLearningRate)
   ))
 _sym_db.RegisterMessage(CosineDecayLearningRate)
 
 
+_OPTIMIZER.oneofs_by_name['optimizer'].has_options = True
+_OPTIMIZER.oneofs_by_name['optimizer']._options = _descriptor._ParseOptions(descriptor_pb2.OneofOptions(), _b('\302>.\n,\n\024\"\022momentum_optimizer\n\024\"\022rms_prop_optimizer'))
+_OPTIMIZER.fields_by_name['use_moving_average'].has_options = True
+_OPTIMIZER.fields_by_name['use_moving_average']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\006\n\004\n\002\030\000\302>\006\n\004\n\002\030\001'))
+_OPTIMIZER.fields_by_name['moving_average_decay'].has_options = True
+_OPTIMIZER.fields_by_name['moving_average_decay']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\rfff?\302>\007\022\005\025\000\000\200?'))
+_RMSPROPOPTIMIZER.fields_by_name['momentum_optimizer_value'].has_options = True
+_RMSPROPOPTIMIZER.fields_by_name['momentum_optimizer_value']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))
+_RMSPROPOPTIMIZER.fields_by_name['decay'].has_options = True
+_RMSPROPOPTIMIZER.fields_by_name['decay']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))
+_MOMENTUMOPTIMIZER.fields_by_name['momentum_optimizer_value'].has_options = True
+_MOMENTUMOPTIMIZER.fields_by_name['momentum_optimizer_value']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\007\022\005\r\000\000\000\000\302>\007\022\005\025\000\000\200?'))
+_LEARNINGRATEPOLICY.oneofs_by_name['learning_rate_policy'].has_options = True
+_LEARNINGRATEPOLICY.oneofs_by_name['learning_rate_policy']._options = _descriptor._ParseOptions(descriptor_pb2.OneofOptions(), _b('\302>9\n7\n\033\"\031manual_step_learning_rate\n\030\"\026constant_learning_rate'))
 # @@protoc_insertion_point(module_scope)
```

## deepomatic/oef/protos/trainer_pb2.py

```diff
@@ -9,27 +9,28 @@
 from google.protobuf import symbol_database as _symbol_database
 from google.protobuf import descriptor_pb2
 # @@protoc_insertion_point(imports)
 
 _sym_db = _symbol_database.Default()
 
 
+from deepomatic.oef.protos import hyperparameter_pb2 as deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2
 from deepomatic.oef.protos import optimizer_pb2 as deepomatic_dot_oef_dot_protos_dot_optimizer__pb2
 from deepomatic.oef.protos.models.image import classification_pb2 as deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_classification__pb2
 from deepomatic.oef.protos.models.image import detection_pb2 as deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection__pb2
 from deepomatic.oef.protos.models.image import ocr_pb2 as deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_ocr__pb2
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='deepomatic/oef/protos/trainer.proto',
   package='deepomatic.oef.trainer',
   syntax='proto2',
-  serialized_pb=_b('\n#deepomatic/oef/protos/trainer.proto\x12\x16\x64\x65\x65pomatic.oef.trainer\x1a%deepomatic/oef/protos/optimizer.proto\x1a\x37\x64\x65\x65pomatic/oef/protos/models/image/classification.proto\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/detection.proto\x1a,deepomatic/oef/protos/models/image/ocr.proto\"Y\n\x0cQuantization\x12\x15\n\x05\x64\x65lay\x18\x01 \x01(\x05:\x06\x35\x30\x30\x30\x30\x30\x12\x16\n\x0bweight_bits\x18\x02 \x01(\x05:\x01\x38\x12\x1a\n\x0f\x61\x63tivation_bits\x18\x03 \x01(\x05:\x01\x38\"\xfe\x06\n\x07Trainer\x12Z\n\x14image_classification\x18\x01 \x01(\x0b\x32:.deepomatic.oef.models.image.classification.ClassificationH\x00\x12K\n\x0fimage_detection\x18\x02 \x01(\x0b\x32\x30.deepomatic.oef.models.image.detection.DetectionH\x00\x12\x39\n\timage_ocr\x18\x03 \x01(\x0b\x32$.deepomatic.oef.models.image.ocr.OCRH\x00\x12\x12\n\nbatch_size\x18\x32 \x02(\x05\x12\x1a\n\x0f\x65val_batch_size\x18\x33 \x01(\x05:\x01\x30\x12\x1f\n\x0fnum_train_steps\x18\x34 \x01(\x05:\x06\x32\x30\x30\x30\x30\x30\x12\x1a\n\x0enum_eval_steps\x18\x35 \x01(\x05:\x02-1\x12%\n\x17\x61\x64\x64_regularization_loss\x18\x36 \x01(\x08:\x04true\x12\x18\n\x10\x66reeze_variables\x18\x37 \x03(\t\x12\"\n\x1aupdate_trainable_variables\x18\x38 \x03(\t\x12\x1f\n\x15pretrained_parameters\x18\x39 \x01(\t:\x00\x12(\n\x1dkeep_checkpoint_every_n_hours\x18: \x01(\x02:\x01\x31\x12\x1e\n\x0fresume_training\x18; \x01(\x08:\x05\x66\x61lse\x12 \n\x18\x64o_not_restore_variables\x18< \x03(\t\x12\x1d\n\x15initial_learning_rate\x18\x64 \x01(\x02\x12J\n\x14learning_rate_policy\x18\x65 \x01(\x0b\x32,.deepomatic.oef.optimizer.LearningRatePolicy\x12\x36\n\toptimizer\x18\x66 \x01(\x0b\x32#.deepomatic.oef.optimizer.Optimizer\x12%\n\x19gradient_clipping_by_norm\x18g \x01(\x02:\x02\x31\x30\x12\x1b\n\x0buse_float16\x18\xc8\x01 \x01(\x08:\x05\x66\x61lse\x12;\n\x0cquantization\x18\xc9\x01 \x01(\x0b\x32$.deepomatic.oef.trainer.QuantizationB\x0c\n\nmodel_type')
+  serialized_pb=_b('\n#deepomatic/oef/protos/trainer.proto\x12\x16\x64\x65\x65pomatic.oef.trainer\x1a*deepomatic/oef/protos/hyperparameter.proto\x1a%deepomatic/oef/protos/optimizer.proto\x1a\x37\x64\x65\x65pomatic/oef/protos/models/image/classification.proto\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/detection.proto\x1a,deepomatic/oef/protos/models/image/ocr.proto\"Y\n\x0cQuantization\x12\x15\n\x05\x64\x65lay\x18\x01 \x01(\x05:\x06\x35\x30\x30\x30\x30\x30\x12\x16\n\x0bweight_bits\x18\x02 \x01(\x05:\x01\x38\x12\x1a\n\x0f\x61\x63tivation_bits\x18\x03 \x01(\x05:\x01\x38\"\xa3\x07\n\x07Trainer\x12Z\n\x14image_classification\x18\x01 \x01(\x0b\x32:.deepomatic.oef.models.image.classification.ClassificationH\x00\x12K\n\x0fimage_detection\x18\x02 \x01(\x0b\x32\x30.deepomatic.oef.models.image.detection.DetectionH\x00\x12\x39\n\timage_ocr\x18\x03 \x01(\x0b\x32$.deepomatic.oef.models.image.ocr.OCRH\x00\x12\x12\n\nbatch_size\x18\x32 \x02(\x05\x12\x1a\n\x0f\x65val_batch_size\x18\x33 \x01(\x05:\x01\x30\x12\x1f\n\x0fnum_train_steps\x18\x34 \x01(\x05:\x06\x32\x30\x30\x30\x30\x30\x12\x1a\n\x0enum_eval_steps\x18\x35 \x01(\x05:\x02-1\x12\x39\n\x17\x61\x64\x64_regularization_loss\x18\x36 \x01(\x08:\x04trueB\x12\xc2>\x06\n\x04\n\x02\x18\x01\xc2>\x06\n\x04\n\x02\x18\x00\x12\x18\n\x10\x66reeze_variables\x18\x37 \x03(\t\x12\"\n\x1aupdate_trainable_variables\x18\x38 \x03(\t\x12\x1f\n\x15pretrained_parameters\x18\x39 \x01(\t:\x00\x12(\n\x1dkeep_checkpoint_every_n_hours\x18: \x01(\x02:\x01\x31\x12\x1e\n\x0fresume_training\x18; \x01(\x08:\x05\x66\x61lse\x12 \n\x18\x64o_not_restore_variables\x18< \x03(\t\x12.\n\x15initial_learning_rate\x18\x64 \x01(\x02\x42\x0f\xc2>\x0c\x1a\n\r\x17\xb7\xd1\x38\x15\xcd\xcc\xcc=\x12J\n\x14learning_rate_policy\x18\x65 \x01(\x0b\x32,.deepomatic.oef.optimizer.LearningRatePolicy\x12\x36\n\toptimizer\x18\x66 \x01(\x0b\x32#.deepomatic.oef.optimizer.Optimizer\x12%\n\x19gradient_clipping_by_norm\x18g \x01(\x02:\x02\x31\x30\x12\x1b\n\x0buse_float16\x18\xc8\x01 \x01(\x08:\x05\x66\x61lse\x12;\n\x0cquantization\x18\xc9\x01 \x01(\x0b\x32$.deepomatic.oef.trainer.QuantizationB\x0c\n\nmodel_type')
   ,
-  dependencies=[deepomatic_dot_oef_dot_protos_dot_optimizer__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_classification__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_ocr__pb2.DESCRIPTOR,])
+  dependencies=[deepomatic_dot_oef_dot_protos_dot_hyperparameter__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_optimizer__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_classification__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_ocr__pb2.DESCRIPTOR,])
 
 
 
 
 _QUANTIZATION = _descriptor.Descriptor(
   name='Quantization',
   full_name='deepomatic.oef.trainer.Quantization',
@@ -66,16 +67,16 @@
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=257,
-  serialized_end=346,
+  serialized_start=301,
+  serialized_end=390,
 )
 
 
 _TRAINER = _descriptor.Descriptor(
   name='Trainer',
   full_name='deepomatic.oef.trainer.Trainer',
   filename=None,
@@ -133,15 +134,15 @@
       options=None),
     _descriptor.FieldDescriptor(
       name='add_regularization_loss', full_name='deepomatic.oef.trainer.Trainer.add_regularization_loss', index=7,
       number=54, type=8, cpp_type=7, label=1,
       has_default_value=True, default_value=True,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\006\n\004\n\002\030\001\302>\006\n\004\n\002\030\000'))),
     _descriptor.FieldDescriptor(
       name='freeze_variables', full_name='deepomatic.oef.trainer.Trainer.freeze_variables', index=8,
       number=55, type=9, cpp_type=9, label=3,
       has_default_value=False, default_value=[],
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
@@ -182,15 +183,15 @@
       options=None),
     _descriptor.FieldDescriptor(
       name='initial_learning_rate', full_name='deepomatic.oef.trainer.Trainer.initial_learning_rate', index=14,
       number=100, type=2, cpp_type=6, label=1,
       has_default_value=False, default_value=float(0),
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
-      options=None),
+      options=_descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\014\032\n\r\027\267\3218\025\315\314\314='))),
     _descriptor.FieldDescriptor(
       name='learning_rate_policy', full_name='deepomatic.oef.trainer.Trainer.learning_rate_policy', index=15,
       number=101, type=11, cpp_type=10, label=1,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
@@ -233,16 +234,16 @@
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='model_type', full_name='deepomatic.oef.trainer.Trainer.model_type',
       index=0, containing_type=None, fields=[]),
   ],
-  serialized_start=349,
-  serialized_end=1243,
+  serialized_start=393,
+  serialized_end=1324,
 )
 
 _TRAINER.fields_by_name['image_classification'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_classification__pb2._CLASSIFICATION
 _TRAINER.fields_by_name['image_detection'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection__pb2._DETECTION
 _TRAINER.fields_by_name['image_ocr'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_ocr__pb2._OCR
 _TRAINER.fields_by_name['learning_rate_policy'].message_type = deepomatic_dot_oef_dot_protos_dot_optimizer__pb2._LEARNINGRATEPOLICY
 _TRAINER.fields_by_name['optimizer'].message_type = deepomatic_dot_oef_dot_protos_dot_optimizer__pb2._OPTIMIZER
@@ -271,8 +272,12 @@
   DESCRIPTOR = _TRAINER,
   __module__ = 'deepomatic.oef.protos.trainer_pb2'
   # @@protoc_insertion_point(class_scope:deepomatic.oef.trainer.Trainer)
   ))
 _sym_db.RegisterMessage(Trainer)
 
 
+_TRAINER.fields_by_name['add_regularization_loss'].has_options = True
+_TRAINER.fields_by_name['add_regularization_loss']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\006\n\004\n\002\030\001\302>\006\n\004\n\002\030\000'))
+_TRAINER.fields_by_name['initial_learning_rate'].has_options = True
+_TRAINER.fields_by_name['initial_learning_rate']._options = _descriptor._ParseOptions(descriptor_pb2.FieldOptions(), _b('\302>\014\032\n\r\027\267\3218\025\315\314\314='))
 # @@protoc_insertion_point(module_scope)
```

## deepomatic/oef/protos/models/image/detection_pb2.py

```diff
@@ -25,15 +25,15 @@
 from deepomatic.oef.protos.models.image.detection import region_similarity_calculator_pb2 as deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_region__similarity__calculator__pb2
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='deepomatic/oef/protos/models/image/detection.proto',
   package='deepomatic.oef.models.image.detection',
   syntax='proto2',
-  serialized_pb=_b('\n2deepomatic/oef/protos/models/image/detection.proto\x12%deepomatic.oef.models.image.detection\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/backbones.proto\x1a>deepomatic/oef/protos/models/image/utils/hyperparameters.proto\x1a\"deepomatic/oef/protos/losses.proto\x1a\x43\x64\x65\x65pomatic/oef/protos/models/image/detection/anchor_generator.proto\x1a@deepomatic/oef/protos/models/image/detection/example_miner.proto\x1a@deepomatic/oef/protos/models/image/detection/box_predictor.proto\x1a<deepomatic/oef/protos/models/image/detection/box_coder.proto\x1a:deepomatic/oef/protos/models/image/detection/matcher.proto\x1a\x42\x64\x65\x65pomatic/oef/protos/models/image/detection/post_processing.proto\x1aOdeepomatic/oef/protos/models/image/detection/region_similarity_calculator.proto\"\x98\x0e\n\x0eRCNNParameters\x12\x1b\n\x10number_of_stages\x18\x01 \x01(\x05:\x01\x32\x12\'\n\x1b\x66irst_stage_features_stride\x18\x02 \x01(\x05:\x02\x31\x36\x12#\n\x14\x62\x61tch_norm_trainable\x18\x03 \x01(\x08:\x05\x66\x61lse\x12\\\n\x1c\x66irst_stage_anchor_generator\x18\x06 \x02(\x0b\x32\x36.deepomatic.oef.models.image.detection.AnchorGenerator\x12\"\n\x17\x66irst_stage_atrous_rate\x18\x07 \x01(\x05:\x01\x31\x12r\n*first_stage_box_predictor_conv_hyperparams\x18\x08 \x02(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x30\n%first_stage_box_predictor_kernel_size\x18\t \x01(\x05:\x01\x33\x12,\n\x1f\x66irst_stage_box_predictor_depth\x18\n \x01(\x05:\x03\x35\x31\x32\x12\'\n\x1a\x66irst_stage_minibatch_size\x18\x0b \x01(\x05:\x03\x32\x35\x36\x12\x32\n%first_stage_positive_balance_fraction\x18\x0c \x01(\x02:\x03\x30.5\x12*\n\x1f\x66irst_stage_nms_score_threshold\x18\r \x01(\x02:\x01\x30\x12*\n\x1d\x66irst_stage_nms_iou_threshold\x18\x0e \x01(\x02:\x03\x30.7\x12&\n\x19\x66irst_stage_max_proposals\x18\x0f \x01(\x05:\x03\x33\x30\x30\x12/\n$first_stage_localization_loss_weight\x18\x10 \x01(\x02:\x01\x32\x12-\n\"first_stage_objectness_loss_weight\x18\x11 \x01(\x02:\x01\x31\x12W\n\x1asecond_stage_box_predictor\x18\x15 \x02(\x0b\x32\x33.deepomatic.oef.models.image.detection.BoxPredictor\x12#\n\x17second_stage_batch_size\x18\x16 \x01(\x05:\x02\x36\x34\x12+\n\x1dsecond_stage_balance_fraction\x18\x17 \x01(\x02:\x04\x30.25\x12[\n\x1csecond_stage_post_processing\x18\x18 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.PostProcessing\x12\x30\n%second_stage_localization_loss_weight\x18\x19 \x01(\x02:\x01\x32\x12\x32\n\'second_stage_classification_loss_weight\x18\x1a \x01(\x02:\x01\x31\x12\x33\n(second_stage_mask_prediction_loss_weight\x18\x1b \x01(\x02:\x01\x31\x12S\n\x12hard_example_miner\x18\x1c \x01(\x0b\x32\x37.deepomatic.oef.models.image.detection.HardExampleMiner\x12S\n second_stage_classification_loss\x18\x1d \x02(\x0b\x32).deepomatic.oef.losses.ClassificationLoss\x12\'\n\x18inplace_batchnorm_update\x18\x1e \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_matmul_crop_and_resize\x18\x1f \x01(\x08:\x05\x66\x61lse\x12$\n\x15\x63lip_anchors_to_image\x18  \x01(\x08:\x05\x66\x61lse\x12+\n\x1cuse_matmul_gather_in_matcher\x18! \x01(\x08:\x05\x66\x61lse\x12\x30\n!use_static_balanced_label_sampler\x18\" \x01(\x08:\x05\x66\x61lse\x12 \n\x11use_static_shapes\x18# \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_static_shapes_for_eval\x18% \x01(\x08:\x05\x66\x61lse\x12\x30\n\"use_partitioned_nms_in_first_stage\x18& \x01(\x08:\x04true\x12\x33\n$return_raw_detections_during_predict\x18\' \x01(\x08:\x05\x66\x61lse\x12.\n\x1fuse_combined_nms_in_first_stage\x18( \x01(\x08:\x05\x66\x61lse\"\xb3\x0c\n\x13SSDMetaArchitecture\x12U\n\x11\x66\x65\x61ture_extractor\x18\x03 \x02(\x0b\x32:.deepomatic.oef.models.image.detection.SSDFeatureExtractor\x12\x42\n\tbox_coder\x18\x04 \x02(\x0b\x32/.deepomatic.oef.models.image.detection.BoxCoder\x12?\n\x07matcher\x18\x05 \x02(\x0b\x32..deepomatic.oef.models.image.detection.Matcher\x12`\n\x15similarity_calculator\x18\x06 \x02(\x0b\x32\x41.deepomatic.oef.models.image.detection.RegionSimilarityCalculator\x12)\n\x1a\x65ncode_background_as_zeros\x18\x0c \x01(\x08:\x05\x66\x61lse\x12 \n\x15negative_class_weight\x18\r \x01(\x02:\x01\x31\x12J\n\rbox_predictor\x18\x07 \x01(\x0b\x32\x33.deepomatic.oef.models.image.detection.BoxPredictor\x12P\n\x10\x61nchor_generator\x18\x08 \x02(\x0b\x32\x36.deepomatic.oef.models.image.detection.AnchorGenerator\x12N\n\x0fpost_processing\x18\t \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.PostProcessing\x12+\n\x1dnormalize_loss_by_num_matches\x18\n \x01(\x08:\x04true\x12-\n\x1enormalize_loc_loss_by_codesize\x18\x0e \x01(\x08:\x05\x66\x61lse\x12+\n\x06losses\x18\x0b \x02(\x0b\x32\x1b.deepomatic.oef.losses.Loss\x12\x1f\n\x10\x66reeze_batchnorm\x18\x10 \x01(\x08:\x05\x66\x61lse\x12\'\n\x18inplace_batchnorm_update\x18\x0f \x01(\x08:\x05\x66\x61lse\x12\"\n\x14\x61\x64\x64_background_class\x18\x15 \x01(\x08:\x04true\x12(\n\x19\x65xplicit_background_class\x18\x18 \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_confidences_as_targets\x18\x16 \x01(\x08:\x05\x66\x61lse\x12\"\n\x17implicit_example_weight\x18\x17 \x01(\x02:\x01\x31\x12\x33\n$return_raw_detections_during_predict\x18\x1a \x01(\x08:\x05\x66\x61lse\x12]\n\x10mask_head_config\x18\x19 \x01(\x0b\x32\x43.deepomatic.oef.models.image.detection.SSDMetaArchitecture.MaskHead\x1a\x9e\x03\n\x08MaskHead\x12\x17\n\x0bmask_height\x18\x01 \x01(\x05:\x02\x31\x35\x12\x16\n\nmask_width\x18\x02 \x01(\x05:\x02\x31\x35\x12&\n\x18masks_are_class_agnostic\x18\x03 \x01(\x08:\x04true\x12\'\n\x1amask_prediction_conv_depth\x18\x04 \x01(\x05:\x03\x32\x35\x36\x12*\n\x1fmask_prediction_num_conv_layers\x18\x05 \x01(\x05:\x01\x32\x12+\n\x1c\x63onvolve_then_upsample_masks\x18\x06 \x01(\x08:\x05\x66\x61lse\x12\x1b\n\x10mask_loss_weight\x18\x07 \x01(\x02:\x01\x35\x12!\n\x15mask_loss_sample_size\x18\x08 \x01(\x05:\x02\x31\x36\x12X\n\x10\x63onv_hyperparams\x18\t \x01(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x1d\n\x11initial_crop_size\x18\n \x01(\x05:\x02\x31\x35\"\xb7\x02\n\x13SSDFeatureExtractor\x12X\n\x10\x63onv_hyperparams\x18\x04 \x01(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x1a\n\x0fpad_to_multiple\x18\x05 \x01(\x05:\x01\x31\x12#\n\x14use_explicit_padding\x18\x07 \x01(\x08:\x05\x66\x61lse\x12\x1c\n\ruse_depthwise\x18\x08 \x01(\x08:\x05\x66\x61lse\x12J\n\x03\x66pn\x18\n \x01(\x0b\x32=.deepomatic.oef.models.image.detection.FeaturePyramidNetworks\x12\x15\n\nnum_layers\x18\x0c \x01(\x05:\x01\x36J\x04\x08\x06\x10\x07\"i\n\x16\x46\x65\x61turePyramidNetworks\x12\x14\n\tmin_level\x18\x01 \x01(\x05:\x01\x33\x12\x14\n\tmax_level\x18\x02 \x01(\x05:\x01\x37\x12#\n\x16\x61\x64\x64itional_layer_depth\x18\x03 \x01(\x05:\x03\x32\x35\x36\"n\n\x0eYoloParameters\x12\x14\n\x0csubdivisions\x18\x02 \x02(\x05\x12\x46\n\x13\x63lassification_loss\x18\x03 \x02(\x0b\x32).deepomatic.oef.losses.ClassificationLoss\"\xb7\x01\n\x1a\x46\x61sterRCNNMetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.RCNNParameters\x12\x19\n\x11initial_crop_size\x18\x12 \x02(\x05\x12\x1b\n\x13maxpool_kernel_size\x18\x13 \x02(\x05\x12\x16\n\x0emaxpool_stride\x18\x14 \x02(\x05\"a\n\x14RFCNMetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.RCNNParameters\"c\n\x16YoloV2MetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.YoloParameters\"c\n\x16YoloV3MetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.YoloParameters\"\xf5\x05\n\x1c\x45\x66\x66icientDetMetaArchitecture\x12\"\n\x13\x61\x63tivation_function\x18\x01 \x01(\t:\x05swish\x12\x14\n\tmin_level\x18\x02 \x01(\x05:\x01\x33\x12\x14\n\tmax_level\x18\x03 \x01(\x05:\x01\x37\x12\x15\n\nnum_scales\x18\x04 \x01(\x05:\x01\x33\x12\x66\n\raspect_ratios\x18\x05 \x03(\x0b\x32O.deepomatic.oef.models.image.detection.EfficientDetMetaArchitecture.AspectRatio\x12\x17\n\x0c\x61nchor_scale\x18\x06 \x01(\x02:\x01\x34\x12\x13\n\x05\x61lpha\x18\x07 \x01(\x02:\x04\x30.25\x12\x12\n\x05gamma\x18\x08 \x01(\x02:\x03\x31.5\x12\x12\n\x05\x64\x65lta\x18\t \x01(\x02:\x03\x30.1\x12\x1b\n\x0f\x62ox_loss_weight\x18\n \x01(\x02:\x02\x35\x30\x12l\n\riou_loss_type\x18\x0b \x01(\x0e\x32O.deepomatic.oef.models.image.detection.EfficientDetMetaArchitecture.IOULossType:\x04NONE\x12\x1a\n\x0fiou_loss_weight\x18\x0c \x01(\x02:\x01\x31\x12\x1b\n\x0cweight_decay\x18\r \x01(\x02:\x05\x34\x65-05\x12\x1c\n\x11\x62ox_class_repeats\x18\x0e \x01(\x05:\x01\x33\x12\x1b\n\x10\x66pn_cell_repeats\x18\x0f \x01(\x05:\x01\x33\x12\x1b\n\x0f\x66pn_num_filters\x18\x10 \x01(\x05:\x02\x38\x38\x12\x1a\n\x08\x66pn_name\x18\x11 \x01(\t:\x08\x62ifpn_fa\x1a\x38\n\x0b\x41spectRatio\x12\x14\n\x0cheight_ratio\x18\x01 \x02(\x02\x12\x13\n\x0bwidth_ratio\x18\x02 \x02(\x02\">\n\x0bIOULossType\x12\x08\n\x04NONE\x10\x00\x12\x07\n\x03iou\x10\x01\x12\x08\n\x04\x63iou\x10\x02\x12\x08\n\x04\x64iou\x10\x03\x12\x08\n\x04giou\x10\x04\"\xf7\x04\n\tDetection\x12\x41\n\x08\x62\x61\x63kbone\x18\x01 \x02(\x0b\x32/.deepomatic.oef.models.image.backbones.Backbone\x12\x1a\n\x0flabel_smoothing\x18\x02 \x01(\x02:\x01\x30\x12X\n\x0b\x66\x61ster_rcnn\x18\x10 \x01(\x0b\x32\x41.deepomatic.oef.models.image.detection.FasterRCNNMetaArchitectureH\x00\x12K\n\x04rfcn\x18\x11 \x01(\x0b\x32;.deepomatic.oef.models.image.detection.RFCNMetaArchitectureH\x00\x12I\n\x03ssd\x18\x12 \x01(\x0b\x32:.deepomatic.oef.models.image.detection.SSDMetaArchitectureH\x00\x12P\n\x07yolo_v2\x18\x13 \x01(\x0b\x32=.deepomatic.oef.models.image.detection.YoloV2MetaArchitectureH\x00\x12P\n\x07yolo_v3\x18\x14 \x01(\x0b\x32=.deepomatic.oef.models.image.detection.YoloV3MetaArchitectureH\x00\x12[\n\x0c\x65\x66\x66icientdet\x18\x15 \x01(\x0b\x32\x43.deepomatic.oef.models.image.detection.EfficientDetMetaArchitectureH\x00\x42\x18\n\x16meta_architecture_type')
+  serialized_pb=_b('\n2deepomatic/oef/protos/models/image/detection.proto\x12%deepomatic.oef.models.image.detection\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/backbones.proto\x1a>deepomatic/oef/protos/models/image/utils/hyperparameters.proto\x1a\"deepomatic/oef/protos/losses.proto\x1a\x43\x64\x65\x65pomatic/oef/protos/models/image/detection/anchor_generator.proto\x1a@deepomatic/oef/protos/models/image/detection/example_miner.proto\x1a@deepomatic/oef/protos/models/image/detection/box_predictor.proto\x1a<deepomatic/oef/protos/models/image/detection/box_coder.proto\x1a:deepomatic/oef/protos/models/image/detection/matcher.proto\x1a\x42\x64\x65\x65pomatic/oef/protos/models/image/detection/post_processing.proto\x1aOdeepomatic/oef/protos/models/image/detection/region_similarity_calculator.proto\"\x98\x0e\n\x0eRCNNParameters\x12\x1b\n\x10number_of_stages\x18\x01 \x01(\x05:\x01\x32\x12\'\n\x1b\x66irst_stage_features_stride\x18\x02 \x01(\x05:\x02\x31\x36\x12#\n\x14\x62\x61tch_norm_trainable\x18\x03 \x01(\x08:\x05\x66\x61lse\x12\\\n\x1c\x66irst_stage_anchor_generator\x18\x06 \x02(\x0b\x32\x36.deepomatic.oef.models.image.detection.AnchorGenerator\x12\"\n\x17\x66irst_stage_atrous_rate\x18\x07 \x01(\x05:\x01\x31\x12r\n*first_stage_box_predictor_conv_hyperparams\x18\x08 \x02(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x30\n%first_stage_box_predictor_kernel_size\x18\t \x01(\x05:\x01\x33\x12,\n\x1f\x66irst_stage_box_predictor_depth\x18\n \x01(\x05:\x03\x35\x31\x32\x12\'\n\x1a\x66irst_stage_minibatch_size\x18\x0b \x01(\x05:\x03\x32\x35\x36\x12\x32\n%first_stage_positive_balance_fraction\x18\x0c \x01(\x02:\x03\x30.5\x12*\n\x1f\x66irst_stage_nms_score_threshold\x18\r \x01(\x02:\x01\x30\x12*\n\x1d\x66irst_stage_nms_iou_threshold\x18\x0e \x01(\x02:\x03\x30.7\x12&\n\x19\x66irst_stage_max_proposals\x18\x0f \x01(\x05:\x03\x33\x30\x30\x12/\n$first_stage_localization_loss_weight\x18\x10 \x01(\x02:\x01\x32\x12-\n\"first_stage_objectness_loss_weight\x18\x11 \x01(\x02:\x01\x31\x12W\n\x1asecond_stage_box_predictor\x18\x15 \x02(\x0b\x32\x33.deepomatic.oef.models.image.detection.BoxPredictor\x12#\n\x17second_stage_batch_size\x18\x16 \x01(\x05:\x02\x36\x34\x12+\n\x1dsecond_stage_balance_fraction\x18\x17 \x01(\x02:\x04\x30.25\x12[\n\x1csecond_stage_post_processing\x18\x18 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.PostProcessing\x12\x30\n%second_stage_localization_loss_weight\x18\x19 \x01(\x02:\x01\x32\x12\x32\n\'second_stage_classification_loss_weight\x18\x1a \x01(\x02:\x01\x31\x12\x33\n(second_stage_mask_prediction_loss_weight\x18\x1b \x01(\x02:\x01\x31\x12S\n\x12hard_example_miner\x18\x1c \x01(\x0b\x32\x37.deepomatic.oef.models.image.detection.HardExampleMiner\x12S\n second_stage_classification_loss\x18\x1d \x02(\x0b\x32).deepomatic.oef.losses.ClassificationLoss\x12\'\n\x18inplace_batchnorm_update\x18\x1e \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_matmul_crop_and_resize\x18\x1f \x01(\x08:\x05\x66\x61lse\x12$\n\x15\x63lip_anchors_to_image\x18  \x01(\x08:\x05\x66\x61lse\x12+\n\x1cuse_matmul_gather_in_matcher\x18! \x01(\x08:\x05\x66\x61lse\x12\x30\n!use_static_balanced_label_sampler\x18\" \x01(\x08:\x05\x66\x61lse\x12 \n\x11use_static_shapes\x18# \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_static_shapes_for_eval\x18% \x01(\x08:\x05\x66\x61lse\x12\x30\n\"use_partitioned_nms_in_first_stage\x18& \x01(\x08:\x04true\x12\x33\n$return_raw_detections_during_predict\x18\' \x01(\x08:\x05\x66\x61lse\x12.\n\x1fuse_combined_nms_in_first_stage\x18( \x01(\x08:\x05\x66\x61lse\"\xb3\x0c\n\x13SSDMetaArchitecture\x12U\n\x11\x66\x65\x61ture_extractor\x18\x03 \x02(\x0b\x32:.deepomatic.oef.models.image.detection.SSDFeatureExtractor\x12\x42\n\tbox_coder\x18\x04 \x02(\x0b\x32/.deepomatic.oef.models.image.detection.BoxCoder\x12?\n\x07matcher\x18\x05 \x02(\x0b\x32..deepomatic.oef.models.image.detection.Matcher\x12`\n\x15similarity_calculator\x18\x06 \x02(\x0b\x32\x41.deepomatic.oef.models.image.detection.RegionSimilarityCalculator\x12)\n\x1a\x65ncode_background_as_zeros\x18\x0c \x01(\x08:\x05\x66\x61lse\x12 \n\x15negative_class_weight\x18\r \x01(\x02:\x01\x31\x12J\n\rbox_predictor\x18\x07 \x01(\x0b\x32\x33.deepomatic.oef.models.image.detection.BoxPredictor\x12P\n\x10\x61nchor_generator\x18\x08 \x02(\x0b\x32\x36.deepomatic.oef.models.image.detection.AnchorGenerator\x12N\n\x0fpost_processing\x18\t \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.PostProcessing\x12+\n\x1dnormalize_loss_by_num_matches\x18\n \x01(\x08:\x04true\x12-\n\x1enormalize_loc_loss_by_codesize\x18\x0e \x01(\x08:\x05\x66\x61lse\x12+\n\x06losses\x18\x0b \x02(\x0b\x32\x1b.deepomatic.oef.losses.Loss\x12\x1f\n\x10\x66reeze_batchnorm\x18\x10 \x01(\x08:\x05\x66\x61lse\x12\'\n\x18inplace_batchnorm_update\x18\x0f \x01(\x08:\x05\x66\x61lse\x12\"\n\x14\x61\x64\x64_background_class\x18\x15 \x01(\x08:\x04true\x12(\n\x19\x65xplicit_background_class\x18\x18 \x01(\x08:\x05\x66\x61lse\x12)\n\x1ause_confidences_as_targets\x18\x16 \x01(\x08:\x05\x66\x61lse\x12\"\n\x17implicit_example_weight\x18\x17 \x01(\x02:\x01\x31\x12\x33\n$return_raw_detections_during_predict\x18\x1a \x01(\x08:\x05\x66\x61lse\x12]\n\x10mask_head_config\x18\x19 \x01(\x0b\x32\x43.deepomatic.oef.models.image.detection.SSDMetaArchitecture.MaskHead\x1a\x9e\x03\n\x08MaskHead\x12\x17\n\x0bmask_height\x18\x01 \x01(\x05:\x02\x31\x35\x12\x16\n\nmask_width\x18\x02 \x01(\x05:\x02\x31\x35\x12&\n\x18masks_are_class_agnostic\x18\x03 \x01(\x08:\x04true\x12\'\n\x1amask_prediction_conv_depth\x18\x04 \x01(\x05:\x03\x32\x35\x36\x12*\n\x1fmask_prediction_num_conv_layers\x18\x05 \x01(\x05:\x01\x32\x12+\n\x1c\x63onvolve_then_upsample_masks\x18\x06 \x01(\x08:\x05\x66\x61lse\x12\x1b\n\x10mask_loss_weight\x18\x07 \x01(\x02:\x01\x35\x12!\n\x15mask_loss_sample_size\x18\x08 \x01(\x05:\x02\x31\x36\x12X\n\x10\x63onv_hyperparams\x18\t \x01(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x1d\n\x11initial_crop_size\x18\n \x01(\x05:\x02\x31\x35\"\xb7\x02\n\x13SSDFeatureExtractor\x12X\n\x10\x63onv_hyperparams\x18\x04 \x01(\x0b\x32>.deepomatic.oef.models.image.utils.hyperparameters.Hyperparams\x12\x1a\n\x0fpad_to_multiple\x18\x05 \x01(\x05:\x01\x31\x12#\n\x14use_explicit_padding\x18\x07 \x01(\x08:\x05\x66\x61lse\x12\x1c\n\ruse_depthwise\x18\x08 \x01(\x08:\x05\x66\x61lse\x12J\n\x03\x66pn\x18\n \x01(\x0b\x32=.deepomatic.oef.models.image.detection.FeaturePyramidNetworks\x12\x15\n\nnum_layers\x18\x0c \x01(\x05:\x01\x36J\x04\x08\x06\x10\x07\"i\n\x16\x46\x65\x61turePyramidNetworks\x12\x14\n\tmin_level\x18\x01 \x01(\x05:\x01\x33\x12\x14\n\tmax_level\x18\x02 \x01(\x05:\x01\x37\x12#\n\x16\x61\x64\x64itional_layer_depth\x18\x03 \x01(\x05:\x03\x32\x35\x36\"n\n\x0eYoloParameters\x12\x14\n\x0csubdivisions\x18\x02 \x02(\x05\x12\x46\n\x13\x63lassification_loss\x18\x03 \x02(\x0b\x32).deepomatic.oef.losses.ClassificationLoss\"\xb7\x01\n\x1a\x46\x61sterRCNNMetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.RCNNParameters\x12\x19\n\x11initial_crop_size\x18\x12 \x02(\x05\x12\x1b\n\x13maxpool_kernel_size\x18\x13 \x02(\x05\x12\x16\n\x0emaxpool_stride\x18\x14 \x02(\x05\"a\n\x14RFCNMetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.RCNNParameters\"c\n\x16YoloV2MetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.YoloParameters\"c\n\x16YoloV3MetaArchitecture\x12I\n\nparameters\x18\x01 \x02(\x0b\x32\x35.deepomatic.oef.models.image.detection.YoloParameters\"\xf5\x05\n\x1c\x45\x66\x66icientDetMetaArchitecture\x12\"\n\x13\x61\x63tivation_function\x18\x01 \x01(\t:\x05swish\x12\x14\n\tmin_level\x18\x02 \x01(\x05:\x01\x33\x12\x14\n\tmax_level\x18\x03 \x01(\x05:\x01\x37\x12\x15\n\nnum_scales\x18\x04 \x01(\x05:\x01\x33\x12\x66\n\raspect_ratios\x18\x05 \x03(\x0b\x32O.deepomatic.oef.models.image.detection.EfficientDetMetaArchitecture.AspectRatio\x12\x17\n\x0c\x61nchor_scale\x18\x06 \x01(\x02:\x01\x34\x12\x13\n\x05\x61lpha\x18\x07 \x01(\x02:\x04\x30.25\x12\x12\n\x05gamma\x18\x08 \x01(\x02:\x03\x31.5\x12\x12\n\x05\x64\x65lta\x18\t \x01(\x02:\x03\x30.1\x12\x1b\n\x0f\x62ox_loss_weight\x18\n \x01(\x02:\x02\x35\x30\x12l\n\riou_loss_type\x18\x0b \x01(\x0e\x32O.deepomatic.oef.models.image.detection.EfficientDetMetaArchitecture.IOULossType:\x04NONE\x12\x1a\n\x0fiou_loss_weight\x18\x0c \x01(\x02:\x01\x31\x12\x1b\n\x0cweight_decay\x18\r \x01(\x02:\x05\x34\x65-05\x12\x1c\n\x11\x62ox_class_repeats\x18\x0e \x01(\x05:\x01\x33\x12\x1b\n\x10\x66pn_cell_repeats\x18\x0f \x01(\x05:\x01\x33\x12\x1b\n\x0f\x66pn_num_filters\x18\x10 \x01(\x05:\x02\x38\x38\x12\x1a\n\x08\x66pn_name\x18\x11 \x01(\t:\x08\x62ifpn_fa\x1a\x38\n\x0b\x41spectRatio\x12\x14\n\x0cheight_ratio\x18\x01 \x02(\x02\x12\x13\n\x0bwidth_ratio\x18\x02 \x02(\x02\">\n\x0bIOULossType\x12\x08\n\x04NONE\x10\x00\x12\x07\n\x03iou\x10\x01\x12\x08\n\x04\x63iou\x10\x02\x12\x08\n\x04\x64iou\x10\x03\x12\x08\n\x04giou\x10\x04\"\xcd\x05\n\tDetection\x12\x41\n\x08\x62\x61\x63kbone\x18\x01 \x02(\x0b\x32/.deepomatic.oef.models.image.backbones.Backbone\x12\x1a\n\x0flabel_smoothing\x18\x02 \x01(\x02:\x01\x30\x12X\n\x0b\x66\x61ster_rcnn\x18\x10 \x01(\x0b\x32\x41.deepomatic.oef.models.image.detection.FasterRCNNMetaArchitectureH\x00\x12K\n\x04rfcn\x18\x11 \x01(\x0b\x32;.deepomatic.oef.models.image.detection.RFCNMetaArchitectureH\x00\x12I\n\x03ssd\x18\x12 \x01(\x0b\x32:.deepomatic.oef.models.image.detection.SSDMetaArchitectureH\x00\x12P\n\x07yolo_v2\x18\x13 \x01(\x0b\x32=.deepomatic.oef.models.image.detection.YoloV2MetaArchitectureH\x00\x12P\n\x07yolo_v3\x18\x14 \x01(\x0b\x32=.deepomatic.oef.models.image.detection.YoloV3MetaArchitectureH\x00\x12T\n\x0byolo_v3_spp\x18\x16 \x01(\x0b\x32=.deepomatic.oef.models.image.detection.YoloV3MetaArchitectureH\x00\x12[\n\x0c\x65\x66\x66icientdet\x18\x15 \x01(\x0b\x32\x43.deepomatic.oef.models.image.detection.EfficientDetMetaArchitectureH\x00\x42\x18\n\x16meta_architecture_type')
   ,
   dependencies=[deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_backbones__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_utils_dot_hyperparameters__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_losses__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_anchor__generator__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_example__miner__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_box__predictor__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_box__coder__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_matcher__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_post__processing__pb2.DESCRIPTOR,deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_region__similarity__calculator__pb2.DESCRIPTOR,])
 
 
 
 _EFFICIENTDETMETAARCHITECTURE_IOULOSSTYPE = _descriptor.EnumDescriptor(
   name='IOULossType',
@@ -1117,15 +1117,22 @@
       name='yolo_v3', full_name='deepomatic.oef.models.image.detection.Detection.yolo_v3', index=6,
       number=20, type=11, cpp_type=10, label=1,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
     _descriptor.FieldDescriptor(
-      name='efficientdet', full_name='deepomatic.oef.models.image.detection.Detection.efficientdet', index=7,
+      name='yolo_v3_spp', full_name='deepomatic.oef.models.image.detection.Detection.yolo_v3_spp', index=7,
+      number=22, type=11, cpp_type=10, label=1,
+      has_default_value=False, default_value=None,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='efficientdet', full_name='deepomatic.oef.models.image.detection.Detection.efficientdet', index=8,
       number=21, type=11, cpp_type=10, label=1,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
   ],
   extensions=[
@@ -1139,15 +1146,15 @@
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='meta_architecture_type', full_name='deepomatic.oef.models.image.detection.Detection.meta_architecture_type',
       index=0, containing_type=None, fields=[]),
   ],
   serialized_start=5907,
-  serialized_end=6538,
+  serialized_end=6624,
 )
 
 _RCNNPARAMETERS.fields_by_name['first_stage_anchor_generator'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_anchor__generator__pb2._ANCHORGENERATOR
 _RCNNPARAMETERS.fields_by_name['first_stage_box_predictor_conv_hyperparams'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_utils_dot_hyperparameters__pb2._HYPERPARAMS
 _RCNNPARAMETERS.fields_by_name['second_stage_box_predictor'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_box__predictor__pb2._BOXPREDICTOR
 _RCNNPARAMETERS.fields_by_name['second_stage_post_processing'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_post__processing__pb2._POSTPROCESSING
 _RCNNPARAMETERS.fields_by_name['hard_example_miner'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_detection_dot_example__miner__pb2._HARDEXAMPLEMINER
@@ -1176,14 +1183,15 @@
 _EFFICIENTDETMETAARCHITECTURE_IOULOSSTYPE.containing_type = _EFFICIENTDETMETAARCHITECTURE
 _DETECTION.fields_by_name['backbone'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_backbones__pb2._BACKBONE
 _DETECTION.fields_by_name['faster_rcnn'].message_type = _FASTERRCNNMETAARCHITECTURE
 _DETECTION.fields_by_name['rfcn'].message_type = _RFCNMETAARCHITECTURE
 _DETECTION.fields_by_name['ssd'].message_type = _SSDMETAARCHITECTURE
 _DETECTION.fields_by_name['yolo_v2'].message_type = _YOLOV2METAARCHITECTURE
 _DETECTION.fields_by_name['yolo_v3'].message_type = _YOLOV3METAARCHITECTURE
+_DETECTION.fields_by_name['yolo_v3_spp'].message_type = _YOLOV3METAARCHITECTURE
 _DETECTION.fields_by_name['efficientdet'].message_type = _EFFICIENTDETMETAARCHITECTURE
 _DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
   _DETECTION.fields_by_name['faster_rcnn'])
 _DETECTION.fields_by_name['faster_rcnn'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
 _DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
   _DETECTION.fields_by_name['rfcn'])
 _DETECTION.fields_by_name['rfcn'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
@@ -1193,14 +1201,17 @@
 _DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
   _DETECTION.fields_by_name['yolo_v2'])
 _DETECTION.fields_by_name['yolo_v2'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
 _DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
   _DETECTION.fields_by_name['yolo_v3'])
 _DETECTION.fields_by_name['yolo_v3'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
 _DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
+  _DETECTION.fields_by_name['yolo_v3_spp'])
+_DETECTION.fields_by_name['yolo_v3_spp'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
+_DETECTION.oneofs_by_name['meta_architecture_type'].fields.append(
   _DETECTION.fields_by_name['efficientdet'])
 _DETECTION.fields_by_name['efficientdet'].containing_oneof = _DETECTION.oneofs_by_name['meta_architecture_type']
 DESCRIPTOR.message_types_by_name['RCNNParameters'] = _RCNNPARAMETERS
 DESCRIPTOR.message_types_by_name['SSDMetaArchitecture'] = _SSDMETAARCHITECTURE
 DESCRIPTOR.message_types_by_name['SSDFeatureExtractor'] = _SSDFEATUREEXTRACTOR
 DESCRIPTOR.message_types_by_name['FeaturePyramidNetworks'] = _FEATUREPYRAMIDNETWORKS
 DESCRIPTOR.message_types_by_name['YoloParameters'] = _YOLOPARAMETERS
```

## deepomatic/oef/protos/models/image/ocr_pb2.py

```diff
@@ -16,15 +16,15 @@
 from deepomatic.oef.protos.models.image import backbones_pb2 as deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_backbones__pb2
 
 
 DESCRIPTOR = _descriptor.FileDescriptor(
   name='deepomatic/oef/protos/models/image/ocr.proto',
   package='deepomatic.oef.models.image.ocr',
   syntax='proto2',
-  serialized_pb=_b('\n,deepomatic/oef/protos/models/image/ocr.proto\x12\x1f\x64\x65\x65pomatic.oef.models.image.ocr\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/backbones.proto\"p\n\tAttention\x12 \n\x12use_autoregression\x18\x01 \x01(\x08:\x04true\x12\x1b\n\x0enum_lstm_units\x18\x02 \x01(\x05:\x03\x32\x35\x36\x12$\n\x16use_coordinate_feature\x18\x03 \x01(\x08:\x04true\"\xdd\x01\n\x03OCR\x12\x41\n\x08\x62\x61\x63kbone\x18\x01 \x02(\x0b\x32/.deepomatic.oef.models.image.backbones.Backbone\x12\x1a\n\x0flabel_smoothing\x18\x02 \x01(\x02:\x01\x30\x12\x1c\n\x11\x66\x65\x61ture_map_ratio\x18\x03 \x01(\x05:\x01\x38\x12?\n\tattention\x18\x10 \x01(\x0b\x32*.deepomatic.oef.models.image.ocr.AttentionH\x00\x42\x18\n\x16meta_architecture_type')
+  serialized_pb=_b('\n,deepomatic/oef/protos/models/image/ocr.proto\x12\x1f\x64\x65\x65pomatic.oef.models.image.ocr\x1a\x32\x64\x65\x65pomatic/oef/protos/models/image/backbones.proto\"\xec\x01\n\tAttention\x12 \n\x12use_autoregression\x18\x01 \x01(\x08:\x04true\x12\x1b\n\x0enum_lstm_units\x18\x02 \x01(\x05:\x03\x32\x35\x36\x12$\n\x16use_coordinate_feature\x18\x03 \x01(\x08:\x04true\x12\x1c\n\x11\x66\x65\x61ture_map_ratio\x18\x04 \x01(\x05:\x01\x38\x12\x1b\n\x0cweight_decay\x18\x05 \x01(\x02:\x05\x34\x65-05\x12!\n\x15lstm_state_clip_value\x18\x06 \x01(\x02:\x02\x31\x30\x12\x1c\n\x0flabel_smoothing\x18\x07 \x01(\x02:\x03\x30.1\"\xa3\x01\n\x03OCR\x12\x41\n\x08\x62\x61\x63kbone\x18\x01 \x02(\x0b\x32/.deepomatic.oef.models.image.backbones.Backbone\x12?\n\tattention\x18\x10 \x01(\x0b\x32*.deepomatic.oef.models.image.ocr.AttentionH\x00\x42\x18\n\x16meta_architecture_type')
   ,
   dependencies=[deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_backbones__pb2.DESCRIPTOR,])
 
 
 
 
 _ATTENTION = _descriptor.Descriptor(
@@ -51,28 +51,56 @@
     _descriptor.FieldDescriptor(
       name='use_coordinate_feature', full_name='deepomatic.oef.models.image.ocr.Attention.use_coordinate_feature', index=2,
       number=3, type=8, cpp_type=7, label=1,
       has_default_value=True, default_value=True,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
+    _descriptor.FieldDescriptor(
+      name='feature_map_ratio', full_name='deepomatic.oef.models.image.ocr.Attention.feature_map_ratio', index=3,
+      number=4, type=5, cpp_type=1, label=1,
+      has_default_value=True, default_value=8,
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='weight_decay', full_name='deepomatic.oef.models.image.ocr.Attention.weight_decay', index=4,
+      number=5, type=2, cpp_type=6, label=1,
+      has_default_value=True, default_value=float(4e-05),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='lstm_state_clip_value', full_name='deepomatic.oef.models.image.ocr.Attention.lstm_state_clip_value', index=5,
+      number=6, type=2, cpp_type=6, label=1,
+      has_default_value=True, default_value=float(10),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
+    _descriptor.FieldDescriptor(
+      name='label_smoothing', full_name='deepomatic.oef.models.image.ocr.Attention.label_smoothing', index=6,
+      number=7, type=2, cpp_type=6, label=1,
+      has_default_value=True, default_value=float(0.1),
+      message_type=None, enum_type=None, containing_type=None,
+      is_extension=False, extension_scope=None,
+      options=None),
   ],
   extensions=[
   ],
   nested_types=[],
   enum_types=[
   ],
   options=None,
   is_extendable=False,
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
   ],
-  serialized_start=133,
-  serialized_end=245,
+  serialized_start=134,
+  serialized_end=370,
 )
 
 
 _OCR = _descriptor.Descriptor(
   name='OCR',
   full_name='deepomatic.oef.models.image.ocr.OCR',
   filename=None,
@@ -83,29 +111,15 @@
       name='backbone', full_name='deepomatic.oef.models.image.ocr.OCR.backbone', index=0,
       number=1, type=11, cpp_type=10, label=2,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
     _descriptor.FieldDescriptor(
-      name='label_smoothing', full_name='deepomatic.oef.models.image.ocr.OCR.label_smoothing', index=1,
-      number=2, type=2, cpp_type=6, label=1,
-      has_default_value=True, default_value=float(0),
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      options=None),
-    _descriptor.FieldDescriptor(
-      name='feature_map_ratio', full_name='deepomatic.oef.models.image.ocr.OCR.feature_map_ratio', index=2,
-      number=3, type=5, cpp_type=1, label=1,
-      has_default_value=True, default_value=8,
-      message_type=None, enum_type=None, containing_type=None,
-      is_extension=False, extension_scope=None,
-      options=None),
-    _descriptor.FieldDescriptor(
-      name='attention', full_name='deepomatic.oef.models.image.ocr.OCR.attention', index=3,
+      name='attention', full_name='deepomatic.oef.models.image.ocr.OCR.attention', index=1,
       number=16, type=11, cpp_type=10, label=1,
       has_default_value=False, default_value=None,
       message_type=None, enum_type=None, containing_type=None,
       is_extension=False, extension_scope=None,
       options=None),
   ],
   extensions=[
@@ -118,16 +132,16 @@
   syntax='proto2',
   extension_ranges=[],
   oneofs=[
     _descriptor.OneofDescriptor(
       name='meta_architecture_type', full_name='deepomatic.oef.models.image.ocr.OCR.meta_architecture_type',
       index=0, containing_type=None, fields=[]),
   ],
-  serialized_start=248,
-  serialized_end=469,
+  serialized_start=373,
+  serialized_end=536,
 )
 
 _OCR.fields_by_name['backbone'].message_type = deepomatic_dot_oef_dot_protos_dot_models_dot_image_dot_backbones__pb2._BACKBONE
 _OCR.fields_by_name['attention'].message_type = _ATTENTION
 _OCR.oneofs_by_name['meta_architecture_type'].fields.append(
   _OCR.fields_by_name['attention'])
 _OCR.fields_by_name['attention'].containing_oneof = _OCR.oneofs_by_name['meta_architecture_type']
```

## deepomatic/oef/utils/class_helpers.py

```diff
@@ -1,91 +1,40 @@
-from enum import Enum
 import importlib
 
-serializer_class = None  # this is a small hack to delay the loading of the Serializer class to break an import loop (serializer.py loads class_helper)
-
 api_prefix = 'deepomatic.oef.'
 api_proto_prefix = api_prefix + 'protos.'
 proto_suffix = '_pb2'
 
-class ClassType(Enum):
-    PROTO = api_proto_prefix
-    API = api_prefix
-
-# -----------------------------------------------------------------------------#
-
-def split_path_into_module_and_class(path):
-    """
-    By convention, classes start with a capital letter and modules only have small letters.
-    We use that to split a path into module and class
-    """
-    module = []
-    classes = []
-    path = path.split('.')
-    for i, part in enumerate(path):
-        if part[0].isupper():
-            classes = path[i:]
-            break
-        module.append(part)
-    module = '.'.join(module)
-    return module, classes
-
-# -----------------------------------------------------------------------------#
-
-def get_normalized_module_and_classes(path):
-    """
-    Get the normalized (non back-end, without '_pb2') module name and class names from a path.
-    E.g. deepomatic.oef.Model.SubClass would return ('model', ['Model', 'SubClass'])
-    """
-
-    # Be careful, the order of the if branch matters
-    if path.startswith(api_proto_prefix):
-        path = path.replace(api_proto_prefix, '')
-        module, classes = split_path_into_module_and_class(path)
-        if module.endswith(proto_suffix):
-            module = module[:-len(proto_suffix)]
-        return module, classes
-    elif path.startswith(api_prefix):
-        path = path.replace(api_prefix, '')
-    else:
-        raise Exception("Unexpected path type, does not start with any known prefix: '{}'".format(path))
-
-    return split_path_into_module_and_class(path)
-
 # -----------------------------------------------------------------------------#
 
-def convert_module_path(path, to_type):
+def convert_module_path(path):
     """
     Takes a normalized module `path` and convert it to a specialized path of type `to_type`
     Args:
-        path (string): a module path, normalized by get_normalized_module_and_classes
-        to_type (ClassType): an enum of type ClassType
+        path (string): a module path
 
     Returns:
         string: The specialized module path.
     """
-    path = to_type.value + path
-    if to_type == ClassType.PROTO:
-        path += proto_suffix
-    return path
+    return api_proto_prefix + path + proto_suffix
 
 
 # -----------------------------------------------------------------------------#
 
-def load_class(module, classes, getter=getattr):
+def load_class(module, classes):
     """Load class from module path and a list of nested classes"""
     class_container = importlib.import_module(module)
     for c in classes:
-        class_container = getter(class_container, c)
+        class_container = getattr(class_container, c)
     return class_container
 
 
 # -----------------------------------------------------------------------------#
 
-def load_proto_class_from_protobuf_descriptor(descriptor, class_type=ClassType.PROTO, getter=getattr):
+def load_proto_class_from_protobuf_descriptor(descriptor):
     """
     Given a protobuf message descriptor, return its associated class: either the protobuf or the serializer
     """
     # We first extract the class name: careful as it may be nested messages.
     # For exemple: descriptor.full_name is `deepomatic.oef.models.image.backbones.EfficientNetBackbone.Version`
     # descriptor.file.package is `deepomatic.oef.models.image.backbones`
     # So field_type is `EfficientNetBackbone.Version`
@@ -96,11 +45,11 @@
     # Find the module name
     module_path = descriptor.file.name
     assert module_path.endswith('.proto'), "File type should normally end with '.proto'"
     module_path = module_path.replace('.proto', '').replace('/', '.')  # order matters for the replace
     assert module_path.startswith(api_proto_prefix), "Package should normally start with '{}'".format(api_proto_prefix)
     module_path = module_path.replace(api_proto_prefix, '')
 
-    module_path = convert_module_path(module_path, class_type)
-    return load_class(module_path, classes.split('.'), getter=getter)
+    module_path = convert_module_path(module_path)
+    return load_class(module_path, classes.split('.'))
 
 # -----------------------------------------------------------------------------#
```

## deepomatic/oef/utils/experiment_builder.py

```diff
@@ -1,17 +1,18 @@
 import copy
 import logging
 from google.protobuf.descriptor import FieldDescriptor
 from google.protobuf.message import Message
 import google.protobuf.json_format as json_format
 
 from deepomatic.oef.configs import model_list
-from deepomatic.oef.utils.serializer import Serializer
+from deepomatic.oef.utils.common import parse_protobuf_from_json_or_binary
 from deepomatic.oef.utils.class_helpers import load_proto_class_from_protobuf_descriptor
 from deepomatic.oef.protos.experiment_pb2 import Experiment
+from deepomatic.oef.protos.hyperparameter_pb2 import field_option, oneof_option, HyperParameter
 
 logger = logging.getLogger(__name__)
 
 
 class InvalidNet(Exception):
     pass
 
@@ -34,96 +35,213 @@
             model_type_key_new_format = '.'.join([model_type_key_parts[0], model_type_key_parts[-1]] + model_type_key_parts[1:-1])
             if model_type_key_new_format in self._model_list:
                 logger.warning("This model key format is deprecated: '{}'. Use '{}' instead.".format(model_type_key, model_type_key_new_format))
                 model_type_key = model_type_key_new_format
             else:
                 raise InvalidNet("Unknown model key '{}'. Also tried '{}' for backward compatibility.".format(model_type_key, model_type_key_new_format))
         self._model_args = self._model_list[model_type_key]
-
-    def get_model_param(self, param):
-        """
-        Search in args and default_args for `param`. This permits searching for a default parameter
-        from the model_list, after an Experiment has been built.
-        Warning: this should be used as a last resort, when you need a param from an Experiment, before even building it.
-        ```
-        builder = ExperimentBuilder(...)
-        batch_size = builder.get_model_param('batch_size')
-        xp = builder.build(num_train_steps = n / batch_size)
-        ```
-        All protobuf default params are exposed once it's built.
-        """
-        if param in self._model_args.default_args:
-            return self._model_args.default_args[param]
-        else:
-            logger.warn('Parameter not found in experiment builder: {}. Available model args are: {}'.format(param, self._model_args))
+        self._hyperparameters = {}
 
     @classmethod
     def load_model_list(cls):
         # Avoid to load it at the root of the module to avoid nested import loops
         cls._model_list = {}
         for key, args in model_list.model_list.items():
             assert key not in cls._model_list, "Duplicate model key, this should not happen"
             cls._model_list[key] = args
 
+    def add_hyperparameter(self, hyperparameter, distribution=None):
+        """
+        Add a hyperparameter to the experiment.
+
+        Args:
+            hyperparameter (string): path to hyperparameter in the protobuf hierarchy seperated by a '.' (e.g., 'trainer.batch_size')
+            distribution (dict, Message, JSON, binary): Hyperparameter distribution
+        """
+        def convert_to_protobuf(value):
+            """
+            Convert a dict / JSON / binary to protobuf Message
+            """
+            if isinstance(value, dict):
+                value = json_format.ParseDict(value, HyperParameter())
+            elif isinstance(value, Message):
+                pass
+            else:
+                value = parse_protobuf_from_json_or_binary(HyperParameter, value)
+            return value
+
+        if distribution is None:
+            distribution = self._get_default_distribution_(Experiment, hyperparameter)
+        else:
+            self._recursive_search_(Experiment, hyperparameter)
+
+        self._hyperparameters[hyperparameter] = convert_to_protobuf(distribution)
+
+    @staticmethod
+    def _get_default_distribution_(protobuf_class, hyperparameter):
+        """
+        Recursively find and fill default distribution for hyperparameter
+
+        Args:
+            protobuf_class (protobuf): parent protobuf class from which to start recursively the finding procedure
+            hyperparameter (string): path to hyperparameter in the protobuf hierarchy seperated by a '.' (e.g., 'trainer.batch_size')
+        """
+
+        # Get field and protobuf class for the given hyperparameter
+        protobuf_class, field_name = ExperimentBuilder._recursive_search_(protobuf_class, hyperparameter)
+
+        # If the field_name is None, it is an OneOf
+        if field_name is None:
+            oneofs = protobuf_class.DESCRIPTOR.oneofs
+            assert len(oneofs) == 1, f'Number of OneOfs should be 1, found {len(oneofs)}. This should not happen.'
+            oneof = oneofs[0]
+            if not oneof.has_options:
+                raise Exception('No distribution given for hyperparemeter {}'.format(oneof.name))
+            return oneof.GetOptions().Extensions[oneof_option]
+        else:
+            field = protobuf_class.DESCRIPTOR.fields_by_name[field_name]
+            if field.message_type is None or field.label == FieldDescriptor.LABEL_REPEATED:
+                if not field.has_options:
+                    raise Exception('No distribution given for hyperparemeter {}'.format(field_name))
+                return field.GetOptions().Extensions[field_option]
+
+    @staticmethod
+    def _recursive_search_(protobuf_class, path_name):
+        """
+        Check if path_name is correct by checking recursively fields of the input protobuf_class
+
+        Args:
+            protobuf_class (protobuf): parent protobuf class from which to start recursively the finding procedure
+            hyperparameter (string): path to hyperparameter in the protobuf hierarchy seperated by a '.' (e.g., 'trainer.batch_size')
+
+        Returns:
+            protobuf, field_name tuple. field_name is None for OneOf
+        """
+        fields = path_name.split('.')
+
+        # We walk down the parameter path recursively
+        for i, field_name in enumerate(fields):
+            # Check if the field exists
+            if field_name not in protobuf_class.DESCRIPTOR.fields_by_name:
+                raise ValueError(f"'{field_name}' field not found in protobuf message '{protobuf_class.DESCRIPTOR.name}'")
+
+            # If it is a nested message or Oneof field
+            field_message_type = protobuf_class.DESCRIPTOR.fields_by_name[field_name].message_type
+            if field_message_type is not None:
+                field_message_class = load_proto_class_from_protobuf_descriptor(field_message_type)
+                # It's a nested message, go deeper
+                if i + 1 < len(fields):
+                    return ExperimentBuilder._recursive_search_(field_message_class, '.'.join(fields[i + 1:]))
+                # It's a Oneof
+                return field_message_class, None
+            # It's a scalar or repeated field
+            else:
+                return protobuf_class, field_name
+
     def build(self, **kwargs):
-        all_args = set()
-        all_args.update(self._model_args.default_args.keys())
-        all_args.update(kwargs.keys())
+        all_args = set([*self._model_args.default_args] + [*kwargs])
         used_args = set()
-        kwargs = copy.deepcopy(kwargs)
-        xp = self._recursive_build_(Experiment, self._model_args.default_args, kwargs, used_args)
+        xp = self._recursive_build_(Experiment, self._model_args.default_args, copy.deepcopy(kwargs), used_args, self._hyperparameters)
         unused_args = all_args - used_args
         if len(unused_args) > 0:
             raise Exception('Unused keyword argument: {}'.format(', '.join(unused_args)))
+        unused_hyperparameters = [k for k, v in self._hyperparameters.items() if v is None]
+        if len(unused_hyperparameters) > 0:
+            raise Exception('hyperparameter not found: {}'.format(', '.join(unused_hyperparameters)))
+        for k, v in self._hyperparameters.items():
+            xp.hyperparameters[k].CopyFrom(v)
         return xp
 
     @staticmethod
-    def _recursive_build_(protobuf_class, default_args, kwargs, used_args):
-        real_args = {}
-
-        unsed_default_args = default_args.keys() - set([f.name for f in protobuf_class.DESCRIPTOR.fields])
-        if len(unsed_default_args) > 0:
-            raise Exception('Unexpected default keyword argument: {}'.format(', '.join(unsed_default_args)))
-
+    def _recursive_build_(protobuf_class, default_args, kwargs, used_args, hyperparameters):
         def convert_to_dict(value):
-            """Convert a serialier into a protobuf"""
-            if isinstance(value, Serializer):
-                value = value._msg
+            """Convert a protobuf message into a dict"""
             if isinstance(value, Message):
                 value = json_format.MessageToDict(value, including_default_value_fields=True, preserving_proto_field_name=True)
+            elif isinstance(value, dict):
+                pass  # nothing to do
             return value
 
-        # This dict will be used to check that a oneof is not set twice
-        oneof_set = {oneof.name: False for oneof in protobuf_class.DESCRIPTOR.oneofs}
+        def check_valid_hp_value(field):
+            """
+            Check if given kwarg is in the hyperparameter distribution
+            """
+            # check that the field value is in the defined hyperparameter distribution range
+            if field.name in hp_to_field_name:
+                value = kwargs[field.name]
+                # Check if it is a OneOf and take the only value
+                if field.message_type is not None:
+                    entries = kwargs[field.name].keys()
+                    assert len(entries) == 1, f'{entries} should be of lenght one for field {field.name}'
+                    value = list(entries)[0]
+                hp = hyperparameters[hp_to_field_name[field.name]]
+                distribution_type = hp.WhichOneof('distribution')
+                if distribution_type == 'categorical':
+                    values = [getattr(v, v.WhichOneof('value')) for v in hp.categorical.values]
+                    assert value in values, f'{value} not in the given hyperparameter categorical distribution ({values})'
+                else:
+                    distribution = getattr(hp, distribution_type)
+                    min = 1
+                    max = -1
+                    if distribution_type in ['uniform', 'log_uniform']:
+                        min = distribution.min
+                        max = distribution.max
+                    elif distribution_type == 'normal':
+                        min = distribution.mu - 5 * distribution.sigma
+                        max = distribution.mu + 5 * distribution.sigma
+                    assert min <= kwargs[field.name] <= max, f'{kwargs[field.name]} not in the given hyperparameter {distribution_type} distribution ({min}, {max})'
+
+        real_args = {}
+
+        unused_default_args = default_args.keys() - set([f.name for f in protobuf_class.DESCRIPTOR.fields])
+        if len(unused_default_args) > 0:
+            raise Exception('Unexpected default keyword argument: {}'.format(', '.join(unused_default_args)))
+
+        hp_to_field_name = {k.split('.')[-1]: k for k in hyperparameters.keys()}
+
+        # The oneof has fields which are also present in the protobuf fields.
+        # We can hence identify the oneof fields which should be skipped, by removing the selected oneof field.
+        # We identify the selected oneof field by its presence in the kwargs or default_args parameters, where kwargs has the higher priority
+        skipped_fields = []
+        for oneof in protobuf_class.DESCRIPTOR.oneofs:
+            fields = [field.name for field in oneof.fields]
+            # Identify selected one of fields
+            selected = set(fields) & set(kwargs.keys()) if len(set(fields) & set(kwargs.keys())) > 0 else set(fields) & set(default_args.keys())
+            # We cannot have more than 1 selected oneof field.
+            assert len(selected) <= 1, "Two or more values are given for the one-of '{}' (error when processing '{}'): {}".format(oneof.name, protobuf_class.DESCRIPTOR.name, selected)
+            # The skipped fields are the symmetric difference of the possible and selected oneof fields
+            skipped_fields += list(set(fields) ^ selected)
 
         for field in protobuf_class.DESCRIPTOR.fields:
+            # Skip fields which are unselected oneof fields
+            if field.name in skipped_fields:
+                continue
+
             # If the field is a scalar or a list ...
             if field.message_type is None or field.label == FieldDescriptor.LABEL_REPEATED:
                 # ... there is only one possible value and kwargs has higher priority
                 if field.name in kwargs:
+                    check_valid_hp_value(field)
                     real_args[field.name] = convert_to_dict(kwargs.pop(field.name))
                 elif field.name in default_args:
                     real_args[field.name] = default_args[field.name]
 
             else:
                 # If the field is required, we build it
-                if field.name in kwargs or field.name in default_args or field.label == FieldDescriptor.LABEL_REQUIRED:
-                    # --> then we build the message
-                    args = {}
-                    if field.name in kwargs:
-                        args = convert_to_dict(kwargs.pop(field.name))
-                    elif field.name in default_args:
-                        args = default_args[field.name]
-                    # This fields is a protobuf message, we build it recursively
-                    field_message_class = load_proto_class_from_protobuf_descriptor(field.message_type)
-                    real_args[field.name] = ExperimentBuilder._recursive_build_(field_message_class, args, kwargs, used_args)
-
-            if field.containing_oneof is not None and field.name in real_args:
-                # The field has a value and belongs to a oneof.
-                # We check if the one-of is already set
-                oneof_name = field.containing_oneof.name
-                assert not oneof_set[oneof_name], "Two values are given for the one-of '{}' (error when processing '{}')".format(oneof_name, field.name)
-                oneof_set[oneof_name] = True
+                # --> then we build the message
+                args = {}
+                used = False
+                if field.name in kwargs:
+                    check_valid_hp_value(field)
+                    args = convert_to_dict(kwargs.pop(field.name))
+                    used = True
+                elif field.name in default_args:
+                    args = default_args[field.name]
+                    used = True
+                # This fields is a protobuf message, we build it recursively
+                field_message_class = load_proto_class_from_protobuf_descriptor(field.message_type)
+                exp_builder = ExperimentBuilder._recursive_build_(field_message_class, args, kwargs, used_args, hyperparameters)
+                if used or field.label == FieldDescriptor.LABEL_REQUIRED:
+                    real_args[field.name] = exp_builder
 
-        for field_name in real_args:
-            used_args.add(field_name)
+        used_args.update([*real_args])
         return protobuf_class(**real_args)
```

## Comparing `deepomatic_oef-0.8.5-nspkg.pth` & `deepomatic_oef-0.9.0-nspkg.pth`

 * *Files identical despite different names*

## Comparing `deepomatic_oef-0.8.5.dist-info/LICENSE` & `deepomatic_oef-0.9.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `deepomatic_oef-0.8.5.dist-info/METADATA` & `deepomatic_oef-0.9.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: deepomatic-oef
-Version: 0.8.5
+Version: 0.9.0
 Summary: Open Experiment Format
 Home-page: https://github.com/Deepomatic/open-experiment-format
 Author: Deepomatic
 Author-email: support@deepomatic.com
 License: MIT License
 Project-URL: Product, https://deepomatic.com
 Project-URL: Source, https://github.com/deepomatic/open-experiment-format
@@ -61,20 +61,19 @@
 
 - Start by doing `git fetch --tags --quiet --force` as a workaround for a bug in `dmake release`.
 - Run `dmake release open-experiment-format` and select the tag you just released
 - Dmake display the URL of you release: you can edit the description to hide unnecessary commits
 
 ### Release the packages for this version on pypi
 
-Simply run `make publish`. You will need to be admin on PyPi for it to work. If on MacOS, you should be
+Open `dmake shell oef`, and simply run `make publish`. You will need to be admin on PyPi for it to work. If on MacOS, you should be
 inside the ubuntu docker container to make sure you build a linux package (maybe not necessary, this has not been verified).
 
 You  can check the release here: https://pypi.org/project/deepomatic-oef/#files
 
 ### Bump the version in `deepomatic/oef/__init__.py`
 
 You now bump the minor / patch version number to prepare for the next release:
 - if you a on the master branch, modify the minor version number
 - if you are on a maintenance branch, change the patch version.
 
 
-
```

## Comparing `deepomatic_oef-0.8.5.dist-info/RECORD` & `deepomatic_oef-0.9.0.dist-info/RECORD`

 * *Files 5% similar despite different names*

```diff
@@ -1,58 +1,59 @@
-deepomatic_oef-0.8.5-nspkg.pth,sha256=PuJzfitrgySP0jcchE43nzwVKwORNejIB4GKwGQweKU,559
-deepomatic/oef/__init__.py,sha256=5-jDqXYDIvcpUav6EPXX-a4DnkyqkluS4Xnss8VXoxA,18
-deepomatic/oef/dataset_dump.py,sha256=V7yXM7qxhHIlzO4M4bE_cFn9Rf11ZW_pdCjYBWrPwmE,5868
+deepomatic_oef-0.9.0-nspkg.pth,sha256=PuJzfitrgySP0jcchE43nzwVKwORNejIB4GKwGQweKU,559
+deepomatic/oef/__init__.py,sha256=a8euLpPHIUzkTzGsxlIUI74L7F0uq-89KOLthvpJY0Y,18
+deepomatic/oef/hyperparameter_dump.py,sha256=SXNB7oekkYKUKDzLABPNOLACyB16HJZRIFyMb0QjEDY,1309
 deepomatic/oef/api/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/api/backbone.py,sha256=5CWGQE_1iQ7nLSrSDcyEYYa4oaUdX-aiwLfwMZ1lENQ,2152
-deepomatic/oef/api/experiment.py,sha256=5yJ5kVfQ0G-qh9o-EMLhbY9uXONM-rqH7QRq-kbQOBI,1483
+deepomatic/oef/api/experiment.py,sha256=L58rcCupaaNp012CGuYqZ-nb2Y_rgWUctWRSz109jhY,1631
 deepomatic/oef/api/model.py,sha256=D1TI2eoqRXIwipun0o1lKH9BE-jzxloi2qwsd6ISlI0,4624
 deepomatic/oef/configs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/configs/config_utils.py,sha256=iHk--5THNbwr6aqUBpy0SKAjqt6_5oja7AgfatLOFY0,6431
 deepomatic/oef/configs/model_args.py,sha256=aG-Rozqr4OGdNWkr1fspqpDO1LchAIqqn6j-Ok8_pWE,1115
-deepomatic/oef/configs/model_list.py,sha256=rc8O8oVNR_q53Dvgc_7pAl-MkN8vmyLjT8K8zA4Z1tQ,690816
+deepomatic/oef/configs/model_list.py,sha256=EPNCzikWZkWaqy1NuyaKXv-CtkCUENYoxHeX4nptLzU,693811
 deepomatic/oef/configs/model_list_generator.py,sha256=iO1lV5EoXczLvqKWXZtls1pOIBQ4LjUZ4gaG1WLZ3wQ,6578
 deepomatic/oef/configs/utils.py,sha256=aOQGTWgy902YKbWwg_iBUZHscvJbheic8Z3TW79iTuY,3532
 deepomatic/oef/configs/image/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/configs/image/backbones.py,sha256=B3e9YU-YOEKnDAC9peAC6lUNlp5_fXbk89Y1TLEDK04,7936
 deepomatic/oef/configs/image/utils.py,sha256=ozodS6_ewkXL6PokwBH2oan_aNYyaLC1q65M0Q_XZKA,455
 deepomatic/oef/configs/image/classification/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/configs/image/classification/configs.py,sha256=6ZS7mPWrjeC3oA_nyCOEG5vO-vcIKOSuFBJllWZxeak,8586
 deepomatic/oef/configs/image/detection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/configs/image/detection/efficientdet.py,sha256=Xmff3wXFwSRJMt_Qj7ifRTamB8omJy-MDRcZQxdub_0,5950
 deepomatic/oef/configs/image/detection/rcnn.py,sha256=3c7dshRfqvZT6Du16EP__4u-DFUplv-BRbdFdKCnj-M,7352
 deepomatic/oef/configs/image/detection/ssd.py,sha256=INis1t0U1Mc4pJK19iusMeUklOoj4qtOFaKM9usNiGc,10261
-deepomatic/oef/configs/image/detection/yolo.py,sha256=EkUsoCmeq8nU2ofiTto6PAyTFGdAPZBU7cmgeVflTDA,1489
+deepomatic/oef/configs/image/detection/yolo.py,sha256=gxU1rA6yFVbwWmUCAA6b2fb7jecqGKuzjoDgU3mjJjE,2171
 deepomatic/oef/configs/image/ocr/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-deepomatic/oef/configs/image/ocr/attention.py,sha256=ziFT9oRoWyayugJZNrx74WblBDAxHIHv8cJDNdZ2Wz8,742
+deepomatic/oef/configs/image/ocr/attention.py,sha256=L0P1MO2iPHaNq3Ehn0P81sJ-NvjLb8Rh3yLfRMdkKNY,1110
 deepomatic/oef/platform/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/platform/api.py,sha256=tTa2hzgMBHHHcyCDkG8Op2mm_G-6oKEUex2JwD3wEhU,1050
-deepomatic/oef/platform/config.py,sha256=7xGy4KI2R-fo-D94ELWG9rhZkxH3pNXzMcWwPCiwPxA,5426
-deepomatic/oef/platform/experiment_to_display_name.py,sha256=34kj7xGTgPZcGueyNpZXUuPrprd6QDULwwx4upQH2go,6137
+deepomatic/oef/platform/config.py,sha256=--8E_CWbIvXdRlKT_wPkY-hsFvnsTc8FHD_lRqOcXFM,5458
+deepomatic/oef/platform/experiment_to_display_name.py,sha256=1PYYydDMc6EVWsCSIDuiyU4hcmeYwil9aVHltv40agE,6190
 deepomatic/oef/platform/helpers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-deepomatic/oef/platform/helpers/backends.json,sha256=pc9ol3R2TqPUDsvnjtVbdmzfNssQOpzMC-UJHSaLnzU,30040
+deepomatic/oef/platform/helpers/backends.json,sha256=x-MSzWW9l3muqebakswZzpcDSZ2tQ9mwvIWj-QHKKak,30350
 deepomatic/oef/platform/helpers/common.py,sha256=uCvb8V7mofhbIyvf90qmHdrZkXp5d7j8Q3mJAT-71QM,2742
 deepomatic/oef/platform/helpers/controls.py,sha256=iUeftzmpDU_wPFJYMGxmSHwSywe-gs4Z-z5DWerRuko,22480
 deepomatic/oef/platform/helpers/form.py,sha256=gTjtAYPcuQV9nR_1gE242eePgRhRA6NJfbk0cDH6csE,6788
 deepomatic/oef/platform/helpers/section.py,sha256=1GXR50FrEXWVxfs5QET7iG3mV9NGbomEe9A76akIgI4,4034
 deepomatic/oef/platform/helpers/tags.py,sha256=OMCNDuIqSU31QoDOEvhxpHrccWDouPxbou33zBqr2fQ,1023
 deepomatic/oef/protos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/protos/dataoperation_pb2.py,sha256=PzBcF-fiBhTZc1eHor8zdh2EXyX5n6j77vtFDHHjFJI,4904
 deepomatic/oef/protos/dataset_dump_pb2.py,sha256=0cSdzZWODq3_dIhhGRlTCmRqSwF76_YWEaaCggOcShE,41041
 deepomatic/oef/protos/dataset_pb2.py,sha256=pyJf3GVMWLpHgcrsRM17QrlvggaG6PclpS7sqOR4U9U,3211
-deepomatic/oef/protos/experiment_pb2.py,sha256=xWvZkoS81T4Iva5sgILLgt_TqWftu-xPDy7KB3r5QaM,3968
+deepomatic/oef/protos/experiment_pb2.py,sha256=yPzpU-kCfmR0CzZ7W4r7AImJnv1jNHmT1--XMqBMJcg,7390
+deepomatic/oef/protos/hyperparameter_pb2.py,sha256=2w1RbjRXttEquZP87vdq00Gb1ynB7gfMtQUr1_7JQy4,16464
 deepomatic/oef/protos/losses_pb2.py,sha256=ld6l8Tc0JReZAS7nVmhoR8b-5bzh7CCx5gEw0J_SZTg,37858
-deepomatic/oef/protos/optimizer_pb2.py,sha256=dr1Gficv0RDpW0xVllkVwfUFT4gXL1QrVCgyqMXl3hg,25067
+deepomatic/oef/protos/optimizer_pb2.py,sha256=Nqr_qFCSs-CVAPb031GqBt39ks4sH6xXYTwD9nT9e8o,28605
 deepomatic/oef/protos/preprocessor_pb2.py,sha256=RoDRkfYM5giWyqWxgtQYjcadAgmJc7TTxTsbgfovsSQ,105075
-deepomatic/oef/protos/trainer_pb2.py,sha256=Ax2FEWiMWSQ9wWZJjn28AmGoAPNgVRhqBQ-dvJlD9Eg,14928
+deepomatic/oef/protos/trainer_pb2.py,sha256=KbOYmkCfZf3gqGcDEFlv-0TrTKpVujphHY-dP45q9rc,15991
 deepomatic/oef/protos/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/protos/models/image/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/protos/models/image/backbones_pb2.py,sha256=BNYq7X4VNHgABNtBGVSvaVmhNPnxNq_t8eEbM_a5r9U,32791
 deepomatic/oef/protos/models/image/classification_pb2.py,sha256=HULJjr9rBFg5CiagiG9UZGVsKsC8ibLUaufqGmdrPp8,4400
-deepomatic/oef/protos/models/image/detection_pb2.py,sha256=nBy6UMg6xS23ujOvaHrZcpX8Y-Uf5ewkfAkaOkfMKEU,75029
-deepomatic/oef/protos/models/image/ocr_pb2.py,sha256=1zDOzmricHooWYUixH8VqiFzwkSDRt0xQefZRSr_n5Y,6377
+deepomatic/oef/protos/models/image/detection_pb2.py,sha256=RqJQ1Du2QiEvW7ehi1DngO0tz8WAWiTkOvJcy0gmIMw,75815
+deepomatic/oef/protos/models/image/ocr_pb2.py,sha256=1VA1YFjtfBeN_c5WHZqarDE5ppCxQYWp7rI2u4QCk6s,7282
 deepomatic/oef/protos/models/image/preprocessing_pb2.py,sha256=WahWpnRoUNLCLpAPR6RQVcBCu6glIvrEYcZ3dsYUWzw,121125
 deepomatic/oef/protos/models/image/detection/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/protos/models/image/detection/anchor_generator_pb2.py,sha256=8r64QilUHLUpe0n7XFer_yG5itp0X2SROcoXtcMFeow,7702
 deepomatic/oef/protos/models/image/detection/argmax_matcher_pb2.py,sha256=61i4rRL9Rbh2FGmlL6MVzGihd9LjHwfYTvCvaCTD5TM,4581
 deepomatic/oef/protos/models/image/detection/bipartite_matcher_pb2.py,sha256=ZE93CjJHb1_ZzRbURLH0RxL4ra1itKfiUMsFTxXWF-I,2327
 deepomatic/oef/protos/models/image/detection/box_coder_pb2.py,sha256=viTiZKTCZ2TFCPPePeNx82powTuOmVOKPFwQluiXmPs,7093
 deepomatic/oef/protos/models/image/detection/box_predictor_pb2.py,sha256=5gxO0BH7bXL2iXONqwp5V7AaOLVdZtxfQjmCenigWpI,37528
@@ -68,17 +69,16 @@
 deepomatic/oef/protos/models/image/detection/post_processing_pb2.py,sha256=fyDIFksPGUYdo0fjwuljw1aU50b8B62_ldv8yWSkkOo,8733
 deepomatic/oef/protos/models/image/detection/region_similarity_calculator_pb2.py,sha256=AqUxNvCU3uCdEZg9bjko3eUoJObfQrDyW55JYSy8RwI,10063
 deepomatic/oef/protos/models/image/detection/square_box_coder_pb2.py,sha256=iehNxRe7taAublRSN9pwWZTFciINVrevtt-vqEr7Rj0,3124
 deepomatic/oef/protos/models/image/detection/ssd_anchor_generator_pb2.py,sha256=Zj0BZgGmMkonccJXr-OQ2FU4igpWs8PZDMc5GtFr9Kk,7598
 deepomatic/oef/protos/models/image/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 deepomatic/oef/protos/models/image/utils/hyperparameters_pb2.py,sha256=yKpr9SykIIeKfw0DW7z3uTJtUrBaH2VDXyPUvDz-uvA,28139
 deepomatic/oef/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-deepomatic/oef/utils/class_helpers.py,sha256=REaywA15Rpwh4zUqU0Yr0zhxD22BSnLvSUVTo3Hpw6A,4270
+deepomatic/oef/utils/class_helpers.py,sha256=gLgUZouOqnHMizSWYcnfpiety46kuIfxBe3HYHX84lg,2306
 deepomatic/oef/utils/common.py,sha256=JFtvnutFkOOIIkpzwvgJaVE8Hn4gvI10grDX_EztX0I,1059
-deepomatic/oef/utils/experiment_builder.py,sha256=dQ_hao4b6QinYLNrrzJP4lGlhYyjbnt-5vutqiwHT8Y,6368
-deepomatic/oef/utils/serializer.py,sha256=PWsDxMpXvQ9D99OI86lOdAzhLh8JQFhLjE1slo12wbY,17951
-deepomatic_oef-0.8.5.dist-info/LICENSE,sha256=rrf3XhWLAb-mD32WUadsialsoWbr-Ss1OVnYuMpHD7k,1105
-deepomatic_oef-0.8.5.dist-info/METADATA,sha256=tSCU_oiyCgDNHlVJfGr_XdYaGuMwTr8st5XNbHrTY1c,2984
-deepomatic_oef-0.8.5.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-deepomatic_oef-0.8.5.dist-info/namespace_packages.txt,sha256=HmzEofpPBjBAHEqPEMMkRoD_Qkkk2HPPZfMoBImGpv8,11
-deepomatic_oef-0.8.5.dist-info/top_level.txt,sha256=HmzEofpPBjBAHEqPEMMkRoD_Qkkk2HPPZfMoBImGpv8,11
-deepomatic_oef-0.8.5.dist-info/RECORD,,
+deepomatic/oef/utils/experiment_builder.py,sha256=7wYVRF14hQoWh6ehebbNp49GAVnkgRjO29I0oZn9Cys,12717
+deepomatic_oef-0.9.0.dist-info/LICENSE,sha256=rrf3XhWLAb-mD32WUadsialsoWbr-Ss1OVnYuMpHD7k,1105
+deepomatic_oef-0.9.0.dist-info/METADATA,sha256=0Rxhf0ekgC1ei0wYJtWA3y9bsY4AcLziqJiB4HEDbYA,3011
+deepomatic_oef-0.9.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+deepomatic_oef-0.9.0.dist-info/namespace_packages.txt,sha256=HmzEofpPBjBAHEqPEMMkRoD_Qkkk2HPPZfMoBImGpv8,11
+deepomatic_oef-0.9.0.dist-info/top_level.txt,sha256=HmzEofpPBjBAHEqPEMMkRoD_Qkkk2HPPZfMoBImGpv8,11
+deepomatic_oef-0.9.0.dist-info/RECORD,,
```

